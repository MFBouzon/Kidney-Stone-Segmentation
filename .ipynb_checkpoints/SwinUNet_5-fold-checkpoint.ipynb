{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf0339d0-739a-4991-a2c0-4392d2ec6f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 18:00:02.622618: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-17 18:00:02.622662: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-17 18:00:02.623263: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-17 18:00:02.627108: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-17 18:00:03.116550: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.backend import set_session\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    " \n",
    "from tqdm import tqdm \n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b6f5337-7770-4f92-a2a4-251e31af3cbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 1\n",
    "k = 5\n",
    "\n",
    "\n",
    "IMG_WIDTH = 512\n",
    "IMG_HEIGHT = 512\n",
    "IMG_CHANNELS = 1\n",
    "\n",
    "DATA_PATH = 'data/'\n",
    "\n",
    "data_ids = next(os.walk(DATA_PATH+'/image'))[2]\n",
    "\n",
    "X = np.zeros((len(data_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "y = np.zeros((len(data_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.float32)\n",
    "\n",
    "# Definição do diretório de saída\n",
    "output_dir = \"Swin UNet DICE 5-fold model\"\n",
    "os.makedirs(output_dir, exist_ok=True)  # Garante que a pasta existe\n",
    "\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "os.environ['TF_GPU_ALLOCATOR']= 'cuda_malloc_async'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6eeed634-f3f7-4cce-8c45-77e4b7c270ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.15.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Resizing training images and masks')\n",
    "for n, id_ in tqdm(enumerate(data_ids), total=len(data_ids)):   \n",
    "    path = DATA_PATH\n",
    "    img = imread(path + '/image/' + id_)[:,:]\n",
    "    img = img.reshape(img.shape[0], img.shape[1], IMG_CHANNELS)\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X[n] = img  #Fill empty X_train with values from img\n",
    "    \n",
    "    mask = imread(path + 'label/' + id_)\n",
    "    mask = (mask >= 250)\n",
    "    mask = np.expand_dims(resize(mask, (IMG_HEIGHT, IMG_WIDTH), mode='constant',  \n",
    "                                      preserve_range=True), axis=-1)\n",
    "    y[n] = mask \n",
    "    #plt.axis(\"off\")\n",
    "    #imshow(y[n])\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2f02a06-5551-4109-97af-8d76f83beb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\n",
      "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
      "Cuda compilation tools, release 12.2, V12.2.140\n",
      "Build cuda_12.2.r12.2/compiler.33191640_0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "def f1_score(y_true, y_pred):\n",
    "    \"\"\"Calcula o F1-Score para segmentação binária\"\"\"\n",
    "    y_pred = K.round(y_pred)  # Arredondar para 0 ou 1\n",
    "    tp = K.sum(K.cast(y_true * y_pred, 'float32'))  # Verdadeiros Positivos\n",
    "    fp = K.sum(K.cast((1 - y_true) * y_pred, 'float32'))  # Falsos Positivos\n",
    "    fn = K.sum(K.cast(y_true * (1 - y_pred), 'float32'))  # Falsos Negativos\n",
    "    \n",
    "    precision = tp / (tp + fp + K.epsilon())  # Precision\n",
    "    recall = tp / (tp + fn + K.epsilon())  # Recall\n",
    "    \n",
    "    f1 = 2 * (precision * recall) / (precision + recall + K.epsilon())  # F1-Score\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e76775c-5fc9-419a-a36a-0bd07fe023ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs disponíveis: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 18:00:06.999591: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-17 18:00:07.024524: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-17 18:00:07.024563: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1e-6\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return 1 - ((2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34b9dd1e-626b-4787-b556-426246e4e48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 1\n",
    "k = 5\n",
    "\n",
    "\n",
    "IMG_WIDTH = 512\n",
    "IMG_HEIGHT = 512\n",
    "IMG_CHANNELS = 1\n",
    "\n",
    "DATA_PATH = 'data/'\n",
    "\n",
    "data_ids = next(os.walk(DATA_PATH+'/image'))[2]\n",
    "\n",
    "X = np.zeros((len(data_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "y = np.zeros((len(data_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=bool)\n",
    "\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "os.environ['TF_GPU_ALLOCATOR']= 'cuda_malloc_async'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "386e7353-1711-436b-93c8-9939c699dd59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing training images and masks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 838/838 [00:19<00:00, 43.78it/s]\n"
     ]
    }
   ],
   "source": [
    "print('Resizing training images and masks')\n",
    "for n, id_ in tqdm(enumerate(data_ids), total=len(data_ids)):   \n",
    "    path = DATA_PATH\n",
    "    img = imread(path + '/image/' + id_)[:,:]\n",
    "    img = img.reshape(img.shape[0], img.shape[1], IMG_CHANNELS)\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X[n] = img  #Fill empty X_train with values from img\n",
    "    \n",
    "    mask = imread(path + 'label/' + id_)\n",
    "    mask = (mask >= 250)\n",
    "    mask = np.expand_dims(resize(mask, (IMG_HEIGHT, IMG_WIDTH), mode='constant',  \n",
    "                                      preserve_range=True), axis=-1)\n",
    "    y[n] = mask \n",
    "    #plt.axis(\"off\")\n",
    "    #imshow(y[n])\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7f297ed-a66e-4727-b154-b60aa8f7fa5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 18:00:32.558278: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-17 18:00:32.558399: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-17 18:00:32.558455: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-17 18:00:32.681691: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-17 18:00:32.681737: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-17 18:00:32.681743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-03-17 18:00:32.681754: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2025-03-17 18:00:32.681758: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:236] Using CUDA malloc Async allocator for GPU: 0\n",
      "2025-03-17 18:00:32.681889: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-17 18:00:32.681908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9558 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Dropout, BatchNormalization, ReLU, MaxPooling2D, Conv2DTranspose, concatenate, Dense, LayerNormalization, Add\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Swin Transformer Block\n",
    "class SwinTransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, dim, num_heads=8, window_size=7):\n",
    "        super(SwinTransformerBlock, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.window_size = window_size\n",
    "        self.attn = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=dim)\n",
    "        self.norm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.norm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.mlp = tf.keras.Sequential([\n",
    "            Dense(4 * dim, activation='relu'),\n",
    "            Dense(dim)\n",
    "        ])\n",
    "    \n",
    "    def call(self, x):\n",
    "        attn_output = self.attn(x, x)\n",
    "        x = self.norm1(x + attn_output)\n",
    "        mlp_output = self.mlp(x)\n",
    "        return self.norm2(x + mlp_output)\n",
    "\n",
    "def swin_unet():\n",
    "    inputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "    \n",
    "    def conv_block(x, filters, dropout=0.1):\n",
    "        x = Conv2D(filters, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = Conv2D(filters, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        return ReLU()(x)\n",
    "    \n",
    "    # Encoder path\n",
    "    c1 = conv_block(inputs, 16)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    \n",
    "    c2 = conv_block(p1, 32)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "    \n",
    "    c3 = conv_block(p2, 64, dropout=0.2)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "    \n",
    "    c4 = conv_block(p3, 128, dropout=0.2)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "    \n",
    "    c5 = conv_block(p4, 256, dropout=0.3)\n",
    "    \n",
    "    # Swin Transformer Encoder\n",
    "    swin_input = tf.keras.layers.Reshape((IMG_HEIGHT // 16, IMG_WIDTH // 16, 256))(c5)\n",
    "    swin_output = SwinTransformerBlock(dim=256)(swin_input)\n",
    "    swin_output = SwinTransformerBlock(dim=256)(swin_output)\n",
    "    swin_output = tf.keras.layers.Reshape((IMG_HEIGHT // 16, IMG_WIDTH // 16, 256))(swin_output)\n",
    "    \n",
    "    # Decoder path (Skip Connections from CNN Encoder)\n",
    "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(swin_output)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = conv_block(u6, 128)\n",
    "    \n",
    "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = conv_block(u7, 64)\n",
    "    \n",
    "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = conv_block(u8, 32)\n",
    "    \n",
    "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = concatenate([u9, c1])\n",
    "    c9 = conv_block(u9, 16)\n",
    "    \n",
    "    outputs = Conv2D(num_classes, (1, 1), activation='sigmoid')(c9)\n",
    "    \n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    model.compile(optimizer='adam', loss=dice_loss, metrics=[\n",
    "        'accuracy', \n",
    "        tf.keras.metrics.Recall(name='recall'), \n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        f1_score,\n",
    "        tf.keras.metrics.IoU(num_classes=2, target_class_ids={0,1}, name='IoU')\n",
    "    ])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bb3dc3-8cc2-41d0-bf67-a27f9775446a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 18:00:33.168912: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 175636480 exceeds 10% of free system memory.\n",
      "2025-03-17 18:00:33.250866: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 175636480 exceeds 10% of free system memory.\n",
      "2025-03-17 18:00:33.324630: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 175636480 exceeds 10% of free system memory.\n",
      "2025-03-17 18:00:33.356587: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 175636480 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 18:00:35.214149: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2025-03-17 18:00:48.312670: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:306] gpu_async_0 cuMemAllocAsync failed to allocate 2164408336 bytes: CUDA error: out of memory (CUDA_ERROR_OUT_OF_MEMORY)\n",
      " Reported by CUDA: Free memory/Total memory: 1608515584/12878086144\n",
      "2025-03-17 18:00:48.312721: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:311] Stats: Limit:                     10022289408\n",
      "InUse:                      9356702765\n",
      "MaxInUse:                  10715878461\n",
      "NumAllocs:                        1287\n",
      "MaxAllocSize:               2737635328\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2025-03-17 18:00:48.312739: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:63] Histogram of current allocation: (allocation_size_in_bytes, nb_allocation_of_that_sizes), ...;\n",
      "2025-03-17 18:00:48.312742: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1, 1\n",
      "2025-03-17 18:00:48.312744: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 4, 62\n",
      "2025-03-17 18:00:48.312746: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 8, 6\n",
      "2025-03-17 18:00:48.312747: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 64, 8\n",
      "2025-03-17 18:00:48.312748: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 128, 8\n",
      "2025-03-17 18:00:48.312750: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 256, 24\n",
      "2025-03-17 18:00:48.312751: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 512, 20\n",
      "2025-03-17 18:00:48.312753: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 576, 4\n",
      "2025-03-17 18:00:48.312754: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1024, 20\n",
      "2025-03-17 18:00:48.312755: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1028, 1\n",
      "2025-03-17 18:00:48.312757: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 2048, 12\n",
      "2025-03-17 18:00:48.312758: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 9216, 4\n",
      "2025-03-17 18:00:48.312760: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 18432, 4\n",
      "2025-03-17 18:00:48.312761: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 36864, 4\n",
      "2025-03-17 18:00:48.312762: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 73728, 4\n",
      "2025-03-17 18:00:48.312764: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 131072, 4\n",
      "2025-03-17 18:00:48.312765: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 147456, 9\n",
      "2025-03-17 18:00:48.312766: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 184320, 4\n",
      "2025-03-17 18:00:48.312768: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 294912, 4\n",
      "2025-03-17 18:00:48.312769: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 524288, 4\n",
      "2025-03-17 18:00:48.312770: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 589824, 8\n",
      "2025-03-17 18:00:48.312772: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 737280, 4\n",
      "2025-03-17 18:00:48.312773: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1179648, 4\n",
      "2025-03-17 18:00:48.312774: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 2097152, 8\n",
      "2025-03-17 18:00:48.312776: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 2359296, 8\n",
      "2025-03-17 18:00:48.312777: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 2949120, 4\n",
      "2025-03-17 18:00:48.312778: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 4194304, 1\n",
      "2025-03-17 18:00:48.312780: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 8388608, 1\n",
      "2025-03-17 18:00:48.312781: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 9437184, 4\n",
      "2025-03-17 18:00:48.312782: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 11796480, 4\n",
      "2025-03-17 18:00:48.312784: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 16777216, 6\n",
      "2025-03-17 18:00:48.312785: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 33554432, 3\n",
      "2025-03-17 18:00:48.312787: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 67108864, 3\n",
      "2025-03-17 18:00:48.312788: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 134217728, 4\n",
      "2025-03-17 18:00:48.312789: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 167772160, 1\n",
      "2025-03-17 18:00:48.312791: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 175636480, 2\n",
      "2025-03-17 18:00:48.312792: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 268435456, 4\n",
      "2025-03-17 18:00:48.312793: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 335544320, 1\n",
      "2025-03-17 18:00:48.312795: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 536870912, 2\n",
      "2025-03-17 18:00:48.312796: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 671088640, 1\n",
      "2025-03-17 18:00:48.312797: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1073741824, 2\n",
      "2025-03-17 18:00:48.312799: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1090519040, 1\n",
      "2025-03-17 18:00:48.312800: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1342177280, 1\n",
      "2025-03-17 18:00:48.312803: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:97] CU_MEMPOOL_ATTR_RESERVED_MEM_CURRENT: 9999220736\n",
      "2025-03-17 18:00:48.312805: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:99] CU_MEMPOOL_ATTR_USED_MEM_CURRENT: 9356702765\n",
      "2025-03-17 18:00:48.312807: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:100] CU_MEMPOOL_ATTR_RESERVED_MEM_HIGH: 12113149952\n",
      "2025-03-17 18:00:48.312808: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:101] CU_MEMPOOL_ATTR_USED_MEM_HIGH: 10715878461\n",
      "2025-03-17 18:01:00.706999: I external/local_xla/xla/service/service.cc:168] XLA service 0x7ff101d24540 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-03-17 18:01:00.707037: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4070, Compute Capability 8.9\n",
      "2025-03-17 18:01:00.710884: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1742245260.772637   26617 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/42 [============================>.] - ETA: 0s - loss: 0.0837 - accuracy: 0.9778 - recall: 0.0400"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "jacc = []\n",
    "f1 = []\n",
    "prec = []\n",
    "rec = []\n",
    "\n",
    "# Dicionário para armazenar métricas por fold\n",
    "fold_metrics_summary = []\n",
    "\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=28)\n",
    "fold = 1\n",
    "\n",
    "for i, (train_ind, test_ind) in enumerate(kf.split(X)):\n",
    "    if i < (fold-1):\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    print(\"Fold: \" + str(fold))\n",
    "    X_train, X_val, y_train, y_val = X[train_ind], X[test_ind], y[train_ind], y[test_ind]\n",
    "\n",
    "    model = swin_unet()\n",
    "    \n",
    "    \n",
    "    checkpoint_filepath = os.path.join(output_dir, f'model_{fold}fold.keras')\n",
    "    callbacks = [\n",
    "            tf.keras.callbacks.TensorBoard(log_dir='logs'),\n",
    "            tf.keras.callbacks.ModelCheckpoint(\n",
    "                filepath=checkpoint_filepath,\n",
    "                save_weights_only=False,\n",
    "                monitor='val_f1_score',\n",
    "                mode='max',\n",
    "                save_best_only=True,\n",
    "                verbose=1)]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train, validation_data=(X_val,y_val), batch_size=16, epochs=150, callbacks=callbacks)\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "\n",
    "     # Salvando o tempo de treinamento\n",
    "    with open(os.path.join(output_dir, 'training_time.txt'), 'a') as f:\n",
    "        f.write(f'Fold {fold}: {training_time:.2f} segundos\\n')\n",
    "    print(f\"O modelo demorou {training_time:.2f} segundos para treinar.\")\n",
    "    \n",
    "    loss = model.history.history['loss']\n",
    "    val_loss = model.history.history['val_loss']\n",
    "    \n",
    "    with open(os.path.join(output_dir, f'loss_fold{fold}.csv'), 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=';')\n",
    "        writer.writerow([\"Epoch\", \"Loss\", \"Validation Loss\"])\n",
    "        for epoch, (l, vl) in enumerate(zip(loss, val_loss), start=1):\n",
    "            writer.writerow([epoch, l, vl])\n",
    "            \n",
    "     # Plotando e salvando a figura\n",
    "    plt.figure()\n",
    "    plt.plot(loss, 'r', label='Training loss')\n",
    "    plt.plot(val_loss, 'g', label='Validation loss')\n",
    "    plt.title(f'Training and Validation Loss - Fold {fold}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss Value')\n",
    "    plt.ylim([0, 1])\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(output_dir, f'loss_plot_fold{fold}.png'))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    fold_metrics = []\n",
    "\n",
    "    acc_fold = []\n",
    "    jacc_fold = []\n",
    "    f1_fold = []\n",
    "    prec_fold = []\n",
    "    rec_fold = []\n",
    "    \n",
    "    for i in range(0, len(X_val)):\n",
    "        sample_image = X_val[i]\n",
    "        sample_mask = y_val[i].astype(np.uint8).flatten()\n",
    "        prediction = model.predict(sample_image[tf.newaxis, ...],verbose=0)[0]\n",
    "        predicted_mask = (prediction > 0.5).astype(np.uint8).flatten()\n",
    "            \n",
    "        acc_score = accuracy_score(sample_mask, predicted_mask)\n",
    "        jacc_score = jaccard_score(sample_mask, predicted_mask)\n",
    "        f1_score_val = f1_score(sample_mask, predicted_mask).numpy()\n",
    "        prec_score = precision_score(sample_mask, predicted_mask)\n",
    "        rec_score = recall_score(sample_mask, predicted_mask)\n",
    "\n",
    "        acc_fold.append(acc_score)\n",
    "        jacc_fold.append(jacc_score)\n",
    "        f1_fold.append(f1_score_val)\n",
    "        prec_fold.append(prec_score)\n",
    "        rec_fold.append(rec_score)\n",
    "\n",
    "        fold_metrics.append([i, acc_score, jacc_score, f1_score_val, prec_score, rec_score])\n",
    "        \n",
    "    # Salvando métricas por imagem\n",
    "    with open(os.path.join(output_dir, f'metrics_fold{fold}.csv'), 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=';')\n",
    "        writer.writerow([\"Index\", \"Accuracy\", \"Jaccard\", \"DICE\", \"Precision\", \"Recall\"])\n",
    "        writer.writerows(fold_metrics)\n",
    "\n",
    "    # Salvando a média do fold para cada métrica\n",
    "    fold_metrics_summary.append([\n",
    "        fold, np.mean(acc_fold), np.std(acc_fold),\n",
    "        np.mean(jacc_fold), np.std(jacc_fold),\n",
    "        np.mean(f1_fold), np.std(f1_fold),\n",
    "        np.mean(prec_fold), np.std(prec_fold),\n",
    "        np.mean(rec_fold), np.std(rec_fold)\n",
    "    ])\n",
    "\n",
    "        \n",
    "    del model \n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    fold+=1\n",
    "    \n",
    "# Calculando médias gerais\n",
    "acc_total = [m[1] for m in fold_metrics_summary]\n",
    "jacc_total = [m[3] for m in fold_metrics_summary]\n",
    "f1_total = [m[5] for m in fold_metrics_summary]\n",
    "prec_total = [m[7] for m in fold_metrics_summary]\n",
    "rec_total = [m[9] for m in fold_metrics_summary]\n",
    "\n",
    "general_summary = [\n",
    "    [\"Fold\", \"Accuracy Mean\", \"Accuracy Std\", \"Jaccard Mean\", \"Jaccard Std\",\n",
    "     \"DICE Mean\", \"DICE Std\", \"Precision Mean\", \"Precision Std\", \"Recall Mean\", \"Recall Std\"]\n",
    "]\n",
    "\n",
    "general_summary.extend(fold_metrics_summary)\n",
    "\n",
    "general_summary.append([\n",
    "    \"Overall Mean\", np.mean(acc_total), np.std(acc_total),\n",
    "    np.mean(jacc_total), np.std(jacc_total),\n",
    "    np.mean(f1_total), np.std(f1_total),\n",
    "    np.mean(prec_total), np.std(prec_total),\n",
    "    np.mean(rec_total), np.std(rec_total)\n",
    "])\n",
    "\n",
    "# Salvando o resumo das métricas por fold e geral\n",
    "with open(os.path.join(output_dir, 'metrics_summary.csv'), 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=';')\n",
    "    writer.writerows(general_summary)\n",
    "\n",
    "print(\"Métricas salvas com sucesso na pasta:\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5d184f-5b31-4156-849f-d24ddac7c3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_mean_fold = []\n",
    "jacc_mean_fold = []\n",
    "f1_mean_fold = []\n",
    "prec_mean_fold = []\n",
    "rec_mean_fold = []\n",
    "\n",
    "acc_std_fold = []\n",
    "jacc_std_fold = []\n",
    "f1_std_fold = []\n",
    "prec_std_fold = []\n",
    "rec_std_fold = []\n",
    "\n",
    "\n",
    "# Dicionário para armazenar métricas por fold\n",
    "fold_metrics_summary = []\n",
    "\n",
    "fold = 1\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=28)\n",
    "for train_ind, test_ind in tqdm(kf.split(X), total=kf.get_n_splits(), desc=\"k-fold\"):\n",
    "    X_train, X_val, y_train, y_val = X[train_ind], X[test_ind], y[train_ind], y[test_ind]\n",
    "\n",
    "    fold_metrics = []\n",
    "\n",
    "    acc_fold = []\n",
    "    jacc_fold = []\n",
    "    f1_fold = []\n",
    "    prec_fold = []\n",
    "    rec_fold = []\n",
    "    \n",
    "    model_filepath = filepath = os.path.join(output_dir, f'model_{fold}fold.keras')\n",
    "    model = tf.keras.models.load_model(model_filepath)\n",
    "\n",
    "    for i in range(0, len(X_val)):\n",
    "        sample_image = X_val[i]\n",
    "        sample_mask = y_val[i].astype(np.uint8).flatten()\n",
    "        prediction = model.predict(sample_image[tf.newaxis, ...],verbose=0)[0]\n",
    "        predicted_mask = (prediction > 0.5).astype(np.uint8).flatten()\n",
    "            \n",
    "        acc_score = accuracy_score(sample_mask, predicted_mask)\n",
    "        jacc_score = jaccard_score(sample_mask, predicted_mask)\n",
    "        f1_score_val = f1_score(sample_mask, predicted_mask).numpy()\n",
    "        prec_score = precision_score(sample_mask, predicted_mask)\n",
    "        rec_score = recall_score(sample_mask, predicted_mask)\n",
    "\n",
    "        acc_fold.append(acc_score)\n",
    "        jacc_fold.append(jacc_score)\n",
    "        f1_fold.append(f1_score_val)\n",
    "        prec_fold.append(prec_score)\n",
    "        rec_fold.append(rec_score)\n",
    "\n",
    "        fold_metrics.append([i, acc_score, jacc_score, f1_score_val, prec_score, rec_score])\n",
    "        \n",
    "    # Salvando métricas por imagem\n",
    "    with open(os.path.join(output_dir, f'metrics_fold{fold}.csv'), 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=';')\n",
    "        writer.writerow([\"Index\", \"Accuracy\", \"Jaccard\", \"DICE\", \"Precision\", \"Recall\"])\n",
    "        writer.writerows(fold_metrics)\n",
    "\n",
    "    # Salvando a média do fold para cada métrica\n",
    "    fold_metrics_summary.append([\n",
    "        fold, np.mean(acc_fold), np.std(acc_fold),\n",
    "        np.mean(jacc_fold), np.std(jacc_fold),\n",
    "        np.mean(f1_fold), np.std(f1_fold),\n",
    "        np.mean(prec_fold), np.std(prec_fold),\n",
    "        np.mean(rec_fold), np.std(rec_fold)\n",
    "    ])\n",
    "\n",
    "\n",
    "    fold += 1\n",
    "\n",
    "# Calculando médias gerais\n",
    "acc_total = [m[1] for m in fold_metrics_summary]\n",
    "jacc_total = [m[3] for m in fold_metrics_summary]\n",
    "f1_total = [m[5] for m in fold_metrics_summary]\n",
    "prec_total = [m[7] for m in fold_metrics_summary]\n",
    "rec_total = [m[9] for m in fold_metrics_summary]\n",
    "\n",
    "general_summary = [\n",
    "    [\"Fold\", \"Accuracy Mean\", \"Accuracy Std\", \"Jaccard Mean\", \"Jaccard Std\",\n",
    "     \"DICE Mean\", \"DICE Std\", \"Precision Mean\", \"Precision Std\", \"Recall Mean\", \"Recall Std\"]\n",
    "]\n",
    "\n",
    "general_summary.extend(fold_metrics_summary)\n",
    "\n",
    "general_summary.append([\n",
    "    \"Overall Mean\", np.mean(acc_total), np.std(acc_total),\n",
    "    np.mean(jacc_total), np.std(jacc_total),\n",
    "    np.mean(f1_total), np.std(f1_total),\n",
    "    np.mean(prec_total), np.std(prec_total),\n",
    "    np.mean(rec_total), np.std(rec_total)\n",
    "])\n",
    "\n",
    "# Salvando o resumo das métricas por fold e geral\n",
    "with open(os.path.join(output_dir, 'metrics_summary.csv'), 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=';')\n",
    "    writer.writerows(general_summary)\n",
    "\n",
    "print(\"Métricas salvas com sucesso na pasta:\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2544ddf-696d-4ff5-8780-9a498daa8413",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: \"+ str(np.mean(acc_total)*100) + \" +- \" + str(np.std(acc_total)*100))\n",
    "print(\"Jaccard: \"+ str(np.mean(jacc_total)*100) + \" +- \" + str(np.std(jacc_total)*100))\n",
    "print(\"Dice: \"+ str(np.mean(f1_total)*100) + \" +- \" + str(np.std(f1_total)*100))\n",
    "print(\"Precision: \"+ str(np.mean(prec_total)*100) + \" +- \" + str(np.std(prec_total)*100))\n",
    "print(\"Recall: \"+ str(np.mean(rec_total)*100) + \" +- \" + str(np.std(rec_total)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e774436e-ff52-47f8-8dce-d80b378b614b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_fold = 2\n",
    "best_model_filepath = filepath = os.path.join(output_dir, f'model_{best_fold}fold.keras')\n",
    "best_model = tf.keras.models.load_model(best_model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac69b19-a5f7-40f1-b395-d65cd72999d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=k, shuffle=True, random_state=28)\n",
    "for i, (train_ind, test_ind) in enumerate(kf.split(X)):\n",
    "    if i == (best_fold-1):\n",
    "        X_train, X_val, y_train, y_val = X[train_ind], X[test_ind], y[train_ind], y[test_ind]\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6713b66-5fa4-436e-a338-dee9851b3462",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(display_list):\n",
    "  plt.figure(figsize=(15, 15))\n",
    "\n",
    "  title = ['Input image', 'True mask', 'Predicted mask']\n",
    "\n",
    "  for i in range(len(display_list)):\n",
    "    plt.subplot(1, len(display_list), i+1)\n",
    "    plt.title(title[i])\n",
    "    plt.imshow(tf.keras.utils.array_to_img(display_list[i]), cmap='gray')\n",
    "    plt.axis('off')\n",
    "  plt.show()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329d56e2-63cb-4232-b7eb-0a9ed7c6b0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = random.randint(0, len(X_val))\n",
    "sample_image = X_val[i]\n",
    "sample_mask = y_val[i]\n",
    "prediction = best_model.predict(sample_image[tf.newaxis, ...])[0]\n",
    "predicted_mask = (prediction > 0.5).astype(np.uint8)\n",
    "display([sample_image, sample_mask,predicted_mask])\n",
    "\n",
    "sample_mask = y_val[i].astype(np.uint8).flatten()\n",
    "predicted_mask = predicted_mask.flatten()\n",
    "\n",
    "\n",
    "print(\"Accuracy: \"+ str(accuracy_score(sample_mask, predicted_mask)))\n",
    "print(\"Jaccard: \"+ str(jaccard_score(sample_mask, predicted_mask)))\n",
    "print(\"Dice: \"+ str((2*jaccard_score(sample_mask, predicted_mask))/(1+jaccard_score(sample_mask, predicted_mask))))\n",
    "print(\"Precision: \"+ str(precision_score(sample_mask, predicted_mask)))\n",
    "print(\"Recall: \"+ str(recall_score(sample_mask, predicted_mask)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bd9e15-bc6d-4743-ae4b-ce8a3202b64c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
