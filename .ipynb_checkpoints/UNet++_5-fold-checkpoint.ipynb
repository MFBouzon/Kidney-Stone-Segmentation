{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf0339d0-739a-4991-a2c0-4392d2ec6f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 18:00:02.622618: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-17 18:00:02.622662: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-17 18:00:02.623263: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-17 18:00:02.627108: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-17 18:00:03.116550: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "from tensorflow.python.keras.backend import set_session\n",
    "from keras_unet_collection import models\n",
    "from tqdm import tqdm \n",
    "from PIL import Image\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b6f5337-7770-4f92-a2a4-251e31af3cbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sysconfig.get_build_info()['cuda_version']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6eeed634-f3f7-4cce-8c45-77e4b7c270ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.15.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf. __version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2f02a06-5551-4109-97af-8d76f83beb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\n",
      "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
      "Cuda compilation tools, release 12.2, V12.2.140\n",
      "Build cuda_12.2.r12.2/compiler.33191640_0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"nvcc --version\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e76775c-5fc9-419a-a36a-0bd07fe023ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs disponíveis: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 18:00:06.999591: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-17 18:00:07.024524: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-17 18:00:07.024563: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"GPUs disponíveis: {gpus}\")\n",
    "else:\n",
    "    print(\"Nenhuma GPU encontrada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34b9dd1e-626b-4787-b556-426246e4e48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 1\n",
    "k = 5\n",
    "\n",
    "\n",
    "IMG_WIDTH = 512\n",
    "IMG_HEIGHT = 512\n",
    "IMG_CHANNELS = 1\n",
    "\n",
    "DATA_PATH = 'data/'\n",
    "\n",
    "data_ids = next(os.walk(DATA_PATH+'/image'))[2]\n",
    "\n",
    "X = np.zeros((len(data_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "y = np.zeros((len(data_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=bool)\n",
    "\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "os.environ['TF_GPU_ALLOCATOR']= 'cuda_malloc_async'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "386e7353-1711-436b-93c8-9939c699dd59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing training images and masks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 838/838 [00:19<00:00, 43.78it/s]\n"
     ]
    }
   ],
   "source": [
    "print('Resizing training images and masks')\n",
    "for n, id_ in tqdm(enumerate(data_ids), total=len(data_ids)):   \n",
    "    path = DATA_PATH\n",
    "    img = imread(path + '/image/' + id_)[:,:]\n",
    "    img = img.reshape(img.shape[0], img.shape[1], IMG_CHANNELS)\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X[n] = img  #Fill empty X_train with values from img\n",
    "    \n",
    "    mask = imread(path + 'label/' + id_)\n",
    "    mask = (mask >= 250)\n",
    "    mask = np.expand_dims(resize(mask, (IMG_HEIGHT, IMG_WIDTH), mode='constant',  \n",
    "                                      preserve_range=True), axis=-1)\n",
    "    y[n] = mask \n",
    "    #plt.axis(\"off\")\n",
    "    #imshow(y[n])\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4d4b93-571d-43dd-a33e-2dc384f372c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ImageDataGenerator for Data Augmentation\n",
    "data_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=2.5,\n",
    "    width_shift_range=0.075,\n",
    "    height_shift_range=0.075,\n",
    "    shear_range=0.075,\n",
    "    zoom_range=0.075,\n",
    "    horizontal_flip=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e245c43-4d2a-46e4-ab8b-31d91873aa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate additional images to equalize classes if necessary\n",
    "def generate(X_all, y_all):\n",
    "\n",
    "# Generation\n",
    "    X_generated = []\n",
    "    y_generated = []\n",
    "    \n",
    "    data_gen.fit(X_all)\n",
    "    \n",
    "    generated_images = data_gen.flow(X_all, y_all, batch_size=1)\n",
    "    \n",
    "    for _ in range(len(X_all)):\n",
    "        X_new, y_new = next(generated_images)\n",
    "        X_generated.append(np.squeeze(X_new))\n",
    "        y_generated.append(np.squeeze(y_new))\n",
    "\n",
    "    print(f'New images generated: {len(X_generated)}')\n",
    "\n",
    "    return X_generated, y_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4eefa37-9bfe-4ee8-907e-65d5ccf671ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new, y_new = generate(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba24a55-abb4-4abf-858e-7871f49670b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, images_per_figure=100):\n",
    "    num_images = len(images)\n",
    "    cols = 5\n",
    "    rows = (images_per_figure + cols - 1) // cols\n",
    "\n",
    "    for start in range(0, num_images, images_per_figure):\n",
    "        plt.figure(figsize=(cols * 3, rows * 3))\n",
    "        end = min(start + images_per_figure, num_images)\n",
    "\n",
    "        for i in range(start, end):\n",
    "            plt.subplot(rows, cols, i - start + 1)\n",
    "            plt.imshow(images[i])\n",
    "            plt.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928b36b8-dac1-44f6-960f-e03c6cf7f376",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_images(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeec224c-eb8f-4dc8-a87f-68087e14548d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = np.expand_dims(X_new, axis=-1)\n",
    "print('X_new: ', X_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7f297ed-a66e-4727-b154-b60aa8f7fa5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 18:00:32.558278: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-17 18:00:32.558399: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-17 18:00:32.558455: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-17 18:00:32.681691: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-17 18:00:32.681737: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-17 18:00:32.681743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-03-17 18:00:32.681754: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2025-03-17 18:00:32.681758: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:236] Using CUDA malloc Async allocator for GPU: 0\n",
      "2025-03-17 18:00:32.681889: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-17 18:00:32.681908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9558 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "from keras import layers, models\n",
    "\n",
    "def unet_plus_plus(tamanho_entrada=(512, 512, 1)):\n",
    "    entradas = layers.Input(tamanho_entrada)\n",
    "    \n",
    "    # Função para blocos de convolução\n",
    "    def conv_block(x, filtros, nome):\n",
    "        x = layers.Conv2D(filtros, (3, 3), activation='relu', padding='same', name=nome+'_conv1')(x)\n",
    "        x = layers.Conv2D(filtros, (3, 3), activation='relu', padding='same', name=nome+'_conv2')(x)\n",
    "        return x\n",
    "    \n",
    "    # Codificador\n",
    "    c1 = conv_block(entradas, 16, 'c1')\n",
    "    p1 = layers.MaxPooling2D((2, 2), name='p1')(c1)\n",
    "\n",
    "    c2 = conv_block(p1, 32, 'c2')\n",
    "    p2 = layers.MaxPooling2D((2, 2), name='p2')(c2)\n",
    "\n",
    "    c3 = conv_block(p2, 64, 'c3')\n",
    "    p3 = layers.MaxPooling2D((2, 2), name='p3')(c3)\n",
    "\n",
    "    c4 = conv_block(p3, 128, 'c4')\n",
    "    p4 = layers.MaxPooling2D((2, 2), name='p4')(c4)\n",
    "\n",
    "    c5 = conv_block(p4, 256, 'c5')\n",
    "\n",
    "    # Decodificador com conexões densas (U-Net++)\n",
    "    u6 = layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same', name='u6')(c5)\n",
    "    u6 = layers.concatenate([u6, c4], axis=3, name='concat6')\n",
    "    c6 = conv_block(u6, 512, 'c6')\n",
    "\n",
    "    u7 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same', name='u7')(c6)\n",
    "    u7 = layers.concatenate([u7, c3], axis=3, name='concat7')  # Conexão compatível\n",
    "    c7 = conv_block(u7, 256, 'c7')\n",
    "\n",
    "    u8 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same', name='u8')(c7)\n",
    "    u8 = layers.concatenate([u8, c2], axis=3, name='concat8')  # Outra conexão compatível\n",
    "    c8 = conv_block(u8, 128, 'c8')\n",
    "\n",
    "    u9 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same', name='u9')(c8)\n",
    "    u9 = layers.concatenate([u9, c1], axis=3, name='concat9')\n",
    "    c9 = conv_block(u9, 64, 'c9')\n",
    "\n",
    "    saidas = layers.Conv2D(1, (1, 1), activation='sigmoid', name='output')(c9)\n",
    "\n",
    "    modelo = models.Model(inputs=[entradas], outputs=[saidas])\n",
    "    return modelo\n",
    "\n",
    "# Compilando o modelo\n",
    "modelo = unet_plus_plus()\n",
    "modelo.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.Recall(name ='recall')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bb3dc3-8cc2-41d0-bf67-a27f9775446a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 18:00:33.168912: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 175636480 exceeds 10% of free system memory.\n",
      "2025-03-17 18:00:33.250866: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 175636480 exceeds 10% of free system memory.\n",
      "2025-03-17 18:00:33.324630: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 175636480 exceeds 10% of free system memory.\n",
      "2025-03-17 18:00:33.356587: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 175636480 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 18:00:35.214149: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2025-03-17 18:00:48.312670: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:306] gpu_async_0 cuMemAllocAsync failed to allocate 2164408336 bytes: CUDA error: out of memory (CUDA_ERROR_OUT_OF_MEMORY)\n",
      " Reported by CUDA: Free memory/Total memory: 1608515584/12878086144\n",
      "2025-03-17 18:00:48.312721: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:311] Stats: Limit:                     10022289408\n",
      "InUse:                      9356702765\n",
      "MaxInUse:                  10715878461\n",
      "NumAllocs:                        1287\n",
      "MaxAllocSize:               2737635328\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2025-03-17 18:00:48.312739: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:63] Histogram of current allocation: (allocation_size_in_bytes, nb_allocation_of_that_sizes), ...;\n",
      "2025-03-17 18:00:48.312742: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1, 1\n",
      "2025-03-17 18:00:48.312744: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 4, 62\n",
      "2025-03-17 18:00:48.312746: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 8, 6\n",
      "2025-03-17 18:00:48.312747: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 64, 8\n",
      "2025-03-17 18:00:48.312748: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 128, 8\n",
      "2025-03-17 18:00:48.312750: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 256, 24\n",
      "2025-03-17 18:00:48.312751: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 512, 20\n",
      "2025-03-17 18:00:48.312753: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 576, 4\n",
      "2025-03-17 18:00:48.312754: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1024, 20\n",
      "2025-03-17 18:00:48.312755: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1028, 1\n",
      "2025-03-17 18:00:48.312757: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 2048, 12\n",
      "2025-03-17 18:00:48.312758: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 9216, 4\n",
      "2025-03-17 18:00:48.312760: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 18432, 4\n",
      "2025-03-17 18:00:48.312761: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 36864, 4\n",
      "2025-03-17 18:00:48.312762: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 73728, 4\n",
      "2025-03-17 18:00:48.312764: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 131072, 4\n",
      "2025-03-17 18:00:48.312765: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 147456, 9\n",
      "2025-03-17 18:00:48.312766: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 184320, 4\n",
      "2025-03-17 18:00:48.312768: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 294912, 4\n",
      "2025-03-17 18:00:48.312769: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 524288, 4\n",
      "2025-03-17 18:00:48.312770: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 589824, 8\n",
      "2025-03-17 18:00:48.312772: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 737280, 4\n",
      "2025-03-17 18:00:48.312773: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1179648, 4\n",
      "2025-03-17 18:00:48.312774: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 2097152, 8\n",
      "2025-03-17 18:00:48.312776: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 2359296, 8\n",
      "2025-03-17 18:00:48.312777: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 2949120, 4\n",
      "2025-03-17 18:00:48.312778: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 4194304, 1\n",
      "2025-03-17 18:00:48.312780: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 8388608, 1\n",
      "2025-03-17 18:00:48.312781: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 9437184, 4\n",
      "2025-03-17 18:00:48.312782: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 11796480, 4\n",
      "2025-03-17 18:00:48.312784: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 16777216, 6\n",
      "2025-03-17 18:00:48.312785: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 33554432, 3\n",
      "2025-03-17 18:00:48.312787: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 67108864, 3\n",
      "2025-03-17 18:00:48.312788: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 134217728, 4\n",
      "2025-03-17 18:00:48.312789: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 167772160, 1\n",
      "2025-03-17 18:00:48.312791: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 175636480, 2\n",
      "2025-03-17 18:00:48.312792: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 268435456, 4\n",
      "2025-03-17 18:00:48.312793: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 335544320, 1\n",
      "2025-03-17 18:00:48.312795: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 536870912, 2\n",
      "2025-03-17 18:00:48.312796: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 671088640, 1\n",
      "2025-03-17 18:00:48.312797: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1073741824, 2\n",
      "2025-03-17 18:00:48.312799: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1090519040, 1\n",
      "2025-03-17 18:00:48.312800: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1342177280, 1\n",
      "2025-03-17 18:00:48.312803: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:97] CU_MEMPOOL_ATTR_RESERVED_MEM_CURRENT: 9999220736\n",
      "2025-03-17 18:00:48.312805: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:99] CU_MEMPOOL_ATTR_USED_MEM_CURRENT: 9356702765\n",
      "2025-03-17 18:00:48.312807: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:100] CU_MEMPOOL_ATTR_RESERVED_MEM_HIGH: 12113149952\n",
      "2025-03-17 18:00:48.312808: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:101] CU_MEMPOOL_ATTR_USED_MEM_HIGH: 10715878461\n",
      "2025-03-17 18:01:00.706999: I external/local_xla/xla/service/service.cc:168] XLA service 0x7ff101d24540 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-03-17 18:01:00.707037: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4070, Compute Capability 8.9\n",
      "2025-03-17 18:01:00.710884: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1742245260.772637   26617 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/42 [============================>.] - ETA: 0s - loss: 0.0837 - accuracy: 0.9778 - recall: 0.0400"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "jacc = []\n",
    "f1 = []\n",
    "prec = []\n",
    "rec = []\n",
    "\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=28)\n",
    "fold = 1\n",
    "\n",
    "for train_ind, test_ind in kf.split(X):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = np.concatenate([X[train_ind], X_new], axis=0), X[test_ind], np.concatenate([y[train_ind], y], axis=0), y[test_ind]\n",
    "    \n",
    "    model = unet_plus_plus()\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.Recall(name ='recall')])\n",
    "    \n",
    "    checkpoint_filepath = 'UnetPLUS_test' + str(fold)+'fold.keras'\n",
    "    callbacks = [\n",
    "            tf.keras.callbacks.EarlyStopping(patience=20, monitor='val_loss'),\n",
    "            tf.keras.callbacks.TensorBoard(log_dir='logs'),\n",
    "            tf.keras.callbacks.ModelCheckpoint(\n",
    "                filepath=checkpoint_filepath,\n",
    "                save_weights_only=False,\n",
    "                monitor='val_recall',\n",
    "                mode='max',\n",
    "                save_best_only=True,\n",
    "                verbose=1)]\n",
    "    \n",
    "    model.fit(X_train, y_train, validation_data=(X_val,y_val), batch_size=16, epochs=300, callbacks=callbacks)\n",
    "    model.save('Unet++Modelo1.keras')\n",
    "    \n",
    "    loss = model.history.history['loss']\n",
    "    val_loss = model.history.history['val_loss']\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot( loss, 'r', label='Training loss')\n",
    "    plt.plot( val_loss, 'g', label='Validation loss')\n",
    "    plt.title('Training and Validation Loss - Fold' + str(fold))\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss Value')\n",
    "    plt.ylim([0, 1])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    for i in range(0, len(X_val)):\n",
    "        sample_image = X_val[i]\n",
    "        sample_mask = y_val[i].astype(np.uint8).flatten()\n",
    "        prediction = model.predict(sample_image[tf.newaxis, ...],verbose=0)[0]\n",
    "        predicted_mask = (prediction > 0.5).astype(np.uint8).flatten()\n",
    "            \n",
    "        acc.append(accuracy_score(sample_mask, predicted_mask))\n",
    "        jacc.append(jaccard_score(sample_mask, predicted_mask))\n",
    "        f1.append(f1_score(sample_mask, predicted_mask))\n",
    "        prec.append(precision_score(sample_mask, predicted_mask))\n",
    "        rec.append(recall_score(sample_mask, predicted_mask))\n",
    "\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "\n",
    "    with open('UNet++_5-fold_REV02_DA_tempo.txt', 'a') as f:\n",
    "        f.write(f'{training_time:.2f}\\n')\n",
    "    print(f\"O modelo demorou {training_time:.2f} segundos para treinar.\")\n",
    "\n",
    "    del model\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    fold+=1\n",
    "    \n",
    "print(\"Accuracy: \"+ str(np.mean(acc)) + \"+- \" + str(np.std(acc)))\n",
    "print(\"Jaccard: \"+ str(np.mean(jacc)) + \"+- \" + str(np.std(jacc)))\n",
    "print(\"Dice: \"+ str(np.mean(f1)) + \"+- \" + str(np.std(f1)))\n",
    "print(\"Precision: \"+ str(np.mean(prec)) + \"+- \" + str(np.std(prec)))\n",
    "print(\"Recall: \"+ str(np.mean(rec)) + \"+- \" + str(np.std(rec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5d184f-5b31-4156-849f-d24ddac7c3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: \"+ str(np.mean(acc)) + \"+- \" + str(np.std(acc)))\n",
    "print(\"Jaccard: \"+ str(np.mean(jacc)) + \"+- \" + str(np.std(jacc)))\n",
    "print(\"Dice: \"+ str(np.mean(f1)) + \"+- \" + str(np.std(f1)))\n",
    "print(\"Precision: \"+ str(np.mean(prec)) + \"+- \" + str(np.std(prec)))\n",
    "print(\"Recall: \"+ str(np.mean(rec)) + \"+- \" + str(np.std(rec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2544ddf-696d-4ff5-8780-9a498daa8413",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_mean_fold = []\n",
    "jacc_mean_fold = []\n",
    "f1_mean_fold = []\n",
    "prec_mean_fold = []\n",
    "rec_mean_fold = []\n",
    "\n",
    "acc_std_fold = []\n",
    "jacc_std_fold = []\n",
    "f1_std_fold = []\n",
    "prec_std_fold = []\n",
    "rec_std_fold = []\n",
    "\n",
    "\n",
    "f = 0\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=28)\n",
    "for train_ind, test_ind in tqdm(kf.split(X), total=kf.get_n_splits(), desc=\"k-fold\"):\n",
    "    X_train, X_val, y_train, y_val = X[train_ind], X[test_ind], y[train_ind], y[test_ind]\n",
    "\n",
    "    acc= []\n",
    "    jacc = []\n",
    "    f1 = []\n",
    "    prec = []\n",
    "    rec = []\n",
    "    \n",
    "    model = tf.keras.models.load_model('UnetPLUS_test'+str(f+1)+'fold.keras')\n",
    "\n",
    "    for i in range(0, len(X_val)):\n",
    "        sample_image = X_val[i]\n",
    "        sample_mask = y_val[i].astype(np.uint8).flatten()\n",
    "        prediction = model.predict(sample_image[tf.newaxis, ...],verbose=0)[0]\n",
    "        predicted_mask = (prediction > 0.5).astype(np.uint8).flatten()\n",
    "            \n",
    "        acc.append(accuracy_score(sample_mask, predicted_mask))\n",
    "        jacc.append(jaccard_score(sample_mask, predicted_mask))\n",
    "        f1.append(f1_score(sample_mask, predicted_mask))\n",
    "        prec.append(precision_score(sample_mask, predicted_mask))\n",
    "        rec.append(recall_score(sample_mask, predicted_mask))\n",
    "\n",
    "    acc_mean_fold.append(np.mean(acc))\n",
    "    acc_std_fold.append(np.std(acc))\n",
    "    jacc_mean_fold.append(np.mean(jacc))\n",
    "    jacc_std_fold.append(np.std(jacc))\n",
    "    f1_mean_fold.append(np.mean(f1))\n",
    "    f1_std_fold.append(np.std(f1))\n",
    "    prec_mean_fold.append(np.mean(prec))\n",
    "    prec_std_fold.append(np.std(prec))\n",
    "    rec_mean_fold.append(np.mean(rec))\n",
    "    rec_std_fold.append(np.std(rec))\n",
    "    \n",
    "    print(\"Model - Fold\" + str(f+1)+ \"Accuracy: \" + str(acc_mean_fold[-1]))\n",
    "    print(\"Model - Fold\" + str(f+1)+ \"Jaccard: \" + str(jacc_mean_fold[-1]))\n",
    "    print(\"Model - Fold\" + str(f+1)+ \"Dice: \" + str(f1_mean_fold[-1]))\n",
    "    print(\"Model - Fold\" + str(f+1)+ \"Precision: \" + str(prec_mean_fold[-1]))\n",
    "    print(\"Model - Fold\" + str(f+1)+ \"Recall: \" + str(rec_mean_fold[-1]))\n",
    "\n",
    "    f += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e774436e-ff52-47f8-8dce-d80b378b614b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: \"+ str(np.mean(acc_mean_fold)*100) + \" +- \" + str(np.std(acc_std_fold)*100))\n",
    "print(\"Jaccard: \"+ str(np.mean(jacc_mean_fold)*100) + \" +- \" + str(np.std(jacc_std_fold)*100))\n",
    "print(\"Dice: \"+ str(np.mean(f1_mean_fold)*100) + \" +- \" + str(np.std(f1_std_fold)*100))\n",
    "print(\"Precision: \"+ str(np.mean(prec_mean_fold)*100) + \" +- \" + str(np.std(prec_std_fold)*100))\n",
    "print(\"Recall: \"+ str(np.mean(rec_mean_fold)*100) + \" +- \" + str(np.std(rec_std_fold)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac69b19-a5f7-40f1-b395-d65cd72999d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tf.keras.models.load_model('UnetPLUS_test2fold.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6713b66-5fa4-436e-a338-dee9851b3462",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=28)\n",
    "for i, (train_ind, test_ind) in enumerate(kf.split(X)):\n",
    "    if i == 1:\n",
    "        X_train, X_val, y_train, y_val = X[train_ind], X[test_ind], y[train_ind], y[test_ind]\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329d56e2-63cb-4232-b7eb-0a9ed7c6b0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(display_list):\n",
    "  plt.figure(figsize=(15, 15))\n",
    "\n",
    "  title = ['Input image', 'True mask', 'Predicted mask']\n",
    "\n",
    "  for i in range(len(display_list)):\n",
    "    plt.subplot(1, len(display_list), i+1)\n",
    "    plt.title(title[i])\n",
    "    plt.imshow(tf.keras.utils.array_to_img(display_list[i]), cmap='gray')\n",
    "    plt.axis('off')\n",
    "  plt.show()\n",
    "  \n",
    "i = random.randint(0, len(X_val))\n",
    "sample_image = X_val[i]\n",
    "sample_mask = y_val[i]\n",
    "prediction = best_model.predict(sample_image[tf.newaxis, ...])[0]\n",
    "predicted_mask = (prediction > 0.5).astype(np.uint8)\n",
    "display([sample_image, sample_mask,predicted_mask])\n",
    "\n",
    "sample_mask = y_val[i].astype(np.uint8).flatten()\n",
    "predicted_mask = predicted_mask.flatten()\n",
    "\n",
    "\n",
    "print(\"Accuracy: \"+ str(accuracy_score(sample_mask, predicted_mask)))\n",
    "print(\"Jaccard: \"+ str(jaccard_score(sample_mask, predicted_mask)))\n",
    "\n",
    "print(\"Dice: \"+ str((2*jaccard_score(sample_mask, predicted_mask))/(1+jaccard_score(sample_mask, predicted_mask))))\n",
    "print(\"Precision: \"+ str(precision_score(sample_mask, predicted_mask)))\n",
    "print(\"Recall: \"+ str(recall_score(sample_mask, predicted_mask)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36ef180-344a-4f01-9a6b-a717a7040fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bd9e15-bc6d-4743-ae4b-ce8a3202b64c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
