{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf0339d0-739a-4991-a2c0-4392d2ec6f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-31 17:15:38.838136: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-31 17:15:39.223609: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-31 17:15:40.042817: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-10-31 17:15:40.042894: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-10-31 17:15:40.042899: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.backend import set_session\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    " \n",
    "from tqdm import tqdm \n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34b9dd1e-626b-4787-b556-426246e4e48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 1\n",
    "k = 5\n",
    "\n",
    "\n",
    "IMG_WIDTH = 512\n",
    "IMG_HEIGHT = 512\n",
    "IMG_CHANNELS = 1\n",
    "\n",
    "DATA_PATH = 'data/'\n",
    "\n",
    "data_ids = next(os.walk(DATA_PATH+'/image'))[2]\n",
    "\n",
    "X = np.zeros((len(data_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "y = np.zeros((len(data_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=bool)\n",
    "\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "os.environ['TF_GPU_ALLOCATOR']= 'cuda_malloc_async'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "386e7353-1711-436b-93c8-9939c699dd59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing training images and masks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 838/838 [00:33<00:00, 25.00it/s]\n"
     ]
    }
   ],
   "source": [
    "print('Resizing training images and masks')\n",
    "for n, id_ in tqdm(enumerate(data_ids), total=len(data_ids)):   \n",
    "    path = DATA_PATH\n",
    "    img = imread(path + '/image/' + id_)[:,:]\n",
    "    img = img.reshape(img.shape[0], img.shape[1], IMG_CHANNELS)\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X[n] = img  #Fill empty X_train with values from img\n",
    "    \n",
    "    mask = imread(path + 'label/' + id_)\n",
    "    mask = (mask >= 250)\n",
    "    mask = np.expand_dims(resize(mask, (IMG_HEIGHT, IMG_WIDTH), mode='constant',  \n",
    "                                      preserve_range=True), axis=-1)\n",
    "    y[n] = mask \n",
    "    #plt.axis(\"off\")\n",
    "    #imshow(y[n])\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85d665ea-e7d8-4b01-a058-ef375b45905f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet():\n",
    "    inputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "    \n",
    "    #Contraction path\n",
    "    c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(inputs)\n",
    "    c1 = tf.keras.layers.Dropout(0.1)(c1)\n",
    "    c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
    "    b1 = tf.keras.layers.BatchNormalization()(c1)\n",
    "    r1 = tf.keras.layers.ReLU()(b1)\n",
    "    p1 = tf.keras.layers.MaxPooling2D((2, 2))(r1)\n",
    "    \n",
    "    c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
    "    c2 = tf.keras.layers.Dropout(0.1)(c2)\n",
    "    c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
    "    b2 = tf.keras.layers.BatchNormalization()(c2)\n",
    "    r2 = tf.keras.layers.ReLU()(b2)\n",
    "    p2 = tf.keras.layers.MaxPooling2D((2, 2))(r2)\n",
    "     \n",
    "    c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "    c3 = tf.keras.layers.Dropout(0.2)(c3)\n",
    "    c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
    "    b3 = tf.keras.layers.BatchNormalization()(c3)\n",
    "    r3 = tf.keras.layers.ReLU()(b3)\n",
    "    p3 = tf.keras.layers.MaxPooling2D((2, 2))(r3)\n",
    "     \n",
    "    c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "    c4 = tf.keras.layers.Dropout(0.2)(c4)\n",
    "    c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
    "    b4 = tf.keras.layers.BatchNormalization()(c4)\n",
    "    r4 = tf.keras.layers.ReLU()(b4)\n",
    "    p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(r4)\n",
    "     \n",
    "    c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
    "    b5 = tf.keras.layers.BatchNormalization()(c5)\n",
    "    r5 = tf.keras.layers.ReLU()(b5)\n",
    "    c5 = tf.keras.layers.Dropout(0.3)(r5)\n",
    "    c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "    \n",
    "    #Expansive path \n",
    "    u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = tf.keras.layers.concatenate([u6, c4])\n",
    "    u6 = tf.keras.layers.BatchNormalization()(u6)\n",
    "    u6 = tf.keras.layers.ReLU()(u6)\n",
    "    \n",
    "     \n",
    "    u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(u6)\n",
    "    u7 = tf.keras.layers.concatenate([u7, c3])\n",
    "    u7 = tf.keras.layers.BatchNormalization()(u7)\n",
    "    u7 = tf.keras.layers.ReLU()(u7)\n",
    "    \n",
    "     \n",
    "    u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(u7)\n",
    "    u8 = tf.keras.layers.concatenate([u8, c2])\n",
    "    u8 = tf.keras.layers.BatchNormalization()(u8)\n",
    "    u8 = tf.keras.layers.ReLU()(u8)\n",
    "     \n",
    "    u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(u8)\n",
    "    u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n",
    "    u9 = tf.keras.layers.BatchNormalization()(u9)\n",
    "    u9 = tf.keras.layers.ReLU()(u9)\n",
    "    \n",
    "     \n",
    "    outputs = tf.keras.layers.Conv2D(num_classes, (1, 1), activation='sigmoid')(u9)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.Recall(name='recall')])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5bb3dc3-8cc2-41d0-bf67-a27f9775446a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-04 14:19:33.925157: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-04 14:19:34.100773: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-04 14:19:34.100822: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-04 14:19:34.102031: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-04 14:19:34.103745: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-04 14:19:34.103787: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-04 14:19:34.103805: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-04 14:19:34.932988: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-04 14:19:34.933500: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-04 14:19:34.933538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-08-04 14:19:34.933690: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-04 14:19:34.934745: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2023-08-04 14:19:34.934862: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0\n",
      "2023-08-04 14:19:34.935603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9394 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-04 14:19:38.147801: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8902\n",
      "2023-08-04 14:19:39.354188: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-08-04 14:19:42.306254: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - ETA: 0s - loss: 0.5900 - accuracy: 0.8201 - recall: 0.1577\n",
      "Epoch 1: val_recall improved from -inf to 0.00003, saving model to model_1fold.h5\n",
      "42/42 [==============================] - 26s 420ms/step - loss: 0.5900 - accuracy: 0.8201 - recall: 0.1577 - val_loss: 0.4144 - val_accuracy: 0.9732 - val_recall: 3.4061e-05\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.3197 - accuracy: 0.9898 - recall: 0.0035\n",
      "Epoch 2: val_recall did not improve from 0.00003\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 0.3197 - accuracy: 0.9898 - recall: 0.0035 - val_loss: 0.3843 - val_accuracy: 0.9888 - val_recall: 0.0000e+00\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1853 - accuracy: 0.9971 - recall: 0.0037\n",
      "Epoch 3: val_recall did not improve from 0.00003\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 0.1853 - accuracy: 0.9971 - recall: 0.0037 - val_loss: 0.2674 - val_accuracy: 0.9985 - val_recall: 0.0000e+00\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1268 - accuracy: 0.9987 - recall: 0.0028\n",
      "Epoch 4: val_recall did not improve from 0.00003\n",
      "42/42 [==============================] - 13s 315ms/step - loss: 0.1268 - accuracy: 0.9987 - recall: 0.0028 - val_loss: 0.1797 - val_accuracy: 0.9993 - val_recall: 0.0000e+00\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0936 - accuracy: 0.9992 - recall: 0.0019\n",
      "Epoch 5: val_recall did not improve from 0.00003\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 0.0936 - accuracy: 0.9992 - recall: 0.0019 - val_loss: 0.1232 - val_accuracy: 0.9993 - val_recall: 0.0000e+00\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0717 - accuracy: 0.9993 - recall: 7.2743e-04\n",
      "Epoch 6: val_recall did not improve from 0.00003\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 0.0717 - accuracy: 0.9993 - recall: 7.2743e-04 - val_loss: 0.0871 - val_accuracy: 0.9993 - val_recall: 0.0000e+00\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0568 - accuracy: 0.9994 - recall: 4.5119e-04\n",
      "Epoch 7: val_recall did not improve from 0.00003\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 0.0568 - accuracy: 0.9994 - recall: 4.5119e-04 - val_loss: 0.0638 - val_accuracy: 0.9993 - val_recall: 0.0000e+00\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0461 - accuracy: 0.9994 - recall: 1.1050e-04\n",
      "Epoch 8: val_recall did not improve from 0.00003\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 0.0461 - accuracy: 0.9994 - recall: 1.1050e-04 - val_loss: 0.0480 - val_accuracy: 0.9993 - val_recall: 0.0000e+00\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0382 - accuracy: 0.9994 - recall: 5.5248e-05\n",
      "Epoch 9: val_recall did not improve from 0.00003\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 0.0382 - accuracy: 0.9994 - recall: 5.5248e-05 - val_loss: 0.0382 - val_accuracy: 0.9993 - val_recall: 0.0000e+00\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0322 - accuracy: 0.9994 - recall: 3.6832e-05\n",
      "Epoch 10: val_recall did not improve from 0.00003\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 0.0322 - accuracy: 0.9994 - recall: 3.6832e-05 - val_loss: 0.0328 - val_accuracy: 0.9993 - val_recall: 0.0000e+00\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0276 - accuracy: 0.9994 - recall: 1.8416e-05\n",
      "Epoch 11: val_recall did not improve from 0.00003\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 0.0276 - accuracy: 0.9994 - recall: 1.8416e-05 - val_loss: 0.0281 - val_accuracy: 0.9993 - val_recall: 0.0000e+00\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0238 - accuracy: 0.9994 - recall: 1.8416e-05\n",
      "Epoch 12: val_recall did not improve from 0.00003\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0238 - accuracy: 0.9994 - recall: 1.8416e-05 - val_loss: 0.0241 - val_accuracy: 0.9993 - val_recall: 0.0000e+00\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0207 - accuracy: 0.9994 - recall: 7.3663e-05\n",
      "Epoch 13: val_recall did not improve from 0.00003\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 0.0207 - accuracy: 0.9994 - recall: 7.3663e-05 - val_loss: 0.0211 - val_accuracy: 0.9993 - val_recall: 0.0000e+00\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 0.9994 - recall: 0.0317\n",
      "Epoch 14: val_recall did not improve from 0.00003\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 0.0173 - accuracy: 0.9994 - recall: 0.0317 - val_loss: 0.0192 - val_accuracy: 0.9993 - val_recall: 0.0000e+00\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0135 - accuracy: 0.9995 - recall: 0.3369\n",
      "Epoch 15: val_recall did not improve from 0.00003\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0135 - accuracy: 0.9995 - recall: 0.3369 - val_loss: 0.0191 - val_accuracy: 0.9993 - val_recall: 0.0000e+00\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9997 - recall: 0.5950\n",
      "Epoch 16: val_recall did not improve from 0.00003\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 0.0109 - accuracy: 0.9997 - recall: 0.5950 - val_loss: 0.0164 - val_accuracy: 0.9993 - val_recall: 0.0000e+00\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9997 - recall: 0.7055\n",
      "Epoch 17: val_recall did not improve from 0.00003\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 0.0092 - accuracy: 0.9997 - recall: 0.7055 - val_loss: 0.0147 - val_accuracy: 0.9993 - val_recall: 0.0000e+00\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 0.9998 - recall: 0.7726\n",
      "Epoch 18: val_recall did not improve from 0.00003\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 0.0079 - accuracy: 0.9998 - recall: 0.7726 - val_loss: 0.0132 - val_accuracy: 0.9993 - val_recall: 0.0000e+00\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9998 - recall: 0.7971\n",
      "Epoch 19: val_recall did not improve from 0.00003\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0070 - accuracy: 0.9998 - recall: 0.7971 - val_loss: 0.0110 - val_accuracy: 0.9993 - val_recall: 0.0000e+00\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9998 - recall: 0.8110\n",
      "Epoch 20: val_recall improved from 0.00003 to 0.00099, saving model to model_1fold.h5\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 0.0062 - accuracy: 0.9998 - recall: 0.8110 - val_loss: 0.0091 - val_accuracy: 0.9993 - val_recall: 9.8777e-04\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9998 - recall: 0.8268\n",
      "Epoch 21: val_recall improved from 0.00099 to 0.05075, saving model to model_1fold.h5\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 0.0056 - accuracy: 0.9998 - recall: 0.8268 - val_loss: 0.0069 - val_accuracy: 0.9994 - val_recall: 0.0508\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9999 - recall: 0.8543\n",
      "Epoch 22: val_recall improved from 0.05075 to 0.26421, saving model to model_1fold.h5\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 0.0050 - accuracy: 0.9999 - recall: 0.8543 - val_loss: 0.0054 - val_accuracy: 0.9995 - val_recall: 0.2642\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.9999 - recall: 0.8569\n",
      "Epoch 23: val_recall improved from 0.26421 to 0.45925, saving model to model_1fold.h5\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 0.0045 - accuracy: 0.9999 - recall: 0.8569 - val_loss: 0.0045 - val_accuracy: 0.9996 - val_recall: 0.4592\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9999 - recall: 0.8726\n",
      "Epoch 24: val_recall improved from 0.45925 to 0.60074, saving model to model_1fold.h5\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 0.0041 - accuracy: 0.9999 - recall: 0.8726 - val_loss: 0.0040 - val_accuracy: 0.9997 - val_recall: 0.6007\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 0.9999 - recall: 0.8792\n",
      "Epoch 25: val_recall improved from 0.60074 to 0.66065, saving model to model_1fold.h5\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 0.0038 - accuracy: 0.9999 - recall: 0.8792 - val_loss: 0.0035 - val_accuracy: 0.9998 - val_recall: 0.6606\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9999 - recall: 0.8825\n",
      "Epoch 26: val_recall improved from 0.66065 to 0.70585, saving model to model_1fold.h5\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 0.0035 - accuracy: 0.9999 - recall: 0.8825 - val_loss: 0.0032 - val_accuracy: 0.9998 - val_recall: 0.7058\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9999 - recall: 0.8863\n",
      "Epoch 27: val_recall improved from 0.70585 to 0.84247, saving model to model_1fold.h5\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 0.0032 - accuracy: 0.9999 - recall: 0.8863 - val_loss: 0.0028 - val_accuracy: 0.9999 - val_recall: 0.8425\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9999 - recall: 0.8862\n",
      "Epoch 28: val_recall did not improve from 0.84247\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0030 - accuracy: 0.9999 - recall: 0.8862 - val_loss: 0.0039 - val_accuracy: 0.9995 - val_recall: 0.1968\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9999 - recall: 0.8852\n",
      "Epoch 29: val_recall did not improve from 0.84247\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 0.0028 - accuracy: 0.9999 - recall: 0.8852 - val_loss: 0.0024 - val_accuracy: 0.9998 - val_recall: 0.7975\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9999 - recall: 0.8998\n",
      "Epoch 30: val_recall did not improve from 0.84247\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 0.0026 - accuracy: 0.9999 - recall: 0.8998 - val_loss: 0.0024 - val_accuracy: 0.9998 - val_recall: 0.6655\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9999 - recall: 0.9063\n",
      "Epoch 31: val_recall did not improve from 0.84247\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0024 - accuracy: 0.9999 - recall: 0.9063 - val_loss: 0.0022 - val_accuracy: 0.9998 - val_recall: 0.7515\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9999 - recall: 0.9033\n",
      "Epoch 32: val_recall did not improve from 0.84247\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0022 - accuracy: 0.9999 - recall: 0.9033 - val_loss: 0.0021 - val_accuracy: 0.9998 - val_recall: 0.8003\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9999 - recall: 0.9125\n",
      "Epoch 33: val_recall did not improve from 0.84247\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 0.0021 - accuracy: 0.9999 - recall: 0.9125 - val_loss: 0.0019 - val_accuracy: 0.9999 - val_recall: 0.8353\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9999 - recall: 0.9128\n",
      "Epoch 34: val_recall improved from 0.84247 to 0.85786, saving model to model_1fold.h5\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 0.0020 - accuracy: 0.9999 - recall: 0.9128 - val_loss: 0.0017 - val_accuracy: 0.9999 - val_recall: 0.8579\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9999 - recall: 0.9212\n",
      "Epoch 35: val_recall improved from 0.85786 to 0.86713, saving model to model_1fold.h5\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 0.0018 - accuracy: 0.9999 - recall: 0.9212 - val_loss: 0.0016 - val_accuracy: 0.9999 - val_recall: 0.8671\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9999 - recall: 0.9233\n",
      "Epoch 36: val_recall did not improve from 0.86713\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0017 - accuracy: 0.9999 - recall: 0.9233 - val_loss: 0.0016 - val_accuracy: 0.9998 - val_recall: 0.7906\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9999 - recall: 0.9204\n",
      "Epoch 37: val_recall did not improve from 0.86713\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 0.0017 - accuracy: 0.9999 - recall: 0.9204 - val_loss: 0.0016 - val_accuracy: 0.9999 - val_recall: 0.8053\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9999 - recall: 0.9186\n",
      "Epoch 38: val_recall improved from 0.86713 to 0.88126, saving model to model_1fold.h5\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 0.0016 - accuracy: 0.9999 - recall: 0.9186 - val_loss: 0.0014 - val_accuracy: 0.9999 - val_recall: 0.8813\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9999 - recall: 0.9256\n",
      "Epoch 39: val_recall did not improve from 0.88126\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0015 - accuracy: 0.9999 - recall: 0.9256 - val_loss: 0.0013 - val_accuracy: 0.9999 - val_recall: 0.8805\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9999 - recall: 0.9285\n",
      "Epoch 40: val_recall improved from 0.88126 to 0.90194, saving model to model_1fold.h5\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 0.0014 - accuracy: 0.9999 - recall: 0.9285 - val_loss: 0.0013 - val_accuracy: 0.9999 - val_recall: 0.9019\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9999 - recall: 0.9293\n",
      "Epoch 41: val_recall did not improve from 0.90194\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 0.0013 - accuracy: 0.9999 - recall: 0.9293 - val_loss: 0.0012 - val_accuracy: 0.9999 - val_recall: 0.8734\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9999 - recall: 0.9304\n",
      "Epoch 42: val_recall did not improve from 0.90194\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 0.0013 - accuracy: 0.9999 - recall: 0.9304 - val_loss: 0.0012 - val_accuracy: 0.9999 - val_recall: 0.8237\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 0.9999 - recall: 0.9277\n",
      "Epoch 43: val_recall did not improve from 0.90194\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 0.0012 - accuracy: 0.9999 - recall: 0.9277 - val_loss: 0.0011 - val_accuracy: 0.9999 - val_recall: 0.8912\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9999 - recall: 0.9325\n",
      "Epoch 44: val_recall did not improve from 0.90194\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 0.0011 - accuracy: 0.9999 - recall: 0.9325 - val_loss: 0.0011 - val_accuracy: 0.9999 - val_recall: 0.8602\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9999 - recall: 0.9365\n",
      "Epoch 45: val_recall did not improve from 0.90194\n",
      "42/42 [==============================] - 13s 322ms/step - loss: 0.0011 - accuracy: 0.9999 - recall: 0.9365 - val_loss: 0.0010 - val_accuracy: 0.9999 - val_recall: 0.8665\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 0.9999 - recall: 0.9364\n",
      "Epoch 46: val_recall improved from 0.90194 to 0.90568, saving model to model_1fold.h5\n",
      "42/42 [==============================] - 14s 325ms/step - loss: 0.0010 - accuracy: 0.9999 - recall: 0.9364 - val_loss: 9.5441e-04 - val_accuracy: 0.9999 - val_recall: 0.9057\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 0.9999 - recall: 0.9345\n",
      "Epoch 47: val_recall did not improve from 0.90568\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 0.0010 - accuracy: 0.9999 - recall: 0.9345 - val_loss: 9.1775e-04 - val_accuracy: 0.9999 - val_recall: 0.9033\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 9.7317e-04 - accuracy: 0.9999 - recall: 0.9353\n",
      "Epoch 48: val_recall did not improve from 0.90568\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 9.7317e-04 - accuracy: 0.9999 - recall: 0.9353 - val_loss: 9.4825e-04 - val_accuracy: 0.9999 - val_recall: 0.8191\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 9.2720e-04 - accuracy: 0.9999 - recall: 0.9372\n",
      "Epoch 49: val_recall did not improve from 0.90568\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 9.2720e-04 - accuracy: 0.9999 - recall: 0.9372 - val_loss: 8.4175e-04 - val_accuracy: 0.9999 - val_recall: 0.8836\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 8.8176e-04 - accuracy: 0.9999 - recall: 0.9392\n",
      "Epoch 50: val_recall did not improve from 0.90568\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 8.8176e-04 - accuracy: 0.9999 - recall: 0.9392 - val_loss: 8.3257e-04 - val_accuracy: 0.9999 - val_recall: 0.8771\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 8.4710e-04 - accuracy: 0.9999 - recall: 0.9387\n",
      "Epoch 51: val_recall improved from 0.90568 to 0.91212, saving model to model_1fold.h5\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 8.4710e-04 - accuracy: 0.9999 - recall: 0.9387 - val_loss: 7.8247e-04 - val_accuracy: 0.9999 - val_recall: 0.9121\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 8.1364e-04 - accuracy: 0.9999 - recall: 0.9412\n",
      "Epoch 52: val_recall improved from 0.91212 to 0.91502, saving model to model_1fold.h5\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 8.1364e-04 - accuracy: 0.9999 - recall: 0.9412 - val_loss: 7.5858e-04 - val_accuracy: 0.9999 - val_recall: 0.9150\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 7.7597e-04 - accuracy: 0.9999 - recall: 0.9421\n",
      "Epoch 53: val_recall improved from 0.91502 to 0.92953, saving model to model_1fold.h5\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 7.7597e-04 - accuracy: 0.9999 - recall: 0.9421 - val_loss: 7.2417e-04 - val_accuracy: 0.9999 - val_recall: 0.9295\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 7.5323e-04 - accuracy: 0.9999 - recall: 0.9440\n",
      "Epoch 54: val_recall did not improve from 0.92953\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 7.5323e-04 - accuracy: 0.9999 - recall: 0.9440 - val_loss: 7.3162e-04 - val_accuracy: 0.9999 - val_recall: 0.8746\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 7.1388e-04 - accuracy: 0.9999 - recall: 0.9460\n",
      "Epoch 55: val_recall did not improve from 0.92953\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 7.1388e-04 - accuracy: 0.9999 - recall: 0.9460 - val_loss: 6.9074e-04 - val_accuracy: 0.9999 - val_recall: 0.8995\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 6.9219e-04 - accuracy: 0.9999 - recall: 0.9444\n",
      "Epoch 56: val_recall did not improve from 0.92953\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 6.9219e-04 - accuracy: 0.9999 - recall: 0.9444 - val_loss: 6.5763e-04 - val_accuracy: 0.9999 - val_recall: 0.9059\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 6.6922e-04 - accuracy: 0.9999 - recall: 0.9454\n",
      "Epoch 57: val_recall did not improve from 0.92953\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 6.6922e-04 - accuracy: 0.9999 - recall: 0.9454 - val_loss: 6.4144e-04 - val_accuracy: 0.9999 - val_recall: 0.9176\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 6.4651e-04 - accuracy: 0.9999 - recall: 0.9463\n",
      "Epoch 58: val_recall did not improve from 0.92953\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 6.4651e-04 - accuracy: 0.9999 - recall: 0.9463 - val_loss: 6.2932e-04 - val_accuracy: 0.9999 - val_recall: 0.9144\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 6.2040e-04 - accuracy: 0.9999 - recall: 0.9478\n",
      "Epoch 59: val_recall improved from 0.92953 to 0.93678, saving model to model_1fold.h5\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 6.2040e-04 - accuracy: 0.9999 - recall: 0.9478 - val_loss: 5.9438e-04 - val_accuracy: 0.9999 - val_recall: 0.9368\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 6.0994e-04 - accuracy: 0.9999 - recall: 0.9453\n",
      "Epoch 60: val_recall did not improve from 0.93678\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 6.0994e-04 - accuracy: 0.9999 - recall: 0.9453 - val_loss: 5.8887e-04 - val_accuracy: 0.9999 - val_recall: 0.9042\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 5.8248e-04 - accuracy: 0.9999 - recall: 0.9492\n",
      "Epoch 61: val_recall did not improve from 0.93678\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 5.8248e-04 - accuracy: 0.9999 - recall: 0.9492 - val_loss: 5.5315e-04 - val_accuracy: 0.9999 - val_recall: 0.9291\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 5.6162e-04 - accuracy: 0.9999 - recall: 0.9509\n",
      "Epoch 62: val_recall did not improve from 0.93678\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 5.6162e-04 - accuracy: 0.9999 - recall: 0.9509 - val_loss: 5.5997e-04 - val_accuracy: 0.9999 - val_recall: 0.9100\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 5.3850e-04 - accuracy: 0.9999 - recall: 0.9505\n",
      "Epoch 63: val_recall did not improve from 0.93678\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 5.3850e-04 - accuracy: 0.9999 - recall: 0.9505 - val_loss: 5.5519e-04 - val_accuracy: 0.9999 - val_recall: 0.8952\n",
      "Epoch 64/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 5.2565e-04 - accuracy: 0.9999 - recall: 0.9509\n",
      "Epoch 64: val_recall did not improve from 0.93678\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 5.2565e-04 - accuracy: 0.9999 - recall: 0.9509 - val_loss: 5.2211e-04 - val_accuracy: 0.9999 - val_recall: 0.9184\n",
      "Epoch 65/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 5.0985e-04 - accuracy: 0.9999 - recall: 0.9511\n",
      "Epoch 65: val_recall did not improve from 0.93678\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 5.0985e-04 - accuracy: 0.9999 - recall: 0.9511 - val_loss: 5.0327e-04 - val_accuracy: 0.9999 - val_recall: 0.9235\n",
      "Epoch 66/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 4.9088e-04 - accuracy: 0.9999 - recall: 0.9550\n",
      "Epoch 66: val_recall did not improve from 0.93678\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 4.9088e-04 - accuracy: 0.9999 - recall: 0.9550 - val_loss: 5.0776e-04 - val_accuracy: 0.9999 - val_recall: 0.9029\n",
      "Epoch 67/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 4.7994e-04 - accuracy: 0.9999 - recall: 0.9516\n",
      "Epoch 67: val_recall did not improve from 0.93678\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 4.7994e-04 - accuracy: 0.9999 - recall: 0.9516 - val_loss: 4.8463e-04 - val_accuracy: 0.9999 - val_recall: 0.9154\n",
      "Epoch 68/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 4.6605e-04 - accuracy: 0.9999 - recall: 0.9531\n",
      "Epoch 68: val_recall did not improve from 0.93678\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 4.6605e-04 - accuracy: 0.9999 - recall: 0.9531 - val_loss: 4.6908e-04 - val_accuracy: 0.9999 - val_recall: 0.9235\n",
      "Epoch 69/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 4.4740e-04 - accuracy: 1.0000 - recall: 0.9539\n",
      "Epoch 69: val_recall did not improve from 0.93678\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 4.4740e-04 - accuracy: 1.0000 - recall: 0.9539 - val_loss: 4.7222e-04 - val_accuracy: 0.9999 - val_recall: 0.9140\n",
      "Epoch 70/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 4.3563e-04 - accuracy: 1.0000 - recall: 0.9543\n",
      "Epoch 70: val_recall improved from 0.93678 to 0.95569, saving model to model_1fold.h5\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 4.3563e-04 - accuracy: 1.0000 - recall: 0.9543 - val_loss: 4.4830e-04 - val_accuracy: 0.9999 - val_recall: 0.9557\n",
      "Epoch 71/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 4.2271e-04 - accuracy: 1.0000 - recall: 0.9574\n",
      "Epoch 71: val_recall did not improve from 0.95569\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 4.2271e-04 - accuracy: 1.0000 - recall: 0.9574 - val_loss: 4.4962e-04 - val_accuracy: 0.9999 - val_recall: 0.9163\n",
      "Epoch 72/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 4.2845e-04 - accuracy: 0.9999 - recall: 0.9505\n",
      "Epoch 72: val_recall did not improve from 0.95569\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 4.2845e-04 - accuracy: 0.9999 - recall: 0.9505 - val_loss: 4.3505e-04 - val_accuracy: 0.9999 - val_recall: 0.9474\n",
      "Epoch 73/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 4.0119e-04 - accuracy: 1.0000 - recall: 0.9555\n",
      "Epoch 73: val_recall did not improve from 0.95569\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 4.0119e-04 - accuracy: 1.0000 - recall: 0.9555 - val_loss: 4.1318e-04 - val_accuracy: 0.9999 - val_recall: 0.9494\n",
      "Epoch 74/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.8895e-04 - accuracy: 1.0000 - recall: 0.9584\n",
      "Epoch 74: val_recall did not improve from 0.95569\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 3.8895e-04 - accuracy: 1.0000 - recall: 0.9584 - val_loss: 4.1025e-04 - val_accuracy: 0.9999 - val_recall: 0.9342\n",
      "Epoch 75/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.7451e-04 - accuracy: 1.0000 - recall: 0.9574\n",
      "Epoch 75: val_recall did not improve from 0.95569\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 3.7451e-04 - accuracy: 1.0000 - recall: 0.9574 - val_loss: 4.1065e-04 - val_accuracy: 0.9999 - val_recall: 0.9359\n",
      "Epoch 76/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.7093e-04 - accuracy: 1.0000 - recall: 0.9572\n",
      "Epoch 76: val_recall did not improve from 0.95569\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 3.7093e-04 - accuracy: 1.0000 - recall: 0.9572 - val_loss: 4.2501e-04 - val_accuracy: 0.9999 - val_recall: 0.9026\n",
      "Epoch 77/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.6741e-04 - accuracy: 1.0000 - recall: 0.9539\n",
      "Epoch 77: val_recall did not improve from 0.95569\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 3.6741e-04 - accuracy: 1.0000 - recall: 0.9539 - val_loss: 3.9439e-04 - val_accuracy: 0.9999 - val_recall: 0.9335\n",
      "Epoch 78/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.7129e-04 - accuracy: 0.9999 - recall: 0.9545\n",
      "Epoch 78: val_recall did not improve from 0.95569\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 3.7129e-04 - accuracy: 0.9999 - recall: 0.9545 - val_loss: 3.8984e-04 - val_accuracy: 0.9999 - val_recall: 0.9350\n",
      "Epoch 79/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.4247e-04 - accuracy: 1.0000 - recall: 0.9588\n",
      "Epoch 79: val_recall did not improve from 0.95569\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 3.4247e-04 - accuracy: 1.0000 - recall: 0.9588 - val_loss: 3.7884e-04 - val_accuracy: 0.9999 - val_recall: 0.9201\n",
      "Epoch 80/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.3302e-04 - accuracy: 1.0000 - recall: 0.9586\n",
      "Epoch 80: val_recall did not improve from 0.95569\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 3.3302e-04 - accuracy: 1.0000 - recall: 0.9586 - val_loss: 3.6948e-04 - val_accuracy: 0.9999 - val_recall: 0.9378\n",
      "Epoch 81/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.2430e-04 - accuracy: 1.0000 - recall: 0.9597\n",
      "Epoch 81: val_recall did not improve from 0.95569\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 3.2430e-04 - accuracy: 1.0000 - recall: 0.9597 - val_loss: 3.6904e-04 - val_accuracy: 0.9999 - val_recall: 0.9293\n",
      "Epoch 82/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.1333e-04 - accuracy: 1.0000 - recall: 0.9613\n",
      "Epoch 82: val_recall did not improve from 0.95569\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 3.1333e-04 - accuracy: 1.0000 - recall: 0.9613 - val_loss: 3.7953e-04 - val_accuracy: 0.9999 - val_recall: 0.9071\n",
      "Epoch 83/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.0875e-04 - accuracy: 1.0000 - recall: 0.9616\n",
      "Epoch 83: val_recall did not improve from 0.95569\n",
      "42/42 [==============================] - 13s 315ms/step - loss: 3.0875e-04 - accuracy: 1.0000 - recall: 0.9616 - val_loss: 3.7282e-04 - val_accuracy: 0.9999 - val_recall: 0.9136\n",
      "Epoch 84/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.0165e-04 - accuracy: 1.0000 - recall: 0.9602\n",
      "Epoch 84: val_recall did not improve from 0.95569\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 3.0165e-04 - accuracy: 1.0000 - recall: 0.9602 - val_loss: 3.5138e-04 - val_accuracy: 0.9999 - val_recall: 0.9244\n",
      "Epoch 85/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.8991e-04 - accuracy: 1.0000 - recall: 0.9639\n",
      "Epoch 85: val_recall did not improve from 0.95569\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 2.8991e-04 - accuracy: 1.0000 - recall: 0.9639 - val_loss: 3.6074e-04 - val_accuracy: 0.9999 - val_recall: 0.9099\n",
      "Epoch 86/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.8361e-04 - accuracy: 1.0000 - recall: 0.9633\n",
      "Epoch 86: val_recall did not improve from 0.95569\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 2.8361e-04 - accuracy: 1.0000 - recall: 0.9633 - val_loss: 3.4407e-04 - val_accuracy: 0.9999 - val_recall: 0.9226\n",
      "Epoch 87/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.7939e-04 - accuracy: 1.0000 - recall: 0.9629\n",
      "Epoch 87: val_recall did not improve from 0.95569\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.7939e-04 - accuracy: 1.0000 - recall: 0.9629 - val_loss: 3.5671e-04 - val_accuracy: 0.9999 - val_recall: 0.9155\n",
      "Epoch 88/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.7548e-04 - accuracy: 1.0000 - recall: 0.9624\n",
      "Epoch 88: val_recall did not improve from 0.95569\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.7548e-04 - accuracy: 1.0000 - recall: 0.9624 - val_loss: 3.2357e-04 - val_accuracy: 0.9999 - val_recall: 0.9376\n",
      "Epoch 89/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.9654e-04 - accuracy: 0.9999 - recall: 0.9557\n",
      "Epoch 89: val_recall did not improve from 0.95569\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 2.9654e-04 - accuracy: 0.9999 - recall: 0.9557 - val_loss: 0.0072 - val_accuracy: 0.9994 - val_recall: 0.0530\n",
      "Epoch 90/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 4.5568e-04 - accuracy: 0.9999 - recall: 0.9115\n",
      "Epoch 90: val_recall did not improve from 0.95569\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 4.5568e-04 - accuracy: 0.9999 - recall: 0.9115 - val_loss: 0.0014 - val_accuracy: 0.9998 - val_recall: 0.7861\n",
      "Epoch 91/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.5632e-04 - accuracy: 0.9999 - recall: 0.9375\n",
      "Epoch 91: val_recall did not improve from 0.95569\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 3.5632e-04 - accuracy: 0.9999 - recall: 0.9375 - val_loss: 3.9017e-04 - val_accuracy: 0.9999 - val_recall: 0.8845\n",
      "Epoch 92/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.0922e-04 - accuracy: 0.9999 - recall: 0.9469\n",
      "Epoch 92: val_recall did not improve from 0.95569\n",
      "42/42 [==============================] - 14s 322ms/step - loss: 3.0922e-04 - accuracy: 0.9999 - recall: 0.9469 - val_loss: 3.2804e-04 - val_accuracy: 0.9999 - val_recall: 0.9273\n",
      "Epoch 93/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.7393e-04 - accuracy: 1.0000 - recall: 0.9550\n",
      "Epoch 93: val_recall improved from 0.95569 to 0.95627, saving model to model_1fold.h5\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 2.7393e-04 - accuracy: 1.0000 - recall: 0.9550 - val_loss: 3.1657e-04 - val_accuracy: 0.9999 - val_recall: 0.9563\n",
      "Epoch 94/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.6227e-04 - accuracy: 1.0000 - recall: 0.9593\n",
      "Epoch 94: val_recall improved from 0.95627 to 0.96066, saving model to model_1fold.h5\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 2.6227e-04 - accuracy: 1.0000 - recall: 0.9593 - val_loss: 3.0618e-04 - val_accuracy: 0.9999 - val_recall: 0.9607\n",
      "Epoch 95/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.5053e-04 - accuracy: 1.0000 - recall: 0.9603\n",
      "Epoch 95: val_recall did not improve from 0.96066\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 2.5053e-04 - accuracy: 1.0000 - recall: 0.9603 - val_loss: 2.9951e-04 - val_accuracy: 0.9999 - val_recall: 0.9381\n",
      "Epoch 96/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.4592e-04 - accuracy: 1.0000 - recall: 0.9616\n",
      "Epoch 96: val_recall did not improve from 0.96066\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 2.4592e-04 - accuracy: 1.0000 - recall: 0.9616 - val_loss: 3.2371e-04 - val_accuracy: 0.9999 - val_recall: 0.9023\n",
      "Epoch 97/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.3644e-04 - accuracy: 1.0000 - recall: 0.9609\n",
      "Epoch 97: val_recall did not improve from 0.96066\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 2.3644e-04 - accuracy: 1.0000 - recall: 0.9609 - val_loss: 2.9703e-04 - val_accuracy: 0.9999 - val_recall: 0.9285\n",
      "Epoch 98/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.2946e-04 - accuracy: 1.0000 - recall: 0.9636\n",
      "Epoch 98: val_recall did not improve from 0.96066\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 2.2946e-04 - accuracy: 1.0000 - recall: 0.9636 - val_loss: 2.8624e-04 - val_accuracy: 0.9999 - val_recall: 0.9466\n",
      "Epoch 99/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.2525e-04 - accuracy: 1.0000 - recall: 0.9630\n",
      "Epoch 99: val_recall did not improve from 0.96066\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.2525e-04 - accuracy: 1.0000 - recall: 0.9630 - val_loss: 2.9394e-04 - val_accuracy: 0.9999 - val_recall: 0.9175\n",
      "Epoch 100/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.1622e-04 - accuracy: 1.0000 - recall: 0.9655\n",
      "Epoch 100: val_recall did not improve from 0.96066\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.1622e-04 - accuracy: 1.0000 - recall: 0.9655 - val_loss: 2.8064e-04 - val_accuracy: 0.9999 - val_recall: 0.9455\n",
      "Epoch 101/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.1743e-04 - accuracy: 1.0000 - recall: 0.9627\n",
      "Epoch 101: val_recall did not improve from 0.96066\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.1743e-04 - accuracy: 1.0000 - recall: 0.9627 - val_loss: 2.7675e-04 - val_accuracy: 0.9999 - val_recall: 0.9537\n",
      "Epoch 102/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.0861e-04 - accuracy: 1.0000 - recall: 0.9657\n",
      "Epoch 102: val_recall did not improve from 0.96066\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 2.0861e-04 - accuracy: 1.0000 - recall: 0.9657 - val_loss: 2.7542e-04 - val_accuracy: 0.9999 - val_recall: 0.9445\n",
      "Epoch 103/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.0528e-04 - accuracy: 1.0000 - recall: 0.9667\n",
      "Epoch 103: val_recall did not improve from 0.96066\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 2.0528e-04 - accuracy: 1.0000 - recall: 0.9667 - val_loss: 3.1919e-04 - val_accuracy: 0.9999 - val_recall: 0.8935\n",
      "Epoch 104/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.0052e-04 - accuracy: 1.0000 - recall: 0.9662\n",
      "Epoch 104: val_recall improved from 0.96066 to 0.96083, saving model to model_1fold.h5\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 2.0052e-04 - accuracy: 1.0000 - recall: 0.9662 - val_loss: 2.7007e-04 - val_accuracy: 0.9999 - val_recall: 0.9608\n",
      "Epoch 105/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.9875e-04 - accuracy: 1.0000 - recall: 0.9654\n",
      "Epoch 105: val_recall did not improve from 0.96083\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 1.9875e-04 - accuracy: 1.0000 - recall: 0.9654 - val_loss: 2.6427e-04 - val_accuracy: 0.9999 - val_recall: 0.9500\n",
      "Epoch 106/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.9704e-04 - accuracy: 1.0000 - recall: 0.9646\n",
      "Epoch 106: val_recall improved from 0.96083 to 0.96648, saving model to model_1fold.h5\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 1.9704e-04 - accuracy: 1.0000 - recall: 0.9646 - val_loss: 2.6787e-04 - val_accuracy: 0.9999 - val_recall: 0.9665\n",
      "Epoch 107/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.8916e-04 - accuracy: 1.0000 - recall: 0.9692\n",
      "Epoch 107: val_recall did not improve from 0.96648\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 1.8916e-04 - accuracy: 1.0000 - recall: 0.9692 - val_loss: 2.7819e-04 - val_accuracy: 0.9999 - val_recall: 0.9228\n",
      "Epoch 108/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.8325e-04 - accuracy: 1.0000 - recall: 0.9683\n",
      "Epoch 108: val_recall did not improve from 0.96648\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 1.8325e-04 - accuracy: 1.0000 - recall: 0.9683 - val_loss: 2.5967e-04 - val_accuracy: 0.9999 - val_recall: 0.9478\n",
      "Epoch 109/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.8107e-04 - accuracy: 1.0000 - recall: 0.9693\n",
      "Epoch 109: val_recall improved from 0.96648 to 0.96935, saving model to model_1fold.h5\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 1.8107e-04 - accuracy: 1.0000 - recall: 0.9693 - val_loss: 2.6479e-04 - val_accuracy: 0.9999 - val_recall: 0.9693\n",
      "Epoch 110/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.7467e-04 - accuracy: 1.0000 - recall: 0.9690\n",
      "Epoch 110: val_recall did not improve from 0.96935\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 1.7467e-04 - accuracy: 1.0000 - recall: 0.9690 - val_loss: 2.5754e-04 - val_accuracy: 0.9999 - val_recall: 0.9406\n",
      "Epoch 111/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.7577e-04 - accuracy: 1.0000 - recall: 0.9691\n",
      "Epoch 111: val_recall did not improve from 0.96935\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 1.7577e-04 - accuracy: 1.0000 - recall: 0.9691 - val_loss: 2.6279e-04 - val_accuracy: 0.9999 - val_recall: 0.9407\n",
      "Epoch 112/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.6899e-04 - accuracy: 1.0000 - recall: 0.9697\n",
      "Epoch 112: val_recall did not improve from 0.96935\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 1.6899e-04 - accuracy: 1.0000 - recall: 0.9697 - val_loss: 2.6016e-04 - val_accuracy: 0.9999 - val_recall: 0.9323\n",
      "Epoch 113/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.7006e-04 - accuracy: 1.0000 - recall: 0.9683\n",
      "Epoch 113: val_recall did not improve from 0.96935\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.7006e-04 - accuracy: 1.0000 - recall: 0.9683 - val_loss: 2.5953e-04 - val_accuracy: 0.9999 - val_recall: 0.9479\n",
      "Epoch 114/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.7295e-04 - accuracy: 1.0000 - recall: 0.9681\n",
      "Epoch 114: val_recall did not improve from 0.96935\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 1.7295e-04 - accuracy: 1.0000 - recall: 0.9681 - val_loss: 2.5053e-04 - val_accuracy: 0.9999 - val_recall: 0.9612\n",
      "Epoch 115/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.5876e-04 - accuracy: 1.0000 - recall: 0.9716\n",
      "Epoch 115: val_recall did not improve from 0.96935\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 1.5876e-04 - accuracy: 1.0000 - recall: 0.9716 - val_loss: 2.5128e-04 - val_accuracy: 0.9999 - val_recall: 0.9407\n",
      "Epoch 116/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.6010e-04 - accuracy: 1.0000 - recall: 0.9703\n",
      "Epoch 116: val_recall did not improve from 0.96935\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.6010e-04 - accuracy: 1.0000 - recall: 0.9703 - val_loss: 2.4108e-04 - val_accuracy: 0.9999 - val_recall: 0.9558\n",
      "Epoch 117/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.5439e-04 - accuracy: 1.0000 - recall: 0.9717\n",
      "Epoch 117: val_recall did not improve from 0.96935\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.5439e-04 - accuracy: 1.0000 - recall: 0.9717 - val_loss: 2.4738e-04 - val_accuracy: 0.9999 - val_recall: 0.9650\n",
      "Epoch 118/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.5223e-04 - accuracy: 1.0000 - recall: 0.9713\n",
      "Epoch 118: val_recall did not improve from 0.96935\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 1.5223e-04 - accuracy: 1.0000 - recall: 0.9713 - val_loss: 2.3920e-04 - val_accuracy: 0.9999 - val_recall: 0.9470\n",
      "Epoch 119/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.5079e-04 - accuracy: 1.0000 - recall: 0.9721\n",
      "Epoch 119: val_recall did not improve from 0.96935\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 1.5079e-04 - accuracy: 1.0000 - recall: 0.9721 - val_loss: 2.8834e-04 - val_accuracy: 0.9999 - val_recall: 0.9005\n",
      "Epoch 120/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.5194e-04 - accuracy: 1.0000 - recall: 0.9705\n",
      "Epoch 120: val_recall did not improve from 0.96935\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.5194e-04 - accuracy: 1.0000 - recall: 0.9705 - val_loss: 2.5747e-04 - val_accuracy: 0.9999 - val_recall: 0.9572\n",
      "Epoch 121/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.4506e-04 - accuracy: 1.0000 - recall: 0.9722\n",
      "Epoch 121: val_recall did not improve from 0.96935\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 1.4506e-04 - accuracy: 1.0000 - recall: 0.9722 - val_loss: 2.5795e-04 - val_accuracy: 0.9999 - val_recall: 0.9686\n",
      "Epoch 122/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.4397e-04 - accuracy: 1.0000 - recall: 0.9726\n",
      "Epoch 122: val_recall did not improve from 0.96935\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 1.4397e-04 - accuracy: 1.0000 - recall: 0.9726 - val_loss: 2.5166e-04 - val_accuracy: 0.9999 - val_recall: 0.9379\n",
      "Epoch 123/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.4233e-04 - accuracy: 1.0000 - recall: 0.9714\n",
      "Epoch 123: val_recall improved from 0.96935 to 0.97033, saving model to model_1fold.h5\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 1.4233e-04 - accuracy: 1.0000 - recall: 0.9714 - val_loss: 2.4383e-04 - val_accuracy: 0.9999 - val_recall: 0.9703\n",
      "Epoch 124/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.4095e-04 - accuracy: 1.0000 - recall: 0.9726\n",
      "Epoch 124: val_recall did not improve from 0.97033\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.4095e-04 - accuracy: 1.0000 - recall: 0.9726 - val_loss: 2.4369e-04 - val_accuracy: 0.9999 - val_recall: 0.9460\n",
      "Epoch 125/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.3583e-04 - accuracy: 1.0000 - recall: 0.9736\n",
      "Epoch 125: val_recall did not improve from 0.97033\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.3583e-04 - accuracy: 1.0000 - recall: 0.9736 - val_loss: 2.3961e-04 - val_accuracy: 0.9999 - val_recall: 0.9633\n",
      "Epoch 126/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.3488e-04 - accuracy: 1.0000 - recall: 0.9732\n",
      "Epoch 126: val_recall did not improve from 0.97033\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 1.3488e-04 - accuracy: 1.0000 - recall: 0.9732 - val_loss: 2.6060e-04 - val_accuracy: 0.9999 - val_recall: 0.9206\n",
      "Epoch 127/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.3644e-04 - accuracy: 1.0000 - recall: 0.9719\n",
      "Epoch 127: val_recall did not improve from 0.97033\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 1.3644e-04 - accuracy: 1.0000 - recall: 0.9719 - val_loss: 2.6673e-04 - val_accuracy: 0.9999 - val_recall: 0.9194\n",
      "Epoch 128/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.2889e-04 - accuracy: 1.0000 - recall: 0.9753\n",
      "Epoch 128: val_recall did not improve from 0.97033\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 1.2889e-04 - accuracy: 1.0000 - recall: 0.9753 - val_loss: 2.3853e-04 - val_accuracy: 0.9999 - val_recall: 0.9440\n",
      "Epoch 129/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.2811e-04 - accuracy: 1.0000 - recall: 0.9745\n",
      "Epoch 129: val_recall did not improve from 0.97033\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 1.2811e-04 - accuracy: 1.0000 - recall: 0.9745 - val_loss: 2.4352e-04 - val_accuracy: 0.9999 - val_recall: 0.9564\n",
      "Epoch 130/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.2728e-04 - accuracy: 1.0000 - recall: 0.9737\n",
      "Epoch 130: val_recall did not improve from 0.97033\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 1.2728e-04 - accuracy: 1.0000 - recall: 0.9737 - val_loss: 2.3625e-04 - val_accuracy: 0.9999 - val_recall: 0.9542\n",
      "Epoch 131/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.2031e-04 - accuracy: 1.0000 - recall: 0.9762\n",
      "Epoch 131: val_recall did not improve from 0.97033\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.2031e-04 - accuracy: 1.0000 - recall: 0.9762 - val_loss: 2.3647e-04 - val_accuracy: 0.9999 - val_recall: 0.9539\n",
      "Epoch 132/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.2410e-04 - accuracy: 1.0000 - recall: 0.9741\n",
      "Epoch 132: val_recall did not improve from 0.97033\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.2410e-04 - accuracy: 1.0000 - recall: 0.9741 - val_loss: 2.4517e-04 - val_accuracy: 0.9999 - val_recall: 0.9502\n",
      "Epoch 133/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.2169e-04 - accuracy: 1.0000 - recall: 0.9758\n",
      "Epoch 133: val_recall did not improve from 0.97033\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 1.2169e-04 - accuracy: 1.0000 - recall: 0.9758 - val_loss: 2.4306e-04 - val_accuracy: 0.9999 - val_recall: 0.9528\n",
      "Epoch 134/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.1581e-04 - accuracy: 1.0000 - recall: 0.9752\n",
      "Epoch 134: val_recall did not improve from 0.97033\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 1.1581e-04 - accuracy: 1.0000 - recall: 0.9752 - val_loss: 2.3588e-04 - val_accuracy: 0.9999 - val_recall: 0.9621\n",
      "Epoch 135/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.1601e-04 - accuracy: 1.0000 - recall: 0.9762\n",
      "Epoch 135: val_recall did not improve from 0.97033\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 1.1601e-04 - accuracy: 1.0000 - recall: 0.9762 - val_loss: 2.4984e-04 - val_accuracy: 0.9999 - val_recall: 0.9654\n",
      "Epoch 136/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.1229e-04 - accuracy: 1.0000 - recall: 0.9772\n",
      "Epoch 136: val_recall did not improve from 0.97033\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 1.1229e-04 - accuracy: 1.0000 - recall: 0.9772 - val_loss: 2.3950e-04 - val_accuracy: 0.9999 - val_recall: 0.9533\n",
      "Epoch 137/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.0869e-04 - accuracy: 1.0000 - recall: 0.9778\n",
      "Epoch 137: val_recall did not improve from 0.97033\n",
      "42/42 [==============================] - 14s 326ms/step - loss: 1.0869e-04 - accuracy: 1.0000 - recall: 0.9778 - val_loss: 2.3874e-04 - val_accuracy: 0.9999 - val_recall: 0.9501\n",
      "Epoch 138/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.0671e-04 - accuracy: 1.0000 - recall: 0.9775\n",
      "Epoch 138: val_recall did not improve from 0.97033\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 1.0671e-04 - accuracy: 1.0000 - recall: 0.9775 - val_loss: 2.4874e-04 - val_accuracy: 0.9999 - val_recall: 0.9388\n",
      "Epoch 139/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.0918e-04 - accuracy: 1.0000 - recall: 0.9771\n",
      "Epoch 139: val_recall did not improve from 0.97033\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.0918e-04 - accuracy: 1.0000 - recall: 0.9771 - val_loss: 2.3794e-04 - val_accuracy: 0.9999 - val_recall: 0.9480\n",
      "Epoch 140/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.0631e-04 - accuracy: 1.0000 - recall: 0.9764\n",
      "Epoch 140: val_recall did not improve from 0.97033\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.0631e-04 - accuracy: 1.0000 - recall: 0.9764 - val_loss: 2.3476e-04 - val_accuracy: 0.9999 - val_recall: 0.9684\n",
      "Epoch 141/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.0319e-04 - accuracy: 1.0000 - recall: 0.9785\n",
      "Epoch 141: val_recall improved from 0.97033 to 0.97074, saving model to model_1fold.h5\n",
      "42/42 [==============================] - 13s 321ms/step - loss: 1.0319e-04 - accuracy: 1.0000 - recall: 0.9785 - val_loss: 2.3397e-04 - val_accuracy: 0.9999 - val_recall: 0.9707\n",
      "Epoch 142/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 9.9802e-05 - accuracy: 1.0000 - recall: 0.9794\n",
      "Epoch 142: val_recall did not improve from 0.97074\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 9.9802e-05 - accuracy: 1.0000 - recall: 0.9794 - val_loss: 2.4282e-04 - val_accuracy: 0.9999 - val_recall: 0.9490\n",
      "Epoch 143/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 9.8015e-05 - accuracy: 1.0000 - recall: 0.9789\n",
      "Epoch 143: val_recall did not improve from 0.97074\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 9.8015e-05 - accuracy: 1.0000 - recall: 0.9789 - val_loss: 2.4569e-04 - val_accuracy: 0.9999 - val_recall: 0.9374\n",
      "Epoch 144/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.0013e-04 - accuracy: 1.0000 - recall: 0.9780\n",
      "Epoch 144: val_recall improved from 0.97074 to 0.97115, saving model to model_1fold.h5\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 1.0013e-04 - accuracy: 1.0000 - recall: 0.9780 - val_loss: 2.4274e-04 - val_accuracy: 0.9999 - val_recall: 0.9712\n",
      "Epoch 145/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 9.6808e-05 - accuracy: 1.0000 - recall: 0.9791\n",
      "Epoch 145: val_recall did not improve from 0.97115\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 9.6808e-05 - accuracy: 1.0000 - recall: 0.9791 - val_loss: 2.4002e-04 - val_accuracy: 0.9999 - val_recall: 0.9691\n",
      "Epoch 146/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 9.5074e-05 - accuracy: 1.0000 - recall: 0.9787\n",
      "Epoch 146: val_recall did not improve from 0.97115\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 9.5074e-05 - accuracy: 1.0000 - recall: 0.9787 - val_loss: 2.4221e-04 - val_accuracy: 0.9999 - val_recall: 0.9648\n",
      "Epoch 147/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 9.2086e-05 - accuracy: 1.0000 - recall: 0.9800\n",
      "Epoch 147: val_recall did not improve from 0.97115\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 9.2086e-05 - accuracy: 1.0000 - recall: 0.9800 - val_loss: 2.3667e-04 - val_accuracy: 0.9999 - val_recall: 0.9583\n",
      "Epoch 148/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 9.1510e-05 - accuracy: 1.0000 - recall: 0.9812\n",
      "Epoch 148: val_recall did not improve from 0.97115\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 9.1510e-05 - accuracy: 1.0000 - recall: 0.9812 - val_loss: 2.4980e-04 - val_accuracy: 0.9999 - val_recall: 0.9363\n",
      "Epoch 149/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 9.0034e-05 - accuracy: 1.0000 - recall: 0.9792\n",
      "Epoch 149: val_recall did not improve from 0.97115\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 9.0034e-05 - accuracy: 1.0000 - recall: 0.9792 - val_loss: 2.4405e-04 - val_accuracy: 0.9999 - val_recall: 0.9654\n",
      "Epoch 150/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 9.1181e-05 - accuracy: 1.0000 - recall: 0.9794\n",
      "Epoch 150: val_recall improved from 0.97115 to 0.97680, saving model to model_1fold.h5\n",
      "42/42 [==============================] - 13s 321ms/step - loss: 9.1181e-05 - accuracy: 1.0000 - recall: 0.9794 - val_loss: 2.4947e-04 - val_accuracy: 0.9999 - val_recall: 0.9768\n",
      "Epoch 151/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 8.7658e-05 - accuracy: 1.0000 - recall: 0.9810\n",
      "Epoch 151: val_recall did not improve from 0.97680\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 8.7658e-05 - accuracy: 1.0000 - recall: 0.9810 - val_loss: 2.3832e-04 - val_accuracy: 0.9999 - val_recall: 0.9630\n",
      "Epoch 152/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 8.9057e-05 - accuracy: 1.0000 - recall: 0.9799\n",
      "Epoch 152: val_recall did not improve from 0.97680\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 8.9057e-05 - accuracy: 1.0000 - recall: 0.9799 - val_loss: 2.3615e-04 - val_accuracy: 0.9999 - val_recall: 0.9491\n",
      "Epoch 153/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 8.4621e-05 - accuracy: 1.0000 - recall: 0.9817\n",
      "Epoch 153: val_recall did not improve from 0.97680\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 8.4621e-05 - accuracy: 1.0000 - recall: 0.9817 - val_loss: 2.3315e-04 - val_accuracy: 0.9999 - val_recall: 0.9572\n",
      "Epoch 154/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 8.5122e-05 - accuracy: 1.0000 - recall: 0.9810\n",
      "Epoch 154: val_recall did not improve from 0.97680\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 8.5122e-05 - accuracy: 1.0000 - recall: 0.9810 - val_loss: 2.4451e-04 - val_accuracy: 0.9999 - val_recall: 0.9381\n",
      "Epoch 155/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 8.2648e-05 - accuracy: 1.0000 - recall: 0.9819\n",
      "Epoch 155: val_recall did not improve from 0.97680\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 8.2648e-05 - accuracy: 1.0000 - recall: 0.9819 - val_loss: 2.4249e-04 - val_accuracy: 0.9999 - val_recall: 0.9461\n",
      "Epoch 156/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 8.1077e-05 - accuracy: 1.0000 - recall: 0.9817\n",
      "Epoch 156: val_recall did not improve from 0.97680\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 8.1077e-05 - accuracy: 1.0000 - recall: 0.9817 - val_loss: 2.5523e-04 - val_accuracy: 0.9999 - val_recall: 0.9429\n",
      "Epoch 157/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 8.0834e-05 - accuracy: 1.0000 - recall: 0.9818\n",
      "Epoch 157: val_recall did not improve from 0.97680\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 8.0834e-05 - accuracy: 1.0000 - recall: 0.9818 - val_loss: 2.5856e-04 - val_accuracy: 0.9999 - val_recall: 0.9417\n",
      "Epoch 158/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 8.0064e-05 - accuracy: 1.0000 - recall: 0.9808\n",
      "Epoch 158: val_recall did not improve from 0.97680\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 8.0064e-05 - accuracy: 1.0000 - recall: 0.9808 - val_loss: 2.4579e-04 - val_accuracy: 0.9999 - val_recall: 0.9520\n",
      "Epoch 159/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 7.7783e-05 - accuracy: 1.0000 - recall: 0.9823\n",
      "Epoch 159: val_recall did not improve from 0.97680\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 7.7783e-05 - accuracy: 1.0000 - recall: 0.9823 - val_loss: 2.4884e-04 - val_accuracy: 0.9999 - val_recall: 0.9530\n",
      "Epoch 160/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 7.6426e-05 - accuracy: 1.0000 - recall: 0.9822\n",
      "Epoch 160: val_recall did not improve from 0.97680\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 7.6426e-05 - accuracy: 1.0000 - recall: 0.9822 - val_loss: 2.4782e-04 - val_accuracy: 0.9999 - val_recall: 0.9494\n",
      "Epoch 161/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 7.6134e-05 - accuracy: 1.0000 - recall: 0.9825\n",
      "Epoch 161: val_recall did not improve from 0.97680\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 7.6134e-05 - accuracy: 1.0000 - recall: 0.9825 - val_loss: 2.4896e-04 - val_accuracy: 0.9999 - val_recall: 0.9561\n",
      "Epoch 162/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 7.2093e-05 - accuracy: 1.0000 - recall: 0.9838\n",
      "Epoch 162: val_recall did not improve from 0.97680\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 7.2093e-05 - accuracy: 1.0000 - recall: 0.9838 - val_loss: 2.7394e-04 - val_accuracy: 0.9999 - val_recall: 0.9346\n",
      "Epoch 163/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 7.3410e-05 - accuracy: 1.0000 - recall: 0.9835\n",
      "Epoch 163: val_recall did not improve from 0.97680\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 7.3410e-05 - accuracy: 1.0000 - recall: 0.9835 - val_loss: 2.6595e-04 - val_accuracy: 0.9999 - val_recall: 0.9416\n",
      "Epoch 164/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 7.1664e-05 - accuracy: 1.0000 - recall: 0.9830\n",
      "Epoch 164: val_recall did not improve from 0.97680\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 7.1664e-05 - accuracy: 1.0000 - recall: 0.9830 - val_loss: 2.5781e-04 - val_accuracy: 0.9999 - val_recall: 0.9649\n",
      "Epoch 165/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 6.9835e-05 - accuracy: 1.0000 - recall: 0.9846\n",
      "Epoch 165: val_recall did not improve from 0.97680\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 6.9835e-05 - accuracy: 1.0000 - recall: 0.9846 - val_loss: 2.6738e-04 - val_accuracy: 0.9999 - val_recall: 0.9631\n",
      "Epoch 166/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 6.9462e-05 - accuracy: 1.0000 - recall: 0.9839\n",
      "Epoch 166: val_recall did not improve from 0.97680\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 6.9462e-05 - accuracy: 1.0000 - recall: 0.9839 - val_loss: 2.6729e-04 - val_accuracy: 0.9999 - val_recall: 0.9471\n",
      "Epoch 167/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 7.0589e-05 - accuracy: 1.0000 - recall: 0.9834\n",
      "Epoch 167: val_recall did not improve from 0.97680\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 7.0589e-05 - accuracy: 1.0000 - recall: 0.9834 - val_loss: 2.4850e-04 - val_accuracy: 0.9999 - val_recall: 0.9563\n",
      "Epoch 168/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 6.8015e-05 - accuracy: 1.0000 - recall: 0.9842\n",
      "Epoch 168: val_recall did not improve from 0.97680\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 6.8015e-05 - accuracy: 1.0000 - recall: 0.9842 - val_loss: 2.5243e-04 - val_accuracy: 0.9999 - val_recall: 0.9343\n",
      "Epoch 169/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 6.7365e-05 - accuracy: 1.0000 - recall: 0.9844\n",
      "Epoch 169: val_recall did not improve from 0.97680\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 6.7365e-05 - accuracy: 1.0000 - recall: 0.9844 - val_loss: 2.5522e-04 - val_accuracy: 0.9999 - val_recall: 0.9463\n",
      "Epoch 170/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 6.6744e-05 - accuracy: 1.0000 - recall: 0.9843\n",
      "Epoch 170: val_recall did not improve from 0.97680\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 6.6744e-05 - accuracy: 1.0000 - recall: 0.9843 - val_loss: 2.3905e-04 - val_accuracy: 0.9999 - val_recall: 0.9533\n",
      "Epoch 171/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 6.5242e-05 - accuracy: 1.0000 - recall: 0.9851\n",
      "Epoch 171: val_recall did not improve from 0.97680\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 6.5242e-05 - accuracy: 1.0000 - recall: 0.9851 - val_loss: 2.5721e-04 - val_accuracy: 0.9999 - val_recall: 0.9659\n",
      "Epoch 172/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 6.3962e-05 - accuracy: 1.0000 - recall: 0.9850\n",
      "Epoch 172: val_recall did not improve from 0.97680\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 6.3962e-05 - accuracy: 1.0000 - recall: 0.9850 - val_loss: 2.6700e-04 - val_accuracy: 0.9999 - val_recall: 0.9521\n",
      "Epoch 173/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 6.2868e-05 - accuracy: 1.0000 - recall: 0.9849\n",
      "Epoch 173: val_recall did not improve from 0.97680\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 6.2868e-05 - accuracy: 1.0000 - recall: 0.9849 - val_loss: 2.6541e-04 - val_accuracy: 0.9999 - val_recall: 0.9618\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mbouzon/miniconda3/envs/tf/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.4819 - accuracy: 0.8929 - recall: 0.1821\n",
      "Epoch 1: val_recall improved from -inf to 0.01954, saving model to model_2fold.h5\n",
      "42/42 [==============================] - 15s 327ms/step - loss: 0.4819 - accuracy: 0.8929 - recall: 0.1821 - val_loss: 0.2289 - val_accuracy: 0.9831 - val_recall: 0.0195\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2139 - accuracy: 0.9977 - recall: 7.6470e-04\n",
      "Epoch 2: val_recall did not improve from 0.01954\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 0.2139 - accuracy: 0.9977 - recall: 7.6470e-04 - val_loss: 0.2280 - val_accuracy: 0.9986 - val_recall: 0.0000e+00\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1341 - accuracy: 0.9992 - recall: 0.0000e+00\n",
      "Epoch 3: val_recall did not improve from 0.01954\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.1341 - accuracy: 0.9992 - recall: 0.0000e+00 - val_loss: 0.1960 - val_accuracy: 0.9990 - val_recall: 0.0000e+00\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0934 - accuracy: 0.9993 - recall: 0.0000e+00\n",
      "Epoch 4: val_recall did not improve from 0.01954\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0934 - accuracy: 0.9993 - recall: 0.0000e+00 - val_loss: 0.1412 - val_accuracy: 0.9993 - val_recall: 0.0000e+00\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0687 - accuracy: 0.9994 - recall: 0.0000e+00\n",
      "Epoch 5: val_recall did not improve from 0.01954\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 0.0687 - accuracy: 0.9994 - recall: 0.0000e+00 - val_loss: 0.0931 - val_accuracy: 0.9993 - val_recall: 0.0000e+00\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0510 - accuracy: 0.9994 - recall: 0.1210\n",
      "Epoch 6: val_recall did not improve from 0.01954\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 0.0510 - accuracy: 0.9994 - recall: 0.1210 - val_loss: 0.0655 - val_accuracy: 0.9993 - val_recall: 0.0000e+00\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0390 - accuracy: 0.9994 - recall: 0.3135\n",
      "Epoch 7: val_recall did not improve from 0.01954\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 0.0390 - accuracy: 0.9994 - recall: 0.3135 - val_loss: 0.0502 - val_accuracy: 0.9993 - val_recall: 0.0000e+00\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0304 - accuracy: 0.9996 - recall: 0.5087\n",
      "Epoch 8: val_recall did not improve from 0.01954\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 0.0304 - accuracy: 0.9996 - recall: 0.5087 - val_loss: 0.0380 - val_accuracy: 0.9993 - val_recall: 0.0000e+00\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0243 - accuracy: 0.9997 - recall: 0.6194\n",
      "Epoch 9: val_recall did not improve from 0.01954\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 0.0243 - accuracy: 0.9997 - recall: 0.6194 - val_loss: 0.0302 - val_accuracy: 0.9993 - val_recall: 0.0000e+00\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0198 - accuracy: 0.9997 - recall: 0.7099\n",
      "Epoch 10: val_recall did not improve from 0.01954\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 0.0198 - accuracy: 0.9997 - recall: 0.7099 - val_loss: 0.0237 - val_accuracy: 0.9993 - val_recall: 0.0000e+00\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0165 - accuracy: 0.9997 - recall: 0.7432\n",
      "Epoch 11: val_recall did not improve from 0.01954\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 0.0165 - accuracy: 0.9997 - recall: 0.7432 - val_loss: 0.0198 - val_accuracy: 0.9993 - val_recall: 1.6995e-04\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 0.9998 - recall: 0.7596\n",
      "Epoch 12: val_recall did not improve from 0.01954\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 0.0138 - accuracy: 0.9998 - recall: 0.7596 - val_loss: 0.0171 - val_accuracy: 0.9993 - val_recall: 0.0047\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 0.9998 - recall: 0.8037\n",
      "Epoch 13: val_recall improved from 0.01954 to 0.03117, saving model to model_2fold.h5\n",
      "42/42 [==============================] - 13s 321ms/step - loss: 0.0116 - accuracy: 0.9998 - recall: 0.8037 - val_loss: 0.0137 - val_accuracy: 0.9994 - val_recall: 0.0312\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 0.9998 - recall: 0.8072\n",
      "Epoch 14: val_recall improved from 0.03117 to 0.07117, saving model to model_2fold.h5\n",
      "42/42 [==============================] - 13s 322ms/step - loss: 0.0099 - accuracy: 0.9998 - recall: 0.8072 - val_loss: 0.0115 - val_accuracy: 0.9994 - val_recall: 0.0712\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 0.9998 - recall: 0.8378\n",
      "Epoch 15: val_recall improved from 0.07117 to 0.35057, saving model to model_2fold.h5\n",
      "42/42 [==============================] - 13s 322ms/step - loss: 0.0085 - accuracy: 0.9998 - recall: 0.8378 - val_loss: 0.0088 - val_accuracy: 0.9996 - val_recall: 0.3506\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 0.9998 - recall: 0.8427\n",
      "Epoch 16: val_recall did not improve from 0.35057\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 0.0075 - accuracy: 0.9998 - recall: 0.8427 - val_loss: 0.0079 - val_accuracy: 0.9995 - val_recall: 0.2551\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 0.9999 - recall: 0.8569\n",
      "Epoch 17: val_recall improved from 0.35057 to 0.39281, saving model to model_2fold.h5\n",
      "42/42 [==============================] - 13s 321ms/step - loss: 0.0066 - accuracy: 0.9999 - recall: 0.8569 - val_loss: 0.0066 - val_accuracy: 0.9996 - val_recall: 0.3928\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 0.9999 - recall: 0.8689\n",
      "Epoch 18: val_recall improved from 0.39281 to 0.63659, saving model to model_2fold.h5\n",
      "42/42 [==============================] - 13s 321ms/step - loss: 0.0059 - accuracy: 0.9999 - recall: 0.8689 - val_loss: 0.0055 - val_accuracy: 0.9998 - val_recall: 0.6366\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 0.9999 - recall: 0.8580\n",
      "Epoch 19: val_recall improved from 0.63659 to 0.64994, saving model to model_2fold.h5\n",
      "42/42 [==============================] - 13s 322ms/step - loss: 0.0053 - accuracy: 0.9999 - recall: 0.8580 - val_loss: 0.0042 - val_accuracy: 0.9998 - val_recall: 0.6499\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9999 - recall: 0.8817\n",
      "Epoch 20: val_recall improved from 0.64994 to 0.78519, saving model to model_2fold.h5\n",
      "42/42 [==============================] - 13s 322ms/step - loss: 0.0047 - accuracy: 0.9999 - recall: 0.8817 - val_loss: 0.0038 - val_accuracy: 0.9998 - val_recall: 0.7852\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 0.9999 - recall: 0.8785\n",
      "Epoch 21: val_recall improved from 0.78519 to 0.86370, saving model to model_2fold.h5\n",
      "42/42 [==============================] - 13s 321ms/step - loss: 0.0042 - accuracy: 0.9999 - recall: 0.8785 - val_loss: 0.0035 - val_accuracy: 0.9999 - val_recall: 0.8637\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9999 - recall: 0.8917\n",
      "Epoch 22: val_recall did not improve from 0.86370\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0039 - accuracy: 0.9999 - recall: 0.8917 - val_loss: 0.0034 - val_accuracy: 0.9998 - val_recall: 0.6650\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9999 - recall: 0.8919\n",
      "Epoch 23: val_recall did not improve from 0.86370\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0035 - accuracy: 0.9999 - recall: 0.8919 - val_loss: 0.0032 - val_accuracy: 0.9998 - val_recall: 0.6587\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9999 - recall: 0.9041\n",
      "Epoch 24: val_recall did not improve from 0.86370\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 0.0032 - accuracy: 0.9999 - recall: 0.9041 - val_loss: 0.0028 - val_accuracy: 0.9999 - val_recall: 0.8145\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9999 - recall: 0.9043\n",
      "Epoch 25: val_recall did not improve from 0.86370\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 0.0030 - accuracy: 0.9999 - recall: 0.9043 - val_loss: 0.0026 - val_accuracy: 0.9999 - val_recall: 0.7925\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9999 - recall: 0.9077\n",
      "Epoch 26: val_recall improved from 0.86370 to 0.93192, saving model to model_2fold.h5\n",
      "42/42 [==============================] - 13s 321ms/step - loss: 0.0028 - accuracy: 0.9999 - recall: 0.9077 - val_loss: 0.0024 - val_accuracy: 0.9999 - val_recall: 0.9319\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9999 - recall: 0.9118\n",
      "Epoch 27: val_recall did not improve from 0.93192\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 0.0026 - accuracy: 0.9999 - recall: 0.9118 - val_loss: 0.0025 - val_accuracy: 0.9998 - val_recall: 0.6825\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9999 - recall: 0.9011\n",
      "Epoch 28: val_recall did not improve from 0.93192\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0025 - accuracy: 0.9999 - recall: 0.9011 - val_loss: 0.0021 - val_accuracy: 0.9999 - val_recall: 0.8666\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9999 - recall: 0.9070\n",
      "Epoch 29: val_recall did not improve from 0.93192\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 0.0023 - accuracy: 0.9999 - recall: 0.9070 - val_loss: 0.0019 - val_accuracy: 0.9999 - val_recall: 0.8563\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9999 - recall: 0.9222\n",
      "Epoch 30: val_recall did not improve from 0.93192\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 0.0021 - accuracy: 0.9999 - recall: 0.9222 - val_loss: 0.0018 - val_accuracy: 0.9999 - val_recall: 0.8811\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9999 - recall: 0.9091\n",
      "Epoch 31: val_recall did not improve from 0.93192\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0020 - accuracy: 0.9999 - recall: 0.9091 - val_loss: 0.0017 - val_accuracy: 0.9999 - val_recall: 0.8784\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9999 - recall: 0.9161\n",
      "Epoch 32: val_recall did not improve from 0.93192\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 0.0019 - accuracy: 0.9999 - recall: 0.9161 - val_loss: 0.0017 - val_accuracy: 0.9999 - val_recall: 0.8203\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9999 - recall: 0.9242\n",
      "Epoch 33: val_recall did not improve from 0.93192\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 0.0018 - accuracy: 0.9999 - recall: 0.9242 - val_loss: 0.0015 - val_accuracy: 0.9999 - val_recall: 0.9151\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9999 - recall: 0.9310\n",
      "Epoch 34: val_recall did not improve from 0.93192\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0017 - accuracy: 0.9999 - recall: 0.9310 - val_loss: 0.0014 - val_accuracy: 0.9999 - val_recall: 0.8770\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9999 - recall: 0.9290\n",
      "Epoch 35: val_recall did not improve from 0.93192\n",
      "42/42 [==============================] - 13s 314ms/step - loss: 0.0016 - accuracy: 0.9999 - recall: 0.9290 - val_loss: 0.0013 - val_accuracy: 0.9999 - val_recall: 0.9101\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9999 - recall: 0.9363\n",
      "Epoch 36: val_recall did not improve from 0.93192\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0015 - accuracy: 0.9999 - recall: 0.9363 - val_loss: 0.0014 - val_accuracy: 0.9999 - val_recall: 0.8671\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9999 - recall: 0.9256\n",
      "Epoch 37: val_recall did not improve from 0.93192\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0014 - accuracy: 0.9999 - recall: 0.9256 - val_loss: 0.0012 - val_accuracy: 0.9999 - val_recall: 0.9259\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9999 - recall: 0.9279\n",
      "Epoch 38: val_recall did not improve from 0.93192\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 0.0014 - accuracy: 0.9999 - recall: 0.9279 - val_loss: 0.0013 - val_accuracy: 0.9999 - val_recall: 0.8317\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9999 - recall: 0.9370\n",
      "Epoch 39: val_recall did not improve from 0.93192\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0013 - accuracy: 0.9999 - recall: 0.9370 - val_loss: 0.0014 - val_accuracy: 0.9998 - val_recall: 0.6610\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9999 - recall: 0.9126\n",
      "Epoch 40: val_recall did not improve from 0.93192\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 0.0013 - accuracy: 0.9999 - recall: 0.9126 - val_loss: 0.0055 - val_accuracy: 0.9994 - val_recall: 0.0319\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9999 - recall: 0.8615\n",
      "Epoch 41: val_recall did not improve from 0.93192\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 0.0015 - accuracy: 0.9999 - recall: 0.8615 - val_loss: 0.0014 - val_accuracy: 0.9998 - val_recall: 0.7751\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 0.9999 - recall: 0.9153\n",
      "Epoch 42: val_recall improved from 0.93192 to 0.93253, saving model to model_2fold.h5\n",
      "42/42 [==============================] - 13s 322ms/step - loss: 0.0012 - accuracy: 0.9999 - recall: 0.9153 - val_loss: 9.9322e-04 - val_accuracy: 0.9999 - val_recall: 0.9325\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9999 - recall: 0.9281\n",
      "Epoch 43: val_recall did not improve from 0.93253\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 0.0011 - accuracy: 0.9999 - recall: 0.9281 - val_loss: 9.7121e-04 - val_accuracy: 0.9999 - val_recall: 0.8964\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 0.9999 - recall: 0.9359\n",
      "Epoch 44: val_recall did not improve from 0.93253\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 0.0010 - accuracy: 0.9999 - recall: 0.9359 - val_loss: 0.0011 - val_accuracy: 0.9999 - val_recall: 0.8011\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 0.9999 - recall: 0.9268\n",
      "Epoch 45: val_recall did not improve from 0.93253\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 0.0010 - accuracy: 0.9999 - recall: 0.9268 - val_loss: 8.6633e-04 - val_accuracy: 0.9999 - val_recall: 0.9158\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 9.4485e-04 - accuracy: 0.9999 - recall: 0.9370\n",
      "Epoch 46: val_recall did not improve from 0.93253\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 9.4485e-04 - accuracy: 0.9999 - recall: 0.9370 - val_loss: 7.9780e-04 - val_accuracy: 0.9999 - val_recall: 0.9253\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 9.2162e-04 - accuracy: 0.9999 - recall: 0.9395\n",
      "Epoch 47: val_recall did not improve from 0.93253\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 9.2162e-04 - accuracy: 0.9999 - recall: 0.9395 - val_loss: 0.0010 - val_accuracy: 0.9998 - val_recall: 0.7523\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 8.7724e-04 - accuracy: 0.9999 - recall: 0.9328\n",
      "Epoch 48: val_recall did not improve from 0.93253\n",
      "42/42 [==============================] - 13s 321ms/step - loss: 8.7724e-04 - accuracy: 0.9999 - recall: 0.9328 - val_loss: 8.0863e-04 - val_accuracy: 0.9999 - val_recall: 0.8715\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 8.4294e-04 - accuracy: 0.9999 - recall: 0.9384\n",
      "Epoch 49: val_recall improved from 0.93253 to 0.96496, saving model to model_2fold.h5\n",
      "42/42 [==============================] - 14s 325ms/step - loss: 8.4294e-04 - accuracy: 0.9999 - recall: 0.9384 - val_loss: 7.1359e-04 - val_accuracy: 1.0000 - val_recall: 0.9650\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 8.2131e-04 - accuracy: 0.9999 - recall: 0.9386\n",
      "Epoch 50: val_recall did not improve from 0.96496\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 8.2131e-04 - accuracy: 0.9999 - recall: 0.9386 - val_loss: 6.5885e-04 - val_accuracy: 1.0000 - val_recall: 0.9556\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 8.2399e-04 - accuracy: 0.9999 - recall: 0.9303\n",
      "Epoch 51: val_recall did not improve from 0.96496\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 8.2399e-04 - accuracy: 0.9999 - recall: 0.9303 - val_loss: 0.0011 - val_accuracy: 0.9998 - val_recall: 0.6443\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 8.0039e-04 - accuracy: 0.9999 - recall: 0.9270\n",
      "Epoch 52: val_recall did not improve from 0.96496\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 8.0039e-04 - accuracy: 0.9999 - recall: 0.9270 - val_loss: 6.5148e-04 - val_accuracy: 0.9999 - val_recall: 0.9085\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 7.4386e-04 - accuracy: 0.9999 - recall: 0.9428\n",
      "Epoch 53: val_recall did not improve from 0.96496\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 7.4386e-04 - accuracy: 0.9999 - recall: 0.9428 - val_loss: 6.1582e-04 - val_accuracy: 0.9999 - val_recall: 0.9283\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 7.5121e-04 - accuracy: 0.9999 - recall: 0.9229\n",
      "Epoch 54: val_recall did not improve from 0.96496\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 7.5121e-04 - accuracy: 0.9999 - recall: 0.9229 - val_loss: 5.7698e-04 - val_accuracy: 1.0000 - val_recall: 0.9469\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 7.0319e-04 - accuracy: 0.9999 - recall: 0.9395\n",
      "Epoch 55: val_recall improved from 0.96496 to 0.98695, saving model to model_2fold.h5\n",
      "42/42 [==============================] - 13s 322ms/step - loss: 7.0319e-04 - accuracy: 0.9999 - recall: 0.9395 - val_loss: 5.9910e-04 - val_accuracy: 0.9999 - val_recall: 0.9869\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 6.5075e-04 - accuracy: 0.9999 - recall: 0.9486\n",
      "Epoch 56: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 6.5075e-04 - accuracy: 0.9999 - recall: 0.9486 - val_loss: 5.6268e-04 - val_accuracy: 0.9999 - val_recall: 0.9373\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 6.2854e-04 - accuracy: 0.9999 - recall: 0.9471\n",
      "Epoch 57: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 6.2854e-04 - accuracy: 0.9999 - recall: 0.9471 - val_loss: 5.5965e-04 - val_accuracy: 0.9999 - val_recall: 0.9178\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 5.9616e-04 - accuracy: 0.9999 - recall: 0.9494\n",
      "Epoch 58: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 5.9616e-04 - accuracy: 0.9999 - recall: 0.9494 - val_loss: 5.2732e-04 - val_accuracy: 0.9999 - val_recall: 0.9299\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 5.8928e-04 - accuracy: 0.9999 - recall: 0.9486\n",
      "Epoch 59: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 5.8928e-04 - accuracy: 0.9999 - recall: 0.9486 - val_loss: 5.0522e-04 - val_accuracy: 1.0000 - val_recall: 0.9381\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 5.7904e-04 - accuracy: 0.9999 - recall: 0.9485\n",
      "Epoch 60: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 5.7904e-04 - accuracy: 0.9999 - recall: 0.9485 - val_loss: 5.2471e-04 - val_accuracy: 0.9999 - val_recall: 0.9035\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 5.5038e-04 - accuracy: 0.9999 - recall: 0.9483\n",
      "Epoch 61: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 5.5038e-04 - accuracy: 0.9999 - recall: 0.9483 - val_loss: 4.6156e-04 - val_accuracy: 1.0000 - val_recall: 0.9522\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 5.3410e-04 - accuracy: 0.9999 - recall: 0.9485\n",
      "Epoch 62: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 5.3410e-04 - accuracy: 0.9999 - recall: 0.9485 - val_loss: 4.6281e-04 - val_accuracy: 1.0000 - val_recall: 0.9540\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 5.2330e-04 - accuracy: 0.9999 - recall: 0.9520\n",
      "Epoch 63: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 5.2330e-04 - accuracy: 0.9999 - recall: 0.9520 - val_loss: 5.6948e-04 - val_accuracy: 0.9999 - val_recall: 0.8555\n",
      "Epoch 64/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 5.1208e-04 - accuracy: 0.9999 - recall: 0.9465\n",
      "Epoch 64: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 5.1208e-04 - accuracy: 0.9999 - recall: 0.9465 - val_loss: 4.8602e-04 - val_accuracy: 0.9999 - val_recall: 0.8988\n",
      "Epoch 65/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 4.9669e-04 - accuracy: 0.9999 - recall: 0.9489\n",
      "Epoch 65: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 4.9669e-04 - accuracy: 0.9999 - recall: 0.9489 - val_loss: 4.8075e-04 - val_accuracy: 0.9999 - val_recall: 0.9125\n",
      "Epoch 66/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 4.8875e-04 - accuracy: 0.9999 - recall: 0.9477\n",
      "Epoch 66: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 4.8875e-04 - accuracy: 0.9999 - recall: 0.9477 - val_loss: 3.9859e-04 - val_accuracy: 1.0000 - val_recall: 0.9786\n",
      "Epoch 67/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 4.6910e-04 - accuracy: 0.9999 - recall: 0.9531\n",
      "Epoch 67: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 4.6910e-04 - accuracy: 0.9999 - recall: 0.9531 - val_loss: 4.6300e-04 - val_accuracy: 0.9999 - val_recall: 0.8924\n",
      "Epoch 68/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 4.4508e-04 - accuracy: 0.9999 - recall: 0.9503\n",
      "Epoch 68: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 4.4508e-04 - accuracy: 0.9999 - recall: 0.9503 - val_loss: 3.8695e-04 - val_accuracy: 1.0000 - val_recall: 0.9336\n",
      "Epoch 69/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 4.3626e-04 - accuracy: 0.9999 - recall: 0.9549\n",
      "Epoch 69: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 4.3626e-04 - accuracy: 0.9999 - recall: 0.9549 - val_loss: 3.7629e-04 - val_accuracy: 1.0000 - val_recall: 0.9721\n",
      "Epoch 70/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 4.3632e-04 - accuracy: 0.9999 - recall: 0.9525\n",
      "Epoch 70: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 4.3632e-04 - accuracy: 0.9999 - recall: 0.9525 - val_loss: 4.1679e-04 - val_accuracy: 0.9999 - val_recall: 0.9268\n",
      "Epoch 71/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 4.1378e-04 - accuracy: 0.9999 - recall: 0.9535\n",
      "Epoch 71: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 4.1378e-04 - accuracy: 0.9999 - recall: 0.9535 - val_loss: 3.5331e-04 - val_accuracy: 1.0000 - val_recall: 0.9410\n",
      "Epoch 72/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.9556e-04 - accuracy: 1.0000 - recall: 0.9588\n",
      "Epoch 72: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 3.9556e-04 - accuracy: 1.0000 - recall: 0.9588 - val_loss: 3.5765e-04 - val_accuracy: 1.0000 - val_recall: 0.9491\n",
      "Epoch 73/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.7010e-04 - accuracy: 1.0000 - recall: 0.9572\n",
      "Epoch 73: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 3.7010e-04 - accuracy: 1.0000 - recall: 0.9572 - val_loss: 3.4304e-04 - val_accuracy: 1.0000 - val_recall: 0.9389\n",
      "Epoch 74/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.5972e-04 - accuracy: 0.9999 - recall: 0.9527\n",
      "Epoch 74: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 3.5972e-04 - accuracy: 0.9999 - recall: 0.9527 - val_loss: 3.6561e-04 - val_accuracy: 0.9999 - val_recall: 0.9133\n",
      "Epoch 75/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.4826e-04 - accuracy: 0.9999 - recall: 0.9528\n",
      "Epoch 75: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 3.4826e-04 - accuracy: 0.9999 - recall: 0.9528 - val_loss: 3.1348e-04 - val_accuracy: 1.0000 - val_recall: 0.9493\n",
      "Epoch 76/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.5416e-04 - accuracy: 0.9999 - recall: 0.9563\n",
      "Epoch 76: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 3.5416e-04 - accuracy: 0.9999 - recall: 0.9563 - val_loss: 2.8921e-04 - val_accuracy: 1.0000 - val_recall: 0.9718\n",
      "Epoch 77/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.2320e-04 - accuracy: 1.0000 - recall: 0.9601\n",
      "Epoch 77: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 3.2320e-04 - accuracy: 1.0000 - recall: 0.9601 - val_loss: 2.8937e-04 - val_accuracy: 1.0000 - val_recall: 0.9664\n",
      "Epoch 78/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.2650e-04 - accuracy: 0.9999 - recall: 0.9522\n",
      "Epoch 78: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 3.2650e-04 - accuracy: 0.9999 - recall: 0.9522 - val_loss: 2.7266e-04 - val_accuracy: 1.0000 - val_recall: 0.9456\n",
      "Epoch 79/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.3528e-04 - accuracy: 0.9999 - recall: 0.9548\n",
      "Epoch 79: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 3.3528e-04 - accuracy: 0.9999 - recall: 0.9548 - val_loss: 2.5377e-04 - val_accuracy: 1.0000 - val_recall: 0.9532\n",
      "Epoch 80/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.1465e-04 - accuracy: 0.9999 - recall: 0.9517\n",
      "Epoch 80: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 3.1465e-04 - accuracy: 0.9999 - recall: 0.9517 - val_loss: 2.4667e-04 - val_accuracy: 1.0000 - val_recall: 0.9656\n",
      "Epoch 81/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.0949e-04 - accuracy: 1.0000 - recall: 0.9577\n",
      "Epoch 81: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 3.0949e-04 - accuracy: 1.0000 - recall: 0.9577 - val_loss: 2.5681e-04 - val_accuracy: 1.0000 - val_recall: 0.9430\n",
      "Epoch 82/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.8769e-04 - accuracy: 1.0000 - recall: 0.9617\n",
      "Epoch 82: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.8769e-04 - accuracy: 1.0000 - recall: 0.9617 - val_loss: 2.4875e-04 - val_accuracy: 1.0000 - val_recall: 0.9777\n",
      "Epoch 83/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.7610e-04 - accuracy: 1.0000 - recall: 0.9591\n",
      "Epoch 83: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 2.7610e-04 - accuracy: 1.0000 - recall: 0.9591 - val_loss: 2.7696e-04 - val_accuracy: 0.9999 - val_recall: 0.9167\n",
      "Epoch 84/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.6363e-04 - accuracy: 1.0000 - recall: 0.9601\n",
      "Epoch 84: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 2.6363e-04 - accuracy: 1.0000 - recall: 0.9601 - val_loss: 2.2043e-04 - val_accuracy: 1.0000 - val_recall: 0.9693\n",
      "Epoch 85/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.8692e-04 - accuracy: 0.9999 - recall: 0.9593\n",
      "Epoch 85: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 2.8692e-04 - accuracy: 0.9999 - recall: 0.9593 - val_loss: 2.7747e-04 - val_accuracy: 0.9999 - val_recall: 0.9115\n",
      "Epoch 86/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.7052e-04 - accuracy: 1.0000 - recall: 0.9598\n",
      "Epoch 86: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 2.7052e-04 - accuracy: 1.0000 - recall: 0.9598 - val_loss: 2.3926e-04 - val_accuracy: 1.0000 - val_recall: 0.9335\n",
      "Epoch 87/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.9132e-04 - accuracy: 0.9999 - recall: 0.9543\n",
      "Epoch 87: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 2.9132e-04 - accuracy: 0.9999 - recall: 0.9543 - val_loss: 2.2405e-04 - val_accuracy: 1.0000 - val_recall: 0.9429\n",
      "Epoch 88/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.5865e-04 - accuracy: 1.0000 - recall: 0.9568\n",
      "Epoch 88: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 2.5865e-04 - accuracy: 1.0000 - recall: 0.9568 - val_loss: 2.1285e-04 - val_accuracy: 1.0000 - val_recall: 0.9712\n",
      "Epoch 89/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.5489e-04 - accuracy: 1.0000 - recall: 0.9608\n",
      "Epoch 89: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 2.5489e-04 - accuracy: 1.0000 - recall: 0.9608 - val_loss: 3.2097e-04 - val_accuracy: 0.9999 - val_recall: 0.8835\n",
      "Epoch 90/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.4708e-04 - accuracy: 1.0000 - recall: 0.9618\n",
      "Epoch 90: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 313ms/step - loss: 2.4708e-04 - accuracy: 1.0000 - recall: 0.9618 - val_loss: 2.8229e-04 - val_accuracy: 0.9999 - val_recall: 0.9033\n",
      "Epoch 91/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.3376e-04 - accuracy: 1.0000 - recall: 0.9631\n",
      "Epoch 91: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.3376e-04 - accuracy: 1.0000 - recall: 0.9631 - val_loss: 3.0495e-04 - val_accuracy: 0.9999 - val_recall: 0.8929\n",
      "Epoch 92/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.3180e-04 - accuracy: 1.0000 - recall: 0.9598\n",
      "Epoch 92: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.3180e-04 - accuracy: 1.0000 - recall: 0.9598 - val_loss: 1.9447e-04 - val_accuracy: 1.0000 - val_recall: 0.9572\n",
      "Epoch 93/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.2859e-04 - accuracy: 1.0000 - recall: 0.9629\n",
      "Epoch 93: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 2.2859e-04 - accuracy: 1.0000 - recall: 0.9629 - val_loss: 2.2339e-04 - val_accuracy: 1.0000 - val_recall: 0.9380\n",
      "Epoch 94/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.2470e-04 - accuracy: 1.0000 - recall: 0.9601\n",
      "Epoch 94: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 2.2470e-04 - accuracy: 1.0000 - recall: 0.9601 - val_loss: 2.4701e-04 - val_accuracy: 0.9999 - val_recall: 0.9268\n",
      "Epoch 95/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.2077e-04 - accuracy: 1.0000 - recall: 0.9641\n",
      "Epoch 95: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 2.2077e-04 - accuracy: 1.0000 - recall: 0.9641 - val_loss: 2.2471e-04 - val_accuracy: 1.0000 - val_recall: 0.9465\n",
      "Epoch 96/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.1748e-04 - accuracy: 1.0000 - recall: 0.9616\n",
      "Epoch 96: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.1748e-04 - accuracy: 1.0000 - recall: 0.9616 - val_loss: 1.8319e-04 - val_accuracy: 1.0000 - val_recall: 0.9538\n",
      "Epoch 97/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.1222e-04 - accuracy: 1.0000 - recall: 0.9649\n",
      "Epoch 97: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 2.1222e-04 - accuracy: 1.0000 - recall: 0.9649 - val_loss: 1.7377e-04 - val_accuracy: 1.0000 - val_recall: 0.9690\n",
      "Epoch 98/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.0352e-04 - accuracy: 1.0000 - recall: 0.9626\n",
      "Epoch 98: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.0352e-04 - accuracy: 1.0000 - recall: 0.9626 - val_loss: 2.6907e-04 - val_accuracy: 0.9999 - val_recall: 0.9053\n",
      "Epoch 99/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.2995e-04 - accuracy: 1.0000 - recall: 0.9593\n",
      "Epoch 99: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 2.2995e-04 - accuracy: 1.0000 - recall: 0.9593 - val_loss: 1.7643e-04 - val_accuracy: 1.0000 - val_recall: 0.9484\n",
      "Epoch 100/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.9583e-04 - accuracy: 1.0000 - recall: 0.9651\n",
      "Epoch 100: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 1.9583e-04 - accuracy: 1.0000 - recall: 0.9651 - val_loss: 0.0052 - val_accuracy: 0.9995 - val_recall: 0.3029\n",
      "Epoch 101/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.6806e-04 - accuracy: 0.9999 - recall: 0.9514\n",
      "Epoch 101: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.6806e-04 - accuracy: 0.9999 - recall: 0.9514 - val_loss: 2.0822e-04 - val_accuracy: 1.0000 - val_recall: 0.9634\n",
      "Epoch 102/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.9840e-04 - accuracy: 1.0000 - recall: 0.9632\n",
      "Epoch 102: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 1.9840e-04 - accuracy: 1.0000 - recall: 0.9632 - val_loss: 1.9688e-04 - val_accuracy: 1.0000 - val_recall: 0.9339\n",
      "Epoch 103/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.0097e-04 - accuracy: 1.0000 - recall: 0.9638\n",
      "Epoch 103: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.0097e-04 - accuracy: 1.0000 - recall: 0.9638 - val_loss: 2.1946e-04 - val_accuracy: 0.9999 - val_recall: 0.9266\n",
      "Epoch 104/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.0077e-04 - accuracy: 1.0000 - recall: 0.9642\n",
      "Epoch 104: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.0077e-04 - accuracy: 1.0000 - recall: 0.9642 - val_loss: 2.1452e-04 - val_accuracy: 0.9999 - val_recall: 0.9187\n",
      "Epoch 105/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.9063e-04 - accuracy: 1.0000 - recall: 0.9639\n",
      "Epoch 105: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 1.9063e-04 - accuracy: 1.0000 - recall: 0.9639 - val_loss: 1.7678e-04 - val_accuracy: 1.0000 - val_recall: 0.9494\n",
      "Epoch 106/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.8037e-04 - accuracy: 1.0000 - recall: 0.9668\n",
      "Epoch 106: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 1.8037e-04 - accuracy: 1.0000 - recall: 0.9668 - val_loss: 1.6074e-04 - val_accuracy: 1.0000 - val_recall: 0.9589\n",
      "Epoch 107/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.9263e-04 - accuracy: 1.0000 - recall: 0.9625\n",
      "Epoch 107: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 1.9263e-04 - accuracy: 1.0000 - recall: 0.9625 - val_loss: 2.0909e-04 - val_accuracy: 0.9999 - val_recall: 0.9227\n",
      "Epoch 108/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.8664e-04 - accuracy: 1.0000 - recall: 0.9634\n",
      "Epoch 108: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 1.8664e-04 - accuracy: 1.0000 - recall: 0.9634 - val_loss: 1.4812e-04 - val_accuracy: 1.0000 - val_recall: 0.9781\n",
      "Epoch 109/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.6914e-04 - accuracy: 1.0000 - recall: 0.9703\n",
      "Epoch 109: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.6914e-04 - accuracy: 1.0000 - recall: 0.9703 - val_loss: 2.2644e-04 - val_accuracy: 0.9999 - val_recall: 0.9136\n",
      "Epoch 110/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.6638e-04 - accuracy: 1.0000 - recall: 0.9661\n",
      "Epoch 110: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.6638e-04 - accuracy: 1.0000 - recall: 0.9661 - val_loss: 1.4573e-04 - val_accuracy: 1.0000 - val_recall: 0.9609\n",
      "Epoch 111/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.5526e-04 - accuracy: 1.0000 - recall: 0.9693\n",
      "Epoch 111: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.5526e-04 - accuracy: 1.0000 - recall: 0.9693 - val_loss: 1.6061e-04 - val_accuracy: 1.0000 - val_recall: 0.9486\n",
      "Epoch 112/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.7764e-04 - accuracy: 1.0000 - recall: 0.9641\n",
      "Epoch 112: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 1.7764e-04 - accuracy: 1.0000 - recall: 0.9641 - val_loss: 1.5057e-04 - val_accuracy: 1.0000 - val_recall: 0.9577\n",
      "Epoch 113/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.6202e-04 - accuracy: 1.0000 - recall: 0.9685\n",
      "Epoch 113: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 1.6202e-04 - accuracy: 1.0000 - recall: 0.9685 - val_loss: 2.1264e-04 - val_accuracy: 0.9999 - val_recall: 0.9195\n",
      "Epoch 114/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.5951e-04 - accuracy: 1.0000 - recall: 0.9662\n",
      "Epoch 114: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 1.5951e-04 - accuracy: 1.0000 - recall: 0.9662 - val_loss: 1.4988e-04 - val_accuracy: 1.0000 - val_recall: 0.9512\n",
      "Epoch 115/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.4739e-04 - accuracy: 1.0000 - recall: 0.9721\n",
      "Epoch 115: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 322ms/step - loss: 1.4739e-04 - accuracy: 1.0000 - recall: 0.9721 - val_loss: 1.3536e-04 - val_accuracy: 1.0000 - val_recall: 0.9710\n",
      "Epoch 116/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.4820e-04 - accuracy: 1.0000 - recall: 0.9677\n",
      "Epoch 116: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 1.4820e-04 - accuracy: 1.0000 - recall: 0.9677 - val_loss: 1.6054e-04 - val_accuracy: 1.0000 - val_recall: 0.9444\n",
      "Epoch 117/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.5738e-04 - accuracy: 1.0000 - recall: 0.9734\n",
      "Epoch 117: val_recall did not improve from 0.98695\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 1.5738e-04 - accuracy: 1.0000 - recall: 0.9734 - val_loss: 2.4260e-04 - val_accuracy: 0.9999 - val_recall: 0.8982\n",
      "Epoch 118/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.8333e-04 - accuracy: 1.0000 - recall: 0.9602\n",
      "Epoch 118: val_recall improved from 0.98695 to 0.99075, saving model to model_2fold.h5\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 1.8333e-04 - accuracy: 1.0000 - recall: 0.9602 - val_loss: 2.0880e-04 - val_accuracy: 0.9999 - val_recall: 0.9908\n",
      "Epoch 119/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.6362e-04 - accuracy: 1.0000 - recall: 0.9679\n",
      "Epoch 119: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.6362e-04 - accuracy: 1.0000 - recall: 0.9679 - val_loss: 1.4461e-04 - val_accuracy: 1.0000 - val_recall: 0.9449\n",
      "Epoch 120/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.4429e-04 - accuracy: 1.0000 - recall: 0.9664\n",
      "Epoch 120: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.4429e-04 - accuracy: 1.0000 - recall: 0.9664 - val_loss: 1.6492e-04 - val_accuracy: 1.0000 - val_recall: 0.9333\n",
      "Epoch 121/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.4751e-04 - accuracy: 1.0000 - recall: 0.9690\n",
      "Epoch 121: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.4751e-04 - accuracy: 1.0000 - recall: 0.9690 - val_loss: 1.3661e-04 - val_accuracy: 1.0000 - val_recall: 0.9540\n",
      "Epoch 122/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.4905e-04 - accuracy: 1.0000 - recall: 0.9683\n",
      "Epoch 122: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.4905e-04 - accuracy: 1.0000 - recall: 0.9683 - val_loss: 1.2147e-04 - val_accuracy: 1.0000 - val_recall: 0.9789\n",
      "Epoch 123/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.4829e-04 - accuracy: 1.0000 - recall: 0.9661\n",
      "Epoch 123: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.4829e-04 - accuracy: 1.0000 - recall: 0.9661 - val_loss: 2.3947e-04 - val_accuracy: 0.9999 - val_recall: 0.8923\n",
      "Epoch 124/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.7935e-04 - accuracy: 1.0000 - recall: 0.9629\n",
      "Epoch 124: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.7935e-04 - accuracy: 1.0000 - recall: 0.9629 - val_loss: 1.2257e-04 - val_accuracy: 1.0000 - val_recall: 0.9672\n",
      "Epoch 125/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.3519e-04 - accuracy: 1.0000 - recall: 0.9725\n",
      "Epoch 125: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.3519e-04 - accuracy: 1.0000 - recall: 0.9725 - val_loss: 1.4821e-04 - val_accuracy: 1.0000 - val_recall: 0.9741\n",
      "Epoch 126/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.4551e-04 - accuracy: 1.0000 - recall: 0.9660\n",
      "Epoch 126: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.4551e-04 - accuracy: 1.0000 - recall: 0.9660 - val_loss: 4.5715e-04 - val_accuracy: 0.9998 - val_recall: 0.7759\n",
      "Epoch 127/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.2472e-04 - accuracy: 1.0000 - recall: 0.9732\n",
      "Epoch 127: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 1.2472e-04 - accuracy: 1.0000 - recall: 0.9732 - val_loss: 1.1410e-04 - val_accuracy: 1.0000 - val_recall: 0.9746\n",
      "Epoch 128/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.2493e-04 - accuracy: 1.0000 - recall: 0.9702\n",
      "Epoch 128: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.2493e-04 - accuracy: 1.0000 - recall: 0.9702 - val_loss: 4.3269e-04 - val_accuracy: 0.9999 - val_recall: 0.8013\n",
      "Epoch 129/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.2486e-04 - accuracy: 1.0000 - recall: 0.9756\n",
      "Epoch 129: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.2486e-04 - accuracy: 1.0000 - recall: 0.9756 - val_loss: 1.8044e-04 - val_accuracy: 0.9999 - val_recall: 0.9205\n",
      "Epoch 130/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.2976e-04 - accuracy: 1.0000 - recall: 0.9687\n",
      "Epoch 130: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.2976e-04 - accuracy: 1.0000 - recall: 0.9687 - val_loss: 1.6210e-04 - val_accuracy: 0.9999 - val_recall: 0.9269\n",
      "Epoch 131/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.3028e-04 - accuracy: 1.0000 - recall: 0.9698\n",
      "Epoch 131: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.3028e-04 - accuracy: 1.0000 - recall: 0.9698 - val_loss: 1.1753e-04 - val_accuracy: 1.0000 - val_recall: 0.9742\n",
      "Epoch 132/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.2869e-04 - accuracy: 1.0000 - recall: 0.9700\n",
      "Epoch 132: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.2869e-04 - accuracy: 1.0000 - recall: 0.9700 - val_loss: 1.3756e-04 - val_accuracy: 1.0000 - val_recall: 0.9449\n",
      "Epoch 133/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.4539e-04 - accuracy: 1.0000 - recall: 0.9652\n",
      "Epoch 133: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.4539e-04 - accuracy: 1.0000 - recall: 0.9652 - val_loss: 5.8966e-04 - val_accuracy: 0.9998 - val_recall: 0.7140\n",
      "Epoch 134/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.6303e-04 - accuracy: 1.0000 - recall: 0.9566\n",
      "Epoch 134: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.6303e-04 - accuracy: 1.0000 - recall: 0.9566 - val_loss: 1.2463e-04 - val_accuracy: 1.0000 - val_recall: 0.9778\n",
      "Epoch 135/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.5094e-04 - accuracy: 1.0000 - recall: 0.9682\n",
      "Epoch 135: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 1.5094e-04 - accuracy: 1.0000 - recall: 0.9682 - val_loss: 1.5215e-04 - val_accuracy: 1.0000 - val_recall: 0.9312\n",
      "Epoch 136/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.3445e-04 - accuracy: 1.0000 - recall: 0.9658\n",
      "Epoch 136: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.3445e-04 - accuracy: 1.0000 - recall: 0.9658 - val_loss: 1.5902e-04 - val_accuracy: 0.9999 - val_recall: 0.9322\n",
      "Epoch 137/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.2298e-04 - accuracy: 1.0000 - recall: 0.9712\n",
      "Epoch 137: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 1.2298e-04 - accuracy: 1.0000 - recall: 0.9712 - val_loss: 2.3214e-04 - val_accuracy: 0.9999 - val_recall: 0.8862\n",
      "Epoch 138/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.1814e-04 - accuracy: 1.0000 - recall: 0.9727\n",
      "Epoch 138: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 315ms/step - loss: 1.1814e-04 - accuracy: 1.0000 - recall: 0.9727 - val_loss: 1.2048e-04 - val_accuracy: 1.0000 - val_recall: 0.9538\n",
      "Epoch 139/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.1493e-04 - accuracy: 1.0000 - recall: 0.9727\n",
      "Epoch 139: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.1493e-04 - accuracy: 1.0000 - recall: 0.9727 - val_loss: 1.2766e-04 - val_accuracy: 1.0000 - val_recall: 0.9458\n",
      "Epoch 140/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.0860e-04 - accuracy: 1.0000 - recall: 0.9737\n",
      "Epoch 140: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 1.0860e-04 - accuracy: 1.0000 - recall: 0.9737 - val_loss: 1.4247e-04 - val_accuracy: 1.0000 - val_recall: 0.9537\n",
      "Epoch 141/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.2544e-04 - accuracy: 1.0000 - recall: 0.9677\n",
      "Epoch 141: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 1.2544e-04 - accuracy: 1.0000 - recall: 0.9677 - val_loss: 1.2789e-04 - val_accuracy: 1.0000 - val_recall: 0.9573\n",
      "Epoch 142/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.2879e-04 - accuracy: 1.0000 - recall: 0.9697\n",
      "Epoch 142: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 1.2879e-04 - accuracy: 1.0000 - recall: 0.9697 - val_loss: 2.9445e-04 - val_accuracy: 0.9999 - val_recall: 0.8663\n",
      "Epoch 143/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.2056e-04 - accuracy: 1.0000 - recall: 0.9757\n",
      "Epoch 143: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 1.2056e-04 - accuracy: 1.0000 - recall: 0.9757 - val_loss: 2.5841e-04 - val_accuracy: 0.9999 - val_recall: 0.8793\n",
      "Epoch 144/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.3520e-04 - accuracy: 1.0000 - recall: 0.9609\n",
      "Epoch 144: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.3520e-04 - accuracy: 1.0000 - recall: 0.9609 - val_loss: 1.1353e-04 - val_accuracy: 1.0000 - val_recall: 0.9569\n",
      "Epoch 145/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.3020e-04 - accuracy: 1.0000 - recall: 0.9683\n",
      "Epoch 145: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.3020e-04 - accuracy: 1.0000 - recall: 0.9683 - val_loss: 1.0302e-04 - val_accuracy: 1.0000 - val_recall: 0.9818\n",
      "Epoch 146/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 9.6503e-05 - accuracy: 1.0000 - recall: 0.9778\n",
      "Epoch 146: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 9.6503e-05 - accuracy: 1.0000 - recall: 0.9778 - val_loss: 1.0054e-04 - val_accuracy: 1.0000 - val_recall: 0.9702\n",
      "Epoch 147/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 9.5980e-05 - accuracy: 1.0000 - recall: 0.9754\n",
      "Epoch 147: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 9.5980e-05 - accuracy: 1.0000 - recall: 0.9754 - val_loss: 1.0449e-04 - val_accuracy: 1.0000 - val_recall: 0.9694\n",
      "Epoch 148/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 9.1780e-05 - accuracy: 1.0000 - recall: 0.9793\n",
      "Epoch 148: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 9.1780e-05 - accuracy: 1.0000 - recall: 0.9793 - val_loss: 1.0106e-04 - val_accuracy: 1.0000 - val_recall: 0.9706\n",
      "Epoch 149/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 9.6286e-05 - accuracy: 1.0000 - recall: 0.9760\n",
      "Epoch 149: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 9.6286e-05 - accuracy: 1.0000 - recall: 0.9760 - val_loss: 1.0418e-04 - val_accuracy: 1.0000 - val_recall: 0.9764\n",
      "Epoch 150/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.0219e-04 - accuracy: 1.0000 - recall: 0.9725\n",
      "Epoch 150: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.0219e-04 - accuracy: 1.0000 - recall: 0.9725 - val_loss: 2.5056e-04 - val_accuracy: 0.9999 - val_recall: 0.8877\n",
      "Epoch 151/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.2609e-04 - accuracy: 1.0000 - recall: 0.9707\n",
      "Epoch 151: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 1.2609e-04 - accuracy: 1.0000 - recall: 0.9707 - val_loss: 1.0812e-04 - val_accuracy: 1.0000 - val_recall: 0.9642\n",
      "Epoch 152/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.1287e-04 - accuracy: 1.0000 - recall: 0.9728\n",
      "Epoch 152: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.1287e-04 - accuracy: 1.0000 - recall: 0.9728 - val_loss: 1.0715e-04 - val_accuracy: 1.0000 - val_recall: 0.9749\n",
      "Epoch 153/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.2836e-04 - accuracy: 1.0000 - recall: 0.9678\n",
      "Epoch 153: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.2836e-04 - accuracy: 1.0000 - recall: 0.9678 - val_loss: 1.4073e-04 - val_accuracy: 1.0000 - val_recall: 0.9434\n",
      "Epoch 154/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.1073e-04 - accuracy: 1.0000 - recall: 0.9751\n",
      "Epoch 154: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.1073e-04 - accuracy: 1.0000 - recall: 0.9751 - val_loss: 1.3883e-04 - val_accuracy: 1.0000 - val_recall: 0.9450\n",
      "Epoch 155/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 8.9874e-05 - accuracy: 1.0000 - recall: 0.9767\n",
      "Epoch 155: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 8.9874e-05 - accuracy: 1.0000 - recall: 0.9767 - val_loss: 1.0399e-04 - val_accuracy: 1.0000 - val_recall: 0.9639\n",
      "Epoch 156/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 9.4245e-05 - accuracy: 1.0000 - recall: 0.9767\n",
      "Epoch 156: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 9.4245e-05 - accuracy: 1.0000 - recall: 0.9767 - val_loss: 1.0535e-04 - val_accuracy: 1.0000 - val_recall: 0.9761\n",
      "Epoch 157/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 8.8067e-05 - accuracy: 1.0000 - recall: 0.9756\n",
      "Epoch 157: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 8.8067e-05 - accuracy: 1.0000 - recall: 0.9756 - val_loss: 3.4783e-04 - val_accuracy: 0.9999 - val_recall: 0.8472\n",
      "Epoch 158/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 9.0685e-05 - accuracy: 1.0000 - recall: 0.9793\n",
      "Epoch 158: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 9.0685e-05 - accuracy: 1.0000 - recall: 0.9793 - val_loss: 1.0394e-04 - val_accuracy: 1.0000 - val_recall: 0.9788\n",
      "Epoch 159/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 8.6993e-05 - accuracy: 1.0000 - recall: 0.9777\n",
      "Epoch 159: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 8.6993e-05 - accuracy: 1.0000 - recall: 0.9777 - val_loss: 9.9425e-05 - val_accuracy: 1.0000 - val_recall: 0.9703\n",
      "Epoch 160/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.0601e-04 - accuracy: 1.0000 - recall: 0.9751\n",
      "Epoch 160: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 1.0601e-04 - accuracy: 1.0000 - recall: 0.9751 - val_loss: 0.0011 - val_accuracy: 0.9996 - val_recall: 0.4750\n",
      "Epoch 161/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.2164e-04 - accuracy: 1.0000 - recall: 0.9650\n",
      "Epoch 161: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.2164e-04 - accuracy: 1.0000 - recall: 0.9650 - val_loss: 1.0322e-04 - val_accuracy: 1.0000 - val_recall: 0.9700\n",
      "Epoch 162/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.0297e-04 - accuracy: 1.0000 - recall: 0.9748\n",
      "Epoch 162: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 1.0297e-04 - accuracy: 1.0000 - recall: 0.9748 - val_loss: 1.2314e-04 - val_accuracy: 1.0000 - val_recall: 0.9448\n",
      "Epoch 163/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 8.2237e-05 - accuracy: 1.0000 - recall: 0.9791\n",
      "Epoch 163: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 8.2237e-05 - accuracy: 1.0000 - recall: 0.9791 - val_loss: 1.0041e-04 - val_accuracy: 1.0000 - val_recall: 0.9818\n",
      "Epoch 164/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.0641e-04 - accuracy: 1.0000 - recall: 0.9709\n",
      "Epoch 164: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.0641e-04 - accuracy: 1.0000 - recall: 0.9709 - val_loss: 1.6049e-04 - val_accuracy: 0.9999 - val_recall: 0.9348\n",
      "Epoch 165/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.0218e-04 - accuracy: 1.0000 - recall: 0.9742\n",
      "Epoch 165: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.0218e-04 - accuracy: 1.0000 - recall: 0.9742 - val_loss: 9.5082e-05 - val_accuracy: 1.0000 - val_recall: 0.9738\n",
      "Epoch 166/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 8.1000e-05 - accuracy: 1.0000 - recall: 0.9800\n",
      "Epoch 166: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 8.1000e-05 - accuracy: 1.0000 - recall: 0.9800 - val_loss: 1.0356e-04 - val_accuracy: 1.0000 - val_recall: 0.9753\n",
      "Epoch 167/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 7.7744e-05 - accuracy: 1.0000 - recall: 0.9809\n",
      "Epoch 167: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 7.7744e-05 - accuracy: 1.0000 - recall: 0.9809 - val_loss: 1.0611e-04 - val_accuracy: 1.0000 - val_recall: 0.9592\n",
      "Epoch 168/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 8.1484e-05 - accuracy: 1.0000 - recall: 0.9765\n",
      "Epoch 168: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 8.1484e-05 - accuracy: 1.0000 - recall: 0.9765 - val_loss: 1.8393e-04 - val_accuracy: 0.9999 - val_recall: 0.9170\n",
      "Epoch 169/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 9.5335e-05 - accuracy: 1.0000 - recall: 0.9768\n",
      "Epoch 169: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 9.5335e-05 - accuracy: 1.0000 - recall: 0.9768 - val_loss: 1.2637e-04 - val_accuracy: 1.0000 - val_recall: 0.9902\n",
      "Epoch 170/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 7.8819e-05 - accuracy: 1.0000 - recall: 0.9807\n",
      "Epoch 170: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 7.8819e-05 - accuracy: 1.0000 - recall: 0.9807 - val_loss: 9.7912e-05 - val_accuracy: 1.0000 - val_recall: 0.9717\n",
      "Epoch 171/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 7.1022e-05 - accuracy: 1.0000 - recall: 0.9813\n",
      "Epoch 171: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 7.1022e-05 - accuracy: 1.0000 - recall: 0.9813 - val_loss: 1.0874e-04 - val_accuracy: 1.0000 - val_recall: 0.9570\n",
      "Epoch 172/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 7.9115e-05 - accuracy: 1.0000 - recall: 0.9810\n",
      "Epoch 172: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 7.9115e-05 - accuracy: 1.0000 - recall: 0.9810 - val_loss: 1.0777e-04 - val_accuracy: 1.0000 - val_recall: 0.9845\n",
      "Epoch 173/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 8.2659e-05 - accuracy: 1.0000 - recall: 0.9767\n",
      "Epoch 173: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 8.2659e-05 - accuracy: 1.0000 - recall: 0.9767 - val_loss: 1.2228e-04 - val_accuracy: 1.0000 - val_recall: 0.9514\n",
      "Epoch 174/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 7.1956e-05 - accuracy: 1.0000 - recall: 0.9819\n",
      "Epoch 174: val_recall did not improve from 0.99075\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 7.1956e-05 - accuracy: 1.0000 - recall: 0.9819 - val_loss: 1.0065e-04 - val_accuracy: 1.0000 - val_recall: 0.9694\n",
      "Epoch 175/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 8.5043e-05 - accuracy: 1.0000 - recall: 0.9773\n",
      "Epoch 175: val_recall improved from 0.99075 to 0.99113, saving model to model_2fold.h5\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 8.5043e-05 - accuracy: 1.0000 - recall: 0.9773 - val_loss: 1.5552e-04 - val_accuracy: 1.0000 - val_recall: 0.9911\n",
      "Epoch 176/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 8.1500e-05 - accuracy: 1.0000 - recall: 0.9770\n",
      "Epoch 176: val_recall did not improve from 0.99113\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 8.1500e-05 - accuracy: 1.0000 - recall: 0.9770 - val_loss: 1.0136e-04 - val_accuracy: 1.0000 - val_recall: 0.9643\n",
      "Epoch 177/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 6.7827e-05 - accuracy: 1.0000 - recall: 0.9825\n",
      "Epoch 177: val_recall did not improve from 0.99113\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 6.7827e-05 - accuracy: 1.0000 - recall: 0.9825 - val_loss: 1.2997e-04 - val_accuracy: 1.0000 - val_recall: 0.9426\n",
      "Epoch 178/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 7.1049e-05 - accuracy: 1.0000 - recall: 0.9826\n",
      "Epoch 178: val_recall did not improve from 0.99113\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 7.1049e-05 - accuracy: 1.0000 - recall: 0.9826 - val_loss: 2.0455e-04 - val_accuracy: 0.9999 - val_recall: 0.9457\n",
      "Epoch 179/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.7058e-04 - accuracy: 1.0000 - recall: 0.9573\n",
      "Epoch 179: val_recall did not improve from 0.99113\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.7058e-04 - accuracy: 1.0000 - recall: 0.9573 - val_loss: 0.0022 - val_accuracy: 0.9996 - val_recall: 0.5103\n",
      "Epoch 180/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.1498e-04 - accuracy: 0.9999 - recall: 0.9482\n",
      "Epoch 180: val_recall did not improve from 0.99113\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.1498e-04 - accuracy: 0.9999 - recall: 0.9482 - val_loss: 1.8496e-04 - val_accuracy: 0.9999 - val_recall: 0.9284\n",
      "Epoch 181/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.1381e-04 - accuracy: 1.0000 - recall: 0.9728\n",
      "Epoch 181: val_recall did not improve from 0.99113\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.1381e-04 - accuracy: 1.0000 - recall: 0.9728 - val_loss: 2.4767e-04 - val_accuracy: 0.9999 - val_recall: 0.8774\n",
      "Epoch 182/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.1455e-04 - accuracy: 1.0000 - recall: 0.9728\n",
      "Epoch 182: val_recall did not improve from 0.99113\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.1455e-04 - accuracy: 1.0000 - recall: 0.9728 - val_loss: 1.5422e-04 - val_accuracy: 0.9999 - val_recall: 0.9417\n",
      "Epoch 183/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 8.5899e-05 - accuracy: 1.0000 - recall: 0.9775\n",
      "Epoch 183: val_recall did not improve from 0.99113\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 8.5899e-05 - accuracy: 1.0000 - recall: 0.9775 - val_loss: 1.0159e-04 - val_accuracy: 1.0000 - val_recall: 0.9599\n",
      "Epoch 184/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 7.7440e-05 - accuracy: 1.0000 - recall: 0.9780\n",
      "Epoch 184: val_recall did not improve from 0.99113\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 7.7440e-05 - accuracy: 1.0000 - recall: 0.9780 - val_loss: 1.1389e-04 - val_accuracy: 1.0000 - val_recall: 0.9503\n",
      "Epoch 185/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 9.5389e-05 - accuracy: 1.0000 - recall: 0.9774\n",
      "Epoch 185: val_recall did not improve from 0.99113\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 9.5389e-05 - accuracy: 1.0000 - recall: 0.9774 - val_loss: 4.8324e-04 - val_accuracy: 0.9998 - val_recall: 0.7286\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mbouzon/miniconda3/envs/tf/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mbouzon/miniconda3/envs/tf/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.4152 - accuracy: 0.9367 - recall: 0.0331\n",
      "Epoch 1: val_recall improved from -inf to 0.00018, saving model to model_3fold.h5\n",
      "42/42 [==============================] - 15s 326ms/step - loss: 0.4152 - accuracy: 0.9367 - recall: 0.0331 - val_loss: 0.3286 - val_accuracy: 0.9716 - val_recall: 1.8200e-04\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2027 - accuracy: 0.9986 - recall: 4.5254e-05\n",
      "Epoch 2: val_recall did not improve from 0.00018\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 0.2027 - accuracy: 0.9986 - recall: 4.5254e-05 - val_loss: 0.2863 - val_accuracy: 0.9984 - val_recall: 0.0000e+00\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1294 - accuracy: 0.9993 - recall: 0.0000e+00\n",
      "Epoch 3: val_recall did not improve from 0.00018\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.1294 - accuracy: 0.9993 - recall: 0.0000e+00 - val_loss: 0.1885 - val_accuracy: 0.9993 - val_recall: 0.0000e+00\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0892 - accuracy: 0.9993 - recall: 9.0508e-06\n",
      "Epoch 4: val_recall did not improve from 0.00018\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0892 - accuracy: 0.9993 - recall: 9.0508e-06 - val_loss: 0.1225 - val_accuracy: 0.9994 - val_recall: 0.0000e+00\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0646 - accuracy: 0.9994 - recall: 0.0000e+00\n",
      "Epoch 5: val_recall did not improve from 0.00018\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0646 - accuracy: 0.9994 - recall: 0.0000e+00 - val_loss: 0.0816 - val_accuracy: 0.9994 - val_recall: 0.0000e+00\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0487 - accuracy: 0.9994 - recall: 0.0000e+00\n",
      "Epoch 6: val_recall did not improve from 0.00018\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0487 - accuracy: 0.9994 - recall: 0.0000e+00 - val_loss: 0.0568 - val_accuracy: 0.9994 - val_recall: 0.0000e+00\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0378 - accuracy: 0.9994 - recall: 0.0000e+00\n",
      "Epoch 7: val_recall did not improve from 0.00018\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0378 - accuracy: 0.9994 - recall: 0.0000e+00 - val_loss: 0.0406 - val_accuracy: 0.9994 - val_recall: 0.0000e+00\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0297 - accuracy: 0.9994 - recall: 0.0023\n",
      "Epoch 8: val_recall did not improve from 0.00018\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0297 - accuracy: 0.9994 - recall: 0.0023 - val_loss: 0.0315 - val_accuracy: 0.9994 - val_recall: 0.0000e+00\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0233 - accuracy: 0.9994 - recall: 0.1718\n",
      "Epoch 9: val_recall did not improve from 0.00018\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0233 - accuracy: 0.9994 - recall: 0.1718 - val_loss: 0.0247 - val_accuracy: 0.9994 - val_recall: 0.0000e+00\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 0.9996 - recall: 0.4977\n",
      "Epoch 10: val_recall did not improve from 0.00018\n",
      "42/42 [==============================] - 13s 321ms/step - loss: 0.0186 - accuracy: 0.9996 - recall: 0.4977 - val_loss: 0.0210 - val_accuracy: 0.9994 - val_recall: 0.0000e+00\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9997 - recall: 0.6840\n",
      "Epoch 11: val_recall did not improve from 0.00018\n",
      "42/42 [==============================] - 13s 321ms/step - loss: 0.0150 - accuracy: 0.9997 - recall: 0.6840 - val_loss: 0.0179 - val_accuracy: 0.9994 - val_recall: 0.0000e+00\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 0.9998 - recall: 0.7769\n",
      "Epoch 12: val_recall did not improve from 0.00018\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 0.0125 - accuracy: 0.9998 - recall: 0.7769 - val_loss: 0.0154 - val_accuracy: 0.9994 - val_recall: 0.0000e+00\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 0.9998 - recall: 0.8126\n",
      "Epoch 13: val_recall did not improve from 0.00018\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 0.0106 - accuracy: 0.9998 - recall: 0.8126 - val_loss: 0.0124 - val_accuracy: 0.9994 - val_recall: 0.0000e+00\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9999 - recall: 0.8509\n",
      "Epoch 14: val_recall improved from 0.00018 to 0.00025, saving model to model_3fold.h5\n",
      "42/42 [==============================] - 14s 326ms/step - loss: 0.0090 - accuracy: 0.9999 - recall: 0.8509 - val_loss: 0.0103 - val_accuracy: 0.9994 - val_recall: 2.5480e-04\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 0.9999 - recall: 0.8622\n",
      "Epoch 15: val_recall improved from 0.00025 to 0.04819, saving model to model_3fold.h5\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 0.0078 - accuracy: 0.9999 - recall: 0.8622 - val_loss: 0.0084 - val_accuracy: 0.9994 - val_recall: 0.0482\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9999 - recall: 0.8745\n",
      "Epoch 16: val_recall improved from 0.04819 to 0.10934, saving model to model_3fold.h5\n",
      "42/42 [==============================] - 14s 330ms/step - loss: 0.0069 - accuracy: 0.9999 - recall: 0.8745 - val_loss: 0.0073 - val_accuracy: 0.9994 - val_recall: 0.1093\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 0.9999 - recall: 0.8790\n",
      "Epoch 17: val_recall improved from 0.10934 to 0.22680, saving model to model_3fold.h5\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 0.0061 - accuracy: 0.9999 - recall: 0.8790 - val_loss: 0.0063 - val_accuracy: 0.9995 - val_recall: 0.2268\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9999 - recall: 0.8893\n",
      "Epoch 18: val_recall improved from 0.22680 to 0.31063, saving model to model_3fold.h5\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 0.0054 - accuracy: 0.9999 - recall: 0.8893 - val_loss: 0.0054 - val_accuracy: 0.9996 - val_recall: 0.3106\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 0.9999 - recall: 0.8884\n",
      "Epoch 19: val_recall improved from 0.31063 to 0.42995, saving model to model_3fold.h5\n",
      "42/42 [==============================] - 14s 322ms/step - loss: 0.0049 - accuracy: 0.9999 - recall: 0.8884 - val_loss: 0.0047 - val_accuracy: 0.9996 - val_recall: 0.4299\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9999 - recall: 0.8966\n",
      "Epoch 20: val_recall improved from 0.42995 to 0.72311, saving model to model_3fold.h5\n",
      "42/42 [==============================] - 14s 329ms/step - loss: 0.0043 - accuracy: 0.9999 - recall: 0.8966 - val_loss: 0.0040 - val_accuracy: 0.9998 - val_recall: 0.7231\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9999 - recall: 0.9008\n",
      "Epoch 21: val_recall improved from 0.72311 to 0.72599, saving model to model_3fold.h5\n",
      "42/42 [==============================] - 14s 330ms/step - loss: 0.0040 - accuracy: 0.9999 - recall: 0.9008 - val_loss: 0.0036 - val_accuracy: 0.9998 - val_recall: 0.7260\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9999 - recall: 0.9106\n",
      "Epoch 22: val_recall improved from 0.72599 to 0.78932, saving model to model_3fold.h5\n",
      "42/42 [==============================] - 14s 333ms/step - loss: 0.0036 - accuracy: 0.9999 - recall: 0.9106 - val_loss: 0.0032 - val_accuracy: 0.9999 - val_recall: 0.7893\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9999 - recall: 0.9188\n",
      "Epoch 23: val_recall did not improve from 0.78932\n",
      "42/42 [==============================] - 14s 328ms/step - loss: 0.0033 - accuracy: 0.9999 - recall: 0.9188 - val_loss: 0.0030 - val_accuracy: 0.9998 - val_recall: 0.7526\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9999 - recall: 0.9168\n",
      "Epoch 24: val_recall did not improve from 0.78932\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 0.0030 - accuracy: 0.9999 - recall: 0.9168 - val_loss: 0.0028 - val_accuracy: 0.9999 - val_recall: 0.7652\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9999 - recall: 0.9263\n",
      "Epoch 25: val_recall improved from 0.78932 to 0.83770, saving model to model_3fold.h5\n",
      "42/42 [==============================] - 14s 333ms/step - loss: 0.0028 - accuracy: 0.9999 - recall: 0.9263 - val_loss: 0.0025 - val_accuracy: 0.9999 - val_recall: 0.8377\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9999 - recall: 0.9165\n",
      "Epoch 26: val_recall improved from 0.83770 to 0.88727, saving model to model_3fold.h5\n",
      "42/42 [==============================] - 14s 335ms/step - loss: 0.0026 - accuracy: 0.9999 - recall: 0.9165 - val_loss: 0.0023 - val_accuracy: 0.9999 - val_recall: 0.8873\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9999 - recall: 0.9241\n",
      "Epoch 27: val_recall did not improve from 0.88727\n",
      "42/42 [==============================] - 14s 329ms/step - loss: 0.0024 - accuracy: 0.9999 - recall: 0.9241 - val_loss: 0.0021 - val_accuracy: 0.9999 - val_recall: 0.8755\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9999 - recall: 0.9252\n",
      "Epoch 28: val_recall did not improve from 0.88727\n",
      "42/42 [==============================] - 14s 327ms/step - loss: 0.0022 - accuracy: 0.9999 - recall: 0.9252 - val_loss: 0.0020 - val_accuracy: 0.9999 - val_recall: 0.8713\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9999 - recall: 0.9235\n",
      "Epoch 29: val_recall improved from 0.88727 to 0.97656, saving model to model_3fold.h5\n",
      "42/42 [==============================] - 14s 331ms/step - loss: 0.0021 - accuracy: 0.9999 - recall: 0.9235 - val_loss: 0.0019 - val_accuracy: 0.9999 - val_recall: 0.9766\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9999 - recall: 0.9286\n",
      "Epoch 30: val_recall did not improve from 0.97656\n",
      "42/42 [==============================] - 14s 333ms/step - loss: 0.0020 - accuracy: 0.9999 - recall: 0.9286 - val_loss: 0.0018 - val_accuracy: 0.9999 - val_recall: 0.8576\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9999 - recall: 0.9099\n",
      "Epoch 31: val_recall improved from 0.97656 to 0.97827, saving model to model_3fold.h5\n",
      "42/42 [==============================] - 14s 326ms/step - loss: 0.0019 - accuracy: 0.9999 - recall: 0.9099 - val_loss: 0.0023 - val_accuracy: 0.9997 - val_recall: 0.9783\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9999 - recall: 0.9237\n",
      "Epoch 32: val_recall did not improve from 0.97827\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 0.0018 - accuracy: 0.9999 - recall: 0.9237 - val_loss: 0.0016 - val_accuracy: 0.9999 - val_recall: 0.8731\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9999 - recall: 0.9314\n",
      "Epoch 33: val_recall did not improve from 0.97827\n",
      "42/42 [==============================] - 14s 322ms/step - loss: 0.0016 - accuracy: 0.9999 - recall: 0.9314 - val_loss: 0.0015 - val_accuracy: 0.9999 - val_recall: 0.8857\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9999 - recall: 0.9337\n",
      "Epoch 34: val_recall did not improve from 0.97827\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 0.0015 - accuracy: 0.9999 - recall: 0.9337 - val_loss: 0.0014 - val_accuracy: 0.9999 - val_recall: 0.8921\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9999 - recall: 0.9336\n",
      "Epoch 35: val_recall did not improve from 0.97827\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 0.0014 - accuracy: 0.9999 - recall: 0.9336 - val_loss: 0.0013 - val_accuracy: 0.9999 - val_recall: 0.9466\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9999 - recall: 0.9379\n",
      "Epoch 36: val_recall did not improve from 0.97827\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 0.0014 - accuracy: 0.9999 - recall: 0.9379 - val_loss: 0.0012 - val_accuracy: 1.0000 - val_recall: 0.9487\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9999 - recall: 0.9412\n",
      "Epoch 37: val_recall did not improve from 0.97827\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 0.0013 - accuracy: 0.9999 - recall: 0.9412 - val_loss: 0.0011 - val_accuracy: 0.9999 - val_recall: 0.9095\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 0.9999 - recall: 0.9403\n",
      "Epoch 38: val_recall did not improve from 0.97827\n",
      "42/42 [==============================] - 14s 327ms/step - loss: 0.0012 - accuracy: 0.9999 - recall: 0.9403 - val_loss: 0.0011 - val_accuracy: 0.9999 - val_recall: 0.9297\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 0.9999 - recall: 0.9416\n",
      "Epoch 39: val_recall did not improve from 0.97827\n",
      "42/42 [==============================] - 14s 330ms/step - loss: 0.0012 - accuracy: 0.9999 - recall: 0.9416 - val_loss: 0.0010 - val_accuracy: 0.9999 - val_recall: 0.9020\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9999 - recall: 0.9386\n",
      "Epoch 40: val_recall did not improve from 0.97827\n",
      "42/42 [==============================] - 14s 332ms/step - loss: 0.0011 - accuracy: 0.9999 - recall: 0.9386 - val_loss: 9.4866e-04 - val_accuracy: 0.9999 - val_recall: 0.9128\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9999 - recall: 0.9461\n",
      "Epoch 41: val_recall did not improve from 0.97827\n",
      "42/42 [==============================] - 14s 329ms/step - loss: 0.0011 - accuracy: 0.9999 - recall: 0.9461 - val_loss: 9.1108e-04 - val_accuracy: 0.9999 - val_recall: 0.9164\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 0.9999 - recall: 0.9389\n",
      "Epoch 42: val_recall did not improve from 0.97827\n",
      "42/42 [==============================] - 14s 325ms/step - loss: 0.0010 - accuracy: 0.9999 - recall: 0.9389 - val_loss: 8.5311e-04 - val_accuracy: 1.0000 - val_recall: 0.9434\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 9.5709e-04 - accuracy: 0.9999 - recall: 0.9440\n",
      "Epoch 43: val_recall did not improve from 0.97827\n",
      "42/42 [==============================] - 14s 328ms/step - loss: 9.5709e-04 - accuracy: 0.9999 - recall: 0.9440 - val_loss: 8.6757e-04 - val_accuracy: 0.9999 - val_recall: 0.8888\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 9.1036e-04 - accuracy: 0.9999 - recall: 0.9464\n",
      "Epoch 44: val_recall did not improve from 0.97827\n",
      "42/42 [==============================] - 14s 326ms/step - loss: 9.1036e-04 - accuracy: 0.9999 - recall: 0.9464 - val_loss: 7.8423e-04 - val_accuracy: 0.9999 - val_recall: 0.9315\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 9.2758e-04 - accuracy: 0.9999 - recall: 0.9268\n",
      "Epoch 45: val_recall did not improve from 0.97827\n",
      "42/42 [==============================] - 14s 328ms/step - loss: 9.2758e-04 - accuracy: 0.9999 - recall: 0.9268 - val_loss: 0.0024 - val_accuracy: 0.9997 - val_recall: 0.5075\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9999 - recall: 0.8798\n",
      "Epoch 46: val_recall did not improve from 0.97827\n",
      "42/42 [==============================] - 14s 330ms/step - loss: 0.0011 - accuracy: 0.9999 - recall: 0.8798 - val_loss: 0.0026 - val_accuracy: 0.9997 - val_recall: 0.5228\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 9.0478e-04 - accuracy: 0.9999 - recall: 0.9297\n",
      "Epoch 47: val_recall did not improve from 0.97827\n",
      "42/42 [==============================] - 14s 332ms/step - loss: 9.0478e-04 - accuracy: 0.9999 - recall: 0.9297 - val_loss: 8.1311e-04 - val_accuracy: 0.9999 - val_recall: 0.9482\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 8.2750e-04 - accuracy: 0.9999 - recall: 0.9299\n",
      "Epoch 48: val_recall did not improve from 0.97827\n",
      "42/42 [==============================] - 14s 327ms/step - loss: 8.2750e-04 - accuracy: 0.9999 - recall: 0.9299 - val_loss: 8.9812e-04 - val_accuracy: 0.9999 - val_recall: 0.8548\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 7.6490e-04 - accuracy: 0.9999 - recall: 0.9389\n",
      "Epoch 49: val_recall did not improve from 0.97827\n",
      "42/42 [==============================] - 14s 329ms/step - loss: 7.6490e-04 - accuracy: 0.9999 - recall: 0.9389 - val_loss: 7.0488e-04 - val_accuracy: 0.9999 - val_recall: 0.9130\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 7.0123e-04 - accuracy: 0.9999 - recall: 0.9447\n",
      "Epoch 50: val_recall did not improve from 0.97827\n",
      "42/42 [==============================] - 14s 328ms/step - loss: 7.0123e-04 - accuracy: 0.9999 - recall: 0.9447 - val_loss: 6.1803e-04 - val_accuracy: 1.0000 - val_recall: 0.9608\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 6.7033e-04 - accuracy: 0.9999 - recall: 0.9383\n",
      "Epoch 51: val_recall did not improve from 0.97827\n",
      "42/42 [==============================] - 14s 327ms/step - loss: 6.7033e-04 - accuracy: 0.9999 - recall: 0.9383 - val_loss: 7.4729e-04 - val_accuracy: 0.9999 - val_recall: 0.9107\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 6.4377e-04 - accuracy: 0.9999 - recall: 0.9473\n",
      "Epoch 52: val_recall did not improve from 0.97827\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 6.4377e-04 - accuracy: 0.9999 - recall: 0.9473 - val_loss: 5.6119e-04 - val_accuracy: 1.0000 - val_recall: 0.9615\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 6.4527e-04 - accuracy: 0.9999 - recall: 0.9364\n",
      "Epoch 53: val_recall did not improve from 0.97827\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 6.4527e-04 - accuracy: 0.9999 - recall: 0.9364 - val_loss: 5.9015e-04 - val_accuracy: 0.9999 - val_recall: 0.9079\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 5.9816e-04 - accuracy: 0.9999 - recall: 0.9444\n",
      "Epoch 54: val_recall did not improve from 0.97827\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 5.9816e-04 - accuracy: 0.9999 - recall: 0.9444 - val_loss: 5.2783e-04 - val_accuracy: 0.9999 - val_recall: 0.9151\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 5.5608e-04 - accuracy: 0.9999 - recall: 0.9500\n",
      "Epoch 55: val_recall did not improve from 0.97827\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 5.5608e-04 - accuracy: 0.9999 - recall: 0.9500 - val_loss: 5.2462e-04 - val_accuracy: 0.9999 - val_recall: 0.8980\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 5.2811e-04 - accuracy: 0.9999 - recall: 0.9503\n",
      "Epoch 56: val_recall did not improve from 0.97827\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 5.2811e-04 - accuracy: 0.9999 - recall: 0.9503 - val_loss: 4.7743e-04 - val_accuracy: 1.0000 - val_recall: 0.9449\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 5.2040e-04 - accuracy: 0.9999 - recall: 0.9500\n",
      "Epoch 57: val_recall did not improve from 0.97827\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 5.2040e-04 - accuracy: 0.9999 - recall: 0.9500 - val_loss: 5.0486e-04 - val_accuracy: 0.9999 - val_recall: 0.9138\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 4.9968e-04 - accuracy: 0.9999 - recall: 0.9469\n",
      "Epoch 58: val_recall did not improve from 0.97827\n",
      "42/42 [==============================] - 13s 322ms/step - loss: 4.9968e-04 - accuracy: 0.9999 - recall: 0.9469 - val_loss: 5.0472e-04 - val_accuracy: 0.9999 - val_recall: 0.8829\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 4.7447e-04 - accuracy: 0.9999 - recall: 0.9533\n",
      "Epoch 59: val_recall did not improve from 0.97827\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 4.7447e-04 - accuracy: 0.9999 - recall: 0.9533 - val_loss: 4.5020e-04 - val_accuracy: 1.0000 - val_recall: 0.9580\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 4.8382e-04 - accuracy: 0.9999 - recall: 0.9456\n",
      "Epoch 60: val_recall did not improve from 0.97827\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 4.8382e-04 - accuracy: 0.9999 - recall: 0.9456 - val_loss: 4.6050e-04 - val_accuracy: 0.9999 - val_recall: 0.8844\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 4.5863e-04 - accuracy: 0.9999 - recall: 0.9565\n",
      "Epoch 61: val_recall did not improve from 0.97827\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 4.5863e-04 - accuracy: 0.9999 - recall: 0.9565 - val_loss: 5.2387e-04 - val_accuracy: 0.9999 - val_recall: 0.8441\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 4.7212e-04 - accuracy: 0.9999 - recall: 0.9462\n",
      "Epoch 62: val_recall improved from 0.97827 to 0.98315, saving model to model_3fold.h5\n",
      "42/42 [==============================] - 13s 322ms/step - loss: 4.7212e-04 - accuracy: 0.9999 - recall: 0.9462 - val_loss: 3.9273e-04 - val_accuracy: 1.0000 - val_recall: 0.9831\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 4.4454e-04 - accuracy: 0.9999 - recall: 0.9496\n",
      "Epoch 63: val_recall did not improve from 0.98315\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 4.4454e-04 - accuracy: 0.9999 - recall: 0.9496 - val_loss: 3.6548e-04 - val_accuracy: 1.0000 - val_recall: 0.9403\n",
      "Epoch 64/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 4.1900e-04 - accuracy: 0.9999 - recall: 0.9546\n",
      "Epoch 64: val_recall did not improve from 0.98315\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 4.1900e-04 - accuracy: 0.9999 - recall: 0.9546 - val_loss: 3.9411e-04 - val_accuracy: 0.9999 - val_recall: 0.9081\n",
      "Epoch 65/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 4.0477e-04 - accuracy: 0.9999 - recall: 0.9552\n",
      "Epoch 65: val_recall did not improve from 0.98315\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 4.0477e-04 - accuracy: 0.9999 - recall: 0.9552 - val_loss: 3.5909e-04 - val_accuracy: 1.0000 - val_recall: 0.9423\n",
      "Epoch 66/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.9168e-04 - accuracy: 0.9999 - recall: 0.9569\n",
      "Epoch 66: val_recall did not improve from 0.98315\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 3.9168e-04 - accuracy: 0.9999 - recall: 0.9569 - val_loss: 3.8812e-04 - val_accuracy: 0.9999 - val_recall: 0.9154\n",
      "Epoch 67/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.8644e-04 - accuracy: 0.9999 - recall: 0.9563\n",
      "Epoch 67: val_recall did not improve from 0.98315\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 3.8644e-04 - accuracy: 0.9999 - recall: 0.9563 - val_loss: 0.0016 - val_accuracy: 0.9997 - val_recall: 0.5182\n",
      "Epoch 68/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 4.2410e-04 - accuracy: 0.9999 - recall: 0.9432\n",
      "Epoch 68: val_recall did not improve from 0.98315\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 4.2410e-04 - accuracy: 0.9999 - recall: 0.9432 - val_loss: 3.2615e-04 - val_accuracy: 1.0000 - val_recall: 0.9541\n",
      "Epoch 69/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.9997e-04 - accuracy: 0.9999 - recall: 0.9490\n",
      "Epoch 69: val_recall did not improve from 0.98315\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 3.9997e-04 - accuracy: 0.9999 - recall: 0.9490 - val_loss: 3.1894e-04 - val_accuracy: 1.0000 - val_recall: 0.9356\n",
      "Epoch 70/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.6485e-04 - accuracy: 0.9999 - recall: 0.9556\n",
      "Epoch 70: val_recall did not improve from 0.98315\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 3.6485e-04 - accuracy: 0.9999 - recall: 0.9556 - val_loss: 3.1986e-04 - val_accuracy: 1.0000 - val_recall: 0.9372\n",
      "Epoch 71/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.9014e-04 - accuracy: 0.9999 - recall: 0.9444\n",
      "Epoch 71: val_recall did not improve from 0.98315\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 3.9014e-04 - accuracy: 0.9999 - recall: 0.9444 - val_loss: 2.7765e-04 - val_accuracy: 1.0000 - val_recall: 0.9753\n",
      "Epoch 72/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.4519e-04 - accuracy: 0.9999 - recall: 0.9553\n",
      "Epoch 72: val_recall improved from 0.98315 to 0.98762, saving model to model_3fold.h5\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 3.4519e-04 - accuracy: 0.9999 - recall: 0.9553 - val_loss: 3.2329e-04 - val_accuracy: 1.0000 - val_recall: 0.9876\n",
      "Epoch 73/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.3262e-04 - accuracy: 1.0000 - recall: 0.9574\n",
      "Epoch 73: val_recall did not improve from 0.98762\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 3.3262e-04 - accuracy: 1.0000 - recall: 0.9574 - val_loss: 2.9990e-04 - val_accuracy: 1.0000 - val_recall: 0.9726\n",
      "Epoch 74/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.2226e-04 - accuracy: 1.0000 - recall: 0.9600\n",
      "Epoch 74: val_recall did not improve from 0.98762\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 3.2226e-04 - accuracy: 1.0000 - recall: 0.9600 - val_loss: 2.6841e-04 - val_accuracy: 1.0000 - val_recall: 0.9720\n",
      "Epoch 75/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.0216e-04 - accuracy: 1.0000 - recall: 0.9599\n",
      "Epoch 75: val_recall did not improve from 0.98762\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 3.0216e-04 - accuracy: 1.0000 - recall: 0.9599 - val_loss: 3.2312e-04 - val_accuracy: 0.9999 - val_recall: 0.9209\n",
      "Epoch 76/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.0825e-04 - accuracy: 0.9999 - recall: 0.9587\n",
      "Epoch 76: val_recall did not improve from 0.98762\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 3.0825e-04 - accuracy: 0.9999 - recall: 0.9587 - val_loss: 2.6453e-04 - val_accuracy: 1.0000 - val_recall: 0.9410\n",
      "Epoch 77/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.8630e-04 - accuracy: 1.0000 - recall: 0.9590\n",
      "Epoch 77: val_recall did not improve from 0.98762\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.8630e-04 - accuracy: 1.0000 - recall: 0.9590 - val_loss: 2.8897e-04 - val_accuracy: 0.9999 - val_recall: 0.9149\n",
      "Epoch 78/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.9665e-04 - accuracy: 0.9999 - recall: 0.9595\n",
      "Epoch 78: val_recall improved from 0.98762 to 0.98802, saving model to model_3fold.h5\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 2.9665e-04 - accuracy: 0.9999 - recall: 0.9595 - val_loss: 2.6019e-04 - val_accuracy: 1.0000 - val_recall: 0.9880\n",
      "Epoch 79/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.8172e-04 - accuracy: 1.0000 - recall: 0.9606\n",
      "Epoch 79: val_recall did not improve from 0.98802\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 2.8172e-04 - accuracy: 1.0000 - recall: 0.9606 - val_loss: 3.4281e-04 - val_accuracy: 0.9999 - val_recall: 0.8779\n",
      "Epoch 80/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.7456e-04 - accuracy: 0.9999 - recall: 0.9571\n",
      "Epoch 80: val_recall did not improve from 0.98802\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 2.7456e-04 - accuracy: 0.9999 - recall: 0.9571 - val_loss: 2.5855e-04 - val_accuracy: 0.9999 - val_recall: 0.9204\n",
      "Epoch 81/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.6576e-04 - accuracy: 1.0000 - recall: 0.9578\n",
      "Epoch 81: val_recall did not improve from 0.98802\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 2.6576e-04 - accuracy: 1.0000 - recall: 0.9578 - val_loss: 2.2460e-04 - val_accuracy: 1.0000 - val_recall: 0.9415\n",
      "Epoch 82/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.6196e-04 - accuracy: 1.0000 - recall: 0.9584\n",
      "Epoch 82: val_recall did not improve from 0.98802\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 2.6196e-04 - accuracy: 1.0000 - recall: 0.9584 - val_loss: 2.9465e-04 - val_accuracy: 0.9999 - val_recall: 0.8913\n",
      "Epoch 83/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.4393e-04 - accuracy: 1.0000 - recall: 0.9642\n",
      "Epoch 83: val_recall did not improve from 0.98802\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 2.4393e-04 - accuracy: 1.0000 - recall: 0.9642 - val_loss: 2.2895e-04 - val_accuracy: 1.0000 - val_recall: 0.9376\n",
      "Epoch 84/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.5373e-04 - accuracy: 1.0000 - recall: 0.9565\n",
      "Epoch 84: val_recall did not improve from 0.98802\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 2.5373e-04 - accuracy: 1.0000 - recall: 0.9565 - val_loss: 3.3408e-04 - val_accuracy: 0.9999 - val_recall: 0.8927\n",
      "Epoch 85/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.4565e-04 - accuracy: 1.0000 - recall: 0.9594\n",
      "Epoch 85: val_recall did not improve from 0.98802\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 2.4565e-04 - accuracy: 1.0000 - recall: 0.9594 - val_loss: 4.7846e-04 - val_accuracy: 0.9999 - val_recall: 0.8357\n",
      "Epoch 86/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.8261e-04 - accuracy: 0.9999 - recall: 0.9494\n",
      "Epoch 86: val_recall improved from 0.98802 to 0.99698, saving model to model_3fold.h5\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 2.8261e-04 - accuracy: 0.9999 - recall: 0.9494 - val_loss: 3.7218e-04 - val_accuracy: 0.9999 - val_recall: 0.9970\n",
      "Epoch 87/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.7340e-04 - accuracy: 0.9999 - recall: 0.9561\n",
      "Epoch 87: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 2.7340e-04 - accuracy: 0.9999 - recall: 0.9561 - val_loss: 2.7406e-04 - val_accuracy: 0.9999 - val_recall: 0.9945\n",
      "Epoch 88/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.4802e-04 - accuracy: 1.0000 - recall: 0.9580\n",
      "Epoch 88: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 2.4802e-04 - accuracy: 1.0000 - recall: 0.9580 - val_loss: 1.8849e-04 - val_accuracy: 1.0000 - val_recall: 0.9571\n",
      "Epoch 89/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.4547e-04 - accuracy: 1.0000 - recall: 0.9584\n",
      "Epoch 89: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 2.4547e-04 - accuracy: 1.0000 - recall: 0.9584 - val_loss: 2.3515e-04 - val_accuracy: 0.9999 - val_recall: 0.9179\n",
      "Epoch 90/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.2197e-04 - accuracy: 1.0000 - recall: 0.9622\n",
      "Epoch 90: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.2197e-04 - accuracy: 1.0000 - recall: 0.9622 - val_loss: 2.1121e-04 - val_accuracy: 1.0000 - val_recall: 0.9312\n",
      "Epoch 91/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.1980e-04 - accuracy: 1.0000 - recall: 0.9617\n",
      "Epoch 91: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.1980e-04 - accuracy: 1.0000 - recall: 0.9617 - val_loss: 2.1176e-04 - val_accuracy: 1.0000 - val_recall: 0.9790\n",
      "Epoch 92/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.4695e-04 - accuracy: 0.9999 - recall: 0.9602\n",
      "Epoch 92: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.4695e-04 - accuracy: 0.9999 - recall: 0.9602 - val_loss: 2.3313e-04 - val_accuracy: 0.9999 - val_recall: 0.9098\n",
      "Epoch 93/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.1244e-04 - accuracy: 1.0000 - recall: 0.9620\n",
      "Epoch 93: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.1244e-04 - accuracy: 1.0000 - recall: 0.9620 - val_loss: 2.0867e-04 - val_accuracy: 0.9999 - val_recall: 0.9264\n",
      "Epoch 94/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.9892e-04 - accuracy: 1.0000 - recall: 0.9656\n",
      "Epoch 94: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.9892e-04 - accuracy: 1.0000 - recall: 0.9656 - val_loss: 2.1773e-04 - val_accuracy: 0.9999 - val_recall: 0.9147\n",
      "Epoch 95/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.1988e-04 - accuracy: 1.0000 - recall: 0.9586\n",
      "Epoch 95: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.1988e-04 - accuracy: 1.0000 - recall: 0.9586 - val_loss: 1.6886e-04 - val_accuracy: 1.0000 - val_recall: 0.9582\n",
      "Epoch 96/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.2668e-04 - accuracy: 1.0000 - recall: 0.9614\n",
      "Epoch 96: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.2668e-04 - accuracy: 1.0000 - recall: 0.9614 - val_loss: 1.5665e-04 - val_accuracy: 1.0000 - val_recall: 0.9676\n",
      "Epoch 97/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.0992e-04 - accuracy: 1.0000 - recall: 0.9615\n",
      "Epoch 97: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.0992e-04 - accuracy: 1.0000 - recall: 0.9615 - val_loss: 1.7070e-04 - val_accuracy: 1.0000 - val_recall: 0.9435\n",
      "Epoch 98/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.9138e-04 - accuracy: 1.0000 - recall: 0.9652\n",
      "Epoch 98: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.9138e-04 - accuracy: 1.0000 - recall: 0.9652 - val_loss: 1.6641e-04 - val_accuracy: 1.0000 - val_recall: 0.9494\n",
      "Epoch 99/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.8305e-04 - accuracy: 1.0000 - recall: 0.9677\n",
      "Epoch 99: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.8305e-04 - accuracy: 1.0000 - recall: 0.9677 - val_loss: 1.8497e-04 - val_accuracy: 1.0000 - val_recall: 0.9498\n",
      "Epoch 100/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.8522e-04 - accuracy: 1.0000 - recall: 0.9623\n",
      "Epoch 100: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.8522e-04 - accuracy: 1.0000 - recall: 0.9623 - val_loss: 1.9027e-04 - val_accuracy: 1.0000 - val_recall: 0.9288\n",
      "Epoch 101/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.9098e-04 - accuracy: 1.0000 - recall: 0.9631\n",
      "Epoch 101: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.9098e-04 - accuracy: 1.0000 - recall: 0.9631 - val_loss: 2.1995e-04 - val_accuracy: 0.9999 - val_recall: 0.9031\n",
      "Epoch 102/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.9181e-04 - accuracy: 1.0000 - recall: 0.9660\n",
      "Epoch 102: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.9181e-04 - accuracy: 1.0000 - recall: 0.9660 - val_loss: 2.2642e-04 - val_accuracy: 0.9999 - val_recall: 0.8973\n",
      "Epoch 103/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.9455e-04 - accuracy: 1.0000 - recall: 0.9598\n",
      "Epoch 103: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.9455e-04 - accuracy: 1.0000 - recall: 0.9598 - val_loss: 2.1342e-04 - val_accuracy: 0.9999 - val_recall: 0.9059\n",
      "Epoch 104/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.8524e-04 - accuracy: 1.0000 - recall: 0.9658\n",
      "Epoch 104: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.8524e-04 - accuracy: 1.0000 - recall: 0.9658 - val_loss: 1.7563e-04 - val_accuracy: 1.0000 - val_recall: 0.9286\n",
      "Epoch 105/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.5829e-04 - accuracy: 1.0000 - recall: 0.9706\n",
      "Epoch 105: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.5829e-04 - accuracy: 1.0000 - recall: 0.9706 - val_loss: 2.1234e-04 - val_accuracy: 0.9999 - val_recall: 0.9325\n",
      "Epoch 106/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.6560e-04 - accuracy: 1.0000 - recall: 0.9637\n",
      "Epoch 106: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.6560e-04 - accuracy: 1.0000 - recall: 0.9637 - val_loss: 1.7387e-04 - val_accuracy: 1.0000 - val_recall: 0.9323\n",
      "Epoch 107/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.8003e-04 - accuracy: 1.0000 - recall: 0.9654\n",
      "Epoch 107: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.8003e-04 - accuracy: 1.0000 - recall: 0.9654 - val_loss: 1.5596e-04 - val_accuracy: 1.0000 - val_recall: 0.9569\n",
      "Epoch 108/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.5639e-04 - accuracy: 1.0000 - recall: 0.9723\n",
      "Epoch 108: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.5639e-04 - accuracy: 1.0000 - recall: 0.9723 - val_loss: 2.0344e-04 - val_accuracy: 0.9999 - val_recall: 0.9103\n",
      "Epoch 109/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.7323e-04 - accuracy: 1.0000 - recall: 0.9636\n",
      "Epoch 109: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.7323e-04 - accuracy: 1.0000 - recall: 0.9636 - val_loss: 1.7074e-04 - val_accuracy: 1.0000 - val_recall: 0.9592\n",
      "Epoch 110/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.4988e-04 - accuracy: 1.0000 - recall: 0.9701\n",
      "Epoch 110: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.4988e-04 - accuracy: 1.0000 - recall: 0.9701 - val_loss: 2.3996e-04 - val_accuracy: 0.9999 - val_recall: 0.8873\n",
      "Epoch 111/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.4459e-04 - accuracy: 1.0000 - recall: 0.9695\n",
      "Epoch 111: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.4459e-04 - accuracy: 1.0000 - recall: 0.9695 - val_loss: 1.3547e-04 - val_accuracy: 1.0000 - val_recall: 0.9566\n",
      "Epoch 112/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.4366e-04 - accuracy: 1.0000 - recall: 0.9716\n",
      "Epoch 112: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.4366e-04 - accuracy: 1.0000 - recall: 0.9716 - val_loss: 5.8718e-04 - val_accuracy: 0.9999 - val_recall: 0.8912\n",
      "Epoch 113/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.6754e-04 - accuracy: 1.0000 - recall: 0.9620\n",
      "Epoch 113: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.6754e-04 - accuracy: 1.0000 - recall: 0.9620 - val_loss: 2.0126e-04 - val_accuracy: 0.9999 - val_recall: 0.9065\n",
      "Epoch 114/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.6540e-04 - accuracy: 1.0000 - recall: 0.9670\n",
      "Epoch 114: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 1.6540e-04 - accuracy: 1.0000 - recall: 0.9670 - val_loss: 1.7198e-04 - val_accuracy: 0.9999 - val_recall: 0.9180\n",
      "Epoch 115/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.4741e-04 - accuracy: 1.0000 - recall: 0.9667\n",
      "Epoch 115: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.4741e-04 - accuracy: 1.0000 - recall: 0.9667 - val_loss: 1.2403e-04 - val_accuracy: 1.0000 - val_recall: 0.9797\n",
      "Epoch 116/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.4966e-04 - accuracy: 1.0000 - recall: 0.9706\n",
      "Epoch 116: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.4966e-04 - accuracy: 1.0000 - recall: 0.9706 - val_loss: 1.3005e-04 - val_accuracy: 1.0000 - val_recall: 0.9640\n",
      "Epoch 117/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.7195e-04 - accuracy: 1.0000 - recall: 0.9588\n",
      "Epoch 117: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.7195e-04 - accuracy: 1.0000 - recall: 0.9588 - val_loss: 2.3817e-04 - val_accuracy: 0.9999 - val_recall: 0.8797\n",
      "Epoch 118/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.8005e-04 - accuracy: 1.0000 - recall: 0.9613\n",
      "Epoch 118: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.8005e-04 - accuracy: 1.0000 - recall: 0.9613 - val_loss: 1.3142e-04 - val_accuracy: 1.0000 - val_recall: 0.9566\n",
      "Epoch 119/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.4159e-04 - accuracy: 1.0000 - recall: 0.9686\n",
      "Epoch 119: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.4159e-04 - accuracy: 1.0000 - recall: 0.9686 - val_loss: 2.9969e-04 - val_accuracy: 0.9999 - val_recall: 0.9216\n",
      "Epoch 120/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.0984e-04 - accuracy: 0.9999 - recall: 0.9569\n",
      "Epoch 120: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.0984e-04 - accuracy: 0.9999 - recall: 0.9569 - val_loss: 1.7754e-04 - val_accuracy: 1.0000 - val_recall: 0.9372\n",
      "Epoch 121/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.9015e-04 - accuracy: 0.9999 - recall: 0.9562\n",
      "Epoch 121: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.9015e-04 - accuracy: 0.9999 - recall: 0.9562 - val_loss: 2.1066e-04 - val_accuracy: 0.9999 - val_recall: 0.9008\n",
      "Epoch 122/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.5727e-04 - accuracy: 1.0000 - recall: 0.9676\n",
      "Epoch 122: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.5727e-04 - accuracy: 1.0000 - recall: 0.9676 - val_loss: 2.6647e-04 - val_accuracy: 0.9999 - val_recall: 0.8774\n",
      "Epoch 123/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.7103e-04 - accuracy: 1.0000 - recall: 0.9570\n",
      "Epoch 123: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.7103e-04 - accuracy: 1.0000 - recall: 0.9570 - val_loss: 1.2070e-04 - val_accuracy: 1.0000 - val_recall: 0.9585\n",
      "Epoch 124/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.3930e-04 - accuracy: 1.0000 - recall: 0.9684\n",
      "Epoch 124: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.3930e-04 - accuracy: 1.0000 - recall: 0.9684 - val_loss: 1.4899e-04 - val_accuracy: 1.0000 - val_recall: 0.9742\n",
      "Epoch 125/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.4288e-04 - accuracy: 1.0000 - recall: 0.9714\n",
      "Epoch 125: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.4288e-04 - accuracy: 1.0000 - recall: 0.9714 - val_loss: 3.4251e-04 - val_accuracy: 0.9999 - val_recall: 0.8073\n",
      "Epoch 126/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.3468e-04 - accuracy: 1.0000 - recall: 0.9673\n",
      "Epoch 126: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 1.3468e-04 - accuracy: 1.0000 - recall: 0.9673 - val_loss: 1.2945e-04 - val_accuracy: 1.0000 - val_recall: 0.9496\n",
      "Epoch 127/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.4193e-04 - accuracy: 1.0000 - recall: 0.9683\n",
      "Epoch 127: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.4193e-04 - accuracy: 1.0000 - recall: 0.9683 - val_loss: 1.5325e-04 - val_accuracy: 1.0000 - val_recall: 0.9314\n",
      "Epoch 128/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.2790e-04 - accuracy: 1.0000 - recall: 0.9714\n",
      "Epoch 128: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 1.2790e-04 - accuracy: 1.0000 - recall: 0.9714 - val_loss: 1.2499e-04 - val_accuracy: 1.0000 - val_recall: 0.9574\n",
      "Epoch 129/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.1773e-04 - accuracy: 1.0000 - recall: 0.9713\n",
      "Epoch 129: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.1773e-04 - accuracy: 1.0000 - recall: 0.9713 - val_loss: 1.5078e-04 - val_accuracy: 1.0000 - val_recall: 0.9292\n",
      "Epoch 130/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.5028e-04 - accuracy: 1.0000 - recall: 0.9676\n",
      "Epoch 130: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.5028e-04 - accuracy: 1.0000 - recall: 0.9676 - val_loss: 1.1496e-04 - val_accuracy: 1.0000 - val_recall: 0.9724\n",
      "Epoch 131/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.2932e-04 - accuracy: 1.0000 - recall: 0.9720\n",
      "Epoch 131: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.2932e-04 - accuracy: 1.0000 - recall: 0.9720 - val_loss: 2.5306e-04 - val_accuracy: 0.9999 - val_recall: 0.8719\n",
      "Epoch 132/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.3476e-04 - accuracy: 1.0000 - recall: 0.9646\n",
      "Epoch 132: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.3476e-04 - accuracy: 1.0000 - recall: 0.9646 - val_loss: 4.1419e-04 - val_accuracy: 0.9999 - val_recall: 0.9875\n",
      "Epoch 133/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.6506e-04 - accuracy: 1.0000 - recall: 0.9630\n",
      "Epoch 133: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.6506e-04 - accuracy: 1.0000 - recall: 0.9630 - val_loss: 1.7462e-04 - val_accuracy: 1.0000 - val_recall: 0.9365\n",
      "Epoch 134/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.3450e-04 - accuracy: 1.0000 - recall: 0.9693\n",
      "Epoch 134: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 1.3450e-04 - accuracy: 1.0000 - recall: 0.9693 - val_loss: 1.6210e-04 - val_accuracy: 0.9999 - val_recall: 0.9235\n",
      "Epoch 135/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.4702e-04 - accuracy: 1.0000 - recall: 0.9686\n",
      "Epoch 135: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.4702e-04 - accuracy: 1.0000 - recall: 0.9686 - val_loss: 1.4129e-04 - val_accuracy: 1.0000 - val_recall: 0.9415\n",
      "Epoch 136/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.3730e-04 - accuracy: 1.0000 - recall: 0.9681\n",
      "Epoch 136: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.3730e-04 - accuracy: 1.0000 - recall: 0.9681 - val_loss: 5.5078e-04 - val_accuracy: 0.9999 - val_recall: 0.7683\n",
      "Epoch 137/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.6272e-04 - accuracy: 1.0000 - recall: 0.9615\n",
      "Epoch 137: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 1.6272e-04 - accuracy: 1.0000 - recall: 0.9615 - val_loss: 0.0022 - val_accuracy: 0.9996 - val_recall: 0.4083\n",
      "Epoch 138/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.3108e-04 - accuracy: 1.0000 - recall: 0.9691\n",
      "Epoch 138: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.3108e-04 - accuracy: 1.0000 - recall: 0.9691 - val_loss: 1.3909e-04 - val_accuracy: 1.0000 - val_recall: 0.9641\n",
      "Epoch 139/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.2991e-04 - accuracy: 1.0000 - recall: 0.9690\n",
      "Epoch 139: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 1.2991e-04 - accuracy: 1.0000 - recall: 0.9690 - val_loss: 1.3324e-04 - val_accuracy: 1.0000 - val_recall: 0.9398\n",
      "Epoch 140/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.2309e-04 - accuracy: 1.0000 - recall: 0.9694\n",
      "Epoch 140: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.2309e-04 - accuracy: 1.0000 - recall: 0.9694 - val_loss: 1.0727e-04 - val_accuracy: 1.0000 - val_recall: 0.9635\n",
      "Epoch 141/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.1416e-04 - accuracy: 1.0000 - recall: 0.9714\n",
      "Epoch 141: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.1416e-04 - accuracy: 1.0000 - recall: 0.9714 - val_loss: 1.5506e-04 - val_accuracy: 1.0000 - val_recall: 0.9263\n",
      "Epoch 142/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.0805e-04 - accuracy: 1.0000 - recall: 0.9760\n",
      "Epoch 142: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 1.0805e-04 - accuracy: 1.0000 - recall: 0.9760 - val_loss: 1.1421e-04 - val_accuracy: 1.0000 - val_recall: 0.9660\n",
      "Epoch 143/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.0762e-04 - accuracy: 1.0000 - recall: 0.9710\n",
      "Epoch 143: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.0762e-04 - accuracy: 1.0000 - recall: 0.9710 - val_loss: 1.3656e-04 - val_accuracy: 1.0000 - val_recall: 0.9399\n",
      "Epoch 144/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.0542e-04 - accuracy: 1.0000 - recall: 0.9738\n",
      "Epoch 144: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 315ms/step - loss: 1.0542e-04 - accuracy: 1.0000 - recall: 0.9738 - val_loss: 1.9079e-04 - val_accuracy: 0.9999 - val_recall: 0.9647\n",
      "Epoch 145/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.1163e-04 - accuracy: 1.0000 - recall: 0.9714\n",
      "Epoch 145: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.1163e-04 - accuracy: 1.0000 - recall: 0.9714 - val_loss: 1.5913e-04 - val_accuracy: 1.0000 - val_recall: 0.9731\n",
      "Epoch 146/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.0222e-04 - accuracy: 1.0000 - recall: 0.9770\n",
      "Epoch 146: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.0222e-04 - accuracy: 1.0000 - recall: 0.9770 - val_loss: 1.3111e-04 - val_accuracy: 1.0000 - val_recall: 0.9352\n",
      "Epoch 147/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.0664e-04 - accuracy: 1.0000 - recall: 0.9723\n",
      "Epoch 147: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.0664e-04 - accuracy: 1.0000 - recall: 0.9723 - val_loss: 1.4735e-04 - val_accuracy: 1.0000 - val_recall: 0.9544\n",
      "Epoch 148/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 9.9200e-05 - accuracy: 1.0000 - recall: 0.9734\n",
      "Epoch 148: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 9.9200e-05 - accuracy: 1.0000 - recall: 0.9734 - val_loss: 0.0018 - val_accuracy: 0.9995 - val_recall: 0.2544\n",
      "Epoch 149/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.4168e-04 - accuracy: 1.0000 - recall: 0.9698\n",
      "Epoch 149: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.4168e-04 - accuracy: 1.0000 - recall: 0.9698 - val_loss: 1.9166e-04 - val_accuracy: 0.9999 - val_recall: 0.9935\n",
      "Epoch 150/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.1734e-04 - accuracy: 1.0000 - recall: 0.9726\n",
      "Epoch 150: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.1734e-04 - accuracy: 1.0000 - recall: 0.9726 - val_loss: 1.1481e-04 - val_accuracy: 1.0000 - val_recall: 0.9516\n",
      "Epoch 151/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.2371e-04 - accuracy: 1.0000 - recall: 0.9723\n",
      "Epoch 151: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.2371e-04 - accuracy: 1.0000 - recall: 0.9723 - val_loss: 1.3666e-04 - val_accuracy: 1.0000 - val_recall: 0.9464\n",
      "Epoch 152/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.1321e-04 - accuracy: 1.0000 - recall: 0.9704\n",
      "Epoch 152: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.1321e-04 - accuracy: 1.0000 - recall: 0.9704 - val_loss: 5.8729e-04 - val_accuracy: 0.9998 - val_recall: 0.7501\n",
      "Epoch 153/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.2780e-04 - accuracy: 1.0000 - recall: 0.9731\n",
      "Epoch 153: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.2780e-04 - accuracy: 1.0000 - recall: 0.9731 - val_loss: 6.5682e-04 - val_accuracy: 0.9999 - val_recall: 0.7861\n",
      "Epoch 154/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.3660e-04 - accuracy: 1.0000 - recall: 0.9679\n",
      "Epoch 154: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 1.3660e-04 - accuracy: 1.0000 - recall: 0.9679 - val_loss: 1.4676e-04 - val_accuracy: 1.0000 - val_recall: 0.9519\n",
      "Epoch 155/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.1267e-04 - accuracy: 1.0000 - recall: 0.9724\n",
      "Epoch 155: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.1267e-04 - accuracy: 1.0000 - recall: 0.9724 - val_loss: 2.5200e-04 - val_accuracy: 0.9999 - val_recall: 0.9505\n",
      "Epoch 156/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.1816e-04 - accuracy: 1.0000 - recall: 0.9702\n",
      "Epoch 156: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.1816e-04 - accuracy: 1.0000 - recall: 0.9702 - val_loss: 3.1282e-04 - val_accuracy: 0.9999 - val_recall: 0.9671\n",
      "Epoch 157/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.0369e-04 - accuracy: 1.0000 - recall: 0.9762\n",
      "Epoch 157: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.0369e-04 - accuracy: 1.0000 - recall: 0.9762 - val_loss: 1.6744e-04 - val_accuracy: 0.9999 - val_recall: 0.9087\n",
      "Epoch 158/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 9.0556e-05 - accuracy: 1.0000 - recall: 0.9769\n",
      "Epoch 158: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 9.0556e-05 - accuracy: 1.0000 - recall: 0.9769 - val_loss: 1.1865e-04 - val_accuracy: 1.0000 - val_recall: 0.9608\n",
      "Epoch 159/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 8.8610e-05 - accuracy: 1.0000 - recall: 0.9766\n",
      "Epoch 159: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 8.8610e-05 - accuracy: 1.0000 - recall: 0.9766 - val_loss: 1.5668e-04 - val_accuracy: 1.0000 - val_recall: 0.9533\n",
      "Epoch 160/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 8.3906e-05 - accuracy: 1.0000 - recall: 0.9792\n",
      "Epoch 160: val_recall did not improve from 0.99698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 8.3906e-05 - accuracy: 1.0000 - recall: 0.9792 - val_loss: 1.7168e-04 - val_accuracy: 1.0000 - val_recall: 0.9307\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.3084 - accuracy: 0.9745 - recall: 0.0099\n",
      "Epoch 1: val_recall improved from -inf to 0.00008, saving model to model_4fold.h5\n",
      "42/42 [==============================] - 18s 400ms/step - loss: 0.3084 - accuracy: 0.9745 - recall: 0.0099 - val_loss: 0.2480 - val_accuracy: 0.9757 - val_recall: 7.8104e-05\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1424 - accuracy: 0.9990 - recall: 1.7801e-05\n",
      "Epoch 2: val_recall did not improve from 0.00008\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 0.1424 - accuracy: 0.9990 - recall: 1.7801e-05 - val_loss: 0.1703 - val_accuracy: 0.9991 - val_recall: 0.0000e+00\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0925 - accuracy: 0.9993 - recall: 0.0000e+00\n",
      "Epoch 3: val_recall did not improve from 0.00008\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0925 - accuracy: 0.9993 - recall: 0.0000e+00 - val_loss: 0.1060 - val_accuracy: 0.9994 - val_recall: 0.0000e+00\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0645 - accuracy: 0.9993 - recall: 8.9004e-06\n",
      "Epoch 4: val_recall did not improve from 0.00008\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 0.0645 - accuracy: 0.9993 - recall: 8.9004e-06 - val_loss: 0.0731 - val_accuracy: 0.9994 - val_recall: 0.0000e+00\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0470 - accuracy: 0.9994 - recall: 0.0000e+00\n",
      "Epoch 5: val_recall did not improve from 0.00008\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0470 - accuracy: 0.9994 - recall: 0.0000e+00 - val_loss: 0.0498 - val_accuracy: 0.9994 - val_recall: 0.0000e+00\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0351 - accuracy: 0.9994 - recall: 0.0104\n",
      "Epoch 6: val_recall did not improve from 0.00008\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0351 - accuracy: 0.9994 - recall: 0.0104 - val_loss: 0.0370 - val_accuracy: 0.9994 - val_recall: 0.0000e+00\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0262 - accuracy: 0.9995 - recall: 0.3474\n",
      "Epoch 7: val_recall did not improve from 0.00008\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 0.0262 - accuracy: 0.9995 - recall: 0.3474 - val_loss: 0.0290 - val_accuracy: 0.9994 - val_recall: 0.0000e+00\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9997 - recall: 0.6171\n",
      "Epoch 8: val_recall did not improve from 0.00008\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 0.0200 - accuracy: 0.9997 - recall: 0.6171 - val_loss: 0.0223 - val_accuracy: 0.9994 - val_recall: 0.0000e+00\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 0.9997 - recall: 0.7043\n",
      "Epoch 9: val_recall did not improve from 0.00008\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0160 - accuracy: 0.9997 - recall: 0.7043 - val_loss: 0.0177 - val_accuracy: 0.9994 - val_recall: 0.0000e+00\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0130 - accuracy: 0.9998 - recall: 0.7603\n",
      "Epoch 10: val_recall did not improve from 0.00008\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 0.0130 - accuracy: 0.9998 - recall: 0.7603 - val_loss: 0.0144 - val_accuracy: 0.9994 - val_recall: 0.0000e+00\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 0.9998 - recall: 0.7911\n",
      "Epoch 11: val_recall improved from 0.00008 to 0.00027, saving model to model_4fold.h5\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 0.0108 - accuracy: 0.9998 - recall: 0.7911 - val_loss: 0.0116 - val_accuracy: 0.9994 - val_recall: 2.7336e-04\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.9998 - recall: 0.8030\n",
      "Epoch 12: val_recall improved from 0.00027 to 0.00531, saving model to model_4fold.h5\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 0.0091 - accuracy: 0.9998 - recall: 0.8030 - val_loss: 0.0106 - val_accuracy: 0.9994 - val_recall: 0.0053\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 0.9998 - recall: 0.8127\n",
      "Epoch 13: val_recall improved from 0.00531 to 0.11282, saving model to model_4fold.h5\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 0.0079 - accuracy: 0.9998 - recall: 0.8127 - val_loss: 0.0078 - val_accuracy: 0.9995 - val_recall: 0.1128\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 0.9998 - recall: 0.8361\n",
      "Epoch 14: val_recall improved from 0.11282 to 0.33245, saving model to model_4fold.h5\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 0.0068 - accuracy: 0.9998 - recall: 0.8361 - val_loss: 0.0058 - val_accuracy: 0.9996 - val_recall: 0.3324\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 0.9998 - recall: 0.8569\n",
      "Epoch 15: val_recall did not improve from 0.33245\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 0.0059 - accuracy: 0.9998 - recall: 0.8569 - val_loss: 0.0059 - val_accuracy: 0.9995 - val_recall: 0.1661\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 0.9998 - recall: 0.8262\n",
      "Epoch 16: val_recall improved from 0.33245 to 0.57754, saving model to model_4fold.h5\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 0.0053 - accuracy: 0.9998 - recall: 0.8262 - val_loss: 0.0046 - val_accuracy: 0.9997 - val_recall: 0.5775\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 0.9999 - recall: 0.8664\n",
      "Epoch 17: val_recall did not improve from 0.57754\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0046 - accuracy: 0.9999 - recall: 0.8664 - val_loss: 0.0043 - val_accuracy: 0.9996 - val_recall: 0.2867\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9999 - recall: 0.8688\n",
      "Epoch 18: val_recall improved from 0.57754 to 0.58785, saving model to model_4fold.h5\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 0.0041 - accuracy: 0.9999 - recall: 0.8688 - val_loss: 0.0036 - val_accuracy: 0.9998 - val_recall: 0.5878\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9999 - recall: 0.8709\n",
      "Epoch 19: val_recall improved from 0.58785 to 0.87367, saving model to model_4fold.h5\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 0.0037 - accuracy: 0.9999 - recall: 0.8709 - val_loss: 0.0031 - val_accuracy: 0.9999 - val_recall: 0.8737\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9999 - recall: 0.8654\n",
      "Epoch 20: val_recall did not improve from 0.87367\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 0.0034 - accuracy: 0.9999 - recall: 0.8654 - val_loss: 0.0028 - val_accuracy: 0.9999 - val_recall: 0.8492\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9999 - recall: 0.8801\n",
      "Epoch 21: val_recall did not improve from 0.87367\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 0.0031 - accuracy: 0.9999 - recall: 0.8801 - val_loss: 0.0026 - val_accuracy: 0.9998 - val_recall: 0.6546\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9999 - recall: 0.8923\n",
      "Epoch 22: val_recall did not improve from 0.87367\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0028 - accuracy: 0.9999 - recall: 0.8923 - val_loss: 0.0026 - val_accuracy: 0.9997 - val_recall: 0.5763\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9999 - recall: 0.8920\n",
      "Epoch 23: val_recall did not improve from 0.87367\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 0.0026 - accuracy: 0.9999 - recall: 0.8920 - val_loss: 0.0026 - val_accuracy: 0.9997 - val_recall: 0.5236\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9999 - recall: 0.8881\n",
      "Epoch 24: val_recall did not improve from 0.87367\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 0.0024 - accuracy: 0.9999 - recall: 0.8881 - val_loss: 0.0022 - val_accuracy: 0.9998 - val_recall: 0.6234\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9999 - recall: 0.8964\n",
      "Epoch 25: val_recall did not improve from 0.87367\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0022 - accuracy: 0.9999 - recall: 0.8964 - val_loss: 0.0020 - val_accuracy: 0.9999 - val_recall: 0.7778\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9999 - recall: 0.9096\n",
      "Epoch 26: val_recall did not improve from 0.87367\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 0.0020 - accuracy: 0.9999 - recall: 0.9096 - val_loss: 0.0018 - val_accuracy: 0.9999 - val_recall: 0.7964\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9999 - recall: 0.9042\n",
      "Epoch 27: val_recall did not improve from 0.87367\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0019 - accuracy: 0.9999 - recall: 0.9042 - val_loss: 0.0018 - val_accuracy: 0.9998 - val_recall: 0.6965\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9999 - recall: 0.9037\n",
      "Epoch 28: val_recall did not improve from 0.87367\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0018 - accuracy: 0.9999 - recall: 0.9037 - val_loss: 0.0016 - val_accuracy: 0.9999 - val_recall: 0.7669\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9999 - recall: 0.9062\n",
      "Epoch 29: val_recall did not improve from 0.87367\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0016 - accuracy: 0.9999 - recall: 0.9062 - val_loss: 0.0014 - val_accuracy: 0.9999 - val_recall: 0.8514\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9999 - recall: 0.9185\n",
      "Epoch 30: val_recall did not improve from 0.87367\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0015 - accuracy: 0.9999 - recall: 0.9185 - val_loss: 0.0014 - val_accuracy: 0.9999 - val_recall: 0.8219\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9999 - recall: 0.9184\n",
      "Epoch 31: val_recall improved from 0.87367 to 0.87769, saving model to model_4fold.h5\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 0.0015 - accuracy: 0.9999 - recall: 0.9184 - val_loss: 0.0012 - val_accuracy: 0.9999 - val_recall: 0.8777\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9999 - recall: 0.9153\n",
      "Epoch 32: val_recall did not improve from 0.87769\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0014 - accuracy: 0.9999 - recall: 0.9153 - val_loss: 0.0013 - val_accuracy: 0.9998 - val_recall: 0.7411\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9999 - recall: 0.9197\n",
      "Epoch 33: val_recall did not improve from 0.87769\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0013 - accuracy: 0.9999 - recall: 0.9197 - val_loss: 0.0012 - val_accuracy: 0.9999 - val_recall: 0.8161\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 0.9999 - recall: 0.9227\n",
      "Epoch 34: val_recall did not improve from 0.87769\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0012 - accuracy: 0.9999 - recall: 0.9227 - val_loss: 0.0012 - val_accuracy: 0.9998 - val_recall: 0.7332\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9999 - recall: 0.9267\n",
      "Epoch 35: val_recall did not improve from 0.87769\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0011 - accuracy: 0.9999 - recall: 0.9267 - val_loss: 9.9298e-04 - val_accuracy: 0.9999 - val_recall: 0.8765\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9999 - recall: 0.9210\n",
      "Epoch 36: val_recall improved from 0.87769 to 0.97071, saving model to model_4fold.h5\n",
      "42/42 [==============================] - 13s 321ms/step - loss: 0.0011 - accuracy: 0.9999 - recall: 0.9210 - val_loss: 8.6999e-04 - val_accuracy: 1.0000 - val_recall: 0.9707\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9999 - recall: 0.9222\n",
      "Epoch 37: val_recall did not improve from 0.97071\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 0.0011 - accuracy: 0.9999 - recall: 0.9222 - val_loss: 8.9316e-04 - val_accuracy: 1.0000 - val_recall: 0.9533\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 9.5693e-04 - accuracy: 0.9999 - recall: 0.9361\n",
      "Epoch 38: val_recall did not improve from 0.97071\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 9.5693e-04 - accuracy: 0.9999 - recall: 0.9361 - val_loss: 7.8996e-04 - val_accuracy: 1.0000 - val_recall: 0.9706\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 9.4909e-04 - accuracy: 0.9999 - recall: 0.9289\n",
      "Epoch 39: val_recall did not improve from 0.97071\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 9.4909e-04 - accuracy: 0.9999 - recall: 0.9289 - val_loss: 8.1613e-04 - val_accuracy: 0.9999 - val_recall: 0.8936\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 9.1396e-04 - accuracy: 0.9999 - recall: 0.9255\n",
      "Epoch 40: val_recall did not improve from 0.97071\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 9.1396e-04 - accuracy: 0.9999 - recall: 0.9255 - val_loss: 7.1916e-04 - val_accuracy: 1.0000 - val_recall: 0.9386\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 8.6012e-04 - accuracy: 0.9999 - recall: 0.9326\n",
      "Epoch 41: val_recall did not improve from 0.97071\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 8.6012e-04 - accuracy: 0.9999 - recall: 0.9326 - val_loss: 7.2249e-04 - val_accuracy: 0.9999 - val_recall: 0.9200\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 8.0494e-04 - accuracy: 0.9999 - recall: 0.9320\n",
      "Epoch 42: val_recall did not improve from 0.97071\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 8.0494e-04 - accuracy: 0.9999 - recall: 0.9320 - val_loss: 6.8344e-04 - val_accuracy: 0.9999 - val_recall: 0.9163\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 7.8883e-04 - accuracy: 0.9999 - recall: 0.9366\n",
      "Epoch 43: val_recall did not improve from 0.97071\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 7.8883e-04 - accuracy: 0.9999 - recall: 0.9366 - val_loss: 6.4595e-04 - val_accuracy: 1.0000 - val_recall: 0.9260\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 7.7333e-04 - accuracy: 0.9999 - recall: 0.9254\n",
      "Epoch 44: val_recall did not improve from 0.97071\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 7.7333e-04 - accuracy: 0.9999 - recall: 0.9254 - val_loss: 6.2529e-04 - val_accuracy: 0.9999 - val_recall: 0.9149\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 7.2859e-04 - accuracy: 0.9999 - recall: 0.9294\n",
      "Epoch 45: val_recall improved from 0.97071 to 0.98153, saving model to model_4fold.h5\n",
      "42/42 [==============================] - 13s 321ms/step - loss: 7.2859e-04 - accuracy: 0.9999 - recall: 0.9294 - val_loss: 6.2145e-04 - val_accuracy: 0.9999 - val_recall: 0.9815\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 6.7125e-04 - accuracy: 0.9999 - recall: 0.9416\n",
      "Epoch 46: val_recall improved from 0.98153 to 0.99059, saving model to model_4fold.h5\n",
      "42/42 [==============================] - 13s 321ms/step - loss: 6.7125e-04 - accuracy: 0.9999 - recall: 0.9416 - val_loss: 5.8001e-04 - val_accuracy: 0.9999 - val_recall: 0.9906\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 6.2729e-04 - accuracy: 0.9999 - recall: 0.9434\n",
      "Epoch 47: val_recall did not improve from 0.99059\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 6.2729e-04 - accuracy: 0.9999 - recall: 0.9434 - val_loss: 5.9625e-04 - val_accuracy: 0.9999 - val_recall: 0.8878\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 6.1137e-04 - accuracy: 0.9999 - recall: 0.9361\n",
      "Epoch 48: val_recall did not improve from 0.99059\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 6.1137e-04 - accuracy: 0.9999 - recall: 0.9361 - val_loss: 4.9515e-04 - val_accuracy: 1.0000 - val_recall: 0.9328\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 5.9185e-04 - accuracy: 0.9999 - recall: 0.9431\n",
      "Epoch 49: val_recall did not improve from 0.99059\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 5.9185e-04 - accuracy: 0.9999 - recall: 0.9431 - val_loss: 4.9657e-04 - val_accuracy: 1.0000 - val_recall: 0.9270\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 5.6378e-04 - accuracy: 0.9999 - recall: 0.9434\n",
      "Epoch 50: val_recall did not improve from 0.99059\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 5.6378e-04 - accuracy: 0.9999 - recall: 0.9434 - val_loss: 4.8549e-04 - val_accuracy: 0.9999 - val_recall: 0.9334\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 5.4392e-04 - accuracy: 0.9999 - recall: 0.9402\n",
      "Epoch 51: val_recall did not improve from 0.99059\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 5.4392e-04 - accuracy: 0.9999 - recall: 0.9402 - val_loss: 5.0228e-04 - val_accuracy: 0.9999 - val_recall: 0.9171\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 5.3600e-04 - accuracy: 0.9999 - recall: 0.9412\n",
      "Epoch 52: val_recall did not improve from 0.99059\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 5.3600e-04 - accuracy: 0.9999 - recall: 0.9412 - val_loss: 5.1379e-04 - val_accuracy: 0.9999 - val_recall: 0.8821\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 5.0671e-04 - accuracy: 0.9999 - recall: 0.9428\n",
      "Epoch 53: val_recall did not improve from 0.99059\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 5.0671e-04 - accuracy: 0.9999 - recall: 0.9428 - val_loss: 4.1415e-04 - val_accuracy: 1.0000 - val_recall: 0.9287\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 4.8523e-04 - accuracy: 0.9999 - recall: 0.9467\n",
      "Epoch 54: val_recall improved from 0.99059 to 0.99461, saving model to model_4fold.h5\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 4.8523e-04 - accuracy: 0.9999 - recall: 0.9467 - val_loss: 4.4093e-04 - val_accuracy: 0.9999 - val_recall: 0.9946\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 4.6665e-04 - accuracy: 0.9999 - recall: 0.9433\n",
      "Epoch 55: val_recall did not improve from 0.99461\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 4.6665e-04 - accuracy: 0.9999 - recall: 0.9433 - val_loss: 3.7817e-04 - val_accuracy: 1.0000 - val_recall: 0.9565\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 4.5172e-04 - accuracy: 0.9999 - recall: 0.9491\n",
      "Epoch 56: val_recall did not improve from 0.99461\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 4.5172e-04 - accuracy: 0.9999 - recall: 0.9491 - val_loss: 4.1110e-04 - val_accuracy: 0.9999 - val_recall: 0.9079\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 4.4165e-04 - accuracy: 0.9999 - recall: 0.9482\n",
      "Epoch 57: val_recall did not improve from 0.99461\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 4.4165e-04 - accuracy: 0.9999 - recall: 0.9482 - val_loss: 3.7748e-04 - val_accuracy: 0.9999 - val_recall: 0.9187\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 4.1193e-04 - accuracy: 0.9999 - recall: 0.9536\n",
      "Epoch 58: val_recall did not improve from 0.99461\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 4.1193e-04 - accuracy: 0.9999 - recall: 0.9536 - val_loss: 3.7629e-04 - val_accuracy: 0.9999 - val_recall: 0.9183\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 4.1809e-04 - accuracy: 0.9999 - recall: 0.9475\n",
      "Epoch 59: val_recall did not improve from 0.99461\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 4.1809e-04 - accuracy: 0.9999 - recall: 0.9475 - val_loss: 3.4004e-04 - val_accuracy: 0.9999 - val_recall: 0.9124\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.9683e-04 - accuracy: 0.9999 - recall: 0.9505\n",
      "Epoch 60: val_recall did not improve from 0.99461\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 3.9683e-04 - accuracy: 0.9999 - recall: 0.9505 - val_loss: 3.2052e-04 - val_accuracy: 1.0000 - val_recall: 0.9483\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.8744e-04 - accuracy: 0.9999 - recall: 0.9530\n",
      "Epoch 61: val_recall did not improve from 0.99461\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 3.8744e-04 - accuracy: 0.9999 - recall: 0.9530 - val_loss: 3.2863e-04 - val_accuracy: 1.0000 - val_recall: 0.9234\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.7370e-04 - accuracy: 0.9999 - recall: 0.9519\n",
      "Epoch 62: val_recall did not improve from 0.99461\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 3.7370e-04 - accuracy: 0.9999 - recall: 0.9519 - val_loss: 3.2202e-04 - val_accuracy: 1.0000 - val_recall: 0.9269\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.5291e-04 - accuracy: 0.9999 - recall: 0.9537\n",
      "Epoch 63: val_recall did not improve from 0.99461\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 3.5291e-04 - accuracy: 0.9999 - recall: 0.9537 - val_loss: 3.0160e-04 - val_accuracy: 1.0000 - val_recall: 0.9691\n",
      "Epoch 64/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.7554e-04 - accuracy: 0.9999 - recall: 0.9494\n",
      "Epoch 64: val_recall did not improve from 0.99461\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 3.7554e-04 - accuracy: 0.9999 - recall: 0.9494 - val_loss: 2.8619e-04 - val_accuracy: 1.0000 - val_recall: 0.9730\n",
      "Epoch 65/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.5795e-04 - accuracy: 0.9999 - recall: 0.9463\n",
      "Epoch 65: val_recall did not improve from 0.99461\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 3.5795e-04 - accuracy: 0.9999 - recall: 0.9463 - val_loss: 3.0563e-04 - val_accuracy: 1.0000 - val_recall: 0.9267\n",
      "Epoch 66/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.6346e-04 - accuracy: 0.9999 - recall: 0.9460\n",
      "Epoch 66: val_recall did not improve from 0.99461\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 3.6346e-04 - accuracy: 0.9999 - recall: 0.9460 - val_loss: 3.5816e-04 - val_accuracy: 0.9999 - val_recall: 0.9732\n",
      "Epoch 67/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.1663e-04 - accuracy: 0.9999 - recall: 0.9552\n",
      "Epoch 67: val_recall did not improve from 0.99461\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 3.1663e-04 - accuracy: 0.9999 - recall: 0.9552 - val_loss: 2.5968e-04 - val_accuracy: 1.0000 - val_recall: 0.9494\n",
      "Epoch 68/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.1820e-04 - accuracy: 0.9999 - recall: 0.9562\n",
      "Epoch 68: val_recall did not improve from 0.99461\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 3.1820e-04 - accuracy: 0.9999 - recall: 0.9562 - val_loss: 2.4950e-04 - val_accuracy: 1.0000 - val_recall: 0.9555\n",
      "Epoch 69/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.1242e-04 - accuracy: 0.9999 - recall: 0.9530\n",
      "Epoch 69: val_recall did not improve from 0.99461\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 3.1242e-04 - accuracy: 0.9999 - recall: 0.9530 - val_loss: 6.4962e-04 - val_accuracy: 0.9999 - val_recall: 0.9601\n",
      "Epoch 70/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 4.3044e-04 - accuracy: 0.9999 - recall: 0.9100\n",
      "Epoch 70: val_recall did not improve from 0.99461\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 4.3044e-04 - accuracy: 0.9999 - recall: 0.9100 - val_loss: 3.4555e-04 - val_accuracy: 0.9999 - val_recall: 0.8871\n",
      "Epoch 71/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.5168e-04 - accuracy: 0.9999 - recall: 0.9465\n",
      "Epoch 71: val_recall did not improve from 0.99461\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 3.5168e-04 - accuracy: 0.9999 - recall: 0.9465 - val_loss: 2.8476e-04 - val_accuracy: 1.0000 - val_recall: 0.9285\n",
      "Epoch 72/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.3998e-04 - accuracy: 0.9999 - recall: 0.9393\n",
      "Epoch 72: val_recall did not improve from 0.99461\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 3.3998e-04 - accuracy: 0.9999 - recall: 0.9393 - val_loss: 2.5614e-04 - val_accuracy: 1.0000 - val_recall: 0.9408\n",
      "Epoch 73/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.9931e-04 - accuracy: 0.9999 - recall: 0.9530\n",
      "Epoch 73: val_recall did not improve from 0.99461\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.9931e-04 - accuracy: 0.9999 - recall: 0.9530 - val_loss: 2.1574e-04 - val_accuracy: 1.0000 - val_recall: 0.9753\n",
      "Epoch 74/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.0379e-04 - accuracy: 0.9999 - recall: 0.9489\n",
      "Epoch 74: val_recall did not improve from 0.99461\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 3.0379e-04 - accuracy: 0.9999 - recall: 0.9489 - val_loss: 2.7201e-04 - val_accuracy: 0.9999 - val_recall: 0.9012\n",
      "Epoch 75/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.6864e-04 - accuracy: 1.0000 - recall: 0.9576\n",
      "Epoch 75: val_recall did not improve from 0.99461\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.6864e-04 - accuracy: 1.0000 - recall: 0.9576 - val_loss: 2.3847e-04 - val_accuracy: 1.0000 - val_recall: 0.9536\n",
      "Epoch 76/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.6818e-04 - accuracy: 1.0000 - recall: 0.9611\n",
      "Epoch 76: val_recall did not improve from 0.99461\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.6818e-04 - accuracy: 1.0000 - recall: 0.9611 - val_loss: 2.0282e-04 - val_accuracy: 1.0000 - val_recall: 0.9615\n",
      "Epoch 77/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.5741e-04 - accuracy: 1.0000 - recall: 0.9583\n",
      "Epoch 77: val_recall did not improve from 0.99461\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.5741e-04 - accuracy: 1.0000 - recall: 0.9583 - val_loss: 2.1117e-04 - val_accuracy: 1.0000 - val_recall: 0.9329\n",
      "Epoch 78/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.6476e-04 - accuracy: 0.9999 - recall: 0.9510\n",
      "Epoch 78: val_recall did not improve from 0.99461\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.6476e-04 - accuracy: 0.9999 - recall: 0.9510 - val_loss: 1.9896e-04 - val_accuracy: 1.0000 - val_recall: 0.9747\n",
      "Epoch 79/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.5761e-04 - accuracy: 0.9999 - recall: 0.9580\n",
      "Epoch 79: val_recall did not improve from 0.99461\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.5761e-04 - accuracy: 0.9999 - recall: 0.9580 - val_loss: 2.1456e-04 - val_accuracy: 1.0000 - val_recall: 0.9340\n",
      "Epoch 80/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.6985e-04 - accuracy: 0.9999 - recall: 0.9546\n",
      "Epoch 80: val_recall improved from 0.99461 to 0.99734, saving model to model_4fold.h5\n",
      "42/42 [==============================] - 13s 321ms/step - loss: 2.6985e-04 - accuracy: 0.9999 - recall: 0.9546 - val_loss: 2.6091e-04 - val_accuracy: 0.9999 - val_recall: 0.9973\n",
      "Epoch 81/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.4334e-04 - accuracy: 1.0000 - recall: 0.9594\n",
      "Epoch 81: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.4334e-04 - accuracy: 1.0000 - recall: 0.9594 - val_loss: 1.9464e-04 - val_accuracy: 1.0000 - val_recall: 0.9399\n",
      "Epoch 82/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.1808e-04 - accuracy: 1.0000 - recall: 0.9628\n",
      "Epoch 82: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.1808e-04 - accuracy: 1.0000 - recall: 0.9628 - val_loss: 1.7515e-04 - val_accuracy: 1.0000 - val_recall: 0.9641\n",
      "Epoch 83/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.4137e-04 - accuracy: 0.9999 - recall: 0.9578\n",
      "Epoch 83: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.4137e-04 - accuracy: 0.9999 - recall: 0.9578 - val_loss: 1.6498e-04 - val_accuracy: 1.0000 - val_recall: 0.9613\n",
      "Epoch 84/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.2730e-04 - accuracy: 1.0000 - recall: 0.9611\n",
      "Epoch 84: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.2730e-04 - accuracy: 1.0000 - recall: 0.9611 - val_loss: 1.7601e-04 - val_accuracy: 1.0000 - val_recall: 0.9394\n",
      "Epoch 85/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.4740e-04 - accuracy: 0.9999 - recall: 0.9557\n",
      "Epoch 85: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.4740e-04 - accuracy: 0.9999 - recall: 0.9557 - val_loss: 3.5293e-04 - val_accuracy: 0.9999 - val_recall: 0.8414\n",
      "Epoch 86/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.2797e-04 - accuracy: 1.0000 - recall: 0.9621\n",
      "Epoch 86: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.2797e-04 - accuracy: 1.0000 - recall: 0.9621 - val_loss: 2.2363e-04 - val_accuracy: 0.9999 - val_recall: 0.9176\n",
      "Epoch 87/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.1159e-04 - accuracy: 1.0000 - recall: 0.9650\n",
      "Epoch 87: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.1159e-04 - accuracy: 1.0000 - recall: 0.9650 - val_loss: 2.0562e-04 - val_accuracy: 1.0000 - val_recall: 0.9203\n",
      "Epoch 88/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.2668e-04 - accuracy: 0.9999 - recall: 0.9539\n",
      "Epoch 88: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.2668e-04 - accuracy: 0.9999 - recall: 0.9539 - val_loss: 1.5887e-04 - val_accuracy: 1.0000 - val_recall: 0.9459\n",
      "Epoch 89/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.1641e-04 - accuracy: 1.0000 - recall: 0.9601\n",
      "Epoch 89: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.1641e-04 - accuracy: 1.0000 - recall: 0.9601 - val_loss: 2.5219e-04 - val_accuracy: 0.9999 - val_recall: 0.8948\n",
      "Epoch 90/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.0573e-04 - accuracy: 1.0000 - recall: 0.9630\n",
      "Epoch 90: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 2.0573e-04 - accuracy: 1.0000 - recall: 0.9630 - val_loss: 1.6852e-04 - val_accuracy: 1.0000 - val_recall: 0.9418\n",
      "Epoch 91/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.9332e-04 - accuracy: 1.0000 - recall: 0.9625\n",
      "Epoch 91: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 1.9332e-04 - accuracy: 1.0000 - recall: 0.9625 - val_loss: 1.5365e-04 - val_accuracy: 1.0000 - val_recall: 0.9846\n",
      "Epoch 92/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.0260e-04 - accuracy: 1.0000 - recall: 0.9619\n",
      "Epoch 92: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.0260e-04 - accuracy: 1.0000 - recall: 0.9619 - val_loss: 2.2268e-04 - val_accuracy: 0.9999 - val_recall: 0.9123\n",
      "Epoch 93/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.9804e-04 - accuracy: 1.0000 - recall: 0.9629\n",
      "Epoch 93: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.9804e-04 - accuracy: 1.0000 - recall: 0.9629 - val_loss: 2.4508e-04 - val_accuracy: 0.9999 - val_recall: 0.8880\n",
      "Epoch 94/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.8753e-04 - accuracy: 1.0000 - recall: 0.9603\n",
      "Epoch 94: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.8753e-04 - accuracy: 1.0000 - recall: 0.9603 - val_loss: 1.3448e-04 - val_accuracy: 1.0000 - val_recall: 0.9743\n",
      "Epoch 95/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.9669e-04 - accuracy: 1.0000 - recall: 0.9650\n",
      "Epoch 95: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.9669e-04 - accuracy: 1.0000 - recall: 0.9650 - val_loss: 1.5176e-04 - val_accuracy: 1.0000 - val_recall: 0.9464\n",
      "Epoch 96/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.8401e-04 - accuracy: 1.0000 - recall: 0.9659\n",
      "Epoch 96: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.8401e-04 - accuracy: 1.0000 - recall: 0.9659 - val_loss: 1.4598e-04 - val_accuracy: 1.0000 - val_recall: 0.9660\n",
      "Epoch 97/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.7919e-04 - accuracy: 1.0000 - recall: 0.9609\n",
      "Epoch 97: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 1.7919e-04 - accuracy: 1.0000 - recall: 0.9609 - val_loss: 1.5527e-04 - val_accuracy: 1.0000 - val_recall: 0.9387\n",
      "Epoch 98/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.7246e-04 - accuracy: 1.0000 - recall: 0.9669\n",
      "Epoch 98: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.7246e-04 - accuracy: 1.0000 - recall: 0.9669 - val_loss: 1.2600e-04 - val_accuracy: 1.0000 - val_recall: 0.9750\n",
      "Epoch 99/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.6849e-04 - accuracy: 1.0000 - recall: 0.9672\n",
      "Epoch 99: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.6849e-04 - accuracy: 1.0000 - recall: 0.9672 - val_loss: 1.4390e-04 - val_accuracy: 1.0000 - val_recall: 0.9413\n",
      "Epoch 100/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.7365e-04 - accuracy: 1.0000 - recall: 0.9654\n",
      "Epoch 100: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.7365e-04 - accuracy: 1.0000 - recall: 0.9654 - val_loss: 1.7537e-04 - val_accuracy: 1.0000 - val_recall: 0.9414\n",
      "Epoch 101/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.7727e-04 - accuracy: 1.0000 - recall: 0.9635\n",
      "Epoch 101: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.7727e-04 - accuracy: 1.0000 - recall: 0.9635 - val_loss: 1.7388e-04 - val_accuracy: 1.0000 - val_recall: 0.9410\n",
      "Epoch 102/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.7822e-04 - accuracy: 1.0000 - recall: 0.9613\n",
      "Epoch 102: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 14s 325ms/step - loss: 1.7822e-04 - accuracy: 1.0000 - recall: 0.9613 - val_loss: 1.4915e-04 - val_accuracy: 1.0000 - val_recall: 0.9902\n",
      "Epoch 103/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.7921e-04 - accuracy: 1.0000 - recall: 0.9628\n",
      "Epoch 103: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 14s 325ms/step - loss: 1.7921e-04 - accuracy: 1.0000 - recall: 0.9628 - val_loss: 1.3687e-04 - val_accuracy: 1.0000 - val_recall: 0.9481\n",
      "Epoch 104/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.7803e-04 - accuracy: 1.0000 - recall: 0.9652\n",
      "Epoch 104: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 1.7803e-04 - accuracy: 1.0000 - recall: 0.9652 - val_loss: 1.3726e-04 - val_accuracy: 1.0000 - val_recall: 0.9450\n",
      "Epoch 105/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.6571e-04 - accuracy: 1.0000 - recall: 0.9652\n",
      "Epoch 105: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 1.6571e-04 - accuracy: 1.0000 - recall: 0.9652 - val_loss: 1.2042e-04 - val_accuracy: 1.0000 - val_recall: 0.9846\n",
      "Epoch 106/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.5260e-04 - accuracy: 1.0000 - recall: 0.9717\n",
      "Epoch 106: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 1.5260e-04 - accuracy: 1.0000 - recall: 0.9717 - val_loss: 1.3720e-04 - val_accuracy: 1.0000 - val_recall: 0.9465\n",
      "Epoch 107/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.5329e-04 - accuracy: 1.0000 - recall: 0.9676\n",
      "Epoch 107: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 1.5329e-04 - accuracy: 1.0000 - recall: 0.9676 - val_loss: 1.0906e-04 - val_accuracy: 1.0000 - val_recall: 0.9716\n",
      "Epoch 108/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.5197e-04 - accuracy: 1.0000 - recall: 0.9684\n",
      "Epoch 108: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 1.5197e-04 - accuracy: 1.0000 - recall: 0.9684 - val_loss: 1.2768e-04 - val_accuracy: 1.0000 - val_recall: 0.9780\n",
      "Epoch 109/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.4107e-04 - accuracy: 1.0000 - recall: 0.9693\n",
      "Epoch 109: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 1.4107e-04 - accuracy: 1.0000 - recall: 0.9693 - val_loss: 1.3195e-04 - val_accuracy: 1.0000 - val_recall: 0.9451\n",
      "Epoch 110/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.5340e-04 - accuracy: 1.0000 - recall: 0.9657\n",
      "Epoch 110: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 1.5340e-04 - accuracy: 1.0000 - recall: 0.9657 - val_loss: 1.3334e-04 - val_accuracy: 1.0000 - val_recall: 0.9403\n",
      "Epoch 111/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.5392e-04 - accuracy: 1.0000 - recall: 0.9672\n",
      "Epoch 111: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 1.5392e-04 - accuracy: 1.0000 - recall: 0.9672 - val_loss: 1.0765e-04 - val_accuracy: 1.0000 - val_recall: 0.9684\n",
      "Epoch 112/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.4486e-04 - accuracy: 1.0000 - recall: 0.9715\n",
      "Epoch 112: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 1.4486e-04 - accuracy: 1.0000 - recall: 0.9715 - val_loss: 1.0725e-04 - val_accuracy: 1.0000 - val_recall: 0.9711\n",
      "Epoch 113/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.4401e-04 - accuracy: 1.0000 - recall: 0.9669\n",
      "Epoch 113: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 1.4401e-04 - accuracy: 1.0000 - recall: 0.9669 - val_loss: 1.3688e-04 - val_accuracy: 1.0000 - val_recall: 0.9365\n",
      "Epoch 114/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.2486e-04 - accuracy: 1.0000 - recall: 0.9719\n",
      "Epoch 114: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 1.2486e-04 - accuracy: 1.0000 - recall: 0.9719 - val_loss: 1.1116e-04 - val_accuracy: 1.0000 - val_recall: 0.9596\n",
      "Epoch 115/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.5358e-04 - accuracy: 1.0000 - recall: 0.9689\n",
      "Epoch 115: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 1.5358e-04 - accuracy: 1.0000 - recall: 0.9689 - val_loss: 1.1065e-04 - val_accuracy: 1.0000 - val_recall: 0.9762\n",
      "Epoch 116/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.5017e-04 - accuracy: 1.0000 - recall: 0.9651\n",
      "Epoch 116: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 1.5017e-04 - accuracy: 1.0000 - recall: 0.9651 - val_loss: 1.4664e-04 - val_accuracy: 1.0000 - val_recall: 0.9949\n",
      "Epoch 117/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.3645e-04 - accuracy: 1.0000 - recall: 0.9677\n",
      "Epoch 117: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 1.3645e-04 - accuracy: 1.0000 - recall: 0.9677 - val_loss: 1.1176e-04 - val_accuracy: 1.0000 - val_recall: 0.9580\n",
      "Epoch 118/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.3120e-04 - accuracy: 1.0000 - recall: 0.9736\n",
      "Epoch 118: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 1.3120e-04 - accuracy: 1.0000 - recall: 0.9736 - val_loss: 1.2555e-04 - val_accuracy: 1.0000 - val_recall: 0.9601\n",
      "Epoch 119/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.2216e-04 - accuracy: 1.0000 - recall: 0.9710\n",
      "Epoch 119: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 1.2216e-04 - accuracy: 1.0000 - recall: 0.9710 - val_loss: 1.2964e-04 - val_accuracy: 1.0000 - val_recall: 0.9411\n",
      "Epoch 120/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.1493e-04 - accuracy: 1.0000 - recall: 0.9750\n",
      "Epoch 120: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 1.1493e-04 - accuracy: 1.0000 - recall: 0.9750 - val_loss: 1.0066e-04 - val_accuracy: 1.0000 - val_recall: 0.9745\n",
      "Epoch 121/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.3601e-04 - accuracy: 1.0000 - recall: 0.9638\n",
      "Epoch 121: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 1.3601e-04 - accuracy: 1.0000 - recall: 0.9638 - val_loss: 1.0781e-04 - val_accuracy: 1.0000 - val_recall: 0.9629\n",
      "Epoch 122/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.5247e-04 - accuracy: 1.0000 - recall: 0.9681\n",
      "Epoch 122: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.5247e-04 - accuracy: 1.0000 - recall: 0.9681 - val_loss: 1.3101e-04 - val_accuracy: 1.0000 - val_recall: 0.9349\n",
      "Epoch 123/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.5054e-04 - accuracy: 1.0000 - recall: 0.9646\n",
      "Epoch 123: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 1.5054e-04 - accuracy: 1.0000 - recall: 0.9646 - val_loss: 1.0038e-04 - val_accuracy: 1.0000 - val_recall: 0.9586\n",
      "Epoch 124/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.2882e-04 - accuracy: 1.0000 - recall: 0.9728\n",
      "Epoch 124: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 1.2882e-04 - accuracy: 1.0000 - recall: 0.9728 - val_loss: 1.1219e-04 - val_accuracy: 1.0000 - val_recall: 0.9720\n",
      "Epoch 125/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.2297e-04 - accuracy: 1.0000 - recall: 0.9701\n",
      "Epoch 125: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 1.2297e-04 - accuracy: 1.0000 - recall: 0.9701 - val_loss: 1.4250e-04 - val_accuracy: 1.0000 - val_recall: 0.9296\n",
      "Epoch 126/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.3464e-04 - accuracy: 1.0000 - recall: 0.9713\n",
      "Epoch 126: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 1.3464e-04 - accuracy: 1.0000 - recall: 0.9713 - val_loss: 1.0793e-04 - val_accuracy: 1.0000 - val_recall: 0.9913\n",
      "Epoch 127/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.2803e-04 - accuracy: 1.0000 - recall: 0.9697\n",
      "Epoch 127: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 1.2803e-04 - accuracy: 1.0000 - recall: 0.9697 - val_loss: 9.4682e-05 - val_accuracy: 1.0000 - val_recall: 0.9798\n",
      "Epoch 128/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.3376e-04 - accuracy: 1.0000 - recall: 0.9677\n",
      "Epoch 128: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 1.3376e-04 - accuracy: 1.0000 - recall: 0.9677 - val_loss: 9.7787e-05 - val_accuracy: 1.0000 - val_recall: 0.9883\n",
      "Epoch 129/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.1903e-04 - accuracy: 1.0000 - recall: 0.9709\n",
      "Epoch 129: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 1.1903e-04 - accuracy: 1.0000 - recall: 0.9709 - val_loss: 8.8334e-05 - val_accuracy: 1.0000 - val_recall: 0.9712\n",
      "Epoch 130/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.1483e-04 - accuracy: 1.0000 - recall: 0.9741\n",
      "Epoch 130: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 1.1483e-04 - accuracy: 1.0000 - recall: 0.9741 - val_loss: 1.0920e-04 - val_accuracy: 1.0000 - val_recall: 0.9775\n",
      "Epoch 131/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.3819e-04 - accuracy: 1.0000 - recall: 0.9657\n",
      "Epoch 131: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 1.3819e-04 - accuracy: 1.0000 - recall: 0.9657 - val_loss: 1.2988e-04 - val_accuracy: 1.0000 - val_recall: 0.9522\n",
      "Epoch 132/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.1198e-04 - accuracy: 1.0000 - recall: 0.9731\n",
      "Epoch 132: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 1.1198e-04 - accuracy: 1.0000 - recall: 0.9731 - val_loss: 1.0710e-04 - val_accuracy: 1.0000 - val_recall: 0.9501\n",
      "Epoch 133/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.0622e-04 - accuracy: 1.0000 - recall: 0.9736\n",
      "Epoch 133: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 1.0622e-04 - accuracy: 1.0000 - recall: 0.9736 - val_loss: 9.2677e-05 - val_accuracy: 1.0000 - val_recall: 0.9875\n",
      "Epoch 134/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.2614e-04 - accuracy: 1.0000 - recall: 0.9704\n",
      "Epoch 134: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 1.2614e-04 - accuracy: 1.0000 - recall: 0.9704 - val_loss: 5.0779e-04 - val_accuracy: 0.9998 - val_recall: 0.6961\n",
      "Epoch 135/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.1593e-04 - accuracy: 1.0000 - recall: 0.9694\n",
      "Epoch 135: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 1.1593e-04 - accuracy: 1.0000 - recall: 0.9694 - val_loss: 1.7961e-04 - val_accuracy: 0.9999 - val_recall: 0.9027\n",
      "Epoch 136/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.9124e-04 - accuracy: 0.9999 - recall: 0.9552\n",
      "Epoch 136: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 1.9124e-04 - accuracy: 0.9999 - recall: 0.9552 - val_loss: 2.7329e-04 - val_accuracy: 0.9999 - val_recall: 0.9898\n",
      "Epoch 137/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.2300e-04 - accuracy: 1.0000 - recall: 0.9709\n",
      "Epoch 137: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 1.2300e-04 - accuracy: 1.0000 - recall: 0.9709 - val_loss: 3.9970e-04 - val_accuracy: 0.9999 - val_recall: 0.8448\n",
      "Epoch 138/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.2585e-04 - accuracy: 1.0000 - recall: 0.9671\n",
      "Epoch 138: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 1.2585e-04 - accuracy: 1.0000 - recall: 0.9671 - val_loss: 9.7350e-05 - val_accuracy: 1.0000 - val_recall: 0.9821\n",
      "Epoch 139/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.1010e-04 - accuracy: 1.0000 - recall: 0.9702\n",
      "Epoch 139: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 1.1010e-04 - accuracy: 1.0000 - recall: 0.9702 - val_loss: 1.4292e-04 - val_accuracy: 1.0000 - val_recall: 0.9238\n",
      "Epoch 140/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.2209e-04 - accuracy: 1.0000 - recall: 0.9708\n",
      "Epoch 140: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 1.2209e-04 - accuracy: 1.0000 - recall: 0.9708 - val_loss: 1.0469e-04 - val_accuracy: 1.0000 - val_recall: 0.9474\n",
      "Epoch 141/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.0840e-04 - accuracy: 1.0000 - recall: 0.9728\n",
      "Epoch 141: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 1.0840e-04 - accuracy: 1.0000 - recall: 0.9728 - val_loss: 1.1517e-04 - val_accuracy: 1.0000 - val_recall: 0.9533\n",
      "Epoch 142/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.0754e-04 - accuracy: 1.0000 - recall: 0.9698\n",
      "Epoch 142: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 1.0754e-04 - accuracy: 1.0000 - recall: 0.9698 - val_loss: 8.5140e-05 - val_accuracy: 1.0000 - val_recall: 0.9745\n",
      "Epoch 143/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.1817e-04 - accuracy: 1.0000 - recall: 0.9734\n",
      "Epoch 143: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 1.1817e-04 - accuracy: 1.0000 - recall: 0.9734 - val_loss: 9.3079e-05 - val_accuracy: 1.0000 - val_recall: 0.9736\n",
      "Epoch 144/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.2441e-04 - accuracy: 1.0000 - recall: 0.9684\n",
      "Epoch 144: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 1.2441e-04 - accuracy: 1.0000 - recall: 0.9684 - val_loss: 7.9742e-05 - val_accuracy: 1.0000 - val_recall: 0.9808\n",
      "Epoch 145/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 9.2863e-05 - accuracy: 1.0000 - recall: 0.9765\n",
      "Epoch 145: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 9.2863e-05 - accuracy: 1.0000 - recall: 0.9765 - val_loss: 9.3932e-05 - val_accuracy: 1.0000 - val_recall: 0.9542\n",
      "Epoch 146/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 9.8063e-05 - accuracy: 1.0000 - recall: 0.9735\n",
      "Epoch 146: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 9.8063e-05 - accuracy: 1.0000 - recall: 0.9735 - val_loss: 1.7035e-04 - val_accuracy: 0.9999 - val_recall: 0.9046\n",
      "Epoch 147/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.4156e-04 - accuracy: 1.0000 - recall: 0.9679\n",
      "Epoch 147: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 1.4156e-04 - accuracy: 1.0000 - recall: 0.9679 - val_loss: 1.7634e-04 - val_accuracy: 0.9999 - val_recall: 0.9053\n",
      "Epoch 148/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.1332e-04 - accuracy: 1.0000 - recall: 0.9727\n",
      "Epoch 148: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 1.1332e-04 - accuracy: 1.0000 - recall: 0.9727 - val_loss: 8.1804e-05 - val_accuracy: 1.0000 - val_recall: 0.9688\n",
      "Epoch 149/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.0735e-04 - accuracy: 1.0000 - recall: 0.9763\n",
      "Epoch 149: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.0735e-04 - accuracy: 1.0000 - recall: 0.9763 - val_loss: 1.6788e-04 - val_accuracy: 0.9999 - val_recall: 0.9148\n",
      "Epoch 150/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.1443e-04 - accuracy: 1.0000 - recall: 0.9682\n",
      "Epoch 150: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.1443e-04 - accuracy: 1.0000 - recall: 0.9682 - val_loss: 9.1306e-05 - val_accuracy: 1.0000 - val_recall: 0.9559\n",
      "Epoch 151/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 8.9898e-05 - accuracy: 1.0000 - recall: 0.9764\n",
      "Epoch 151: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 8.9898e-05 - accuracy: 1.0000 - recall: 0.9764 - val_loss: 8.1882e-05 - val_accuracy: 1.0000 - val_recall: 0.9692\n",
      "Epoch 152/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.0344e-04 - accuracy: 1.0000 - recall: 0.9729\n",
      "Epoch 152: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 1.0344e-04 - accuracy: 1.0000 - recall: 0.9729 - val_loss: 9.3761e-05 - val_accuracy: 1.0000 - val_recall: 0.9536\n",
      "Epoch 153/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.1620e-04 - accuracy: 1.0000 - recall: 0.9711\n",
      "Epoch 153: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.1620e-04 - accuracy: 1.0000 - recall: 0.9711 - val_loss: 8.3565e-05 - val_accuracy: 1.0000 - val_recall: 0.9665\n",
      "Epoch 154/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.2013e-04 - accuracy: 1.0000 - recall: 0.9714\n",
      "Epoch 154: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 1.2013e-04 - accuracy: 1.0000 - recall: 0.9714 - val_loss: 1.3649e-04 - val_accuracy: 1.0000 - val_recall: 0.9231\n",
      "Epoch 155/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.1465e-04 - accuracy: 1.0000 - recall: 0.9738\n",
      "Epoch 155: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 14s 325ms/step - loss: 1.1465e-04 - accuracy: 1.0000 - recall: 0.9738 - val_loss: 8.7859e-05 - val_accuracy: 1.0000 - val_recall: 0.9750\n",
      "Epoch 156/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 9.0504e-05 - accuracy: 1.0000 - recall: 0.9755\n",
      "Epoch 156: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 9.0504e-05 - accuracy: 1.0000 - recall: 0.9755 - val_loss: 8.4672e-05 - val_accuracy: 1.0000 - val_recall: 0.9664\n",
      "Epoch 157/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 9.2063e-05 - accuracy: 1.0000 - recall: 0.9752\n",
      "Epoch 157: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 9.2063e-05 - accuracy: 1.0000 - recall: 0.9752 - val_loss: 9.3770e-05 - val_accuracy: 1.0000 - val_recall: 0.9574\n",
      "Epoch 158/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.2553e-04 - accuracy: 1.0000 - recall: 0.9744\n",
      "Epoch 158: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 1.2553e-04 - accuracy: 1.0000 - recall: 0.9744 - val_loss: 7.7073e-05 - val_accuracy: 1.0000 - val_recall: 0.9840\n",
      "Epoch 159/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.1540e-04 - accuracy: 1.0000 - recall: 0.9685\n",
      "Epoch 159: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 1.1540e-04 - accuracy: 1.0000 - recall: 0.9685 - val_loss: 1.3373e-04 - val_accuracy: 1.0000 - val_recall: 0.9249\n",
      "Epoch 160/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.0375e-04 - accuracy: 1.0000 - recall: 0.9758\n",
      "Epoch 160: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 1.0375e-04 - accuracy: 1.0000 - recall: 0.9758 - val_loss: 1.2018e-04 - val_accuracy: 1.0000 - val_recall: 0.9955\n",
      "Epoch 161/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 9.9780e-05 - accuracy: 1.0000 - recall: 0.9725\n",
      "Epoch 161: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 9.9780e-05 - accuracy: 1.0000 - recall: 0.9725 - val_loss: 7.5322e-04 - val_accuracy: 0.9997 - val_recall: 0.5650\n",
      "Epoch 162/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 9.9219e-05 - accuracy: 1.0000 - recall: 0.9735\n",
      "Epoch 162: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 9.9219e-05 - accuracy: 1.0000 - recall: 0.9735 - val_loss: 2.6542e-04 - val_accuracy: 0.9999 - val_recall: 0.8275\n",
      "Epoch 163/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.0188e-04 - accuracy: 1.0000 - recall: 0.9737\n",
      "Epoch 163: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 1.0188e-04 - accuracy: 1.0000 - recall: 0.9737 - val_loss: 1.2240e-04 - val_accuracy: 1.0000 - val_recall: 0.9791\n",
      "Epoch 164/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 9.8618e-05 - accuracy: 1.0000 - recall: 0.9727\n",
      "Epoch 164: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 9.8618e-05 - accuracy: 1.0000 - recall: 0.9727 - val_loss: 9.3408e-05 - val_accuracy: 1.0000 - val_recall: 0.9574\n",
      "Epoch 165/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 8.6128e-05 - accuracy: 1.0000 - recall: 0.9775\n",
      "Epoch 165: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 8.6128e-05 - accuracy: 1.0000 - recall: 0.9775 - val_loss: 1.0521e-04 - val_accuracy: 1.0000 - val_recall: 0.9795\n",
      "Epoch 166/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.0816e-04 - accuracy: 1.0000 - recall: 0.9717\n",
      "Epoch 166: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 1.0816e-04 - accuracy: 1.0000 - recall: 0.9717 - val_loss: 1.0082e-04 - val_accuracy: 1.0000 - val_recall: 0.9539\n",
      "Epoch 167/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.0134e-04 - accuracy: 1.0000 - recall: 0.9731\n",
      "Epoch 167: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 1.0134e-04 - accuracy: 1.0000 - recall: 0.9731 - val_loss: 7.8814e-05 - val_accuracy: 1.0000 - val_recall: 0.9816\n",
      "Epoch 168/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 8.9023e-05 - accuracy: 1.0000 - recall: 0.9751\n",
      "Epoch 168: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 8.9023e-05 - accuracy: 1.0000 - recall: 0.9751 - val_loss: 7.9435e-05 - val_accuracy: 1.0000 - val_recall: 0.9766\n",
      "Epoch 169/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 8.9077e-05 - accuracy: 1.0000 - recall: 0.9744\n",
      "Epoch 169: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 8.9077e-05 - accuracy: 1.0000 - recall: 0.9744 - val_loss: 8.7465e-05 - val_accuracy: 1.0000 - val_recall: 0.9604\n",
      "Epoch 170/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 7.6734e-05 - accuracy: 1.0000 - recall: 0.9814\n",
      "Epoch 170: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 7.6734e-05 - accuracy: 1.0000 - recall: 0.9814 - val_loss: 9.4843e-05 - val_accuracy: 1.0000 - val_recall: 0.9523\n",
      "Epoch 171/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 7.8320e-05 - accuracy: 1.0000 - recall: 0.9796\n",
      "Epoch 171: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 7.8320e-05 - accuracy: 1.0000 - recall: 0.9796 - val_loss: 1.1692e-04 - val_accuracy: 1.0000 - val_recall: 0.9970\n",
      "Epoch 172/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 9.0629e-05 - accuracy: 1.0000 - recall: 0.9736\n",
      "Epoch 172: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 9.0629e-05 - accuracy: 1.0000 - recall: 0.9736 - val_loss: 8.5637e-05 - val_accuracy: 1.0000 - val_recall: 0.9633\n",
      "Epoch 173/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 9.5740e-05 - accuracy: 1.0000 - recall: 0.9743\n",
      "Epoch 173: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 9.5740e-05 - accuracy: 1.0000 - recall: 0.9743 - val_loss: 8.8072e-05 - val_accuracy: 1.0000 - val_recall: 0.9586\n",
      "Epoch 174/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 7.8405e-05 - accuracy: 1.0000 - recall: 0.9787\n",
      "Epoch 174: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 7.8405e-05 - accuracy: 1.0000 - recall: 0.9787 - val_loss: 7.8449e-05 - val_accuracy: 1.0000 - val_recall: 0.9911\n",
      "Epoch 175/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 7.1389e-05 - accuracy: 1.0000 - recall: 0.9808\n",
      "Epoch 175: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 7.1389e-05 - accuracy: 1.0000 - recall: 0.9808 - val_loss: 8.9050e-05 - val_accuracy: 1.0000 - val_recall: 0.9548\n",
      "Epoch 176/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 7.0718e-05 - accuracy: 1.0000 - recall: 0.9820\n",
      "Epoch 176: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 7.0718e-05 - accuracy: 1.0000 - recall: 0.9820 - val_loss: 8.2580e-05 - val_accuracy: 1.0000 - val_recall: 0.9657\n",
      "Epoch 177/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 7.2897e-05 - accuracy: 1.0000 - recall: 0.9801\n",
      "Epoch 177: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 7.2897e-05 - accuracy: 1.0000 - recall: 0.9801 - val_loss: 9.5380e-05 - val_accuracy: 1.0000 - val_recall: 0.9546\n",
      "Epoch 178/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 6.8309e-05 - accuracy: 1.0000 - recall: 0.9826\n",
      "Epoch 178: val_recall did not improve from 0.99734\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 6.8309e-05 - accuracy: 1.0000 - recall: 0.9826 - val_loss: 8.5581e-05 - val_accuracy: 1.0000 - val_recall: 0.9602\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.5437 - accuracy: 0.8707 - recall: 0.0438\n",
      "Epoch 1: val_recall improved from -inf to 0.00000, saving model to model_5fold.h5\n",
      "42/42 [==============================] - 15s 326ms/step - loss: 0.5437 - accuracy: 0.8707 - recall: 0.0438 - val_loss: 0.3677 - val_accuracy: 0.9843 - val_recall: 0.0000e+00\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.3328 - accuracy: 0.9949 - recall: 1.0728e-04\n",
      "Epoch 2: val_recall did not improve from 0.00000\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.3328 - accuracy: 0.9949 - recall: 1.0728e-04 - val_loss: 0.3633 - val_accuracy: 0.9941 - val_recall: 0.0000e+00\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1837 - accuracy: 0.9980 - recall: 8.9397e-06\n",
      "Epoch 3: val_recall did not improve from 0.00000\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 0.1837 - accuracy: 0.9980 - recall: 8.9397e-06 - val_loss: 0.2517 - val_accuracy: 0.9975 - val_recall: 0.0000e+00\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1201 - accuracy: 0.9992 - recall: 0.0000e+00\n",
      "Epoch 4: val_recall did not improve from 0.00000\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.1201 - accuracy: 0.9992 - recall: 0.0000e+00 - val_loss: 0.1771 - val_accuracy: 0.9988 - val_recall: 0.0000e+00\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0834 - accuracy: 0.9993 - recall: 0.0000e+00\n",
      "Epoch 5: val_recall did not improve from 0.00000\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 0.0834 - accuracy: 0.9993 - recall: 0.0000e+00 - val_loss: 0.1260 - val_accuracy: 0.9994 - val_recall: 0.0000e+00\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0611 - accuracy: 0.9994 - recall: 0.0000e+00\n",
      "Epoch 6: val_recall did not improve from 0.00000\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0611 - accuracy: 0.9994 - recall: 0.0000e+00 - val_loss: 0.0855 - val_accuracy: 0.9994 - val_recall: 0.0000e+00\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0469 - accuracy: 0.9994 - recall: 0.0000e+00\n",
      "Epoch 7: val_recall did not improve from 0.00000\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0469 - accuracy: 0.9994 - recall: 0.0000e+00 - val_loss: 0.0557 - val_accuracy: 0.9994 - val_recall: 0.0000e+00\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0373 - accuracy: 0.9994 - recall: 0.0000e+00\n",
      "Epoch 8: val_recall did not improve from 0.00000\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0373 - accuracy: 0.9994 - recall: 0.0000e+00 - val_loss: 0.0389 - val_accuracy: 0.9994 - val_recall: 0.0000e+00\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0304 - accuracy: 0.9994 - recall: 0.0000e+00\n",
      "Epoch 9: val_recall did not improve from 0.00000\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0304 - accuracy: 0.9994 - recall: 0.0000e+00 - val_loss: 0.0310 - val_accuracy: 0.9994 - val_recall: 0.0000e+00\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0252 - accuracy: 0.9994 - recall: 0.0000e+00\n",
      "Epoch 10: val_recall did not improve from 0.00000\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0252 - accuracy: 0.9994 - recall: 0.0000e+00 - val_loss: 0.0267 - val_accuracy: 0.9994 - val_recall: 0.0000e+00\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0208 - accuracy: 0.9994 - recall: 8.9397e-06\n",
      "Epoch 11: val_recall did not improve from 0.00000\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 0.0208 - accuracy: 0.9994 - recall: 8.9397e-06 - val_loss: 0.0231 - val_accuracy: 0.9994 - val_recall: 0.0000e+00\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0158 - accuracy: 0.9994 - recall: 0.1916\n",
      "Epoch 12: val_recall did not improve from 0.00000\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 0.0158 - accuracy: 0.9994 - recall: 0.1916 - val_loss: 0.0202 - val_accuracy: 0.9994 - val_recall: 0.0000e+00\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 0.9996 - recall: 0.5279\n",
      "Epoch 13: val_recall did not improve from 0.00000\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 0.0121 - accuracy: 0.9996 - recall: 0.5279 - val_loss: 0.0169 - val_accuracy: 0.9994 - val_recall: 0.0000e+00\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 0.9997 - recall: 0.6850\n",
      "Epoch 14: val_recall did not improve from 0.00000\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0099 - accuracy: 0.9997 - recall: 0.6850 - val_loss: 0.0132 - val_accuracy: 0.9994 - val_recall: 0.0000e+00\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.9998 - recall: 0.7723\n",
      "Epoch 15: val_recall did not improve from 0.00000\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 0.0083 - accuracy: 0.9998 - recall: 0.7723 - val_loss: 0.0115 - val_accuracy: 0.9994 - val_recall: 0.0000e+00\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 0.9998 - recall: 0.8041\n",
      "Epoch 16: val_recall did not improve from 0.00000\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 0.0072 - accuracy: 0.9998 - recall: 0.8041 - val_loss: 0.0096 - val_accuracy: 0.9994 - val_recall: 0.0000e+00\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9998 - recall: 0.8259\n",
      "Epoch 17: val_recall improved from 0.00000 to 0.00038, saving model to model_5fold.h5\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 0.0062 - accuracy: 0.9998 - recall: 0.8259 - val_loss: 0.0072 - val_accuracy: 0.9994 - val_recall: 3.8313e-04\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9998 - recall: 0.8455\n",
      "Epoch 18: val_recall improved from 0.00038 to 0.00590, saving model to model_5fold.h5\n",
      "42/42 [==============================] - 13s 321ms/step - loss: 0.0055 - accuracy: 0.9998 - recall: 0.8455 - val_loss: 0.0066 - val_accuracy: 0.9994 - val_recall: 0.0059\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 0.9999 - recall: 0.8548\n",
      "Epoch 19: val_recall improved from 0.00590 to 0.03893, saving model to model_5fold.h5\n",
      "42/42 [==============================] - 13s 321ms/step - loss: 0.0049 - accuracy: 0.9999 - recall: 0.8548 - val_loss: 0.0058 - val_accuracy: 0.9994 - val_recall: 0.0389\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9999 - recall: 0.8732\n",
      "Epoch 20: val_recall improved from 0.03893 to 0.09705, saving model to model_5fold.h5\n",
      "42/42 [==============================] - 13s 321ms/step - loss: 0.0044 - accuracy: 0.9999 - recall: 0.8732 - val_loss: 0.0046 - val_accuracy: 0.9995 - val_recall: 0.0970\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9999 - recall: 0.8789\n",
      "Epoch 21: val_recall improved from 0.09705 to 0.13241, saving model to model_5fold.h5\n",
      "42/42 [==============================] - 14s 322ms/step - loss: 0.0039 - accuracy: 0.9999 - recall: 0.8789 - val_loss: 0.0040 - val_accuracy: 0.9995 - val_recall: 0.1324\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9999 - recall: 0.8837\n",
      "Epoch 22: val_recall improved from 0.13241 to 0.19516, saving model to model_5fold.h5\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 0.0036 - accuracy: 0.9999 - recall: 0.8837 - val_loss: 0.0038 - val_accuracy: 0.9995 - val_recall: 0.1952\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9999 - recall: 0.8819\n",
      "Epoch 23: val_recall improved from 0.19516 to 0.27819, saving model to model_5fold.h5\n",
      "42/42 [==============================] - 13s 321ms/step - loss: 0.0033 - accuracy: 0.9999 - recall: 0.8819 - val_loss: 0.0033 - val_accuracy: 0.9996 - val_recall: 0.2782\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9999 - recall: 0.8942\n",
      "Epoch 24: val_recall improved from 0.27819 to 0.36041, saving model to model_5fold.h5\n",
      "42/42 [==============================] - 13s 321ms/step - loss: 0.0030 - accuracy: 0.9999 - recall: 0.8942 - val_loss: 0.0030 - val_accuracy: 0.9996 - val_recall: 0.3604\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9999 - recall: 0.8777\n",
      "Epoch 25: val_recall improved from 0.36041 to 0.53071, saving model to model_5fold.h5\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 0.0028 - accuracy: 0.9999 - recall: 0.8777 - val_loss: 0.0025 - val_accuracy: 0.9997 - val_recall: 0.5307\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9999 - recall: 0.8945\n",
      "Epoch 26: val_recall did not improve from 0.53071\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0025 - accuracy: 0.9999 - recall: 0.8945 - val_loss: 0.0027 - val_accuracy: 0.9996 - val_recall: 0.3356\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9999 - recall: 0.8991\n",
      "Epoch 27: val_recall improved from 0.53071 to 0.61270, saving model to model_5fold.h5\n",
      "42/42 [==============================] - 13s 321ms/step - loss: 0.0024 - accuracy: 0.9999 - recall: 0.8991 - val_loss: 0.0021 - val_accuracy: 0.9998 - val_recall: 0.6127\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9999 - recall: 0.9001\n",
      "Epoch 28: val_recall did not improve from 0.61270\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0022 - accuracy: 0.9999 - recall: 0.9001 - val_loss: 0.0022 - val_accuracy: 0.9997 - val_recall: 0.4522\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9999 - recall: 0.8996\n",
      "Epoch 29: val_recall improved from 0.61270 to 0.82706, saving model to model_5fold.h5\n",
      "42/42 [==============================] - 13s 321ms/step - loss: 0.0021 - accuracy: 0.9999 - recall: 0.8996 - val_loss: 0.0017 - val_accuracy: 0.9999 - val_recall: 0.8271\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9999 - recall: 0.9174\n",
      "Epoch 30: val_recall did not improve from 0.82706\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0019 - accuracy: 0.9999 - recall: 0.9174 - val_loss: 0.0022 - val_accuracy: 0.9996 - val_recall: 0.3095\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9999 - recall: 0.9112\n",
      "Epoch 31: val_recall improved from 0.82706 to 0.83001, saving model to model_5fold.h5\n",
      "42/42 [==============================] - 13s 321ms/step - loss: 0.0018 - accuracy: 0.9999 - recall: 0.9112 - val_loss: 0.0015 - val_accuracy: 0.9999 - val_recall: 0.8300\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9999 - recall: 0.9186\n",
      "Epoch 32: val_recall did not improve from 0.83001\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0017 - accuracy: 0.9999 - recall: 0.9186 - val_loss: 0.0014 - val_accuracy: 0.9999 - val_recall: 0.8203\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9999 - recall: 0.9122\n",
      "Epoch 33: val_recall did not improve from 0.83001\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0016 - accuracy: 0.9999 - recall: 0.9122 - val_loss: 0.0015 - val_accuracy: 0.9998 - val_recall: 0.7484\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9999 - recall: 0.9194\n",
      "Epoch 34: val_recall improved from 0.83001 to 0.92698, saving model to model_5fold.h5\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 0.0015 - accuracy: 0.9999 - recall: 0.9194 - val_loss: 0.0012 - val_accuracy: 0.9999 - val_recall: 0.9270\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9999 - recall: 0.9180\n",
      "Epoch 35: val_recall did not improve from 0.92698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0014 - accuracy: 0.9999 - recall: 0.9180 - val_loss: 0.0011 - val_accuracy: 0.9999 - val_recall: 0.8991\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9999 - recall: 0.9218\n",
      "Epoch 36: val_recall did not improve from 0.92698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0013 - accuracy: 0.9999 - recall: 0.9218 - val_loss: 0.0011 - val_accuracy: 0.9999 - val_recall: 0.9251\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 0.9999 - recall: 0.9264\n",
      "Epoch 37: val_recall did not improve from 0.92698\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0012 - accuracy: 0.9999 - recall: 0.9264 - val_loss: 0.0011 - val_accuracy: 0.9999 - val_recall: 0.8554\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 0.9999 - recall: 0.9234\n",
      "Epoch 38: val_recall improved from 0.92698 to 0.93131, saving model to model_5fold.h5\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 0.0012 - accuracy: 0.9999 - recall: 0.9234 - val_loss: 9.4579e-04 - val_accuracy: 1.0000 - val_recall: 0.9313\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9999 - recall: 0.9243\n",
      "Epoch 39: val_recall did not improve from 0.93131\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0011 - accuracy: 0.9999 - recall: 0.9243 - val_loss: 9.6670e-04 - val_accuracy: 0.9999 - val_recall: 0.8661\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9999 - recall: 0.9283\n",
      "Epoch 40: val_recall improved from 0.93131 to 0.93625, saving model to model_5fold.h5\n",
      "42/42 [==============================] - 13s 321ms/step - loss: 0.0011 - accuracy: 0.9999 - recall: 0.9283 - val_loss: 8.3436e-04 - val_accuracy: 1.0000 - val_recall: 0.9362\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 0.9999 - recall: 0.9345   \n",
      "Epoch 41: val_recall did not improve from 0.93625\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 0.0010 - accuracy: 0.9999 - recall: 0.9345 - val_loss: 8.8559e-04 - val_accuracy: 0.9999 - val_recall: 0.8731\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 9.8882e-04 - accuracy: 0.9999 - recall: 0.9231\n",
      "Epoch 42: val_recall did not improve from 0.93625\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 9.8882e-04 - accuracy: 0.9999 - recall: 0.9231 - val_loss: 8.0706e-04 - val_accuracy: 0.9999 - val_recall: 0.8984\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 9.3354e-04 - accuracy: 0.9999 - recall: 0.9348\n",
      "Epoch 43: val_recall did not improve from 0.93625\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 9.3354e-04 - accuracy: 0.9999 - recall: 0.9348 - val_loss: 0.0012 - val_accuracy: 0.9997 - val_recall: 0.5072\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 9.2657e-04 - accuracy: 0.9999 - recall: 0.9254\n",
      "Epoch 44: val_recall improved from 0.93625 to 0.95360, saving model to model_5fold.h5\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 9.2657e-04 - accuracy: 0.9999 - recall: 0.9254 - val_loss: 6.9994e-04 - val_accuracy: 1.0000 - val_recall: 0.9536\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 8.4405e-04 - accuracy: 0.9999 - recall: 0.9388\n",
      "Epoch 45: val_recall did not improve from 0.95360\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 8.4405e-04 - accuracy: 0.9999 - recall: 0.9388 - val_loss: 7.6385e-04 - val_accuracy: 0.9999 - val_recall: 0.8396\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 8.0102e-04 - accuracy: 0.9999 - recall: 0.9407\n",
      "Epoch 46: val_recall did not improve from 0.95360\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 8.0102e-04 - accuracy: 0.9999 - recall: 0.9407 - val_loss: 6.9207e-04 - val_accuracy: 0.9999 - val_recall: 0.9104\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 8.2036e-04 - accuracy: 0.9999 - recall: 0.9274\n",
      "Epoch 47: val_recall did not improve from 0.95360\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 8.2036e-04 - accuracy: 0.9999 - recall: 0.9274 - val_loss: 0.0020 - val_accuracy: 0.9996 - val_recall: 0.3550\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 7.7920e-04 - accuracy: 0.9999 - recall: 0.9351\n",
      "Epoch 48: val_recall did not improve from 0.95360\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 7.7920e-04 - accuracy: 0.9999 - recall: 0.9351 - val_loss: 7.2853e-04 - val_accuracy: 0.9999 - val_recall: 0.8330\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 7.5196e-04 - accuracy: 0.9999 - recall: 0.9332\n",
      "Epoch 49: val_recall did not improve from 0.95360\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 7.5196e-04 - accuracy: 0.9999 - recall: 0.9332 - val_loss: 5.6880e-04 - val_accuracy: 1.0000 - val_recall: 0.9531\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 7.0975e-04 - accuracy: 0.9999 - recall: 0.9401\n",
      "Epoch 50: val_recall did not improve from 0.95360\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 7.0975e-04 - accuracy: 0.9999 - recall: 0.9401 - val_loss: 6.7265e-04 - val_accuracy: 0.9999 - val_recall: 0.8317\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 6.8610e-04 - accuracy: 0.9999 - recall: 0.9377\n",
      "Epoch 51: val_recall did not improve from 0.95360\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 6.8610e-04 - accuracy: 0.9999 - recall: 0.9377 - val_loss: 5.2375e-04 - val_accuracy: 1.0000 - val_recall: 0.9477\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 6.3920e-04 - accuracy: 0.9999 - recall: 0.9453\n",
      "Epoch 52: val_recall did not improve from 0.95360\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 6.3920e-04 - accuracy: 0.9999 - recall: 0.9453 - val_loss: 6.3056e-04 - val_accuracy: 0.9999 - val_recall: 0.8372\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 6.2295e-04 - accuracy: 0.9999 - recall: 0.9422\n",
      "Epoch 53: val_recall did not improve from 0.95360\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 6.2295e-04 - accuracy: 0.9999 - recall: 0.9422 - val_loss: 5.1008e-04 - val_accuracy: 0.9999 - val_recall: 0.9198\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 6.1262e-04 - accuracy: 0.9999 - recall: 0.9399\n",
      "Epoch 54: val_recall did not improve from 0.95360\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 6.1262e-04 - accuracy: 0.9999 - recall: 0.9399 - val_loss: 6.6326e-04 - val_accuracy: 0.9999 - val_recall: 0.7802\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 5.9852e-04 - accuracy: 0.9999 - recall: 0.9408\n",
      "Epoch 55: val_recall did not improve from 0.95360\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 5.9852e-04 - accuracy: 0.9999 - recall: 0.9408 - val_loss: 4.6359e-04 - val_accuracy: 1.0000 - val_recall: 0.9339\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 5.8161e-04 - accuracy: 0.9999 - recall: 0.9411\n",
      "Epoch 56: val_recall improved from 0.95360 to 0.95763, saving model to model_5fold.h5\n",
      "42/42 [==============================] - 13s 321ms/step - loss: 5.8161e-04 - accuracy: 0.9999 - recall: 0.9411 - val_loss: 4.3271e-04 - val_accuracy: 1.0000 - val_recall: 0.9576\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 5.5458e-04 - accuracy: 0.9999 - recall: 0.9422\n",
      "Epoch 57: val_recall improved from 0.95763 to 0.96081, saving model to model_5fold.h5\n",
      "42/42 [==============================] - 13s 321ms/step - loss: 5.5458e-04 - accuracy: 0.9999 - recall: 0.9422 - val_loss: 4.2240e-04 - val_accuracy: 1.0000 - val_recall: 0.9608\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 5.4052e-04 - accuracy: 0.9999 - recall: 0.9445\n",
      "Epoch 58: val_recall did not improve from 0.96081\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 5.4052e-04 - accuracy: 0.9999 - recall: 0.9445 - val_loss: 4.3146e-04 - val_accuracy: 1.0000 - val_recall: 0.9326\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 5.1709e-04 - accuracy: 0.9999 - recall: 0.9459\n",
      "Epoch 59: val_recall did not improve from 0.96081\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 5.1709e-04 - accuracy: 0.9999 - recall: 0.9459 - val_loss: 4.5424e-04 - val_accuracy: 0.9999 - val_recall: 0.9394\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 5.1356e-04 - accuracy: 0.9999 - recall: 0.9445\n",
      "Epoch 60: val_recall improved from 0.96081 to 0.96173, saving model to model_5fold.h5\n",
      "42/42 [==============================] - 13s 321ms/step - loss: 5.1356e-04 - accuracy: 0.9999 - recall: 0.9445 - val_loss: 3.7191e-04 - val_accuracy: 1.0000 - val_recall: 0.9617\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 4.7898e-04 - accuracy: 0.9999 - recall: 0.9499\n",
      "Epoch 61: val_recall did not improve from 0.96173\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 4.7898e-04 - accuracy: 0.9999 - recall: 0.9499 - val_loss: 9.3041e-04 - val_accuracy: 0.9997 - val_recall: 0.5507\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 5.0899e-04 - accuracy: 0.9999 - recall: 0.9410\n",
      "Epoch 62: val_recall did not improve from 0.96173\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 5.0899e-04 - accuracy: 0.9999 - recall: 0.9410 - val_loss: 4.1822e-04 - val_accuracy: 0.9999 - val_recall: 0.9048\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 4.5918e-04 - accuracy: 0.9999 - recall: 0.9510\n",
      "Epoch 63: val_recall did not improve from 0.96173\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 4.5918e-04 - accuracy: 0.9999 - recall: 0.9510 - val_loss: 5.0660e-04 - val_accuracy: 0.9999 - val_recall: 0.8158\n",
      "Epoch 64/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 4.6038e-04 - accuracy: 0.9999 - recall: 0.9452\n",
      "Epoch 64: val_recall did not improve from 0.96173\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 4.6038e-04 - accuracy: 0.9999 - recall: 0.9452 - val_loss: 3.2175e-04 - val_accuracy: 1.0000 - val_recall: 0.9600\n",
      "Epoch 65/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 4.2785e-04 - accuracy: 0.9999 - recall: 0.9529\n",
      "Epoch 65: val_recall did not improve from 0.96173\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 4.2785e-04 - accuracy: 0.9999 - recall: 0.9529 - val_loss: 5.3231e-04 - val_accuracy: 0.9999 - val_recall: 0.7610\n",
      "Epoch 66/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 4.2314e-04 - accuracy: 0.9999 - recall: 0.9487\n",
      "Epoch 66: val_recall did not improve from 0.96173\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 4.2314e-04 - accuracy: 0.9999 - recall: 0.9487 - val_loss: 3.7533e-04 - val_accuracy: 0.9999 - val_recall: 0.9254\n",
      "Epoch 67/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 4.4762e-04 - accuracy: 0.9999 - recall: 0.9421\n",
      "Epoch 67: val_recall did not improve from 0.96173\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 4.4762e-04 - accuracy: 0.9999 - recall: 0.9421 - val_loss: 3.0110e-04 - val_accuracy: 1.0000 - val_recall: 0.9583\n",
      "Epoch 68/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 4.0755e-04 - accuracy: 0.9999 - recall: 0.9478\n",
      "Epoch 68: val_recall did not improve from 0.96173\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 4.0755e-04 - accuracy: 0.9999 - recall: 0.9478 - val_loss: 2.9509e-04 - val_accuracy: 1.0000 - val_recall: 0.9425\n",
      "Epoch 69/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.8787e-04 - accuracy: 0.9999 - recall: 0.9533\n",
      "Epoch 69: val_recall did not improve from 0.96173\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 3.8787e-04 - accuracy: 0.9999 - recall: 0.9533 - val_loss: 3.4940e-04 - val_accuracy: 0.9999 - val_recall: 0.9336\n",
      "Epoch 70/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.9346e-04 - accuracy: 0.9999 - recall: 0.9486\n",
      "Epoch 70: val_recall did not improve from 0.96173\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 3.9346e-04 - accuracy: 0.9999 - recall: 0.9486 - val_loss: 2.9942e-04 - val_accuracy: 1.0000 - val_recall: 0.9578\n",
      "Epoch 71/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.7205e-04 - accuracy: 0.9999 - recall: 0.9514\n",
      "Epoch 71: val_recall did not improve from 0.96173\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 3.7205e-04 - accuracy: 0.9999 - recall: 0.9514 - val_loss: 3.0346e-04 - val_accuracy: 1.0000 - val_recall: 0.9585\n",
      "Epoch 72/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.5976e-04 - accuracy: 0.9999 - recall: 0.9555\n",
      "Epoch 72: val_recall did not improve from 0.96173\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 3.5976e-04 - accuracy: 0.9999 - recall: 0.9555 - val_loss: 2.9846e-04 - val_accuracy: 1.0000 - val_recall: 0.9301\n",
      "Epoch 73/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.6926e-04 - accuracy: 0.9999 - recall: 0.9464\n",
      "Epoch 73: val_recall improved from 0.96173 to 0.98586, saving model to model_5fold.h5\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 3.6926e-04 - accuracy: 0.9999 - recall: 0.9464 - val_loss: 3.0535e-04 - val_accuracy: 1.0000 - val_recall: 0.9859\n",
      "Epoch 74/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.6592e-04 - accuracy: 0.9999 - recall: 0.9480\n",
      "Epoch 74: val_recall did not improve from 0.98586\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 3.6592e-04 - accuracy: 0.9999 - recall: 0.9480 - val_loss: 2.7258e-04 - val_accuracy: 1.0000 - val_recall: 0.9704\n",
      "Epoch 75/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.3860e-04 - accuracy: 0.9999 - recall: 0.9585\n",
      "Epoch 75: val_recall did not improve from 0.98586\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 3.3860e-04 - accuracy: 0.9999 - recall: 0.9585 - val_loss: 3.1348e-04 - val_accuracy: 1.0000 - val_recall: 0.9525\n",
      "Epoch 76/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.2047e-04 - accuracy: 0.9999 - recall: 0.9535\n",
      "Epoch 76: val_recall did not improve from 0.98586\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 3.2047e-04 - accuracy: 0.9999 - recall: 0.9535 - val_loss: 2.6944e-04 - val_accuracy: 1.0000 - val_recall: 0.9337\n",
      "Epoch 77/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.2385e-04 - accuracy: 0.9999 - recall: 0.9555\n",
      "Epoch 77: val_recall did not improve from 0.98586\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 3.2385e-04 - accuracy: 0.9999 - recall: 0.9555 - val_loss: 2.5383e-04 - val_accuracy: 1.0000 - val_recall: 0.9422\n",
      "Epoch 78/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.1428e-04 - accuracy: 0.9999 - recall: 0.9542\n",
      "Epoch 78: val_recall did not improve from 0.98586\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 3.1428e-04 - accuracy: 0.9999 - recall: 0.9542 - val_loss: 2.3013e-04 - val_accuracy: 1.0000 - val_recall: 0.9614\n",
      "Epoch 79/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.0746e-04 - accuracy: 0.9999 - recall: 0.9546\n",
      "Epoch 79: val_recall did not improve from 0.98586\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 3.0746e-04 - accuracy: 0.9999 - recall: 0.9546 - val_loss: 2.2623e-04 - val_accuracy: 1.0000 - val_recall: 0.9685\n",
      "Epoch 80/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.1848e-04 - accuracy: 0.9999 - recall: 0.9537\n",
      "Epoch 80: val_recall did not improve from 0.98586\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 3.1848e-04 - accuracy: 0.9999 - recall: 0.9537 - val_loss: 5.6811e-04 - val_accuracy: 0.9998 - val_recall: 0.9576\n",
      "Epoch 81/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 4.1335e-04 - accuracy: 0.9999 - recall: 0.9310\n",
      "Epoch 81: val_recall did not improve from 0.98586\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 4.1335e-04 - accuracy: 0.9999 - recall: 0.9310 - val_loss: 4.7757e-04 - val_accuracy: 0.9999 - val_recall: 0.8392\n",
      "Epoch 82/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.3806e-04 - accuracy: 0.9999 - recall: 0.9454\n",
      "Epoch 82: val_recall improved from 0.98586 to 0.99107, saving model to model_5fold.h5\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 3.3806e-04 - accuracy: 0.9999 - recall: 0.9454 - val_loss: 2.3719e-04 - val_accuracy: 1.0000 - val_recall: 0.9911\n",
      "Epoch 83/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.9375e-04 - accuracy: 0.9999 - recall: 0.9534\n",
      "Epoch 83: val_recall did not improve from 0.99107\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.9375e-04 - accuracy: 0.9999 - recall: 0.9534 - val_loss: 3.3536e-04 - val_accuracy: 0.9999 - val_recall: 0.8730\n",
      "Epoch 84/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.9100e-04 - accuracy: 0.9999 - recall: 0.9536\n",
      "Epoch 84: val_recall did not improve from 0.99107\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.9100e-04 - accuracy: 0.9999 - recall: 0.9536 - val_loss: 2.3018e-04 - val_accuracy: 1.0000 - val_recall: 0.9360\n",
      "Epoch 85/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.8011e-04 - accuracy: 0.9999 - recall: 0.9549\n",
      "Epoch 85: val_recall did not improve from 0.99107\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.8011e-04 - accuracy: 0.9999 - recall: 0.9549 - val_loss: 2.0687e-04 - val_accuracy: 1.0000 - val_recall: 0.9518\n",
      "Epoch 86/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.7395e-04 - accuracy: 0.9999 - recall: 0.9564\n",
      "Epoch 86: val_recall did not improve from 0.99107\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.7395e-04 - accuracy: 0.9999 - recall: 0.9564 - val_loss: 3.7125e-04 - val_accuracy: 0.9999 - val_recall: 0.8140\n",
      "Epoch 87/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.5895e-04 - accuracy: 0.9999 - recall: 0.9583\n",
      "Epoch 87: val_recall did not improve from 0.99107\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.5895e-04 - accuracy: 0.9999 - recall: 0.9583 - val_loss: 1.9042e-04 - val_accuracy: 1.0000 - val_recall: 0.9679\n",
      "Epoch 88/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.4790e-04 - accuracy: 1.0000 - recall: 0.9622\n",
      "Epoch 88: val_recall did not improve from 0.99107\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.4790e-04 - accuracy: 1.0000 - recall: 0.9622 - val_loss: 4.3103e-04 - val_accuracy: 0.9999 - val_recall: 0.7824\n",
      "Epoch 89/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.8140e-04 - accuracy: 0.9999 - recall: 0.9490\n",
      "Epoch 89: val_recall did not improve from 0.99107\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.8140e-04 - accuracy: 0.9999 - recall: 0.9490 - val_loss: 2.4162e-04 - val_accuracy: 1.0000 - val_recall: 0.9218\n",
      "Epoch 90/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.7040e-04 - accuracy: 0.9999 - recall: 0.9547\n",
      "Epoch 90: val_recall did not improve from 0.99107\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.7040e-04 - accuracy: 0.9999 - recall: 0.9547 - val_loss: 1.9843e-04 - val_accuracy: 1.0000 - val_recall: 0.9403\n",
      "Epoch 91/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.5550e-04 - accuracy: 0.9999 - recall: 0.9574\n",
      "Epoch 91: val_recall did not improve from 0.99107\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.5550e-04 - accuracy: 0.9999 - recall: 0.9574 - val_loss: 2.1660e-04 - val_accuracy: 1.0000 - val_recall: 0.9332\n",
      "Epoch 92/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.4532e-04 - accuracy: 0.9999 - recall: 0.9576\n",
      "Epoch 92: val_recall did not improve from 0.99107\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.4532e-04 - accuracy: 0.9999 - recall: 0.9576 - val_loss: 1.8507e-04 - val_accuracy: 1.0000 - val_recall: 0.9515\n",
      "Epoch 93/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.3348e-04 - accuracy: 1.0000 - recall: 0.9597\n",
      "Epoch 93: val_recall did not improve from 0.99107\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.3348e-04 - accuracy: 1.0000 - recall: 0.9597 - val_loss: 2.9276e-04 - val_accuracy: 0.9999 - val_recall: 0.8900\n",
      "Epoch 94/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.4877e-04 - accuracy: 0.9999 - recall: 0.9568\n",
      "Epoch 94: val_recall did not improve from 0.99107\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.4877e-04 - accuracy: 0.9999 - recall: 0.9568 - val_loss: 4.0734e-04 - val_accuracy: 0.9999 - val_recall: 0.8012\n",
      "Epoch 95/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.1919e-04 - accuracy: 1.0000 - recall: 0.9600\n",
      "Epoch 95: val_recall did not improve from 0.99107\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.1919e-04 - accuracy: 1.0000 - recall: 0.9600 - val_loss: 2.0430e-04 - val_accuracy: 1.0000 - val_recall: 0.9450\n",
      "Epoch 96/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.4703e-04 - accuracy: 0.9999 - recall: 0.9544\n",
      "Epoch 96: val_recall did not improve from 0.99107\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.4703e-04 - accuracy: 0.9999 - recall: 0.9544 - val_loss: 1.8583e-04 - val_accuracy: 1.0000 - val_recall: 0.9441\n",
      "Epoch 97/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.7459e-04 - accuracy: 0.9999 - recall: 0.9487\n",
      "Epoch 97: val_recall did not improve from 0.99107\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.7459e-04 - accuracy: 0.9999 - recall: 0.9487 - val_loss: 2.0531e-04 - val_accuracy: 1.0000 - val_recall: 0.9288\n",
      "Epoch 98/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.4517e-04 - accuracy: 0.9999 - recall: 0.9558\n",
      "Epoch 98: val_recall did not improve from 0.99107\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.4517e-04 - accuracy: 0.9999 - recall: 0.9558 - val_loss: 1.5183e-04 - val_accuracy: 1.0000 - val_recall: 0.9623\n",
      "Epoch 99/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.2019e-04 - accuracy: 1.0000 - recall: 0.9593\n",
      "Epoch 99: val_recall did not improve from 0.99107\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.2019e-04 - accuracy: 1.0000 - recall: 0.9593 - val_loss: 1.6952e-04 - val_accuracy: 1.0000 - val_recall: 0.9797\n",
      "Epoch 100/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.1601e-04 - accuracy: 1.0000 - recall: 0.9584\n",
      "Epoch 100: val_recall did not improve from 0.99107\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.1601e-04 - accuracy: 1.0000 - recall: 0.9584 - val_loss: 1.4980e-04 - val_accuracy: 1.0000 - val_recall: 0.9882\n",
      "Epoch 101/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.1135e-04 - accuracy: 1.0000 - recall: 0.9604\n",
      "Epoch 101: val_recall did not improve from 0.99107\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.1135e-04 - accuracy: 1.0000 - recall: 0.9604 - val_loss: 1.5482e-04 - val_accuracy: 1.0000 - val_recall: 0.9507\n",
      "Epoch 102/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.1725e-04 - accuracy: 1.0000 - recall: 0.9623\n",
      "Epoch 102: val_recall did not improve from 0.99107\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.1725e-04 - accuracy: 1.0000 - recall: 0.9623 - val_loss: 1.8335e-04 - val_accuracy: 1.0000 - val_recall: 0.9464\n",
      "Epoch 103/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.9434e-04 - accuracy: 1.0000 - recall: 0.9611\n",
      "Epoch 103: val_recall did not improve from 0.99107\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.9434e-04 - accuracy: 1.0000 - recall: 0.9611 - val_loss: 1.4561e-04 - val_accuracy: 1.0000 - val_recall: 0.9640\n",
      "Epoch 104/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.9931e-04 - accuracy: 1.0000 - recall: 0.9608\n",
      "Epoch 104: val_recall did not improve from 0.99107\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.9931e-04 - accuracy: 1.0000 - recall: 0.9608 - val_loss: 2.0848e-04 - val_accuracy: 1.0000 - val_recall: 0.9329\n",
      "Epoch 105/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.3024e-04 - accuracy: 0.9999 - recall: 0.9518\n",
      "Epoch 105: val_recall did not improve from 0.99107\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.3024e-04 - accuracy: 0.9999 - recall: 0.9518 - val_loss: 0.0012 - val_accuracy: 0.9997 - val_recall: 0.4636\n",
      "Epoch 106/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.2348e-04 - accuracy: 1.0000 - recall: 0.9597\n",
      "Epoch 106: val_recall did not improve from 0.99107\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.2348e-04 - accuracy: 1.0000 - recall: 0.9597 - val_loss: 1.8232e-04 - val_accuracy: 1.0000 - val_recall: 0.9897\n",
      "Epoch 107/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.0823e-04 - accuracy: 1.0000 - recall: 0.9593\n",
      "Epoch 107: val_recall did not improve from 0.99107\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.0823e-04 - accuracy: 1.0000 - recall: 0.9593 - val_loss: 1.7360e-04 - val_accuracy: 1.0000 - val_recall: 0.9622\n",
      "Epoch 108/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.0530e-04 - accuracy: 1.0000 - recall: 0.9582\n",
      "Epoch 108: val_recall did not improve from 0.99107\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 2.0530e-04 - accuracy: 1.0000 - recall: 0.9582 - val_loss: 1.8765e-04 - val_accuracy: 1.0000 - val_recall: 0.9411\n",
      "Epoch 109/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.8104e-04 - accuracy: 1.0000 - recall: 0.9656\n",
      "Epoch 109: val_recall did not improve from 0.99107\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 1.8104e-04 - accuracy: 1.0000 - recall: 0.9656 - val_loss: 1.4243e-04 - val_accuracy: 1.0000 - val_recall: 0.9548\n",
      "Epoch 110/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.7730e-04 - accuracy: 1.0000 - recall: 0.9642\n",
      "Epoch 110: val_recall did not improve from 0.99107\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.7730e-04 - accuracy: 1.0000 - recall: 0.9642 - val_loss: 1.6092e-04 - val_accuracy: 1.0000 - val_recall: 0.9447\n",
      "Epoch 111/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.6606e-04 - accuracy: 1.0000 - recall: 0.9670\n",
      "Epoch 111: val_recall did not improve from 0.99107\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.6606e-04 - accuracy: 1.0000 - recall: 0.9670 - val_loss: 1.6072e-04 - val_accuracy: 1.0000 - val_recall: 0.9532\n",
      "Epoch 112/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.6993e-04 - accuracy: 1.0000 - recall: 0.9649\n",
      "Epoch 112: val_recall did not improve from 0.99107\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.6993e-04 - accuracy: 1.0000 - recall: 0.9649 - val_loss: 2.1172e-04 - val_accuracy: 1.0000 - val_recall: 0.9641\n",
      "Epoch 113/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.6246e-04 - accuracy: 1.0000 - recall: 0.9667\n",
      "Epoch 113: val_recall did not improve from 0.99107\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.6246e-04 - accuracy: 1.0000 - recall: 0.9667 - val_loss: 1.7952e-04 - val_accuracy: 1.0000 - val_recall: 0.9513\n",
      "Epoch 114/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.5264e-04 - accuracy: 1.0000 - recall: 0.9700\n",
      "Epoch 114: val_recall did not improve from 0.99107\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.5264e-04 - accuracy: 1.0000 - recall: 0.9700 - val_loss: 2.4149e-04 - val_accuracy: 0.9999 - val_recall: 0.9083\n",
      "Epoch 115/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.4741e-04 - accuracy: 1.0000 - recall: 0.9699\n",
      "Epoch 115: val_recall did not improve from 0.99107\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.4741e-04 - accuracy: 1.0000 - recall: 0.9699 - val_loss: 2.2268e-04 - val_accuracy: 1.0000 - val_recall: 0.9262\n",
      "Epoch 116/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.4691e-04 - accuracy: 1.0000 - recall: 0.9686\n",
      "Epoch 116: val_recall did not improve from 0.99107\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.4691e-04 - accuracy: 1.0000 - recall: 0.9686 - val_loss: 2.6725e-04 - val_accuracy: 1.0000 - val_recall: 0.9456\n",
      "Epoch 117/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.5178e-04 - accuracy: 0.9999 - recall: 0.9465\n",
      "Epoch 117: val_recall did not improve from 0.99107\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 2.5178e-04 - accuracy: 0.9999 - recall: 0.9465 - val_loss: 0.0031 - val_accuracy: 0.9996 - val_recall: 0.3361\n",
      "Epoch 118/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.6438e-04 - accuracy: 0.9999 - recall: 0.9414\n",
      "Epoch 118: val_recall did not improve from 0.99107\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 2.6438e-04 - accuracy: 0.9999 - recall: 0.9414 - val_loss: 3.0853e-04 - val_accuracy: 0.9999 - val_recall: 0.9786\n",
      "Epoch 119/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.1044e-04 - accuracy: 0.9999 - recall: 0.9540\n",
      "Epoch 119: val_recall did not improve from 0.99107\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 2.1044e-04 - accuracy: 0.9999 - recall: 0.9540 - val_loss: 1.3391e-04 - val_accuracy: 1.0000 - val_recall: 0.9871\n",
      "Epoch 120/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.8759e-04 - accuracy: 1.0000 - recall: 0.9592\n",
      "Epoch 120: val_recall did not improve from 0.99107\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.8759e-04 - accuracy: 1.0000 - recall: 0.9592 - val_loss: 1.2319e-04 - val_accuracy: 1.0000 - val_recall: 0.9580\n",
      "Epoch 121/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.8704e-04 - accuracy: 1.0000 - recall: 0.9608\n",
      "Epoch 121: val_recall improved from 0.99107 to 0.99881, saving model to model_5fold.h5\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 1.8704e-04 - accuracy: 1.0000 - recall: 0.9608 - val_loss: 2.8420e-04 - val_accuracy: 0.9999 - val_recall: 0.9988\n",
      "Epoch 122/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.6806e-04 - accuracy: 1.0000 - recall: 0.9631\n",
      "Epoch 122: val_recall did not improve from 0.99881\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.6806e-04 - accuracy: 1.0000 - recall: 0.9631 - val_loss: 1.2066e-04 - val_accuracy: 1.0000 - val_recall: 0.9821\n",
      "Epoch 123/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.6400e-04 - accuracy: 1.0000 - recall: 0.9648\n",
      "Epoch 123: val_recall did not improve from 0.99881\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.6400e-04 - accuracy: 1.0000 - recall: 0.9648 - val_loss: 1.0780e-04 - val_accuracy: 1.0000 - val_recall: 0.9708\n",
      "Epoch 124/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.6449e-04 - accuracy: 1.0000 - recall: 0.9625\n",
      "Epoch 124: val_recall did not improve from 0.99881\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.6449e-04 - accuracy: 1.0000 - recall: 0.9625 - val_loss: 1.4218e-04 - val_accuracy: 1.0000 - val_recall: 0.9315\n",
      "Epoch 125/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.6127e-04 - accuracy: 1.0000 - recall: 0.9617\n",
      "Epoch 125: val_recall did not improve from 0.99881\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.6127e-04 - accuracy: 1.0000 - recall: 0.9617 - val_loss: 1.0004e-04 - val_accuracy: 1.0000 - val_recall: 0.9723\n",
      "Epoch 126/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.4836e-04 - accuracy: 1.0000 - recall: 0.9675\n",
      "Epoch 126: val_recall did not improve from 0.99881\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.4836e-04 - accuracy: 1.0000 - recall: 0.9675 - val_loss: 1.2680e-04 - val_accuracy: 1.0000 - val_recall: 0.9575\n",
      "Epoch 127/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.5610e-04 - accuracy: 1.0000 - recall: 0.9645\n",
      "Epoch 127: val_recall did not improve from 0.99881\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.5610e-04 - accuracy: 1.0000 - recall: 0.9645 - val_loss: 1.2340e-04 - val_accuracy: 1.0000 - val_recall: 0.9446\n",
      "Epoch 128/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.5320e-04 - accuracy: 1.0000 - recall: 0.9657\n",
      "Epoch 128: val_recall did not improve from 0.99881\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.5320e-04 - accuracy: 1.0000 - recall: 0.9657 - val_loss: 1.8690e-04 - val_accuracy: 0.9999 - val_recall: 0.9051\n",
      "Epoch 129/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.4866e-04 - accuracy: 1.0000 - recall: 0.9639\n",
      "Epoch 129: val_recall did not improve from 0.99881\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.4866e-04 - accuracy: 1.0000 - recall: 0.9639 - val_loss: 2.4613e-04 - val_accuracy: 0.9999 - val_recall: 0.8690\n",
      "Epoch 130/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.5929e-04 - accuracy: 1.0000 - recall: 0.9639\n",
      "Epoch 130: val_recall did not improve from 0.99881\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.5929e-04 - accuracy: 1.0000 - recall: 0.9639 - val_loss: 1.0944e-04 - val_accuracy: 1.0000 - val_recall: 0.9784\n",
      "Epoch 131/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.5506e-04 - accuracy: 1.0000 - recall: 0.9658\n",
      "Epoch 131: val_recall did not improve from 0.99881\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.5506e-04 - accuracy: 1.0000 - recall: 0.9658 - val_loss: 1.3187e-04 - val_accuracy: 1.0000 - val_recall: 0.9802\n",
      "Epoch 132/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.4223e-04 - accuracy: 1.0000 - recall: 0.9658\n",
      "Epoch 132: val_recall did not improve from 0.99881\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.4223e-04 - accuracy: 1.0000 - recall: 0.9658 - val_loss: 1.1715e-04 - val_accuracy: 1.0000 - val_recall: 0.9507\n",
      "Epoch 133/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.2358e-04 - accuracy: 1.0000 - recall: 0.9715\n",
      "Epoch 133: val_recall did not improve from 0.99881\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.2358e-04 - accuracy: 1.0000 - recall: 0.9715 - val_loss: 1.8249e-04 - val_accuracy: 0.9999 - val_recall: 0.9135\n",
      "Epoch 134/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.4785e-04 - accuracy: 1.0000 - recall: 0.9666\n",
      "Epoch 134: val_recall did not improve from 0.99881\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.4785e-04 - accuracy: 1.0000 - recall: 0.9666 - val_loss: 1.2026e-04 - val_accuracy: 1.0000 - val_recall: 0.9779\n",
      "Epoch 135/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.2976e-04 - accuracy: 1.0000 - recall: 0.9702\n",
      "Epoch 135: val_recall did not improve from 0.99881\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.2976e-04 - accuracy: 1.0000 - recall: 0.9702 - val_loss: 1.3485e-04 - val_accuracy: 1.0000 - val_recall: 0.9416\n",
      "Epoch 136/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.1976e-04 - accuracy: 1.0000 - recall: 0.9713\n",
      "Epoch 136: val_recall did not improve from 0.99881\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.1976e-04 - accuracy: 1.0000 - recall: 0.9713 - val_loss: 1.6127e-04 - val_accuracy: 1.0000 - val_recall: 0.9287\n",
      "Epoch 137/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.1369e-04 - accuracy: 1.0000 - recall: 0.9737\n",
      "Epoch 137: val_recall did not improve from 0.99881\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.1369e-04 - accuracy: 1.0000 - recall: 0.9737 - val_loss: 1.4003e-04 - val_accuracy: 1.0000 - val_recall: 0.9472\n",
      "Epoch 138/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.1230e-04 - accuracy: 1.0000 - recall: 0.9731\n",
      "Epoch 138: val_recall did not improve from 0.99881\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 1.1230e-04 - accuracy: 1.0000 - recall: 0.9731 - val_loss: 1.6115e-04 - val_accuracy: 1.0000 - val_recall: 0.9298\n",
      "Epoch 139/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.0984e-04 - accuracy: 1.0000 - recall: 0.9741\n",
      "Epoch 139: val_recall did not improve from 0.99881\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.0984e-04 - accuracy: 1.0000 - recall: 0.9741 - val_loss: 1.3176e-04 - val_accuracy: 1.0000 - val_recall: 0.9536\n",
      "Epoch 140/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.1154e-04 - accuracy: 1.0000 - recall: 0.9734\n",
      "Epoch 140: val_recall did not improve from 0.99881\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 1.1154e-04 - accuracy: 1.0000 - recall: 0.9734 - val_loss: 1.3185e-04 - val_accuracy: 1.0000 - val_recall: 0.9543\n",
      "Epoch 141/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.0496e-04 - accuracy: 1.0000 - recall: 0.9752\n",
      "Epoch 141: val_recall did not improve from 0.99881\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.0496e-04 - accuracy: 1.0000 - recall: 0.9752 - val_loss: 1.7713e-04 - val_accuracy: 1.0000 - val_recall: 0.9238\n",
      "Epoch 142/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.0640e-04 - accuracy: 1.0000 - recall: 0.9744\n",
      "Epoch 142: val_recall did not improve from 0.99881\n",
      "42/42 [==============================] - 13s 316ms/step - loss: 1.0640e-04 - accuracy: 1.0000 - recall: 0.9744 - val_loss: 1.3049e-04 - val_accuracy: 1.0000 - val_recall: 0.9460\n",
      "Epoch 143/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.0546e-04 - accuracy: 1.0000 - recall: 0.9751\n",
      "Epoch 143: val_recall did not improve from 0.99881\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.0546e-04 - accuracy: 1.0000 - recall: 0.9751 - val_loss: 1.4216e-04 - val_accuracy: 1.0000 - val_recall: 0.9547\n",
      "Epoch 144/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.0444e-04 - accuracy: 1.0000 - recall: 0.9759\n",
      "Epoch 144: val_recall did not improve from 0.99881\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.0444e-04 - accuracy: 1.0000 - recall: 0.9759 - val_loss: 1.3606e-04 - val_accuracy: 1.0000 - val_recall: 0.9642\n",
      "Epoch 145/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.0770e-04 - accuracy: 1.0000 - recall: 0.9729\n",
      "Epoch 145: val_recall did not improve from 0.99881\n",
      "42/42 [==============================] - 13s 317ms/step - loss: 1.0770e-04 - accuracy: 1.0000 - recall: 0.9729 - val_loss: 1.7749e-04 - val_accuracy: 0.9999 - val_recall: 0.9065\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mbouzon/miniconda3/envs/tf/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mbouzon/miniconda3/envs/tf/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mbouzon/miniconda3/envs/tf/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9999252310231648+- 0.0002059279341788072\n",
      "Jaccard: 0.8800747563525256+- 0.15156699065448165\n",
      "Dice: 0.9260260332261608+- 0.12964189760557987\n",
      "Precision: 0.975612424215455+- 0.10110841347161979\n",
      "Recall: 0.8944275179556206+- 0.14973851264921056\n"
     ]
    }
   ],
   "source": [
    "\n",
    "acc = []\n",
    "jacc = []\n",
    "f1 = []\n",
    "prec = []\n",
    "rec = []\n",
    "\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=28)\n",
    "f = 1\n",
    "\n",
    "for train_ind, test_ind in kf.split(X):\n",
    "    X_train, X_val, y_train, y_val = X[train_ind], X[test_ind], y[train_ind], y[test_ind]\n",
    "\n",
    "    model = unet()\n",
    "    \n",
    "    checkpoint_filepath = 'model_' + str(f)+'fold.h5'\n",
    "    callbacks = [\n",
    "            tf.keras.callbacks.EarlyStopping(patience=20, monitor='val_loss'),\n",
    "            tf.keras.callbacks.TensorBoard(log_dir='logs'),\n",
    "            tf.keras.callbacks.ModelCheckpoint(\n",
    "                filepath=checkpoint_filepath,\n",
    "                save_weights_only=False,\n",
    "                monitor='val_recall',\n",
    "                mode='max',\n",
    "                save_best_only=True,\n",
    "                verbose=1)]\n",
    "    \n",
    "    model.fit(X_train, y_train, validation_data=(X_val,y_val), batch_size=16, epochs=300, callbacks=callbacks)\n",
    "\n",
    "    loss = model.history.history['loss']\n",
    "    val_loss = model.history.history['val_loss']\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot( loss, 'r', label='Training loss')\n",
    "    plt.plot( val_loss, 'bo', label='Validation loss')\n",
    "    plt.title('Training and Validation Loss - Fold' + str(f))\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss Value')\n",
    "    plt.ylim([0, 1])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    for i in range(0, len(X_val)):\n",
    "        sample_image = X_val[i]\n",
    "        sample_mask = y_val[i].astype(np.uint8).flatten()\n",
    "        prediction = model.predict(sample_image[tf.newaxis, ...],verbose=0)[0]\n",
    "        predicted_mask = (prediction > 0.5).astype(np.uint8).flatten()\n",
    "            \n",
    "        acc.append(accuracy_score(sample_mask, predicted_mask))\n",
    "        jacc.append(jaccard_score(sample_mask, predicted_mask))\n",
    "        f1.append(f1_score(sample_mask, predicted_mask))\n",
    "        prec.append(precision_score(sample_mask, predicted_mask))\n",
    "        rec.append(recall_score(sample_mask, predicted_mask))\n",
    "\n",
    "    del model \n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    f+=1\n",
    "    \n",
    "print(\"Accuracy: \"+ str(np.mean(acc)) + \"+- \" + str(np.std(acc)))\n",
    "print(\"Jaccard: \"+ str(np.mean(jacc)) + \"+- \" + str(np.std(jacc)))\n",
    "print(\"Dice: \"+ str(np.mean(f1)) + \"+- \" + str(np.std(f1)))\n",
    "print(\"Precision: \"+ str(np.mean(prec)) + \"+- \" + str(np.std(prec)))\n",
    "print(\"Recall: \"+ str(np.mean(rec)) + \"+- \" + str(np.std(rec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa5d184f-5b31-4156-849f-d24ddac7c3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.999915300015204+- 7.959252220921675e-05\n",
      "Jaccard: 0.8170915371657571+- 0.1265145625712798\n",
      "Dice: 0.8930179350642634+- 0.09203663438413323\n",
      "Precision: 0.8178295846547864+- 0.12685965188939227\n",
      "Recall: 0.9990411194260411+- 0.003908553546141049\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \"+ str(np.mean(acc)) + \"+- \" + str(np.std(acc)))\n",
    "print(\"Jaccard: \"+ str(np.mean(jacc)) + \"+- \" + str(np.std(jacc)))\n",
    "print(\"Dice: \"+ str(np.mean(f1)) + \"+- \" + str(np.std(f1)))\n",
    "print(\"Precision: \"+ str(np.mean(prec)) + \"+- \" + str(np.std(prec)))\n",
    "print(\"Recall: \"+ str(np.mean(rec)) + \"+- \" + str(np.std(rec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2544ddf-696d-4ff5-8780-9a498daa8413",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "k-fold:   0%|                                                                                     | 0/5 [00:00<?, ?it/s]/home/mbouzon/miniconda3/envs/tf/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "k-fold:  20%|███████████████▍                                                             | 1/5 [00:30<02:02, 30.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - Fold1Accuracy: 0.9999462990533738\n",
      "Model - Fold1Jaccard: 0.9187525201741183\n",
      "Model - Fold1Dice: 0.9513527624956103\n",
      "Model - Fold1Precision: 0.944259975025257\n",
      "Model - Fold1Recall: 0.9629832362797363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "k-fold:  40%|██████████████████████████████▊                                              | 2/5 [01:00<01:31, 30.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - Fold2Accuracy: 0.999950477055141\n",
      "Model - Fold2Jaccard: 0.894915812416774\n",
      "Model - Fold2Dice: 0.9410717794643\n",
      "Model - Fold2Precision: 0.9022293088566278\n",
      "Model - Fold2Recall: 0.9885731329803736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "k-fold:  60%|██████████████████████████████████████████████▏                              | 3/5 [01:31<01:00, 30.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - Fold3Accuracy: 0.9999080158415294\n",
      "Model - Fold3Jaccard: 0.8188939053827247\n",
      "Model - Fold3Dice: 0.8937424364863357\n",
      "Model - Fold3Precision: 0.822083917440476\n",
      "Model - Fold3Recall: 0.9941403850283234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "k-fold:  80%|█████████████████████████████████████████████████████████████▌               | 4/5 [02:02<00:30, 30.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - Fold4Accuracy: 0.9999386450487696\n",
      "Model - Fold4Jaccard: 0.8716610961132153\n",
      "Model - Fold4Dice: 0.9293192731478103\n",
      "Model - Fold4Precision: 0.8769388953589097\n",
      "Model - Fold4Recall: 0.9939014820480496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "k-fold: 100%|█████████████████████████████████████████████████████████████████████████████| 5/5 [02:32<00:00, 30.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - Fold5Accuracy: 0.999915300015204\n",
      "Model - Fold5Jaccard: 0.8170915371657571\n",
      "Model - Fold5Dice: 0.8930179350642634\n",
      "Model - Fold5Precision: 0.8178295846547864\n",
      "Model - Fold5Recall: 0.9990411194260411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "acc_mean_fold = []\n",
    "jacc_mean_fold = []\n",
    "f1_mean_fold = []\n",
    "prec_mean_fold = []\n",
    "rec_mean_fold = []\n",
    "\n",
    "acc_std_fold = []\n",
    "jacc_std_fold = []\n",
    "f1_std_fold = []\n",
    "prec_std_fold = []\n",
    "rec_std_fold = []\n",
    "\n",
    "\n",
    "f = 0\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=28)\n",
    "for train_ind, test_ind in tqdm(kf.split(X), total=kf.get_n_splits(), desc=\"k-fold\"):\n",
    "    X_train, X_val, y_train, y_val = X[train_ind], X[test_ind], y[train_ind], y[test_ind]\n",
    "\n",
    "    acc= []\n",
    "    jacc = []\n",
    "    f1 = []\n",
    "    prec = []\n",
    "    rec = []\n",
    "    \n",
    "    model = tf.keras.models.load_model('model_'+str(f+1)+'fold.h5')\n",
    "\n",
    "    for i in range(0, len(X_val)):\n",
    "        sample_image = X_val[i]\n",
    "        sample_mask = y_val[i].astype(np.uint8).flatten()\n",
    "        prediction = model.predict(sample_image[tf.newaxis, ...],verbose=0)[0]\n",
    "        predicted_mask = (prediction > 0.5).astype(np.uint8).flatten()\n",
    "            \n",
    "        acc.append(accuracy_score(sample_mask, predicted_mask))\n",
    "        jacc.append(jaccard_score(sample_mask, predicted_mask))\n",
    "        f1.append(f1_score(sample_mask, predicted_mask))\n",
    "        prec.append(precision_score(sample_mask, predicted_mask))\n",
    "        rec.append(recall_score(sample_mask, predicted_mask))\n",
    "\n",
    "    acc_mean_fold.append(np.mean(acc))\n",
    "    acc_std_fold.append(np.std(acc))\n",
    "    jacc_mean_fold.append(np.mean(jacc))\n",
    "    jacc_std_fold.append(np.std(jacc))\n",
    "    f1_mean_fold.append(np.mean(f1))\n",
    "    f1_std_fold.append(np.std(f1))\n",
    "    prec_mean_fold.append(np.mean(prec))\n",
    "    prec_std_fold.append(np.std(prec))\n",
    "    rec_mean_fold.append(np.mean(rec))\n",
    "    rec_std_fold.append(np.std(rec))\n",
    "    \n",
    "    print(\"Model - Fold\" + str(f+1)+ \"Accuracy: \" + str(acc_mean_fold[-1]))\n",
    "    print(\"Model - Fold\" + str(f+1)+ \"Jaccard: \" + str(jacc_mean_fold[-1]))\n",
    "    print(\"Model - Fold\" + str(f+1)+ \"Dice: \" + str(f1_mean_fold[-1]))\n",
    "    print(\"Model - Fold\" + str(f+1)+ \"Precision: \" + str(prec_mean_fold[-1]))\n",
    "    print(\"Model - Fold\" + str(f+1)+ \"Recall: \" + str(rec_mean_fold[-1]))\n",
    "\n",
    "    f += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e774436e-ff52-47f8-8dce-d80b378b614b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.99317474028035 +- 0.005555623613547455\n",
      "Jaccard: 86.42629742505179 +- 1.8090608968500312\n",
      "Dice: 92.1700837331664 +- 2.112926733488158\n",
      "Precision: 87.26683362672114 +- 1.8959768200068368\n",
      "Recall: 98.77278711525047 +- 2.9380004678423832\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \"+ str(np.mean(acc_mean_fold)*100) + \" +- \" + str(np.std(acc_std_fold)*100))\n",
    "print(\"Jaccard: \"+ str(np.mean(jacc_mean_fold)*100) + \" +- \" + str(np.std(jacc_std_fold)*100))\n",
    "print(\"Dice: \"+ str(np.mean(f1_mean_fold)*100) + \" +- \" + str(np.std(f1_std_fold)*100))\n",
    "print(\"Precision: \"+ str(np.mean(prec_mean_fold)*100) + \" +- \" + str(np.std(prec_std_fold)*100))\n",
    "print(\"Recall: \"+ str(np.mean(rec_mean_fold)*100) + \" +- \" + str(np.std(rec_std_fold)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ac69b19-a5f7-40f1-b395-d65cd72999d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at model_1fold.h5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_1fold.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/saving/save.py:226\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath_str, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mexists(filepath_str):\n\u001b[0;32m--> 226\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\n\u001b[1;32m    227\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo file or directory found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    228\u001b[0m         )\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39misdir(filepath_str):\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m saved_model_load\u001b[38;5;241m.\u001b[39mload(\n\u001b[1;32m    232\u001b[0m             filepath_str, \u001b[38;5;28mcompile\u001b[39m, options\n\u001b[1;32m    233\u001b[0m         )\n",
      "\u001b[0;31mOSError\u001b[0m: No file or directory found at model_1fold.h5"
     ]
    }
   ],
   "source": [
    "best_model = tf.keras.models.load_model('UNET 10-fold models\\model_1fold.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6713b66-5fa4-436e-a338-dee9851b3462",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (train_ind, test_ind) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mkf\u001b[49m\u001b[38;5;241m.\u001b[39msplit(X)):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      3\u001b[0m         X_train, X_val, y_train, y_val \u001b[38;5;241m=\u001b[39m X[train_ind], X[test_ind], y[train_ind], y[test_ind]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'kf' is not defined"
     ]
    }
   ],
   "source": [
    "for i, (train_ind, test_ind) in enumerate(kf.split(X)):\n",
    "    if i == 0:\n",
    "        X_train, X_val, y_train, y_val = X[train_ind], X[test_ind], y[train_ind], y[test_ind]\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "329d56e2-63cb-4232-b7eb-0a9ed7c6b0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9999275207519531\n",
      "Jaccard: 0.9221311475409836\n",
      "Dice: 0.9594882729211087\n",
      "Precision: 0.9259259259259259\n",
      "Recall: 0.995575221238938\n"
     ]
    }
   ],
   "source": [
    "def display(display_list):\n",
    "  plt.figure(figsize=(15, 15))\n",
    "\n",
    "  title = ['Input image', 'True mask', 'Predicted mask']\n",
    "\n",
    "  for i in range(len(display_list)):\n",
    "    plt.subplot(1, len(display_list), i+1)\n",
    "    plt.title(title[i])\n",
    "    plt.imshow(tf.keras.utils.array_to_img(display_list[i]), cmap='gray')\n",
    "    plt.axis('off')\n",
    "  plt.show()\n",
    "  \n",
    "i = random.randint(0, len(X_val))\n",
    "sample_image = X_val[i]\n",
    "sample_mask = y_val[i]\n",
    "prediction = best_model.predict(sample_image[tf.newaxis, ...])[0]\n",
    "predicted_mask = (prediction > 0.5).astype(np.uint8)\n",
    "display([sample_image, sample_mask,predicted_mask])\n",
    "\n",
    "sample_mask = y_val[i].astype(np.uint8).flatten()\n",
    "predicted_mask = predicted_mask.flatten()\n",
    "\n",
    "\n",
    "print(\"Accuracy: \"+ str(accuracy_score(sample_mask, predicted_mask)))\n",
    "print(\"Jaccard: \"+ str(jaccard_score(sample_mask, predicted_mask)))\n",
    "print(\"Dice: \"+ str((2*jaccard_score(sample_mask, predicted_mask))/(1+jaccard_score(sample_mask, predicted_mask))))\n",
    "print(\"Precision: \"+ str(precision_score(sample_mask, predicted_mask)))\n",
    "print(\"Recall: \"+ str(recall_score(sample_mask, predicted_mask)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87842022-0cb6-47c0-b401-678af1a287e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
