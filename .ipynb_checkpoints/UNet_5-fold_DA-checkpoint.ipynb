{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf0339d0-739a-4991-a2c0-4392d2ec6f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 14:58:41.909757: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-18 14:58:41.909802: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-18 14:58:41.910405: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-18 14:58:41.914752: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-18 14:58:42.393305: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "from tensorflow.python.keras.backend import set_session\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34b9dd1e-626b-4787-b556-426246e4e48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 1\n",
    "k = 5\n",
    "\n",
    "\n",
    "IMG_WIDTH = 512\n",
    "IMG_HEIGHT = 512\n",
    "IMG_CHANNELS = 1\n",
    "\n",
    "DATA_PATH = 'data/'\n",
    "\n",
    "data_ids = next(os.walk(DATA_PATH+'/image'))[2]\n",
    "\n",
    "X = np.zeros((len(data_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "y = np.zeros((len(data_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.float32)\n",
    "\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "os.environ['TF_GPU_ALLOCATOR']= 'cuda_malloc_async'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "386e7353-1711-436b-93c8-9939c699dd59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing training images and masks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 838/838 [00:19<00:00, 44.00it/s]\n"
     ]
    }
   ],
   "source": [
    "print('Resizing training images and masks')\n",
    "for n, id_ in tqdm(enumerate(data_ids), total=len(data_ids)):   \n",
    "    path = DATA_PATH\n",
    "    img = imread(path + '/image/' + id_)[:,:]\n",
    "    img = img.reshape(img.shape[0], img.shape[1], IMG_CHANNELS)\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X[n] = img  #Fill empty X_train with values from img\n",
    "    \n",
    "    mask = imread(path + 'label/' + id_)\n",
    "    mask = (mask >= 250)\n",
    "    mask = np.expand_dims(resize(mask, (IMG_HEIGHT, IMG_WIDTH), mode='constant',  \n",
    "                                      preserve_range=True), axis=-1)\n",
    "    y[n] = mask \n",
    "    #plt.axis(\"off\")\n",
    "    #imshow(y[n])\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1db8dbfb-5731-4bc6-8ce3-a0214e325da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ImageDataGenerator for Data Augmentation\n",
    "data_genX = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=2.5,\n",
    "    width_shift_range=0.075,\n",
    "    height_shift_range=0.075,\n",
    "    shear_range=0.075,\n",
    "    zoom_range=0.075,\n",
    "    horizontal_flip=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81233ce6-93fc-4cec-a5a9-dcc63e55693f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ImageDataGenerator for Data Augmentation\n",
    "data_genY = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=2.5,\n",
    "    width_shift_range=0.075,\n",
    "    height_shift_range=0.075,\n",
    "    shear_range=0.075,\n",
    "    zoom_range=0.075,\n",
    "    horizontal_flip=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf18407b-adca-470d-b5a5-91b74646e9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate additional images to equalize classes if necessary\n",
    "def generate(X_all, y_all):\n",
    "\n",
    "# Generation\n",
    "    X_generated = []\n",
    "    y_generated = []\n",
    "    \n",
    "    data_gen.fit(X_all)\n",
    "    \n",
    "    generated_images = data_gen.flow(X_all, y_all, batch_size=1)\n",
    "    \n",
    "    for _ in range(len(X_all)):\n",
    "        X_new, y_new = next(generated_images)\n",
    "        X_generated.append(np.squeeze(X_new))\n",
    "        y_generated.append(np.squeeze(y_new))\n",
    "\n",
    "    print(f'New images generated: {len(X_generated)}')\n",
    "\n",
    "    return X_generated, y_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37156bfd-418e-4bc8-908f-2d5530052e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New images generated: 838\n"
     ]
    }
   ],
   "source": [
    "X_new, y_new = generate(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fe69e60-6b8a-410f-bf4f-842705b80900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, images_per_figure=100):\n",
    "    num_images = len(images)\n",
    "    cols = 5\n",
    "    rows = (images_per_figure + cols - 1) // cols\n",
    "\n",
    "    for start in range(0, num_images, images_per_figure):\n",
    "        plt.figure(figsize=(cols * 3, rows * 3))\n",
    "        end = min(start + images_per_figure, num_images)\n",
    "\n",
    "        for i in range(start, end):\n",
    "            plt.subplot(rows, cols, i - start + 1)\n",
    "            plt.imshow(images[i])\n",
    "            plt.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68474ccd-938e-4167-9749-e91070d79a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_images(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96b2a529-e221-4f43-adf2-9428e66d1790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_new:  (838, 512, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "X_new = np.expand_dims(X_new, axis=-1)\n",
    "print('X_new: ', X_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85d665ea-e7d8-4b01-a058-ef375b45905f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet():\n",
    "    inputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "    \n",
    "    #Contraction path\n",
    "    c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(inputs)\n",
    "    c1 = tf.keras.layers.Dropout(0.1)(c1)\n",
    "    c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
    "    b1 = tf.keras.layers.BatchNormalization()(c1)\n",
    "    r1 = tf.keras.layers.ReLU()(b1)\n",
    "    p1 = tf.keras.layers.MaxPooling2D((2, 2))(r1)\n",
    "    \n",
    "    c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
    "    c2 = tf.keras.layers.Dropout(0.1)(c2)\n",
    "    c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
    "    b2 = tf.keras.layers.BatchNormalization()(c2)\n",
    "    r2 = tf.keras.layers.ReLU()(b2)\n",
    "    p2 = tf.keras.layers.MaxPooling2D((2, 2))(r2)\n",
    "     \n",
    "    c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "    c3 = tf.keras.layers.Dropout(0.2)(c3)\n",
    "    c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
    "    b3 = tf.keras.layers.BatchNormalization()(c3)\n",
    "    r3 = tf.keras.layers.ReLU()(b3)\n",
    "    p3 = tf.keras.layers.MaxPooling2D((2, 2))(r3)\n",
    "     \n",
    "    c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "    c4 = tf.keras.layers.Dropout(0.2)(c4)\n",
    "    c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
    "    b4 = tf.keras.layers.BatchNormalization()(c4)\n",
    "    r4 = tf.keras.layers.ReLU()(b4)\n",
    "    p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(r4)\n",
    "     \n",
    "    c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
    "    b5 = tf.keras.layers.BatchNormalization()(c5)\n",
    "    r5 = tf.keras.layers.ReLU()(b5)\n",
    "    c5 = tf.keras.layers.Dropout(0.3)(r5)\n",
    "    c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "    \n",
    "    #Expansive path \n",
    "    u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = tf.keras.layers.concatenate([u6, c4])\n",
    "    u6 = tf.keras.layers.BatchNormalization()(u6)\n",
    "    u6 = tf.keras.layers.ReLU()(u6)\n",
    "    \n",
    "     \n",
    "    u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(u6)\n",
    "    u7 = tf.keras.layers.concatenate([u7, c3])\n",
    "    u7 = tf.keras.layers.BatchNormalization()(u7)\n",
    "    u7 = tf.keras.layers.ReLU()(u7)\n",
    "    \n",
    "     \n",
    "    u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(u7)\n",
    "    u8 = tf.keras.layers.concatenate([u8, c2])\n",
    "    u8 = tf.keras.layers.BatchNormalization()(u8)\n",
    "    u8 = tf.keras.layers.ReLU()(u8)\n",
    "     \n",
    "    u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(u8)\n",
    "    u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n",
    "    u9 = tf.keras.layers.BatchNormalization()(u9)\n",
    "    u9 = tf.keras.layers.ReLU()(u9)\n",
    "    \n",
    "     \n",
    "    outputs = tf.keras.layers.Conv2D(num_classes, (1, 1), activation='sigmoid')(u9)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "    model.compile(optimizer='adam', loss=\"binary_crossentropy\", metrics=['accuracy', tf.keras.metrics.Recall(name='recall')])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5bb3dc3-8cc2-41d0-bf67-a27f9775446a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 15:03:46.005457: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_2/dropout_10/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - ETA: 0s - loss: 0.5176 - accuracy: 0.8917 - recall: 0.2224\n",
      "Epoch 1: val_recall improved from -inf to 0.27382, saving model to model_1fold.keras\n",
      "42/42 [==============================] - 14s 231ms/step - loss: 0.5176 - accuracy: 0.8917 - recall: 0.2224 - val_loss: 0.4113 - val_accuracy: 0.8750 - val_recall: 0.2738\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.3091 - accuracy: 0.9959 - recall: 0.0125\n",
      "Epoch 2: val_recall did not improve from 0.27382\n",
      "42/42 [==============================] - 9s 214ms/step - loss: 0.3091 - accuracy: 0.9959 - recall: 0.0125 - val_loss: 0.2963 - val_accuracy: 0.9828 - val_recall: 2.0437e-04\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2532 - accuracy: 0.9943 - recall: 0.1052\n",
      "Epoch 3: val_recall did not improve from 0.27382\n",
      "42/42 [==============================] - 9s 214ms/step - loss: 0.2532 - accuracy: 0.9943 - recall: 0.1052 - val_loss: 0.1272 - val_accuracy: 0.9976 - val_recall: 0.0011\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2108 - accuracy: 0.9888 - recall: 0.2381\n",
      "Epoch 4: val_recall improved from 0.27382 to 0.61351, saving model to model_1fold.keras\n",
      "42/42 [==============================] - 9s 218ms/step - loss: 0.2108 - accuracy: 0.9888 - recall: 0.2381 - val_loss: 0.1883 - val_accuracy: 0.9474 - val_recall: 0.6135\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1798 - accuracy: 0.9857 - recall: 0.3340\n",
      "Epoch 5: val_recall did not improve from 0.61351\n",
      "42/42 [==============================] - 9s 214ms/step - loss: 0.1798 - accuracy: 0.9857 - recall: 0.3340 - val_loss: 0.1330 - val_accuracy: 0.9683 - val_recall: 0.5666\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1646 - accuracy: 0.9861 - recall: 0.3517\n",
      "Epoch 6: val_recall improved from 0.61351 to 0.71981, saving model to model_1fold.keras\n",
      "42/42 [==============================] - 9s 219ms/step - loss: 0.1646 - accuracy: 0.9861 - recall: 0.3517 - val_loss: 0.1093 - val_accuracy: 0.9716 - val_recall: 0.7198\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1493 - accuracy: 0.9858 - recall: 0.4069"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 15:04:53.094950: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 41943040 bytes after encountering the first element of size 41943040 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7: val_recall did not improve from 0.71981\n",
      "42/42 [==============================] - 9s 215ms/step - loss: 0.1493 - accuracy: 0.9858 - recall: 0.4069 - val_loss: 0.0721 - val_accuracy: 0.9862 - val_recall: 0.3997\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1352 - accuracy: 0.9846 - recall: 0.4621\n",
      "Epoch 8: val_recall did not improve from 0.71981\n",
      "42/42 [==============================] - 9s 215ms/step - loss: 0.1352 - accuracy: 0.9846 - recall: 0.4621 - val_loss: 0.0449 - val_accuracy: 0.9961 - val_recall: 0.2663\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1326 - accuracy: 0.9856 - recall: 0.4400\n",
      "Epoch 9: val_recall did not improve from 0.71981\n",
      "42/42 [==============================] - 9s 216ms/step - loss: 0.1326 - accuracy: 0.9856 - recall: 0.4400 - val_loss: 0.0430 - val_accuracy: 0.9929 - val_recall: 0.2506\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1235 - accuracy: 0.9851 - recall: 0.4833\n",
      "Epoch 10: val_recall did not improve from 0.71981\n",
      "42/42 [==============================] - 9s 214ms/step - loss: 0.1235 - accuracy: 0.9851 - recall: 0.4833 - val_loss: 0.0299 - val_accuracy: 0.9984 - val_recall: 0.0819\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1204 - accuracy: 0.9849 - recall: 0.4898\n",
      "Epoch 11: val_recall did not improve from 0.71981\n",
      "42/42 [==============================] - 9s 214ms/step - loss: 0.1204 - accuracy: 0.9849 - recall: 0.4898 - val_loss: 0.0422 - val_accuracy: 0.9922 - val_recall: 0.5299\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1145 - accuracy: 0.9853 - recall: 0.5050\n",
      "Epoch 12: val_recall did not improve from 0.71981\n",
      "42/42 [==============================] - 9s 214ms/step - loss: 0.1145 - accuracy: 0.9853 - recall: 0.5050 - val_loss: 0.0282 - val_accuracy: 0.9972 - val_recall: 0.1066\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1101 - accuracy: 0.9849 - recall: 0.5251\n",
      "Epoch 13: val_recall did not improve from 0.71981\n",
      "42/42 [==============================] - 9s 214ms/step - loss: 0.1101 - accuracy: 0.9849 - recall: 0.5251 - val_loss: 0.0548 - val_accuracy: 0.9817 - val_recall: 0.6821\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1061 - accuracy: 0.9859 - recall: 0.5522\n",
      "Epoch 14: val_recall improved from 0.71981 to 0.81093, saving model to model_1fold.keras\n",
      "42/42 [==============================] - 10s 224ms/step - loss: 0.1061 - accuracy: 0.9859 - recall: 0.5522 - val_loss: 0.0398 - val_accuracy: 0.9890 - val_recall: 0.8109\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0998 - accuracy: 0.9847 - recall: 0.5919\n",
      "Epoch 15: val_recall did not improve from 0.81093\n",
      "42/42 [==============================] - 9s 217ms/step - loss: 0.0998 - accuracy: 0.9847 - recall: 0.5919 - val_loss: 0.0153 - val_accuracy: 0.9987 - val_recall: 0.0445\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1014 - accuracy: 0.9853 - recall: 0.5604\n",
      "Epoch 16: val_recall did not improve from 0.81093\n",
      "42/42 [==============================] - 9s 223ms/step - loss: 0.1014 - accuracy: 0.9853 - recall: 0.5604 - val_loss: 0.0475 - val_accuracy: 0.9818 - val_recall: 0.8016\n",
      "Epoch 17/300\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1028 - accuracy: 0.9845 - recall: 0.5628"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 31\u001b[0m\n\u001b[1;32m     19\u001b[0m checkpoint_filepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(fold)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold.keras\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     20\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     21\u001b[0m         tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     22\u001b[0m         tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mTensorBoard(log_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogs\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m             save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     29\u001b[0m             verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n\u001b[0;32m---> 31\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_gen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m100.0\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(fold)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold.keras\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     34\u001b[0m loss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "jacc = []\n",
    "f1 = []\n",
    "prec = []\n",
    "rec = []\n",
    "\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=28)\n",
    "fold = 1\n",
    "seed = [42, 21, 5, 10, 72]\n",
    "for train_ind, test_ind in kf.split(X):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(fold)\n",
    "    X_train, X_val, y_train, y_val = X[train_ind], X[test_ind], y[train_ind], y[test_ind]\n",
    "    #y_train = y_train.astype('float')\n",
    "    #y_val = y_val.astype('float')\n",
    "    model = unet()\n",
    "    \n",
    "    checkpoint_filepath = 'model_' + str(fold)+'fold.keras'\n",
    "    callbacks = [\n",
    "            tf.keras.callbacks.EarlyStopping(patience=20, monitor='val_loss'),\n",
    "            tf.keras.callbacks.TensorBoard(log_dir='logs'),\n",
    "            tf.keras.callbacks.ModelCheckpoint(\n",
    "                filepath=checkpoint_filepath,\n",
    "                save_weights_only=False,\n",
    "                monitor='val_recall',\n",
    "                mode='max',\n",
    "                save_best_only=True,\n",
    "                verbose=1)]\n",
    "\n",
    "    image_generator = data_genX.flow(X_train, batch_size=16, seed=seed[fold-1])\n",
    "    mask_generator = data_genY.flow(y_train, batch_size=16, seed=seed[fold-1])\n",
    "    \n",
    "    # Criar um gerador que produza (imagem, máscara) no mesmo passo\n",
    "    train_generator = zip(image_generator, mask_generator)\n",
    "    \n",
    "    model.fit(train_generator,validation_data=(X_val,y_val), epochs=300, callbacks=callbacks, class_weight={0:1.0, 1:100.0})\n",
    "    model.save('model_' + str(fold)+'fold.keras')\n",
    "    \n",
    "    loss = model.history.history['loss']\n",
    "    val_loss = model.history.history['val_loss']\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot( loss, 'r', label='Training loss')\n",
    "    plt.plot( val_loss, 'g', label='Validation loss')\n",
    "    plt.title('Training and Validation Loss - Fold' + str(fold))\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss Value')\n",
    "    plt.ylim([0, 1])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    for i in range(0, len(X_val)):\n",
    "        sample_image = X_val[i]\n",
    "        sample_mask = y_val[i].astype(np.uint8).flatten()\n",
    "        prediction = model.predict(sample_image[tf.newaxis, ...],verbose=0)[0]\n",
    "        predicted_mask = (prediction > 0.5).astype(np.uint8).flatten()\n",
    "            \n",
    "        acc.append(accuracy_score(sample_mask, predicted_mask))\n",
    "        jacc.append(jaccard_score(sample_mask, predicted_mask))\n",
    "        f1.append(f1_score(sample_mask, predicted_mask))\n",
    "        prec.append(precision_score(sample_mask, predicted_mask))\n",
    "        rec.append(recall_score(sample_mask, predicted_mask))\n",
    "\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "\n",
    "    with open('UNet_5-fold_DA_tempo.txt', 'a') as f:\n",
    "        f.write(f'{training_time:.2f}\\n')\n",
    "    print(f\"O modelo demorou {training_time:.2f} segundos para treinar.\")\n",
    "    \n",
    "    del model\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    fold+=1\n",
    "    \n",
    "print(\"Accuracy: \"+ str(np.mean(acc)) + \"+- \" + str(np.std(acc)))\n",
    "print(\"Jaccard: \"+ str(np.mean(jacc)) + \"+- \" + str(np.std(jacc)))\n",
    "print(\"Dice: \"+ str(np.mean(f1)) + \"+- \" + str(np.std(f1)))\n",
    "print(\"Precision: \"+ str(np.mean(prec)) + \"+- \" + str(np.std(prec)))\n",
    "print(\"Recall: \"+ str(np.mean(rec)) + \"+- \" + str(np.std(rec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5d184f-5b31-4156-849f-d24ddac7c3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: \"+ str(np.mean(acc)) + \"+- \" + str(np.std(acc)))\n",
    "print(\"Jaccard: \"+ str(np.mean(jacc)) + \"+- \" + str(np.std(jacc)))\n",
    "print(\"Dice: \"+ str(np.mean(f1)) + \"+- \" + str(np.std(f1)))\n",
    "print(\"Precision: \"+ str(np.mean(prec)) + \"+- \" + str(np.std(prec)));\n",
    "print(\"Recall: \"+ str(np.mean(rec)) + \"+- \" + str(np.std(rec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2544ddf-696d-4ff5-8780-9a498daa8413",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_mean_fold = []\n",
    "jacc_mean_fold = []\n",
    "f1_mean_fold = []\n",
    "prec_mean_fold = []\n",
    "rec_mean_fold = []\n",
    "\n",
    "acc_std_fold = []\n",
    "jacc_std_fold = []\n",
    "f1_std_fold = []\n",
    "prec_std_fold = []\n",
    "rec_std_fold = []\n",
    "\n",
    "\n",
    "f = 0\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=28)\n",
    "for train_ind, test_ind in tqdm(kf.split(X), total=kf.get_n_splits(), desc=\"k-fold\"):\n",
    "    X_train, X_val, y_train, y_val = X[train_ind], X[test_ind], y[train_ind], y[test_ind]\n",
    "\n",
    "    acc= []\n",
    "    jacc = []\n",
    "    f1 = []\n",
    "    prec = []\n",
    "    rec = []\n",
    "    \n",
    "    model = tf.keras.models.load_model('model_'+str(f+1)+'fold.keras')\n",
    "\n",
    "    for i in range(0, len(X_val)):\n",
    "        sample_image = X_val[i]\n",
    "        sample_mask = y_val[i].astype(np.uint8).flatten()\n",
    "        prediction = model.predict(sample_image[tf.newaxis, ...],verbose=0)[0]\n",
    "        predicted_mask = (prediction > 0.5).astype(np.uint8).flatten()\n",
    "            \n",
    "        acc.append(accuracy_score(sample_mask, predicted_mask))\n",
    "        jacc.append(jaccard_score(sample_mask, predicted_mask))\n",
    "        f1.append(f1_score(sample_mask, predicted_mask))\n",
    "        prec.append(precision_score(sample_mask, predicted_mask))\n",
    "        rec.append(recall_score(sample_mask, predicted_mask))\n",
    "\n",
    "    acc_mean_fold.append(np.mean(acc))\n",
    "    acc_std_fold.append(np.std(acc))\n",
    "    jacc_mean_fold.append(np.mean(jacc))\n",
    "    jacc_std_fold.append(np.std(jacc))\n",
    "    f1_mean_fold.append(np.mean(f1))\n",
    "    f1_std_fold.append(np.std(f1))\n",
    "    prec_mean_fold.append(np.mean(prec))\n",
    "    prec_std_fold.append(np.std(prec))\n",
    "    rec_mean_fold.append(np.mean(rec))\n",
    "    rec_std_fold.append(np.std(rec))\n",
    "    \n",
    "    print(\"Model - Fold\" + str(f+1)+ \"Accuracy: \" + str(acc_mean_fold[-1]))\n",
    "    print(\"Model - Fold\" + str(f+1)+ \"Jaccard: \" + str(jacc_mean_fold[-1]))\n",
    "    print(\"Model - Fold\" + str(f+1)+ \"Dice: \" + str(f1_mean_fold[-1]))\n",
    "    print(\"Model - Fold\" + str(f+1)+ \"Precision: \" + str(prec_mean_fold[-1]))\n",
    "    print(\"Model - Fold\" + str(f+1)+ \"Recall: \" + str(rec_mean_fold[-1]))\n",
    "\n",
    "    f += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e774436e-ff52-47f8-8dce-d80b378b614b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: \"+ str(np.mean(acc_mean_fold)*100) + \" +- \" + str(np.std(acc_std_fold)*100))\n",
    "print(\"Jaccard: \"+ str(np.mean(jacc_mean_fold)*100) + \" +- \" + str(np.std(jacc_std_fold)*100))\n",
    "print(\"Dice: \"+ str(np.mean(f1_mean_fold)*100) + \" +- \" + str(np.std(f1_std_fold)*100))\n",
    "print(\"Precision: \"+ str(np.mean(prec_mean_fold)*100) + \" +- \" + str(np.std(prec_std_fold)*100))\n",
    "print(\"Recall: \"+ str(np.mean(rec_mean_fold)*100) + \" +- \" + str(np.std(rec_std_fold)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac69b19-a5f7-40f1-b395-d65cd72999d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tf.keras.models.load_model('model_5fold.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6713b66-5fa4-436e-a338-dee9851b3462",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=28)\n",
    "for i, (train_ind, test_ind) in enumerate(kf.split(X)):\n",
    "    if i == 4:\n",
    "        X_train, X_val, y_train, y_val = X[train_ind], X[test_ind], y[train_ind], y[test_ind]\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329d56e2-63cb-4232-b7eb-0a9ed7c6b0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(display_list):\n",
    "  plt.figure(figsize=(15, 15))\n",
    "\n",
    "  title = ['Input image', 'True mask', 'Predicted mask']\n",
    "\n",
    "  for i in range(len(display_list)):\n",
    "    plt.subplot(1, len(display_list), i+1)\n",
    "    plt.title(title[i])\n",
    "    plt.imshow(tf.keras.utils.array_to_img(display_list[i]), cmap='gray')\n",
    "    plt.axis('off')\n",
    "  plt.show()\n",
    "  \n",
    "i = random.randint(0, len(X_val))\n",
    "sample_image = X_val[i]\n",
    "sample_mask = y_val[i]\n",
    "prediction = best_model.predict(sample_image[tf.newaxis, ...])[0]\n",
    "predicted_mask = (prediction > 0.5).astype(np.uint8)\n",
    "display([sample_image, sample_mask,predicted_mask])\n",
    "\n",
    "sample_mask = y_val[i].astype(np.uint8).flatten()\n",
    "predicted_mask = predicted_mask.flatten()\n",
    "\n",
    "\n",
    "print(\"Accuracy: \"+ str(accuracy_score(sample_mask, predicted_mask)))\n",
    "print(\"Jaccard: \"+ str(jaccard_score(sample_mask, predicted_mask)))\n",
    "print(\"Dice: \"+ str((2*jaccard_score(sample_mask, predicted_mask))/(1+jaccard_score(sample_mask, predicted_mask))))\n",
    "print(\"Precision: \"+ str(precision_score(sample_mask, predicted_mask)))\n",
    "print(\"Recall: \"+ str(recall_score(sample_mask, predicted_mask)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36ef180-344a-4f01-9a6b-a717a7040fc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
