{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "826de9a0-6fef-4596-b88d-92812eec548a",
   "metadata": {},
   "source": [
    "# Kidney Stone Segmentation Using U-Net and Fully Convolutional Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db35651-dc99-4580-ab80-993d2a6f9700",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba0e4f92-f4e9-456b-bcd8-be0be162c74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 17:21:54.534765: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-04 17:21:55.332208: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.backend import set_session\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from keras_unet_collection import models\n",
    "from tqdm import tqdm \n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21436e78-0900-4ee6-a7e7-0b4d00e1418a",
   "metadata": {},
   "source": [
    "## Parameters and Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7719007a-9a55-4c2a-b1d4-a117bc8fc577",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [13, 42, 1, 83, 76]\n",
    "np.random.seed(0)\n",
    "\n",
    "num_classes = 1\n",
    "split_size = 0.2\n",
    "\n",
    "\n",
    "IMG_WIDTH = 512\n",
    "IMG_HEIGHT = 512\n",
    "IMG_CHANNELS = 1\n",
    "\n",
    "DATA_PATH = 'data/'\n",
    "\n",
    "data_ids = next(os.walk(DATA_PATH+'/image'))[2]\n",
    "\n",
    "X = np.zeros((len(data_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "y = np.zeros((len(data_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=bool)\n",
    "\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "os.environ['TF_GPU_ALLOCATOR']= 'cuda_malloc_async'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbb5484-21fd-4c8c-a391-3e65f1ed1c89",
   "metadata": {},
   "source": [
    "## Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1285fa8-16fc-424c-8368-1055498ba0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing training images and masks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 838/838 [00:18<00:00, 45.35it/s]\n"
     ]
    }
   ],
   "source": [
    "print('Resizing training images and masks')\n",
    "for n, id_ in tqdm(enumerate(data_ids), total=len(data_ids)):   \n",
    "    path = DATA_PATH\n",
    "    img = imread(path + '/image/' + id_)[:,:]\n",
    "    img = img.reshape(img.shape[0], img.shape[1], IMG_CHANNELS)\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X[n] = img  #Fill empty X_train with values from img\n",
    "    \n",
    "    mask = imread(path + 'label/' + id_)\n",
    "    mask = (mask >= 250)\n",
    "    mask = np.expand_dims(resize(mask, (IMG_HEIGHT, IMG_WIDTH), mode='constant',  \n",
    "                                      preserve_range=True), axis=-1)\n",
    "    y[n] = mask \n",
    "    #plt.axis(\"off\")\n",
    "    #imshow(y[n])\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55f6dad6-3c7f-4aee-803d-d50dcc1cb923",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 17:22:16.031390: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automated hyper-parameter determination is applied with the following details:\n",
      "----------\n",
      "\tNumber of convolution filters after each full-scale skip connection: filter_num_skip = [16, 16, 16, 16]\n",
      "\tNumber of channels of full-scale aggregated feature maps: filter_num_aggregate = 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 17:22:16.176488: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-04 17:22:16.176546: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-04 17:22:16.178989: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-04 17:22:16.179036: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-04 17:22:16.179055: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-04 17:22:17.463589: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-04 17:22:17.463744: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-04 17:22:17.463752: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-11-04 17:22:17.463764: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2024-11-04 17:22:17.463768: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-11-04 17:22:17.464105: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-04 17:22:17.464135: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9332 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "deep_supervision = True\n",
      "names of output tensors are listed as follows (\"sup0\" is the shallowest supervision layer;\n",
      "\"final\" is the final output layer):\n",
      "\n",
      "\tunet3plus_output_sup0_activation\n",
      "\tunet3plus_output_sup1_activation\n",
      "\tunet3plus_output_sup2_activation\n",
      "\tunet3plus_output_sup3_activation\n",
      "\tunet3plus_output_final_activation\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mbouzon/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/optimizers/base_optimizer.py:576: UserWarning: Gradients do not exist for variables ['kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'gamma', 'beta', 'gamma', 'beta', 'gamma', 'beta', 'gamma', 'beta', 'kernel', 'kernel', 'kernel', 'kernel', 'gamma', 'beta', 'gamma', 'beta', 'gamma', 'beta', 'gamma', 'beta', 'kernel', 'gamma', 'beta', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias'] when minimizing the loss. If using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "For a model with multiple outputs, when providing the `metrics` argument as a list, it should have as many entries as the model has outputs. Received:\nmetrics=['accuracy', <Recall name=recall>]\nof length 2 whereas the model has 5 outputs.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 53\u001b[0m\n\u001b[1;32m     41\u001b[0m checkpoint_filepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(f)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold.keras\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     42\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     43\u001b[0m         tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     44\u001b[0m         tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mTensorBoard(log_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogs\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     50\u001b[0m             save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     51\u001b[0m             verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n\u001b[0;32m---> 53\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(X_val)):\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/trainers/compile_utils.py:250\u001b[0m, in \u001b[0;36mCompileMetrics._build_metrics_set\u001b[0;34m(self, metrics, num_outputs, output_names, y_true, y_pred, argument_name)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(metrics, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(metrics) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(y_pred):\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    251\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor a model with multiple outputs, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    252\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhen providing the `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margument_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` argument as a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    253\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist, it should have as many entries as the model has \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    254\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs. Received:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00margument_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mof \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    255\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(metrics)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m whereas the model has \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    256\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(y_pred)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m outputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    257\u001b[0m         )\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, (mls, yt, yp) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mzip\u001b[39m(metrics, y_true, y_pred)\n\u001b[1;32m    260\u001b[0m     ):\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mls, \u001b[38;5;28mlist\u001b[39m):\n",
      "\u001b[0;31mValueError\u001b[0m: For a model with multiple outputs, when providing the `metrics` argument as a list, it should have as many entries as the model has outputs. Received:\nmetrics=['accuracy', <Recall name=recall>]\nof length 2 whereas the model has 5 outputs."
     ]
    }
   ],
   "source": [
    "\n",
    "acc = []\n",
    "jacc = []\n",
    "f1 = []\n",
    "prec = []\n",
    "rec = []\n",
    "\n",
    "\n",
    "for f in range(1, len(seeds)):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=split_size, random_state=seeds[f])\n",
    "    \n",
    "    y_train = {\n",
    "        'unet3plus_output_sup0_activation': y_train,\n",
    "        'unet3plus_output_sup1_activation': y_train,\n",
    "        'unet3plus_output_sup2_activation': y_train,\n",
    "        'unet3plus_output_final_activation': y_train\n",
    "    }\n",
    "    y_val = {\n",
    "        'unet3plus_output_sup0_activation': y_val,\n",
    "        'unet3plus_output_sup1_activation': y_val,\n",
    "        'unet3plus_output_sup2_activation': y_val,\n",
    "        'unet3plus_output_final_activation': y_val\n",
    "    }\n",
    "\n",
    "\n",
    "    model = models.unet_3plus_2d((512, 512, 1), n_labels=1, filter_num_down=[16, 32, 64, 128, 256],\n",
    "                             filter_num_skip='auto', filter_num_aggregate='auto',\n",
    "                             stack_num_down=2, stack_num_up=1, activation='ReLU', output_activation='Sigmoid',\n",
    "                             batch_norm=True, pool='max', unpool=False, deep_supervision=True, name='unet3plus')\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss={\n",
    "            'unet3plus_output_sup0_activation': 'binary_crossentropy',\n",
    "            'unet3plus_output_sup1_activation': 'binary_crossentropy',\n",
    "            'unet3plus_output_sup2_activation': 'binary_crossentropy',\n",
    "            'unet3plus_output_final_activation': 'binary_crossentropy'\n",
    "        },\n",
    "        metrics={'unet3plus_output_sup0_activation': ['accuracy', tf.keras.metrics.Recall(name='recall')]}\n",
    "    )\n",
    "\n",
    "    checkpoint_filepath = 'model_' + str(f)+'fold.keras'\n",
    "    callbacks = [\n",
    "            tf.keras.callbacks.EarlyStopping(patience=5, monitor='val_loss'),\n",
    "            tf.keras.callbacks.TensorBoard(log_dir='logs'),\n",
    "            tf.keras.callbacks.ModelCheckpoint(\n",
    "                filepath=checkpoint_filepath,\n",
    "                save_weights_only=False,\n",
    "                monitor='val_recall',\n",
    "                mode='max',\n",
    "                save_best_only=True,\n",
    "                verbose=1)]\n",
    "    \n",
    "    model.fit(X_train, y_train, validation_data=(X_val,y_val), batch_size=8, epochs=300, callbacks=callbacks)\n",
    "\n",
    "    print('stop')\n",
    "\n",
    "    for i in range(0, len(X_val)):\n",
    "        sample_image = X_val[i]\n",
    "        sample_mask = y_val['unet3plus_output_final_activation'][i].astype(np.uint8).flatten()\n",
    "        prediction = model.predict(sample_image[tf.newaxis, ...],verbose=0)[0]\n",
    "        predicted_mask = (prediction > 0.5).astype(np.uint8).flatten()\n",
    "            \n",
    "        acc.append(accuracy_score(sample_mask, predicted_mask))\n",
    "        jacc.append(jaccard_score(sample_mask, predicted_mask))\n",
    "        f1.append(f1_score(sample_mask, predicted_mask))\n",
    "        prec.append(precision_score(sample_mask, predicted_mask))\n",
    "        rec.append(recall_score(sample_mask, predicted_mask))\n",
    "\n",
    "    del model \n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    \n",
    "    \n",
    "print(\"Accuracy: \"+ np.mean(acc) + \"+- \" + np.std(acc))\n",
    "print(\"Jaccard: \"+ np.mean(jacc) + \"+- \" + np.std(jacc))\n",
    "print(\"Dice: \"+ (2*np.mean(jacc))/(1+np.mean(jacc)) + \"+- \" + np.std(2*jacc/(1+jacc)))\n",
    "print(\"F1 Score: \"+ np.mean(f1)+ \"+- \" + np.std(f1))\n",
    "print(\"Precision: \"+ np.mean(prec) + \"+- \" + np.std(prec))\n",
    "print(\"Recall: \"+ np.mean(rec) + \"+- \" + np.std(rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fe2699-1bbe-4170-9fe9-564b062a3061",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1580c34e-3ffe-4229-be58-987b8047b675",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model.history.history['loss']\n",
    "val_loss = model.history.history['val_loss']\n",
    "\n",
    "plt.figure()\n",
    "plt.plot( loss, 'r', label='Training loss')\n",
    "plt.plot( val_loss, 'bo', label='Validation loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss Value')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ad042d-d944-4c42-9e6a-ddc16a9a68fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f744c257-471a-4e24-bda9-2e53aa2cd324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(display_list):\n",
    "  plt.figure(figsize=(15, 15))\n",
    "\n",
    "  title = ['Input image', 'True mask', 'Predicted mask']\n",
    "\n",
    "  for i in range(len(display_list)):\n",
    "    plt.subplot(1, len(display_list), i+1)\n",
    "    plt.title(title[i])\n",
    "    plt.imshow(tf.keras.utils.array_to_img(display_list[i]), cmap='gray')\n",
    "    plt.axis('off')\n",
    "  plt.show()\n",
    "  \n",
    "i = random.randint(0, len(X_val))\n",
    "sample_image = X_val[i]\n",
    "sample_mask = y_val[i]\n",
    "prediction = model.predict(sample_image[tf.newaxis, ...])[0]\n",
    "predicted_mask = (prediction > 0.5).astype(np.uint8)\n",
    "display([sample_image, sample_mask,predicted_mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a721d54b-4388-4d00-8ae8-be17de0ed637",
   "metadata": {},
   "source": [
    "Acuraccy:  0.9998064804077148\r\n",
    "Jaccard:  0.7504550150031974\r\n",
    "F1 Score:  0.8574399325558522\r\n",
    "Precision:  0.9923892538866844\r\n",
    "Recall:  0.7547991292301603"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cec6c4-26b6-4707-931c-ae0a07ec1156",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc_mean_fold = []\n",
    "jacc_mean_fold = []\n",
    "dice_mean_fold = []\n",
    "f1_mean_fold = []\n",
    "prec_mean_fold = []\n",
    "rec_mean_fold = []\n",
    "\n",
    "acc_std_fold = []\n",
    "jacc_std_fold = []\n",
    "dice_std_fold = []\n",
    "f1_std_fold = []\n",
    "prec_std_fold = []\n",
    "rec_std_fold = []\n",
    "\n",
    "\n",
    "\n",
    "for f in range(0, len(seeds)):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=split_size, random_state=seeds[f])\n",
    "\n",
    "    acc= []\n",
    "    jacc = []\n",
    "    dice = []\n",
    "    f1 = []\n",
    "    prec = []\n",
    "    rec = []\n",
    "    \n",
    "    model = tf.keras.models.load_model('model1_'+str(f+1)+'fold.h5')\n",
    "\n",
    "    for i in range(0, len(X_val)):\n",
    "        sample_image = X_val[i]\n",
    "        sample_mask = y_val[i].astype(np.uint8).flatten()\n",
    "        prediction = model.predict(sample_image[tf.newaxis, ...],verbose=0)[0]\n",
    "        predicted_mask = (prediction > 0.5).astype(np.uint8).flatten()\n",
    "            \n",
    "        acc.append(accuracy_score(sample_mask, predicted_mask))\n",
    "        jacc.append(jaccard_score(sample_mask, predicted_mask))\n",
    "        dice.append((2*jaccard_score(sample_mask, predicted_mask))/(1+jaccard_score(sample_mask, predicted_mask)))\n",
    "        f1.append(f1_score(sample_mask, predicted_mask))\n",
    "        prec.append(precision_score(sample_mask, predicted_mask))\n",
    "        rec.append(recall_score(sample_mask, predicted_mask))\n",
    "\n",
    "    acc_mean_fold.append(np.mean(acc))\n",
    "    acc_std_fold.append(np.std(acc))\n",
    "    jacc_mean_fold.append(np.mean(jacc))\n",
    "    jacc_std_fold.append(np.std(jacc))\n",
    "    dice_mean_fold.append(np.mean(dice))\n",
    "    dice_std_fold.append(np.std(dice))\n",
    "    f1_mean_fold.append(np.mean(f1))\n",
    "    f1_std_fold.append(np.std(f1))\n",
    "    prec_mean_fold.append(np.mean(prec))\n",
    "    prec_std_fold.append(np.std(prec))\n",
    "    rec_mean_fold.append(np.mean(rec))\n",
    "    rec_std_fold.append(np.std(rec))\n",
    "    \n",
    "    print(\"Model1 - Fold\" + str(f+1)+ \"Accuracy: \" + str(acc_mean_fold[-1]))\n",
    "    print(\"Model1 - Fold\" + str(f+1)+ \"Jaccard: \" + str(jacc_mean_fold[-1]))\n",
    "    print(\"Model1 - Fold\" + str(f+1)+ \"Dice: \" + str(dice_mean_fold[-1]))\n",
    "    print(\"Model1 - Fold\" + str(f+1)+ \"F1-Score: \" + str(f1_mean_fold[-1]))\n",
    "    print(\"Model1 - Fold\" + str(f+1)+ \"Precision: \" + str(prec_mean_fold[-1]))\n",
    "    print(\"Model1 - Fold\" + str(f+1)+ \"Recall: \" + str(rec_mean_fold[-1]))\n",
    "\n",
    "    acc= []\n",
    "    jacc = []\n",
    "    dice = []\n",
    "    f1 = []\n",
    "    prec = []\n",
    "    rec = []\n",
    "    \n",
    "    model2 = tf.keras.models.load_model('model2_'+str(f+1)+'fold.h5')\n",
    "    \n",
    "\n",
    "    for i in range(0, len(X_train)):\n",
    "            sample_image = X_train[i]\n",
    "            sample_mask = y_train[i].astype(np.uint8).flatten()\n",
    "            prediction = model.predict(sample_image[tf.newaxis, ...],verbose=0)[0]\n",
    "            predicted_mask = (prediction > 0.5).astype(np.uint8).flatten()\n",
    "                \n",
    "            acc.append(accuracy_score(sample_mask, predicted_mask))\n",
    "            jacc.append(jaccard_score(sample_mask, predicted_mask))\n",
    "            dice.append((2*jaccard_score(sample_mask, predicted_mask))/(1+jaccard_score(sample_mask, predicted_mask)))\n",
    "            f1.append(f1_score(sample_mask, predicted_mask))\n",
    "            prec.append(precision_score(sample_mask, predicted_mask))\n",
    "            rec.append(recall_score(sample_mask, predicted_mask))\n",
    "\n",
    "    acc_mean_fold.append(np.mean(acc))\n",
    "    acc_std_fold.append(np.std(acc))\n",
    "    jacc_mean_fold.append(np.mean(jacc))\n",
    "    jacc_std_fold.append(np.std(jacc))\n",
    "    dice_mean_fold.append(np.mean(dice))\n",
    "    dice_std_fold.append(np.std(dice))\n",
    "    f1_mean_fold.append(np.mean(f1))\n",
    "    f1_std_fold.append(np.std(f1))\n",
    "    prec_mean_fold.append(np.mean(prec))\n",
    "    prec_std_fold.append(np.std(prec))\n",
    "    rec_mean_fold.append(np.mean(rec))\n",
    "    rec_std_fold.append(np.std(rec))\n",
    "    \n",
    "    print(\"Model2 - Fold\" + str(f+1)+ \"Accuracy: \" + str(acc_mean_fold[-1]))\n",
    "    print(\"Model2 - Fold\" + str(f+1)+ \"Jaccard: \" + str(jacc_mean_fold[-1]))\n",
    "    print(\"Model2 - Fold\" + str(f+1)+ \"Dice: \" + str(dice_mean_fold[-1]))\n",
    "    print(\"Model2 - Fold\" + str(f+1)+ \"F1-Score: \" + str(f1_mean_fold[-1]))\n",
    "    print(\"Model2 - Fold\" + str(f+1)+ \"Precision: \" + str(prec_mean_fold[-1]))\n",
    "    print(\"Model2 - Fold\" + str(f+1)+ \"Recall: \" + str(rec_mean_fold[-1]))\n",
    "        \n",
    "  \n",
    "#print(\"Accuracy: \"+ str(np.mean(acc)) + \"+- \" + str(np.std(acc)))\n",
    "#print(\"Jaccard: \"+ str(np.mean(jacc)) + \"+- \" + str(np.std(jacc)))\n",
    "#print(\"Dice: \"+ str((2*np.mean(jacc))/(1+np.mean(jacc))) + \"+- \" + str(np.std(2*jacc/(1+jacc))))\n",
    "#print(\"F1 Score: \"+ str(np.mean(f1)) + \"+- \" + str(np.std(f1)))\n",
    "#print(\"Precision: \"+ str(np.mean(prec)) + \"+- \" + str(np.std(prec)))\n",
    "#print(\"Recall: \"+ str(np.mean(rec)) + \"+- \" + str(np.std(rec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573eb2f5-b90d-4669-9668-7f33d5374cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: \"+ str(np.mean(acc_mean_fold)*100) + \" +- \" + str(np.std(acc_std_fold)*100))\n",
    "print(\"Jaccard: \"+ str(np.mean(jacc_mean_fold)*100) + \" +- \" + str(np.std(jacc_std_fold)*100))\n",
    "print(\"Dice: \"+ str(np.mean(dice_mean_fold)*100) + \" +- \" + str(np.std(dice_std_fold)*100))\n",
    "print(\"F1 Score: \"+ str(np.mean(f1_mean_fold)*100) + \" +- \" + str(np.std(f1_std_fold)*100))\n",
    "print(\"Precision: \"+ str(np.mean(prec_mean_fold)*100) + \" +- \" + str(np.std(prec_std_fold)*100))\n",
    "print(\"Recall: \"+ str(np.mean(rec_mean_fold)*100) + \" +- \" + str(np.std(rec_std_fold)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ab8d7b-724e-4ca1-b8ed-dbb138b7b9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_mean_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b199080-1a6a-403a-8d4a-c681196019fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tf.keras.models.load_model('UNET 5x2-fold models/model1_4fold.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b76dbb5-4b6a-4c54-bae2-dddaba8e486e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=split_size, random_state=seeds[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b57778-954a-4a5a-a3dd-67ca85534ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(display_list):\n",
    "  plt.figure(figsize=(15, 15))\n",
    "\n",
    "  title = ['Input image', 'True mask', 'Predicted mask']\n",
    "\n",
    "  for i in range(len(display_list)):\n",
    "    plt.subplot(1, len(display_list), i+1)\n",
    "    plt.title(title[i])\n",
    "    plt.imshow(tf.keras.utils.array_to_img(display_list[i]), cmap='gray')\n",
    "    plt.axis('off')\n",
    "  plt.show()\n",
    "  \n",
    "i = random.randint(0, len(X_val))\n",
    "sample_image = X_val[i]\n",
    "sample_mask = y_val[i]\n",
    "prediction = best_model.predict(sample_image[tf.newaxis, ...])[0]\n",
    "predicted_mask = (prediction > 0.5).astype(np.uint8)\n",
    "display([sample_image, sample_mask,predicted_mask])\n",
    "\n",
    "sample_mask = y_val[i].astype(np.uint8).flatten()\n",
    "predicted_mask = predicted_mask.flatten()\n",
    "\n",
    "\n",
    "print(\"Accuracy: \"+ str(accuracy_score(sample_mask, predicted_mask)))\n",
    "print(\"Jaccard: \"+ str(jaccard_score(sample_mask, predicted_mask)))\n",
    "print(\"Dice: \"+ str((2*jaccard_score(sample_mask, predicted_mask))/(1+jaccard_score(sample_mask, predicted_mask))))\n",
    "print(\"Precision: \"+ str(precision_score(sample_mask, predicted_mask)))\n",
    "print(\"Recall: \"+ str(recall_score(sample_mask, predicted_mask)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83122c2c-9ff3-47d0-b18e-10363b4755ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img = imread('normal/image/normal2.jpg', as_gray=True)[:,:]\n",
    "img = img.reshape(img.shape[0], img.shape[1], IMG_CHANNELS)\n",
    "img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "\n",
    "mask = imread('normal/label/2.png', as_gray=True)\n",
    "mask = (mask != 0)\n",
    "mask = np.expand_dims(resize(mask, (IMG_HEIGHT, IMG_WIDTH), mode='constant',  \n",
    "                                  preserve_range=True), axis=-1)\n",
    "sample_image = img\n",
    "sample_mask = mask\n",
    "prediction = best_model.predict(sample_image[tf.newaxis, ...])[0]\n",
    "predicted_mask = (prediction > 0.5).astype(np.uint8)\n",
    "display([sample_image, sample_mask,predicted_mask])\n",
    "\n",
    "sample_mask = mask.astype(np.uint8).flatten()\n",
    "predicted_mask = predicted_mask.flatten()\n",
    "\n",
    "\n",
    "print(\"Accuracy: \"+ str(accuracy_score(sample_mask, predicted_mask)))\n",
    "print(\"Jaccard: \"+ str(jaccard_score(sample_mask, predicted_mask)))\n",
    "print(\"Dice: \"+ str((2*jaccard_score(sample_mask, predicted_mask))/(1+jaccard_score(sample_mask, predicted_mask))))\n",
    "print(\"Precision: \"+ str(precision_score(sample_mask, predicted_mask)))\n",
    "print(\"Recall: \"+ str(recall_score(sample_mask, predicted_mask)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928f6ff1-6545-42d4-ac5b-b0cea8e7da0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
