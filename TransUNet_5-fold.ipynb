{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf0339d0-739a-4991-a2c0-4392d2ec6f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 13:47:51.143358: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-24 13:47:51.143404: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-24 13:47:51.144122: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-24 13:47:51.148194: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-24 13:47:51.888994: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.backend import set_session\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    " \n",
    "from tqdm import tqdm \n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b6f5337-7770-4f92-a2a4-251e31af3cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 1\n",
    "k = 5\n",
    "\n",
    "\n",
    "IMG_WIDTH = 512\n",
    "IMG_HEIGHT = 512\n",
    "IMG_CHANNELS = 1\n",
    "\n",
    "DATA_PATH = 'data/'\n",
    "\n",
    "data_ids = next(os.walk(DATA_PATH+'/image'))[2]\n",
    "\n",
    "X = np.zeros((len(data_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "y = np.zeros((len(data_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.float32)\n",
    "\n",
    "# Definição do diretório de saída\n",
    "output_dir = \"Trans UNet DICE 5-fold model\"\n",
    "os.makedirs(output_dir, exist_ok=True)  # Garante que a pasta existe\n",
    "\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "os.environ['TF_GPU_ALLOCATOR']= 'cuda_malloc_async'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6eeed634-f3f7-4cce-8c45-77e4b7c270ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing training images and masks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 838/838 [00:20<00:00, 41.41it/s]\n"
     ]
    }
   ],
   "source": [
    "print('Resizing training images and masks')\n",
    "for n, id_ in tqdm(enumerate(data_ids), total=len(data_ids)):   \n",
    "    path = DATA_PATH\n",
    "    img = imread(path + '/image/' + id_)[:,:]\n",
    "    img = img.reshape(img.shape[0], img.shape[1], IMG_CHANNELS)\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X[n] = img  #Fill empty X_train with values from img\n",
    "    \n",
    "    mask = imread(path + 'label/' + id_)\n",
    "    mask = (mask >= 250)\n",
    "    mask = np.expand_dims(resize(mask, (IMG_HEIGHT, IMG_WIDTH), mode='constant',  \n",
    "                                      preserve_range=True), axis=-1)\n",
    "    y[n] = mask \n",
    "    #plt.axis(\"off\")\n",
    "    #imshow(y[n])\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2f02a06-5551-4109-97af-8d76f83beb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "def f1_score(y_true, y_pred):\n",
    "    \"\"\"Calcula o F1-Score para segmentação binária\"\"\"\n",
    "    y_pred = K.round(y_pred)  # Arredondar para 0 ou 1\n",
    "    tp = K.sum(K.cast(y_true * y_pred, 'float32'))  # Verdadeiros Positivos\n",
    "    fp = K.sum(K.cast((1 - y_true) * y_pred, 'float32'))  # Falsos Positivos\n",
    "    fn = K.sum(K.cast(y_true * (1 - y_pred), 'float32'))  # Falsos Negativos\n",
    "    \n",
    "    precision = tp / (tp + fp + K.epsilon())  # Precision\n",
    "    recall = tp / (tp + fn + K.epsilon())  # Recall\n",
    "    \n",
    "    f1 = 2 * (precision * recall) / (precision + recall + K.epsilon())  # F1-Score\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e76775c-5fc9-419a-a36a-0bd07fe023ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1e-6\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return 1 - ((2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7f297ed-a66e-4727-b154-b60aa8f7fa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, Dropout, BatchNormalization, ReLU, MaxPooling2D,\n",
    "    Conv2DTranspose, Concatenate, Reshape, Dense, LayerNormalization,\n",
    "    MultiHeadAttention, Input\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_patches, d_model):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        self.pos_emb = self.add_weight(\n",
    "            shape=(1, num_patches, d_model),\n",
    "            initializer='zeros',\n",
    "            trainable=True,\n",
    "            name='positional_embedding'\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_emb\n",
    "\n",
    "def trans_unet():\n",
    "    input_shape =  (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    def conv_block(x, filters, dropout=0.1):\n",
    "        x = Conv2D(filters, (3, 3), activation='relu', \n",
    "                 kernel_initializer='he_normal', padding='same')(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = Conv2D(filters, (3, 3), activation='relu', \n",
    "                 kernel_initializer='he_normal', padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        return ReLU()(x)\n",
    "    \n",
    "    # Encoder (CNN)\n",
    "    c1 = conv_block(inputs, 16)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    \n",
    "    c2 = conv_block(p1, 32)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "    \n",
    "    c3 = conv_block(p2, 64, dropout=0.2)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "    \n",
    "    c4 = conv_block(p3, 128, dropout=0.2)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "    \n",
    "    # Transformer Bottleneck\n",
    "    h = input_shape[0] // 16\n",
    "    w = input_shape[1] // 16\n",
    "    num_patches = h * w\n",
    "    d_model = 256\n",
    "    \n",
    "    x = Reshape((num_patches, 128))(p4)\n",
    "    x = Dense(d_model)(x)\n",
    "    x = PositionalEmbedding(num_patches, d_model)(x)\n",
    "    \n",
    "    # Transformer Encoder\n",
    "    num_heads = 8\n",
    "    for _ in range(4):\n",
    "        x1 = LayerNormalization()(x)\n",
    "        attn = MultiHeadAttention(num_heads=num_heads, key_dim=d_model//num_heads)(x1, x1)\n",
    "        x = attn + x\n",
    "        x2 = LayerNormalization()(x)\n",
    "        mlp = Dense(d_model * 4, activation='gelu')(x2)\n",
    "        mlp = Dense(d_model)(mlp)\n",
    "        x = mlp + x\n",
    "    \n",
    "    x = Reshape((h, w, d_model))(x)\n",
    "    \n",
    "    # Decoder (UNet++ style)\n",
    "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(x)\n",
    "    u6 = Concatenate()([u6, c4])\n",
    "    c6 = conv_block(u6, 128)\n",
    "    \n",
    "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = Concatenate()([u7, c3])\n",
    "    c7 = conv_block(u7, 64)\n",
    "    \n",
    "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = Concatenate()([u8, c2])\n",
    "    c8 = conv_block(u8, 32)\n",
    "    \n",
    "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = Concatenate()([u9, c1])\n",
    "    c9 = conv_block(u9, 16)\n",
    "    \n",
    "    outputs = Conv2D(num_classes, (1, 1), activation='sigmoid')(c9)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss=dice_loss, metrics=[\n",
    "        'accuracy', \n",
    "        tf.keras.metrics.Recall(name='recall'), \n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        f1_score,\n",
    "        tf.keras.metrics.IoU(num_classes=2, target_class_ids={0,1}, name='IoU')\n",
    "    ])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bb3dc3-8cc2-41d0-bf67-a27f9775446a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 13:48:14.088149: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-24 13:48:14.127962: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-24 13:48:14.128012: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-24 13:48:14.130858: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-24 13:48:14.130903: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-24 13:48:14.130923: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-24 13:48:14.265580: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-24 13:48:14.265651: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-24 13:48:14.265659: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-03-24 13:48:14.265670: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2025-03-24 13:48:14.265675: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:236] Using CUDA malloc Async allocator for GPU: 0\n",
      "2025-03-24 13:48:14.265878: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-24 13:48:14.265914: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9558 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 13:48:20.624710: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2025-03-24 13:48:21.435853: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2025-03-24 13:48:25.975303: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:306] gpu_async_0 cuMemAllocAsync failed to allocate 1828790272 bytes: CUDA error: out of memory (CUDA_ERROR_OUT_OF_MEMORY)\n",
      " Reported by CUDA: Free memory/Total memory: 425234400/12878086144\n",
      "2025-03-24 13:48:25.975352: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:311] Stats: Limit:                     10022289408\n",
      "InUse:                     10531789734\n",
      "MaxInUse:                  11353891766\n",
      "NumAllocs:                        1627\n",
      "MaxAllocSize:               2722250752\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2025-03-24 13:48:25.975377: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:63] Histogram of current allocation: (allocation_size_in_bytes, nb_allocation_of_that_sizes), ...;\n",
      "2025-03-24 13:48:25.975381: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1, 22\n",
      "2025-03-24 13:48:25.975382: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 4, 57\n",
      "2025-03-24 13:48:25.975384: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 8, 9\n",
      "2025-03-24 13:48:25.975385: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 16, 2\n",
      "2025-03-24 13:48:25.975387: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 64, 36\n",
      "2025-03-24 13:48:25.975388: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 128, 35\n",
      "2025-03-24 13:48:25.975389: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 256, 35\n",
      "2025-03-24 13:48:25.975391: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 512, 35\n",
      "2025-03-24 13:48:25.975392: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 576, 3\n",
      "2025-03-24 13:48:25.975393: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1024, 111\n",
      "2025-03-24 13:48:25.975395: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1028, 1\n",
      "2025-03-24 13:48:25.975396: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 4096, 12\n",
      "2025-03-24 13:48:25.975397: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 8192, 3\n",
      "2025-03-24 13:48:25.975399: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 9216, 6\n",
      "2025-03-24 13:48:25.975400: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 18432, 7\n",
      "2025-03-24 13:48:25.975402: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 32768, 3\n",
      "2025-03-24 13:48:25.975403: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 36864, 6\n",
      "2025-03-24 13:48:25.975404: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 65536, 24\n",
      "2025-03-24 13:48:25.975405: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 73728, 6\n",
      "2025-03-24 13:48:25.975407: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 131072, 6\n",
      "2025-03-24 13:48:25.975408: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 147456, 6\n",
      "2025-03-24 13:48:25.975410: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 262144, 48\n",
      "2025-03-24 13:48:25.975411: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 294912, 6\n",
      "2025-03-24 13:48:25.975412: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 524288, 3\n",
      "2025-03-24 13:48:25.975413: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 589824, 6\n",
      "2025-03-24 13:48:25.975415: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1048576, 27\n",
      "2025-03-24 13:48:25.975416: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1179648, 3\n",
      "2025-03-24 13:48:25.975418: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 4194304, 2\n",
      "2025-03-24 13:48:25.975419: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 8388608, 3\n",
      "2025-03-24 13:48:25.975420: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 16777216, 47\n",
      "2025-03-24 13:48:25.975422: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 33554432, 11\n",
      "2025-03-24 13:48:25.975423: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 67108864, 27\n",
      "2025-03-24 13:48:25.975425: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 134217728, 9\n",
      "2025-03-24 13:48:25.975426: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 175898624, 1\n",
      "2025-03-24 13:48:25.975427: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 268435456, 7\n",
      "2025-03-24 13:48:25.975429: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 285212672, 1\n",
      "2025-03-24 13:48:25.975430: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 536870912, 6\n",
      "2025-03-24 13:48:25.975431: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 703594496, 1\n",
      "2025-03-24 13:48:25.975436: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:97] CU_MEMPOOL_ATTR_RESERVED_MEM_CURRENT: 11106516992\n",
      "2025-03-24 13:48:25.975437: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:99] CU_MEMPOOL_ATTR_USED_MEM_CURRENT: 10531789734\n",
      "2025-03-24 13:48:25.975439: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:100] CU_MEMPOOL_ATTR_RESERVED_MEM_HIGH: 12952010752\n",
      "2025-03-24 13:48:25.975441: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:101] CU_MEMPOOL_ATTR_USED_MEM_HIGH: 11353891766\n",
      "2025-03-24 13:48:27.246159: I external/local_xla/xla/service/service.cc:168] XLA service 0x7ef9cc819640 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-03-24 13:48:27.246195: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4070, Compute Capability 8.9\n",
      "2025-03-24 13:48:27.250724: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1742834907.320531  898667 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - ETA: 0s - loss: 0.9966 - accuracy: 0.7622 - recall: 0.9798 - precision: 0.0026 - f1_score: 0.0053 - IoU: 0.5017\n",
      "Epoch 1: val_f1_score improved from -inf to 0.00161, saving model to Trans UNet DICE 5-fold model/model_5fold.keras\n",
      "42/42 [==============================] - 110s 1s/step - loss: 0.9966 - accuracy: 0.7622 - recall: 0.9798 - precision: 0.0026 - f1_score: 0.0053 - IoU: 0.5017 - val_loss: 0.9984 - val_accuracy: 0.2965 - val_recall: 1.0000 - val_precision: 8.4677e-04 - val_f1_score: 0.0016 - val_IoU: 0.2309\n",
      "Epoch 2/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.9900 - accuracy: 0.9760 - recall: 0.9781 - precision: 0.0253 - f1_score: 0.0766 - IoU: 0.5480\n",
      "Epoch 2: val_f1_score improved from 0.00161 to 0.00226, saving model to Trans UNet DICE 5-fold model/model_5fold.keras\n",
      "42/42 [==============================] - 37s 893ms/step - loss: 0.9900 - accuracy: 0.9760 - recall: 0.9781 - precision: 0.0253 - f1_score: 0.0766 - IoU: 0.5480 - val_loss: 0.9977 - val_accuracy: 0.6167 - val_recall: 0.7522 - val_precision: 0.0012 - val_f1_score: 0.0023 - val_IoU: 0.4882\n",
      "Epoch 3/150\n",
      " 1/42 [..............................] - ETA: 25s - loss: 0.9856 - accuracy: 0.9927 - recall: 0.9715 - precision: 0.0774 - f1_score: 0.1433 - IoU: 0.6083"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "jacc = []\n",
    "f1 = []\n",
    "prec = []\n",
    "rec = []\n",
    "\n",
    "# Dicionário para armazenar métricas por fold\n",
    "fold_metrics_summary = []\n",
    "\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=28)\n",
    "fold = 5\n",
    "\n",
    "for i, (train_ind, test_ind) in enumerate(kf.split(X)):\n",
    "    if i < (fold-1):\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    print(\"Fold: \" + str(fold))\n",
    "    X_train, X_val, y_train, y_val = X[train_ind], X[test_ind], y[train_ind], y[test_ind]\n",
    "\n",
    "    model = trans_unet()\n",
    "    \n",
    "    \n",
    "    checkpoint_filepath = os.path.join(output_dir, f'model_{fold}fold.keras')\n",
    "    callbacks = [\n",
    "            tf.keras.callbacks.TensorBoard(log_dir='logs'),\n",
    "            tf.keras.callbacks.ModelCheckpoint(\n",
    "                filepath=checkpoint_filepath,\n",
    "                save_weights_only=False,\n",
    "                monitor='val_f1_score',\n",
    "                mode='max',\n",
    "                save_best_only=True,\n",
    "                verbose=1)]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train, validation_data=(X_val,y_val), batch_size=16, epochs=150, callbacks=callbacks)\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "\n",
    "     # Salvando o tempo de treinamento\n",
    "    with open(os.path.join(output_dir, 'training_time.txt'), 'a') as f:\n",
    "        f.write(f'Fold {fold}: {training_time:.2f} segundos\\n')\n",
    "    print(f\"O modelo demorou {training_time:.2f} segundos para treinar.\")\n",
    "    \n",
    "    loss = model.history.history['loss']\n",
    "    val_loss = model.history.history['val_loss']\n",
    "    \n",
    "    with open(os.path.join(output_dir, f'loss_fold{fold}.csv'), 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=';')\n",
    "        writer.writerow([\"Epoch\", \"Loss\", \"Validation Loss\"])\n",
    "        for epoch, (l, vl) in enumerate(zip(loss, val_loss), start=1):\n",
    "            writer.writerow([epoch, l, vl])\n",
    "            \n",
    "     # Plotando e salvando a figura\n",
    "    plt.figure()\n",
    "    plt.plot(loss, 'r', label='Training loss')\n",
    "    plt.plot(val_loss, 'g', label='Validation loss')\n",
    "    plt.title(f'Training and Validation Loss - Fold {fold}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss Value')\n",
    "    plt.ylim([0, 1])\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(output_dir, f'loss_plot_fold{fold}.png'))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    fold_metrics = []\n",
    "\n",
    "    acc_fold = []\n",
    "    jacc_fold = []\n",
    "    f1_fold = []\n",
    "    prec_fold = []\n",
    "    rec_fold = []\n",
    "    \n",
    "    for i in range(0, len(X_val)):\n",
    "        sample_image = X_val[i]\n",
    "        sample_mask = y_val[i].astype(np.uint8).flatten()\n",
    "        prediction = model.predict(sample_image[tf.newaxis, ...],verbose=0)[0]\n",
    "        predicted_mask = (prediction > 0.5).astype(np.uint8).flatten()\n",
    "            \n",
    "        acc_score = accuracy_score(sample_mask, predicted_mask)\n",
    "        jacc_score = jaccard_score(sample_mask, predicted_mask)\n",
    "        f1_score_val = f1_score(sample_mask, predicted_mask).numpy()\n",
    "        prec_score = precision_score(sample_mask, predicted_mask)\n",
    "        rec_score = recall_score(sample_mask, predicted_mask)\n",
    "\n",
    "        acc_fold.append(acc_score)\n",
    "        jacc_fold.append(jacc_score)\n",
    "        f1_fold.append(f1_score_val)\n",
    "        prec_fold.append(prec_score)\n",
    "        rec_fold.append(rec_score)\n",
    "\n",
    "        fold_metrics.append([i, acc_score, jacc_score, f1_score_val, prec_score, rec_score])\n",
    "        \n",
    "    # Salvando métricas por imagem\n",
    "    with open(os.path.join(output_dir, f'metrics_fold{fold}.csv'), 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=';')\n",
    "        writer.writerow([\"Index\", \"Accuracy\", \"Jaccard\", \"DICE\", \"Precision\", \"Recall\"])\n",
    "        writer.writerows(fold_metrics)\n",
    "\n",
    "    # Salvando a média do fold para cada métrica\n",
    "    fold_metrics_summary.append([\n",
    "        fold, np.mean(acc_fold), np.std(acc_fold),\n",
    "        np.mean(jacc_fold), np.std(jacc_fold),\n",
    "        np.mean(f1_fold), np.std(f1_fold),\n",
    "        np.mean(prec_fold), np.std(prec_fold),\n",
    "        np.mean(rec_fold), np.std(rec_fold)\n",
    "    ])\n",
    "\n",
    "        \n",
    "    del model \n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    fold+=1\n",
    "    \n",
    "# Calculando médias gerais\n",
    "acc_total = [m[1] for m in fold_metrics_summary]\n",
    "jacc_total = [m[3] for m in fold_metrics_summary]\n",
    "f1_total = [m[5] for m in fold_metrics_summary]\n",
    "prec_total = [m[7] for m in fold_metrics_summary]\n",
    "rec_total = [m[9] for m in fold_metrics_summary]\n",
    "\n",
    "general_summary = [\n",
    "    [\"Fold\", \"Accuracy Mean\", \"Accuracy Std\", \"Jaccard Mean\", \"Jaccard Std\",\n",
    "     \"DICE Mean\", \"DICE Std\", \"Precision Mean\", \"Precision Std\", \"Recall Mean\", \"Recall Std\"]\n",
    "]\n",
    "\n",
    "general_summary.extend(fold_metrics_summary)\n",
    "\n",
    "general_summary.append([\n",
    "    \"Overall Mean\", np.mean(acc_total), np.std(acc_total),\n",
    "    np.mean(jacc_total), np.std(jacc_total),\n",
    "    np.mean(f1_total), np.std(f1_total),\n",
    "    np.mean(prec_total), np.std(prec_total),\n",
    "    np.mean(rec_total), np.std(rec_total)\n",
    "])\n",
    "\n",
    "# Salvando o resumo das métricas por fold e geral\n",
    "with open(os.path.join(output_dir, 'metrics_summary.csv'), 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=';')\n",
    "    writer.writerows(general_summary)\n",
    "\n",
    "print(\"Métricas salvas com sucesso na pasta:\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5d184f-5b31-4156-849f-d24ddac7c3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_mean_fold = []\n",
    "jacc_mean_fold = []\n",
    "f1_mean_fold = []\n",
    "prec_mean_fold = []\n",
    "rec_mean_fold = []\n",
    "\n",
    "acc_std_fold = []\n",
    "jacc_std_fold = []\n",
    "f1_std_fold = []\n",
    "prec_std_fold = []\n",
    "rec_std_fold = []\n",
    "\n",
    "\n",
    "# Dicionário para armazenar métricas por fold\n",
    "fold_metrics_summary = []\n",
    "\n",
    "fold = 1\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=28)\n",
    "for train_ind, test_ind in tqdm(kf.split(X), total=kf.get_n_splits(), desc=\"k-fold\"):\n",
    "    X_train, X_val, y_train, y_val = X[train_ind], X[test_ind], y[train_ind], y[test_ind]\n",
    "\n",
    "    fold_metrics = []\n",
    "\n",
    "    acc_fold = []\n",
    "    jacc_fold = []\n",
    "    f1_fold = []\n",
    "    prec_fold = []\n",
    "    rec_fold = []\n",
    "    \n",
    "    model_filepath = filepath = os.path.join(output_dir, f'model_{fold}fold.keras')\n",
    "    model = tf.keras.models.load_model(model_filepath)\n",
    "\n",
    "    for i in range(0, len(X_val)):\n",
    "        sample_image = X_val[i]\n",
    "        sample_mask = y_val[i].astype(np.uint8).flatten()\n",
    "        prediction = model.predict(sample_image[tf.newaxis, ...],verbose=0)[0]\n",
    "        predicted_mask = (prediction > 0.5).astype(np.uint8).flatten()\n",
    "            \n",
    "        acc_score = accuracy_score(sample_mask, predicted_mask)\n",
    "        jacc_score = jaccard_score(sample_mask, predicted_mask)\n",
    "        f1_score_val = f1_score(sample_mask, predicted_mask).numpy()\n",
    "        prec_score = precision_score(sample_mask, predicted_mask)\n",
    "        rec_score = recall_score(sample_mask, predicted_mask)\n",
    "\n",
    "        acc_fold.append(acc_score)\n",
    "        jacc_fold.append(jacc_score)\n",
    "        f1_fold.append(f1_score_val)\n",
    "        prec_fold.append(prec_score)\n",
    "        rec_fold.append(rec_score)\n",
    "\n",
    "        fold_metrics.append([i, acc_score, jacc_score, f1_score_val, prec_score, rec_score])\n",
    "        \n",
    "    # Salvando métricas por imagem\n",
    "    with open(os.path.join(output_dir, f'metrics_fold{fold}.csv'), 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=';')\n",
    "        writer.writerow([\"Index\", \"Accuracy\", \"Jaccard\", \"DICE\", \"Precision\", \"Recall\"])\n",
    "        writer.writerows(fold_metrics)\n",
    "\n",
    "    # Salvando a média do fold para cada métrica\n",
    "    fold_metrics_summary.append([\n",
    "        fold, np.mean(acc_fold), np.std(acc_fold),\n",
    "        np.mean(jacc_fold), np.std(jacc_fold),\n",
    "        np.mean(f1_fold), np.std(f1_fold),\n",
    "        np.mean(prec_fold), np.std(prec_fold),\n",
    "        np.mean(rec_fold), np.std(rec_fold)\n",
    "    ])\n",
    "\n",
    "\n",
    "    fold += 1\n",
    "\n",
    "# Calculando médias gerais\n",
    "acc_total = [m[1] for m in fold_metrics_summary]\n",
    "jacc_total = [m[3] for m in fold_metrics_summary]\n",
    "f1_total = [m[5] for m in fold_metrics_summary]\n",
    "prec_total = [m[7] for m in fold_metrics_summary]\n",
    "rec_total = [m[9] for m in fold_metrics_summary]\n",
    "\n",
    "general_summary = [\n",
    "    [\"Fold\", \"Accuracy Mean\", \"Accuracy Std\", \"Jaccard Mean\", \"Jaccard Std\",\n",
    "     \"DICE Mean\", \"DICE Std\", \"Precision Mean\", \"Precision Std\", \"Recall Mean\", \"Recall Std\"]\n",
    "]\n",
    "\n",
    "general_summary.extend(fold_metrics_summary)\n",
    "\n",
    "general_summary.append([\n",
    "    \"Overall Mean\", np.mean(acc_total), np.std(acc_total),\n",
    "    np.mean(jacc_total), np.std(jacc_total),\n",
    "    np.mean(f1_total), np.std(f1_total),\n",
    "    np.mean(prec_total), np.std(prec_total),\n",
    "    np.mean(rec_total), np.std(rec_total)\n",
    "])\n",
    "\n",
    "# Salvando o resumo das métricas por fold e geral\n",
    "with open(os.path.join(output_dir, 'metrics_summary.csv'), 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=';')\n",
    "    writer.writerows(general_summary)\n",
    "\n",
    "print(\"Métricas salvas com sucesso na pasta:\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2544ddf-696d-4ff5-8780-9a498daa8413",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: \"+ str(np.mean(acc_total)*100) + \" +- \" + str(np.std(acc_total)*100))\n",
    "print(\"Jaccard: \"+ str(np.mean(jacc_total)*100) + \" +- \" + str(np.std(jacc_total)*100))\n",
    "print(\"Dice: \"+ str(np.mean(f1_total)*100) + \" +- \" + str(np.std(f1_total)*100))\n",
    "print(\"Precision: \"+ str(np.mean(prec_total)*100) + \" +- \" + str(np.std(prec_total)*100))\n",
    "print(\"Recall: \"+ str(np.mean(rec_total)*100) + \" +- \" + str(np.std(rec_total)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e774436e-ff52-47f8-8dce-d80b378b614b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_fold = 2\n",
    "best_model_filepath = filepath = os.path.join(output_dir, f'model_{best_fold}fold.keras')\n",
    "best_model = tf.keras.models.load_model(best_model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac69b19-a5f7-40f1-b395-d65cd72999d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=k, shuffle=True, random_state=28)\n",
    "for i, (train_ind, test_ind) in enumerate(kf.split(X)):\n",
    "    if i == (best_fold-1):\n",
    "        X_train, X_val, y_train, y_val = X[train_ind], X[test_ind], y[train_ind], y[test_ind]\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6713b66-5fa4-436e-a338-dee9851b3462",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(display_list):\n",
    "  plt.figure(figsize=(15, 15))\n",
    "\n",
    "  title = ['Input image', 'True mask', 'Predicted mask']\n",
    "\n",
    "  for i in range(len(display_list)):\n",
    "    plt.subplot(1, len(display_list), i+1)\n",
    "    plt.title(title[i])\n",
    "    plt.imshow(tf.keras.utils.array_to_img(display_list[i]), cmap='gray')\n",
    "    plt.axis('off')\n",
    "  plt.show()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329d56e2-63cb-4232-b7eb-0a9ed7c6b0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = random.randint(0, len(X_val))\n",
    "sample_image = X_val[i]\n",
    "sample_mask = y_val[i]\n",
    "prediction = best_model.predict(sample_image[tf.newaxis, ...])[0]\n",
    "predicted_mask = (prediction > 0.5).astype(np.uint8)\n",
    "display([sample_image, sample_mask,predicted_mask])\n",
    "\n",
    "sample_mask = y_val[i].astype(np.uint8).flatten()\n",
    "predicted_mask = predicted_mask.flatten()\n",
    "\n",
    "\n",
    "print(\"Accuracy: \"+ str(accuracy_score(sample_mask, predicted_mask)))\n",
    "print(\"Jaccard: \"+ str(jaccard_score(sample_mask, predicted_mask)))\n",
    "print(\"Dice: \"+ str((2*jaccard_score(sample_mask, predicted_mask))/(1+jaccard_score(sample_mask, predicted_mask))))\n",
    "print(\"Precision: \"+ str(precision_score(sample_mask, predicted_mask)))\n",
    "print(\"Recall: \"+ str(recall_score(sample_mask, predicted_mask)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bd9e15-bc6d-4743-ae4b-ce8a3202b64c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
