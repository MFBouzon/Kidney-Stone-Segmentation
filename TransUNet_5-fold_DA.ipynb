{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf0339d0-739a-4991-a2c0-4392d2ec6f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 13:33:13.725835: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-25 13:33:13.725873: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-25 13:33:13.726521: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-25 13:33:13.730393: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-25 13:33:14.448241: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.backend import set_session\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    " \n",
    "from tqdm import tqdm \n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b6f5337-7770-4f92-a2a4-251e31af3cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 1\n",
    "k = 5\n",
    "\n",
    "\n",
    "IMG_WIDTH = 512\n",
    "IMG_HEIGHT = 512\n",
    "IMG_CHANNELS = 1\n",
    "\n",
    "DATA_PATH = 'data/'\n",
    "\n",
    "data_ids = next(os.walk(DATA_PATH+'/image'))[2]\n",
    "\n",
    "X = np.zeros((len(data_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "y = np.zeros((len(data_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.float32)\n",
    "\n",
    "# Definição do diretório de saída\n",
    "output_dir = \"Trans UNet DA DICE 5-fold model\"\n",
    "os.makedirs(output_dir, exist_ok=True)  # Garante que a pasta existe\n",
    "\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "os.environ['TF_GPU_ALLOCATOR']= 'cuda_malloc_async'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6eeed634-f3f7-4cce-8c45-77e4b7c270ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing training images and masks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 838/838 [00:19<00:00, 43.80it/s]\n"
     ]
    }
   ],
   "source": [
    "print('Resizing training images and masks')\n",
    "for n, id_ in tqdm(enumerate(data_ids), total=len(data_ids)):   \n",
    "    path = DATA_PATH\n",
    "    img = imread(path + '/image/' + id_)[:,:]\n",
    "    img = img.reshape(img.shape[0], img.shape[1], IMG_CHANNELS)\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X[n] = img  #Fill empty X_train with values from img\n",
    "    \n",
    "    mask = imread(path + 'label/' + id_)\n",
    "    mask = (mask >= 250)\n",
    "    mask = np.expand_dims(resize(mask, (IMG_HEIGHT, IMG_WIDTH), mode='constant',  \n",
    "                                      preserve_range=True), axis=-1)\n",
    "    y[n] = mask \n",
    "    #plt.axis(\"off\")\n",
    "    #imshow(y[n])\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2f02a06-5551-4109-97af-8d76f83beb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ImageDataGenerator for Data Augmentation\n",
    "data_genX = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=2.5,\n",
    "    width_shift_range=0.075,\n",
    "    height_shift_range=0.075,\n",
    "    shear_range=0.075,\n",
    "    zoom_range=0.075,\n",
    "    horizontal_flip=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e76775c-5fc9-419a-a36a-0bd07fe023ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ImageDataGenerator for Data Augmentation\n",
    "data_genY = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=2.5,\n",
    "    width_shift_range=0.075,\n",
    "    height_shift_range=0.075,\n",
    "    shear_range=0.075,\n",
    "    zoom_range=0.075,\n",
    "    horizontal_flip=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34b9dd1e-626b-4787-b556-426246e4e48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate additional images to equalize classes if necessary\n",
    "def generate(X_all, y_all):\n",
    "\n",
    "# Generation\n",
    "    X_generated = []\n",
    "    y_generated = []\n",
    "    \n",
    "    data_gen.fit(X_all)\n",
    "    \n",
    "    generated_images = data_gen.flow(X_all, y_all, batch_size=1)\n",
    "    \n",
    "    for _ in range(len(X_all)):\n",
    "        X_new, y_new = next(generated_images)\n",
    "        X_generated.append(np.squeeze(X_new))\n",
    "        y_generated.append(np.squeeze(y_new))\n",
    "\n",
    "    print(f'New images generated: {len(X_generated)}')\n",
    "\n",
    "    return X_generated, y_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "386e7353-1711-436b-93c8-9939c699dd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, images_per_figure=100):\n",
    "    num_images = len(images)\n",
    "    cols = 5\n",
    "    rows = (images_per_figure + cols - 1) // cols\n",
    "\n",
    "    for start in range(0, num_images, images_per_figure):\n",
    "        plt.figure(figsize=(cols * 3, rows * 3))\n",
    "        end = min(start + images_per_figure, num_images)\n",
    "\n",
    "        for i in range(start, end):\n",
    "            plt.subplot(rows, cols, i - start + 1)\n",
    "            plt.imshow(images[i])\n",
    "            plt.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c4d4b93-571d-43dd-a33e-2dc384f372c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "def f1_score(y_true, y_pred):\n",
    "    \"\"\"Calcula o F1-Score para segmentação binária\"\"\"\n",
    "    y_pred = K.round(y_pred)  # Arredondar para 0 ou 1\n",
    "    tp = K.sum(K.cast(y_true * y_pred, 'float32'))  # Verdadeiros Positivos\n",
    "    fp = K.sum(K.cast((1 - y_true) * y_pred, 'float32'))  # Falsos Positivos\n",
    "    fn = K.sum(K.cast(y_true * (1 - y_pred), 'float32'))  # Falsos Negativos\n",
    "    \n",
    "    precision = tp / (tp + fp + K.epsilon())  # Precision\n",
    "    recall = tp / (tp + fn + K.epsilon())  # Recall\n",
    "    \n",
    "    f1 = 2 * (precision * recall) / (precision + recall + K.epsilon())  # F1-Score\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e245c43-4d2a-46e4-ab8b-31d91873aa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1e-6\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return 1 - ((2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7f297ed-a66e-4727-b154-b60aa8f7fa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, Dropout, BatchNormalization, ReLU, MaxPooling2D,\n",
    "    Conv2DTranspose, Concatenate, Reshape, Dense, LayerNormalization,\n",
    "    MultiHeadAttention, Input\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_patches, d_model):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        self.pos_emb = self.add_weight(\n",
    "            shape=(1, num_patches, d_model),\n",
    "            initializer='zeros',\n",
    "            trainable=True,\n",
    "            name='positional_embedding'\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_emb\n",
    "\n",
    "def trans_unet():\n",
    "    input_shape =  (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    def conv_block(x, filters, dropout=0.1):\n",
    "        x = Conv2D(filters, (3, 3), activation='relu', \n",
    "                 kernel_initializer='he_normal', padding='same')(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = Conv2D(filters, (3, 3), activation='relu', \n",
    "                 kernel_initializer='he_normal', padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        return ReLU()(x)\n",
    "    \n",
    "    # Encoder (CNN)\n",
    "    c1 = conv_block(inputs, 16)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    \n",
    "    c2 = conv_block(p1, 32)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "    \n",
    "    c3 = conv_block(p2, 64, dropout=0.2)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "    \n",
    "    c4 = conv_block(p3, 128, dropout=0.2)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "    \n",
    "    # Transformer Bottleneck\n",
    "    h = input_shape[0] // 16\n",
    "    w = input_shape[1] // 16\n",
    "    num_patches = h * w\n",
    "    d_model = 256\n",
    "    \n",
    "    x = Reshape((num_patches, 128))(p4)\n",
    "    x = Dense(d_model)(x)\n",
    "    x = PositionalEmbedding(num_patches, d_model)(x)\n",
    "    \n",
    "    # Transformer Encoder\n",
    "    num_heads = 8\n",
    "    for _ in range(4):\n",
    "        x1 = LayerNormalization()(x)\n",
    "        attn = MultiHeadAttention(num_heads=num_heads, key_dim=d_model//num_heads)(x1, x1)\n",
    "        x = attn + x\n",
    "        x2 = LayerNormalization()(x)\n",
    "        mlp = Dense(d_model * 4, activation='gelu')(x2)\n",
    "        mlp = Dense(d_model)(mlp)\n",
    "        x = mlp + x\n",
    "    \n",
    "    x = Reshape((h, w, d_model))(x)\n",
    "    \n",
    "    # Decoder (UNet++ style)\n",
    "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(x)\n",
    "    u6 = Concatenate()([u6, c4])\n",
    "    c6 = conv_block(u6, 128)\n",
    "    \n",
    "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = Concatenate()([u7, c3])\n",
    "    c7 = conv_block(u7, 64)\n",
    "    \n",
    "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = Concatenate()([u8, c2])\n",
    "    c8 = conv_block(u8, 32)\n",
    "    \n",
    "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = Concatenate()([u9, c1])\n",
    "    c9 = conv_block(u9, 16)\n",
    "    \n",
    "    outputs = Conv2D(num_classes, (1, 1), activation='sigmoid')(c9)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss=dice_loss, metrics=[\n",
    "        'accuracy', \n",
    "        tf.keras.metrics.Recall(name='recall'), \n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        f1_score,\n",
    "        tf.keras.metrics.IoU(num_classes=2, target_class_ids={0,1}, name='IoU')\n",
    "    ])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5bb3dc3-8cc2-41d0-bf67-a27f9775446a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 13:33:35.375236: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-25 13:33:35.403728: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-25 13:33:35.403767: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-25 13:33:35.405403: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-25 13:33:35.405432: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-25 13:33:35.405446: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-25 13:33:35.516766: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-25 13:33:35.516822: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-25 13:33:35.516829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-03-25 13:33:35.516841: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2025-03-25 13:33:35.516846: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:236] Using CUDA malloc Async allocator for GPU: 0\n",
      "2025-03-25 13:33:35.517034: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-25 13:33:35.517057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9558 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 13:33:40.622031: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2025-03-25 13:33:41.289028: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2025-03-25 13:33:45.144081: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:306] gpu_async_0 cuMemAllocAsync failed to allocate 1828790272 bytes: CUDA error: out of memory (CUDA_ERROR_OUT_OF_MEMORY)\n",
      " Reported by CUDA: Free memory/Total memory: 1340080128/12878086144\n",
      "2025-03-25 13:33:45.144126: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:311] Stats: Limit:                     10022289408\n",
      "InUse:                      9669073826\n",
      "MaxInUse:                  10491175858\n",
      "NumAllocs:                        1626\n",
      "MaxAllocSize:               2722250752\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2025-03-25 13:33:45.144150: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:63] Histogram of current allocation: (allocation_size_in_bytes, nb_allocation_of_that_sizes), ...;\n",
      "2025-03-25 13:33:45.144153: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1, 22\n",
      "2025-03-25 13:33:45.144155: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 4, 56\n",
      "2025-03-25 13:33:45.144157: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 8, 9\n",
      "2025-03-25 13:33:45.144158: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 16, 2\n",
      "2025-03-25 13:33:45.144159: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 64, 36\n",
      "2025-03-25 13:33:45.144161: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 128, 35\n",
      "2025-03-25 13:33:45.144162: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 256, 35\n",
      "2025-03-25 13:33:45.144163: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 512, 35\n",
      "2025-03-25 13:33:45.144165: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 576, 3\n",
      "2025-03-25 13:33:45.144166: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1024, 111\n",
      "2025-03-25 13:33:45.144168: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1028, 1\n",
      "2025-03-25 13:33:45.144169: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 4096, 12\n",
      "2025-03-25 13:33:45.144170: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 8192, 3\n",
      "2025-03-25 13:33:45.144172: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 9216, 6\n",
      "2025-03-25 13:33:45.144173: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 18432, 7\n",
      "2025-03-25 13:33:45.144174: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 32768, 3\n",
      "2025-03-25 13:33:45.144176: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 36864, 6\n",
      "2025-03-25 13:33:45.144177: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 65536, 24\n",
      "2025-03-25 13:33:45.144178: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 73728, 6\n",
      "2025-03-25 13:33:45.144180: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 131072, 6\n",
      "2025-03-25 13:33:45.144181: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 147456, 6\n",
      "2025-03-25 13:33:45.144182: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 262144, 48\n",
      "2025-03-25 13:33:45.144184: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 294912, 6\n",
      "2025-03-25 13:33:45.144185: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 524288, 3\n",
      "2025-03-25 13:33:45.144186: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 589824, 6\n",
      "2025-03-25 13:33:45.144188: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1048576, 27\n",
      "2025-03-25 13:33:45.144189: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1179648, 3\n",
      "2025-03-25 13:33:45.144190: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 4194304, 2\n",
      "2025-03-25 13:33:45.144192: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 8388608, 3\n",
      "2025-03-25 13:33:45.144193: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 16777216, 48\n",
      "2025-03-25 13:33:45.144195: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 33554432, 11\n",
      "2025-03-25 13:33:45.144196: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 67108864, 27\n",
      "2025-03-25 13:33:45.144198: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 134217728, 9\n",
      "2025-03-25 13:33:45.144199: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 268435456, 7\n",
      "2025-03-25 13:33:45.144200: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 285212672, 1\n",
      "2025-03-25 13:33:45.144201: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 536870912, 6\n",
      "2025-03-25 13:33:45.144205: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:97] CU_MEMPOOL_ATTR_RESERVED_MEM_CURRENT: 10267656192\n",
      "2025-03-25 13:33:45.144207: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:99] CU_MEMPOOL_ATTR_USED_MEM_CURRENT: 9669073826\n",
      "2025-03-25 13:33:45.144208: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:100] CU_MEMPOOL_ATTR_RESERVED_MEM_HIGH: 12113149952\n",
      "2025-03-25 13:33:45.144210: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:101] CU_MEMPOOL_ATTR_USED_MEM_HIGH: 10491175858\n",
      "2025-03-25 13:33:45.746107: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f5677685910 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-03-25 13:33:45.746137: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4070, Compute Capability 8.9\n",
      "2025-03-25 13:33:45.749980: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1742920425.816029  282363 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - ETA: 0s - loss: 1.0589 - accuracy: 0.6695 - recall: 0.9991 - precision: 0.0024 - f1_score: 0.0043 - IoU: 0.4972\n",
      "Epoch 1: val_f1_score improved from -inf to 0.00187, saving model to Trans UNet DA DICE 5-fold model/model_3fold.keras\n",
      "41/41 [==============================] - 64s 699ms/step - loss: 1.0589 - accuracy: 0.6695 - recall: 0.9991 - precision: 0.0024 - f1_score: 0.0043 - IoU: 0.4972 - val_loss: 0.9982 - val_accuracy: 0.3923 - val_recall: 1.0000 - val_precision: 0.0010 - val_f1_score: 0.0019 - val_IoU: 0.2892\n",
      "Epoch 2/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.0589 - accuracy: 0.9405 - recall: 0.9944 - precision: 0.0134 - f1_score: 0.0276 - IoU: 0.5148\n",
      "Epoch 2: val_f1_score improved from 0.00187 to 0.07518, saving model to Trans UNet DA DICE 5-fold model/model_3fold.keras\n",
      "41/41 [==============================] - 40s 490ms/step - loss: 1.0589 - accuracy: 0.9405 - recall: 0.9944 - precision: 0.0134 - f1_score: 0.0276 - IoU: 0.5148 - val_loss: 0.9913 - val_accuracy: 0.9878 - val_recall: 0.8827 - val_precision: 0.0433 - val_f1_score: 0.0752 - val_IoU: 0.5435\n",
      "Epoch 3/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.0570 - accuracy: 0.9815 - recall: 0.9924 - precision: 0.0419 - f1_score: 0.0669 - IoU: 0.5281\n",
      "Epoch 3: val_f1_score did not improve from 0.07518\n",
      "41/41 [==============================] - 20s 479ms/step - loss: 1.0570 - accuracy: 0.9815 - recall: 0.9924 - precision: 0.0419 - f1_score: 0.0669 - IoU: 0.5281 - val_loss: 0.9933 - val_accuracy: 0.9584 - val_recall: 0.9994 - val_precision: 0.0148 - val_f1_score: 0.0263 - val_IoU: 0.5201\n",
      "Epoch 4/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.0550 - accuracy: 0.9876 - recall: 0.9856 - precision: 0.0608 - f1_score: 0.1026 - IoU: 0.5402\n",
      "Epoch 4: val_f1_score improved from 0.07518 to 0.33743, saving model to Trans UNet DA DICE 5-fold model/model_3fold.keras\n",
      "41/41 [==============================] - 20s 488ms/step - loss: 1.0550 - accuracy: 0.9876 - recall: 0.9856 - precision: 0.0608 - f1_score: 0.1026 - IoU: 0.5402 - val_loss: 0.9905 - val_accuracy: 0.9989 - val_recall: 0.4277 - val_precision: 0.2567 - val_f1_score: 0.3374 - val_IoU: 0.5550\n",
      "Epoch 5/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.0532 - accuracy: 0.9926 - recall: 0.9818 - precision: 0.1009 - f1_score: 0.1590 - IoU: 0.5630\n",
      "Epoch 5: val_f1_score did not improve from 0.33743\n",
      "41/41 [==============================] - 20s 478ms/step - loss: 1.0532 - accuracy: 0.9926 - recall: 0.9818 - precision: 0.1009 - f1_score: 0.1590 - IoU: 0.5630 - val_loss: 0.9910 - val_accuracy: 0.9759 - val_recall: 0.7464 - val_precision: 0.0191 - val_f1_score: 0.0368 - val_IoU: 0.5117\n",
      "Epoch 6/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.0478 - accuracy: 0.9950 - recall: 0.9758 - precision: 0.1415 - f1_score: 0.2152 - IoU: 0.5755\n",
      "Epoch 6: val_f1_score did not improve from 0.33743\n",
      "41/41 [==============================] - 20s 478ms/step - loss: 1.0478 - accuracy: 0.9950 - recall: 0.9758 - precision: 0.1415 - f1_score: 0.2152 - IoU: 0.5755 - val_loss: 0.9886 - val_accuracy: 0.9864 - val_recall: 0.9949 - val_precision: 0.0437 - val_f1_score: 0.0760 - val_IoU: 0.5448\n",
      "Epoch 7/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.0385 - accuracy: 0.9947 - recall: 0.9322 - precision: 0.1338 - f1_score: 0.2133 - IoU: 0.5708\n",
      "Epoch 7: val_f1_score did not improve from 0.33743\n",
      "41/41 [==============================] - 20s 479ms/step - loss: 1.0385 - accuracy: 0.9947 - recall: 0.9322 - precision: 0.1338 - f1_score: 0.2133 - IoU: 0.5708 - val_loss: 0.9980 - val_accuracy: 0.9884 - val_recall: 0.0090 - val_precision: 5.1236e-04 - val_f1_score: 0.0014 - val_IoU: 0.4998\n",
      "Epoch 8/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.0031 - accuracy: 0.9971 - recall: 0.9234 - precision: 0.2182 - f1_score: 0.3428 - IoU: 0.6021\n",
      "Epoch 8: val_f1_score did not improve from 0.33743\n",
      "41/41 [==============================] - 20s 478ms/step - loss: 1.0031 - accuracy: 0.9971 - recall: 0.9234 - precision: 0.2182 - f1_score: 0.3428 - IoU: 0.6021 - val_loss: 0.9958 - val_accuracy: 0.9989 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_IoU: 0.4997\n",
      "Epoch 9/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.9030 - accuracy: 0.9988 - recall: 0.8784 - precision: 0.4500 - f1_score: 0.5447 - IoU: 0.6835\n",
      "Epoch 9: val_f1_score did not improve from 0.33743\n",
      "41/41 [==============================] - 20s 478ms/step - loss: 0.9030 - accuracy: 0.9988 - recall: 0.8784 - precision: 0.4500 - f1_score: 0.5447 - IoU: 0.6835 - val_loss: 1.0000 - val_accuracy: 0.9994 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_IoU: 0.4997\n",
      "Epoch 10/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.7196 - accuracy: 0.9991 - recall: 0.7880 - precision: 0.5532 - f1_score: 0.6167 - IoU: 0.7096\n",
      "Epoch 10: val_f1_score did not improve from 0.33743\n",
      "41/41 [==============================] - 20s 479ms/step - loss: 0.7196 - accuracy: 0.9991 - recall: 0.7880 - precision: 0.5532 - f1_score: 0.6167 - IoU: 0.7096 - val_loss: 0.9999 - val_accuracy: 0.9994 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_IoU: 0.4997\n",
      "Epoch 11/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.4233 - accuracy: 0.9995 - recall: 0.7461 - precision: 0.8163 - f1_score: 0.7738 - IoU: 0.8062\n",
      "Epoch 11: val_f1_score did not improve from 0.33743\n",
      "41/41 [==============================] - 20s 479ms/step - loss: 0.4233 - accuracy: 0.9995 - recall: 0.7461 - precision: 0.8163 - f1_score: 0.7738 - IoU: 0.8062 - val_loss: 1.0000 - val_accuracy: 0.9994 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_IoU: 0.4997\n",
      "Epoch 12/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.3091 - accuracy: 0.9995 - recall: 0.7143 - precision: 0.8350 - f1_score: 0.7873 - IoU: 0.8088\n",
      "Epoch 12: val_f1_score did not improve from 0.33743\n",
      "41/41 [==============================] - 20s 480ms/step - loss: 0.3091 - accuracy: 0.9995 - recall: 0.7143 - precision: 0.8350 - f1_score: 0.7873 - IoU: 0.8088 - val_loss: 1.0000 - val_accuracy: 0.9994 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_IoU: 0.4997\n",
      "Epoch 13/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.2649 - accuracy: 0.9995 - recall: 0.7072 - precision: 0.8591 - f1_score: 0.7949 - IoU: 0.8240\n",
      "Epoch 13: val_f1_score did not improve from 0.33743\n",
      "41/41 [==============================] - 20s 481ms/step - loss: 0.2649 - accuracy: 0.9995 - recall: 0.7072 - precision: 0.8591 - f1_score: 0.7949 - IoU: 0.8240 - val_loss: 0.9472 - val_accuracy: 0.9994 - val_recall: 0.1143 - val_precision: 0.9915 - val_f1_score: 0.1581 - val_IoU: 0.5281\n",
      "Epoch 14/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.2157 - accuracy: 0.9996 - recall: 0.7243 - precision: 0.9026 - f1_score: 0.8292 - IoU: 0.8399\n",
      "Epoch 14: val_f1_score improved from 0.33743 to 0.33922, saving model to Trans UNet DA DICE 5-fold model/model_3fold.keras\n",
      "41/41 [==============================] - 20s 490ms/step - loss: 0.2157 - accuracy: 0.9996 - recall: 0.7243 - precision: 0.9026 - f1_score: 0.8292 - IoU: 0.8399 - val_loss: 0.8600 - val_accuracy: 0.9995 - val_recall: 0.2072 - val_precision: 0.9899 - val_f1_score: 0.3392 - val_IoU: 0.5642\n",
      "Epoch 15/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1779 - accuracy: 0.9996 - recall: 0.7485 - precision: 0.9219 - f1_score: 0.8582 - IoU: 0.8637\n",
      "Epoch 15: val_f1_score did not improve from 0.33922\n",
      "41/41 [==============================] - 20s 479ms/step - loss: 0.1779 - accuracy: 0.9996 - recall: 0.7485 - precision: 0.9219 - f1_score: 0.8582 - IoU: 0.8637 - val_loss: 0.9882 - val_accuracy: 0.9994 - val_recall: 0.0121 - val_precision: 1.0000 - val_f1_score: 0.0137 - val_IoU: 0.5024\n",
      "Epoch 16/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1553 - accuracy: 0.9996 - recall: 0.7584 - precision: 0.9432 - f1_score: 0.8734 - IoU: 0.8743\n",
      "Epoch 16: val_f1_score improved from 0.33922 to 0.58786, saving model to Trans UNet DA DICE 5-fold model/model_3fold.keras\n",
      "41/41 [==============================] - 20s 490ms/step - loss: 0.1553 - accuracy: 0.9996 - recall: 0.7584 - precision: 0.9432 - f1_score: 0.8734 - IoU: 0.8743 - val_loss: 0.5636 - val_accuracy: 0.9997 - val_recall: 0.4908 - val_precision: 0.9868 - val_f1_score: 0.5879 - val_IoU: 0.6932\n",
      "Epoch 17/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1498 - accuracy: 0.9996 - recall: 0.7476 - precision: 0.9514 - f1_score: 0.8748 - IoU: 0.8691\n",
      "Epoch 17: val_f1_score improved from 0.58786 to 0.90729, saving model to Trans UNet DA DICE 5-fold model/model_3fold.keras\n",
      "41/41 [==============================] - 20s 489ms/step - loss: 0.1498 - accuracy: 0.9996 - recall: 0.7476 - precision: 0.9514 - f1_score: 0.8748 - IoU: 0.8691 - val_loss: 0.2899 - val_accuracy: 0.9999 - val_recall: 0.8624 - val_precision: 0.9882 - val_f1_score: 0.9073 - val_IoU: 0.8755\n",
      "Epoch 18/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1411 - accuracy: 0.9996 - recall: 0.7476 - precision: 0.9639 - f1_score: 0.8802 - IoU: 0.8760\n",
      "Epoch 18: val_f1_score did not improve from 0.90729\n",
      "41/41 [==============================] - 20s 478ms/step - loss: 0.1411 - accuracy: 0.9996 - recall: 0.7476 - precision: 0.9639 - f1_score: 0.8802 - IoU: 0.8760 - val_loss: 0.2642 - val_accuracy: 0.9999 - val_recall: 0.9343 - val_precision: 0.8534 - val_f1_score: 0.8356 - val_IoU: 0.8989\n",
      "Epoch 19/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1334 - accuracy: 0.9996 - recall: 0.7679 - precision: 0.9609 - f1_score: 0.8858 - IoU: 0.8785\n",
      "Epoch 19: val_f1_score improved from 0.90729 to 0.90796, saving model to Trans UNet DA DICE 5-fold model/model_3fold.keras\n",
      "41/41 [==============================] - 20s 489ms/step - loss: 0.1334 - accuracy: 0.9996 - recall: 0.7679 - precision: 0.9609 - f1_score: 0.8858 - IoU: 0.8785 - val_loss: 0.1738 - val_accuracy: 0.9999 - val_recall: 0.9262 - val_precision: 0.9424 - val_f1_score: 0.9080 - val_IoU: 0.9171\n",
      "Epoch 20/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.2730 - accuracy: 0.9994 - recall: 0.6867 - precision: 0.7740 - f1_score: 0.7517 - IoU: 0.7943\n",
      "Epoch 20: val_f1_score did not improve from 0.90796\n",
      "41/41 [==============================] - 20s 478ms/step - loss: 0.2730 - accuracy: 0.9994 - recall: 0.6867 - precision: 0.7740 - f1_score: 0.7517 - IoU: 0.7943 - val_loss: 0.8265 - val_accuracy: 0.9983 - val_recall: 0.3733 - val_precision: 0.1551 - val_f1_score: 0.1579 - val_IoU: 0.5629\n",
      "Epoch 21/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.4355 - accuracy: 0.9993 - recall: 0.5349 - precision: 0.6422 - f1_score: 0.5996 - IoU: 0.7110\n",
      "Epoch 21: val_f1_score did not improve from 0.90796\n",
      "41/41 [==============================] - 20s 478ms/step - loss: 0.4355 - accuracy: 0.9993 - recall: 0.5349 - precision: 0.6422 - f1_score: 0.5996 - IoU: 0.7110 - val_loss: 0.9998 - val_accuracy: 0.9994 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_IoU: 0.4997\n",
      "Epoch 22/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.5079 - accuracy: 0.9992 - recall: 0.4716 - precision: 0.5880 - f1_score: 0.5273 - IoU: 0.6658\n",
      "Epoch 22: val_f1_score did not improve from 0.90796\n",
      "41/41 [==============================] - 20s 480ms/step - loss: 0.5079 - accuracy: 0.9992 - recall: 0.4716 - precision: 0.5880 - f1_score: 0.5273 - IoU: 0.6658 - val_loss: 0.8825 - val_accuracy: 0.9994 - val_recall: 0.0599 - val_precision: 0.9024 - val_f1_score: 0.1800 - val_IoU: 0.5176\n",
      "Epoch 23/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.4088 - accuracy: 0.9993 - recall: 0.5451 - precision: 0.6817 - f1_score: 0.6217 - IoU: 0.7139\n",
      "Epoch 23: val_f1_score did not improve from 0.90796\n",
      "41/41 [==============================] - 20s 479ms/step - loss: 0.4088 - accuracy: 0.9993 - recall: 0.5451 - precision: 0.6817 - f1_score: 0.6217 - IoU: 0.7139 - val_loss: 0.7526 - val_accuracy: 0.9994 - val_recall: 0.1569 - val_precision: 0.7253 - val_f1_score: 0.2913 - val_IoU: 0.5545\n",
      "Epoch 24/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.4715 - accuracy: 0.9992 - recall: 0.4996 - precision: 0.6211 - f1_score: 0.5616 - IoU: 0.6849\n",
      "Epoch 24: val_f1_score did not improve from 0.90796\n",
      "41/41 [==============================] - 20s 479ms/step - loss: 0.4715 - accuracy: 0.9992 - recall: 0.4996 - precision: 0.6211 - f1_score: 0.5616 - IoU: 0.6849 - val_loss: 0.9970 - val_accuracy: 0.9994 - val_recall: 0.0012 - val_precision: 1.0000 - val_f1_score: 0.0028 - val_IoU: 0.4997\n",
      "Epoch 25/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.4131 - accuracy: 0.9993 - recall: 0.5694 - precision: 0.6260 - f1_score: 0.6172 - IoU: 0.7116\n",
      "Epoch 25: val_f1_score did not improve from 0.90796\n",
      "41/41 [==============================] - 20s 480ms/step - loss: 0.4131 - accuracy: 0.9993 - recall: 0.5694 - precision: 0.6260 - f1_score: 0.6172 - IoU: 0.7116 - val_loss: 0.9978 - val_accuracy: 0.9994 - val_recall: 5.4599e-04 - val_precision: 1.0000 - val_f1_score: 0.0020 - val_IoU: 0.4997\n",
      "Epoch 26/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.2641 - accuracy: 0.9995 - recall: 0.6479 - precision: 0.8315 - f1_score: 0.7567 - IoU: 0.7890\n",
      "Epoch 26: val_f1_score did not improve from 0.90796\n",
      "41/41 [==============================] - 20s 480ms/step - loss: 0.2641 - accuracy: 0.9995 - recall: 0.6479 - precision: 0.8315 - f1_score: 0.7567 - IoU: 0.7890 - val_loss: 0.9591 - val_accuracy: 0.9994 - val_recall: 0.0148 - val_precision: 0.9951 - val_f1_score: 0.0384 - val_IoU: 0.5034\n",
      "Epoch 27/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.2599 - accuracy: 0.9995 - recall: 0.6496 - precision: 0.8445 - f1_score: 0.7596 - IoU: 0.7961\n",
      "Epoch 27: val_f1_score did not improve from 0.90796\n",
      "41/41 [==============================] - 20s 479ms/step - loss: 0.2599 - accuracy: 0.9995 - recall: 0.6496 - precision: 0.8445 - f1_score: 0.7596 - IoU: 0.7961 - val_loss: 0.8212 - val_accuracy: 0.9994 - val_recall: 0.0789 - val_precision: 0.9696 - val_f1_score: 0.2256 - val_IoU: 0.5200\n",
      "Epoch 28/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.2278 - accuracy: 0.9995 - recall: 0.6698 - precision: 0.8808 - f1_score: 0.7905 - IoU: 0.8130\n",
      "Epoch 28: val_f1_score did not improve from 0.90796\n",
      "41/41 [==============================] - 20s 479ms/step - loss: 0.2278 - accuracy: 0.9995 - recall: 0.6698 - precision: 0.8808 - f1_score: 0.7905 - IoU: 0.8130 - val_loss: 0.1885 - val_accuracy: 0.9998 - val_recall: 0.7135 - val_precision: 0.9405 - val_f1_score: 0.8169 - val_IoU: 0.7856\n",
      "Epoch 29/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.2153 - accuracy: 0.9995 - recall: 0.6865 - precision: 0.8785 - f1_score: 0.8018 - IoU: 0.8224\n",
      "Epoch 29: val_f1_score did not improve from 0.90796\n",
      "41/41 [==============================] - 20s 481ms/step - loss: 0.2153 - accuracy: 0.9995 - recall: 0.6865 - precision: 0.8785 - f1_score: 0.8018 - IoU: 0.8224 - val_loss: 0.1355 - val_accuracy: 0.9999 - val_recall: 0.9124 - val_precision: 0.8836 - val_f1_score: 0.8693 - val_IoU: 0.9039\n",
      "Epoch 30/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.2276 - accuracy: 0.9995 - recall: 0.6627 - precision: 0.8804 - f1_score: 0.7894 - IoU: 0.8104\n",
      "Epoch 30: val_f1_score did not improve from 0.90796\n",
      "41/41 [==============================] - 20s 483ms/step - loss: 0.2276 - accuracy: 0.9995 - recall: 0.6627 - precision: 0.8804 - f1_score: 0.7894 - IoU: 0.8104 - val_loss: 0.1598 - val_accuracy: 0.9999 - val_recall: 0.8400 - val_precision: 0.9352 - val_f1_score: 0.8521 - val_IoU: 0.8760\n",
      "Epoch 31/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.2412 - accuracy: 0.9995 - recall: 0.6746 - precision: 0.8540 - f1_score: 0.7763 - IoU: 0.8065\n",
      "Epoch 31: val_f1_score did not improve from 0.90796\n",
      "41/41 [==============================] - 20s 484ms/step - loss: 0.2412 - accuracy: 0.9995 - recall: 0.6746 - precision: 0.8540 - f1_score: 0.7763 - IoU: 0.8065 - val_loss: 0.5458 - val_accuracy: 0.9996 - val_recall: 0.3561 - val_precision: 0.9706 - val_f1_score: 0.4748 - val_IoU: 0.6475\n",
      "Epoch 32/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.2456 - accuracy: 0.9995 - recall: 0.6691 - precision: 0.8378 - f1_score: 0.7715 - IoU: 0.8064\n",
      "Epoch 32: val_f1_score did not improve from 0.90796\n",
      "41/41 [==============================] - 20s 483ms/step - loss: 0.2456 - accuracy: 0.9995 - recall: 0.6691 - precision: 0.8378 - f1_score: 0.7715 - IoU: 0.8064 - val_loss: 0.1607 - val_accuracy: 0.9998 - val_recall: 0.7911 - val_precision: 0.8797 - val_f1_score: 0.8586 - val_IoU: 0.8300\n",
      "Epoch 33/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1889 - accuracy: 0.9996 - recall: 0.7083 - precision: 0.8956 - f1_score: 0.8252 - IoU: 0.8338\n",
      "Epoch 33: val_f1_score did not improve from 0.90796\n",
      "41/41 [==============================] - 20s 486ms/step - loss: 0.1889 - accuracy: 0.9996 - recall: 0.7083 - precision: 0.8956 - f1_score: 0.8252 - IoU: 0.8338 - val_loss: 0.2895 - val_accuracy: 0.9997 - val_recall: 0.5365 - val_precision: 0.9418 - val_f1_score: 0.7410 - val_IoU: 0.7282\n",
      "Epoch 34/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1979 - accuracy: 0.9996 - recall: 0.6904 - precision: 0.9086 - f1_score: 0.8170 - IoU: 0.8318\n",
      "Epoch 34: val_f1_score improved from 0.90796 to 0.92129, saving model to Trans UNet DA DICE 5-fold model/model_3fold.keras\n",
      "41/41 [==============================] - 20s 497ms/step - loss: 0.1979 - accuracy: 0.9996 - recall: 0.6904 - precision: 0.9086 - f1_score: 0.8170 - IoU: 0.8318 - val_loss: 0.0872 - val_accuracy: 0.9999 - val_recall: 0.9046 - val_precision: 0.9558 - val_f1_score: 0.9213 - val_IoU: 0.9083\n",
      "Epoch 35/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1710 - accuracy: 0.9996 - recall: 0.7189 - precision: 0.9121 - f1_score: 0.8418 - IoU: 0.8441\n",
      "Epoch 35: val_f1_score did not improve from 0.92129\n",
      "41/41 [==============================] - 20s 486ms/step - loss: 0.1710 - accuracy: 0.9996 - recall: 0.7189 - precision: 0.9121 - f1_score: 0.8418 - IoU: 0.8441 - val_loss: 0.1859 - val_accuracy: 0.9998 - val_recall: 0.7331 - val_precision: 0.9743 - val_f1_score: 0.8226 - val_IoU: 0.8197\n",
      "Epoch 36/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1703 - accuracy: 0.9996 - recall: 0.7285 - precision: 0.9187 - f1_score: 0.8422 - IoU: 0.8466\n",
      "Epoch 36: val_f1_score did not improve from 0.92129\n",
      "41/41 [==============================] - 20s 485ms/step - loss: 0.1703 - accuracy: 0.9996 - recall: 0.7285 - precision: 0.9187 - f1_score: 0.8422 - IoU: 0.8466 - val_loss: 0.3050 - val_accuracy: 0.9998 - val_recall: 0.6307 - val_precision: 0.9751 - val_f1_score: 0.6943 - val_IoU: 0.7718\n",
      "Epoch 37/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1518 - accuracy: 0.9996 - recall: 0.7483 - precision: 0.9217 - f1_score: 0.8595 - IoU: 0.8597\n",
      "Epoch 37: val_f1_score did not improve from 0.92129\n",
      "41/41 [==============================] - 20s 485ms/step - loss: 0.1518 - accuracy: 0.9996 - recall: 0.7483 - precision: 0.9217 - f1_score: 0.8595 - IoU: 0.8597 - val_loss: 0.2980 - val_accuracy: 0.9997 - val_recall: 0.5484 - val_precision: 0.9776 - val_f1_score: 0.7225 - val_IoU: 0.7086\n",
      "Epoch 38/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1447 - accuracy: 0.9996 - recall: 0.7396 - precision: 0.9381 - f1_score: 0.8662 - IoU: 0.8601\n",
      "Epoch 38: val_f1_score did not improve from 0.92129\n",
      "41/41 [==============================] - 20s 488ms/step - loss: 0.1447 - accuracy: 0.9996 - recall: 0.7396 - precision: 0.9381 - f1_score: 0.8662 - IoU: 0.8601 - val_loss: 0.0950 - val_accuracy: 0.9999 - val_recall: 0.8764 - val_precision: 0.9742 - val_f1_score: 0.9146 - val_IoU: 0.8874\n",
      "Epoch 39/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1379 - accuracy: 0.9996 - recall: 0.7507 - precision: 0.9378 - f1_score: 0.8725 - IoU: 0.8657\n",
      "Epoch 39: val_f1_score did not improve from 0.92129\n",
      "41/41 [==============================] - 20s 485ms/step - loss: 0.1379 - accuracy: 0.9996 - recall: 0.7507 - precision: 0.9378 - f1_score: 0.8725 - IoU: 0.8657 - val_loss: 0.0953 - val_accuracy: 0.9999 - val_recall: 0.8859 - val_precision: 0.9617 - val_f1_score: 0.9172 - val_IoU: 0.8866\n",
      "Epoch 40/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1466 - accuracy: 0.9996 - recall: 0.7447 - precision: 0.9405 - f1_score: 0.8638 - IoU: 0.8558\n",
      "Epoch 40: val_f1_score improved from 0.92129 to 0.94680, saving model to Trans UNet DA DICE 5-fold model/model_3fold.keras\n",
      "41/41 [==============================] - 20s 499ms/step - loss: 0.1466 - accuracy: 0.9996 - recall: 0.7447 - precision: 0.9405 - f1_score: 0.8638 - IoU: 0.8558 - val_loss: 0.0583 - val_accuracy: 0.9999 - val_recall: 0.9330 - val_precision: 0.9510 - val_f1_score: 0.9468 - val_IoU: 0.9190\n",
      "Epoch 41/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1408 - accuracy: 0.9996 - recall: 0.7495 - precision: 0.9303 - f1_score: 0.8695 - IoU: 0.8654\n",
      "Epoch 41: val_f1_score did not improve from 0.94680\n",
      "41/41 [==============================] - 20s 489ms/step - loss: 0.1408 - accuracy: 0.9996 - recall: 0.7495 - precision: 0.9303 - f1_score: 0.8695 - IoU: 0.8654 - val_loss: 0.1108 - val_accuracy: 0.9999 - val_recall: 0.8078 - val_precision: 0.9762 - val_f1_score: 0.9024 - val_IoU: 0.8498\n",
      "Epoch 42/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1308 - accuracy: 0.9996 - recall: 0.7507 - precision: 0.9510 - f1_score: 0.8786 - IoU: 0.8720\n",
      "Epoch 42: val_f1_score did not improve from 0.94680\n",
      "41/41 [==============================] - 20s 488ms/step - loss: 0.1308 - accuracy: 0.9996 - recall: 0.7507 - precision: 0.9510 - f1_score: 0.8786 - IoU: 0.8720 - val_loss: 0.0809 - val_accuracy: 0.9999 - val_recall: 0.9329 - val_precision: 0.9262 - val_f1_score: 0.9202 - val_IoU: 0.9297\n",
      "Epoch 43/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1410 - accuracy: 0.9996 - recall: 0.7450 - precision: 0.9377 - f1_score: 0.8689 - IoU: 0.8639\n",
      "Epoch 43: val_f1_score did not improve from 0.94680\n",
      "41/41 [==============================] - 20s 491ms/step - loss: 0.1410 - accuracy: 0.9996 - recall: 0.7450 - precision: 0.9377 - f1_score: 0.8689 - IoU: 0.8639 - val_loss: 0.1155 - val_accuracy: 0.9999 - val_recall: 0.8484 - val_precision: 0.9649 - val_f1_score: 0.8952 - val_IoU: 0.8716\n",
      "Epoch 44/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1327 - accuracy: 0.9996 - recall: 0.7549 - precision: 0.9525 - f1_score: 0.8763 - IoU: 0.8702\n",
      "Epoch 44: val_f1_score did not improve from 0.94680\n",
      "41/41 [==============================] - 20s 491ms/step - loss: 0.1327 - accuracy: 0.9996 - recall: 0.7549 - precision: 0.9525 - f1_score: 0.8763 - IoU: 0.8702 - val_loss: 0.0681 - val_accuracy: 0.9999 - val_recall: 0.9405 - val_precision: 0.9444 - val_f1_score: 0.9340 - val_IoU: 0.9321\n",
      "Epoch 45/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1427 - accuracy: 0.9996 - recall: 0.7324 - precision: 0.9507 - f1_score: 0.8675 - IoU: 0.8624\n",
      "Epoch 45: val_f1_score did not improve from 0.94680\n",
      "41/41 [==============================] - 20s 487ms/step - loss: 0.1427 - accuracy: 0.9996 - recall: 0.7324 - precision: 0.9507 - f1_score: 0.8675 - IoU: 0.8624 - val_loss: 0.1276 - val_accuracy: 0.9998 - val_recall: 0.7671 - val_precision: 0.9718 - val_f1_score: 0.8836 - val_IoU: 0.8155\n",
      "Epoch 46/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1467 - accuracy: 0.9996 - recall: 0.7554 - precision: 0.9318 - f1_score: 0.8630 - IoU: 0.8635\n",
      "Epoch 46: val_f1_score improved from 0.94680 to 0.95499, saving model to Trans UNet DA DICE 5-fold model/model_3fold.keras\n",
      "41/41 [==============================] - 20s 496ms/step - loss: 0.1467 - accuracy: 0.9996 - recall: 0.7554 - precision: 0.9318 - f1_score: 0.8630 - IoU: 0.8635 - val_loss: 0.0585 - val_accuracy: 0.9999 - val_recall: 0.9360 - val_precision: 0.9704 - val_f1_score: 0.9550 - val_IoU: 0.9318\n",
      "Epoch 47/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1197 - accuracy: 0.9996 - recall: 0.7620 - precision: 0.9559 - f1_score: 0.8888 - IoU: 0.8784\n",
      "Epoch 47: val_f1_score did not improve from 0.95499\n",
      "41/41 [==============================] - 20s 488ms/step - loss: 0.1197 - accuracy: 0.9996 - recall: 0.7620 - precision: 0.9559 - f1_score: 0.8888 - IoU: 0.8784 - val_loss: 0.1533 - val_accuracy: 0.9998 - val_recall: 0.7002 - val_precision: 0.9819 - val_f1_score: 0.8672 - val_IoU: 0.7869\n",
      "Epoch 48/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1267 - accuracy: 0.9996 - recall: 0.7620 - precision: 0.9482 - f1_score: 0.8821 - IoU: 0.8745\n",
      "Epoch 48: val_f1_score did not improve from 0.95499\n",
      "41/41 [==============================] - 21s 511ms/step - loss: 0.1267 - accuracy: 0.9996 - recall: 0.7620 - precision: 0.9482 - f1_score: 0.8821 - IoU: 0.8745 - val_loss: 0.0769 - val_accuracy: 0.9999 - val_recall: 0.9706 - val_precision: 0.9085 - val_f1_score: 0.9137 - val_IoU: 0.9438\n",
      "Epoch 49/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1230 - accuracy: 0.9996 - recall: 0.7584 - precision: 0.9584 - f1_score: 0.8853 - IoU: 0.8733\n",
      "Epoch 49: val_f1_score did not improve from 0.95499\n",
      "41/41 [==============================] - 22s 527ms/step - loss: 0.1230 - accuracy: 0.9996 - recall: 0.7584 - precision: 0.9584 - f1_score: 0.8853 - IoU: 0.8733 - val_loss: 0.0538 - val_accuracy: 0.9999 - val_recall: 0.9764 - val_precision: 0.9216 - val_f1_score: 0.9455 - val_IoU: 0.9562\n",
      "Epoch 50/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1161 - accuracy: 0.9996 - recall: 0.7681 - precision: 0.9641 - f1_score: 0.8918 - IoU: 0.8844\n",
      "Epoch 50: val_f1_score did not improve from 0.95499\n",
      "41/41 [==============================] - 22s 527ms/step - loss: 0.1161 - accuracy: 0.9996 - recall: 0.7681 - precision: 0.9641 - f1_score: 0.8918 - IoU: 0.8844 - val_loss: 0.0593 - val_accuracy: 0.9999 - val_recall: 0.9517 - val_precision: 0.9443 - val_f1_score: 0.9403 - val_IoU: 0.9432\n",
      "Epoch 51/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1146 - accuracy: 0.9997 - recall: 0.7710 - precision: 0.9570 - f1_score: 0.8931 - IoU: 0.8801\n",
      "Epoch 51: val_f1_score did not improve from 0.95499\n",
      "41/41 [==============================] - 20s 484ms/step - loss: 0.1146 - accuracy: 0.9997 - recall: 0.7710 - precision: 0.9570 - f1_score: 0.8931 - IoU: 0.8801 - val_loss: 0.0691 - val_accuracy: 0.9999 - val_recall: 0.8939 - val_precision: 0.9782 - val_f1_score: 0.9388 - val_IoU: 0.9055\n",
      "Epoch 52/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1074 - accuracy: 0.9996 - recall: 0.7631 - precision: 0.9749 - f1_score: 0.8999 - IoU: 0.8867\n",
      "Epoch 52: val_f1_score did not improve from 0.95499\n",
      "41/41 [==============================] - 20s 485ms/step - loss: 0.1074 - accuracy: 0.9996 - recall: 0.7631 - precision: 0.9749 - f1_score: 0.8999 - IoU: 0.8867 - val_loss: 0.0562 - val_accuracy: 0.9999 - val_recall: 0.9211 - val_precision: 0.9777 - val_f1_score: 0.9489 - val_IoU: 0.9235\n",
      "Epoch 53/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1131 - accuracy: 0.9997 - recall: 0.7757 - precision: 0.9644 - f1_score: 0.8938 - IoU: 0.8827\n",
      "Epoch 53: val_f1_score did not improve from 0.95499\n",
      "41/41 [==============================] - 20s 485ms/step - loss: 0.1131 - accuracy: 0.9997 - recall: 0.7757 - precision: 0.9644 - f1_score: 0.8938 - IoU: 0.8827 - val_loss: 0.0496 - val_accuracy: 0.9999 - val_recall: 0.9798 - val_precision: 0.9304 - val_f1_score: 0.9489 - val_IoU: 0.9595\n",
      "Epoch 54/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1223 - accuracy: 0.9996 - recall: 0.7577 - precision: 0.9606 - f1_score: 0.8859 - IoU: 0.8711\n",
      "Epoch 54: val_f1_score did not improve from 0.95499\n",
      "41/41 [==============================] - 20s 484ms/step - loss: 0.1223 - accuracy: 0.9996 - recall: 0.7577 - precision: 0.9606 - f1_score: 0.8859 - IoU: 0.8711 - val_loss: 0.0694 - val_accuracy: 0.9999 - val_recall: 0.8762 - val_precision: 0.9776 - val_f1_score: 0.9367 - val_IoU: 0.8999\n",
      "Epoch 55/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1183 - accuracy: 0.9996 - recall: 0.7590 - precision: 0.9616 - f1_score: 0.8895 - IoU: 0.8775\n",
      "Epoch 55: val_f1_score did not improve from 0.95499\n",
      "41/41 [==============================] - 20s 485ms/step - loss: 0.1183 - accuracy: 0.9996 - recall: 0.7590 - precision: 0.9616 - f1_score: 0.8895 - IoU: 0.8775 - val_loss: 0.0598 - val_accuracy: 0.9999 - val_recall: 0.9501 - val_precision: 0.9481 - val_f1_score: 0.9428 - val_IoU: 0.9375\n",
      "Epoch 56/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1400 - accuracy: 0.9996 - recall: 0.7363 - precision: 0.9376 - f1_score: 0.8688 - IoU: 0.8654\n",
      "Epoch 56: val_f1_score did not improve from 0.95499\n",
      "41/41 [==============================] - 20s 485ms/step - loss: 0.1400 - accuracy: 0.9996 - recall: 0.7363 - precision: 0.9376 - f1_score: 0.8688 - IoU: 0.8654 - val_loss: 0.2532 - val_accuracy: 0.9997 - val_recall: 0.6039 - val_precision: 0.9721 - val_f1_score: 0.7709 - val_IoU: 0.7634\n",
      "Epoch 57/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1415 - accuracy: 0.9996 - recall: 0.7374 - precision: 0.9532 - f1_score: 0.8678 - IoU: 0.8620\n",
      "Epoch 57: val_f1_score did not improve from 0.95499\n",
      "41/41 [==============================] - 20s 484ms/step - loss: 0.1415 - accuracy: 0.9996 - recall: 0.7374 - precision: 0.9532 - f1_score: 0.8678 - IoU: 0.8620 - val_loss: 0.0806 - val_accuracy: 0.9999 - val_recall: 0.9105 - val_precision: 0.9674 - val_f1_score: 0.9246 - val_IoU: 0.9216\n",
      "Epoch 58/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1084 - accuracy: 0.9996 - recall: 0.7672 - precision: 0.9690 - f1_score: 0.8988 - IoU: 0.8860\n",
      "Epoch 58: val_f1_score did not improve from 0.95499\n",
      "41/41 [==============================] - 20s 484ms/step - loss: 0.1084 - accuracy: 0.9996 - recall: 0.7672 - precision: 0.9690 - f1_score: 0.8988 - IoU: 0.8860 - val_loss: 0.1095 - val_accuracy: 0.9999 - val_recall: 0.7982 - val_precision: 0.9827 - val_f1_score: 0.8979 - val_IoU: 0.8588\n",
      "Epoch 59/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1186 - accuracy: 0.9996 - recall: 0.7635 - precision: 0.9604 - f1_score: 0.8889 - IoU: 0.8741\n",
      "Epoch 59: val_f1_score did not improve from 0.95499\n",
      "41/41 [==============================] - 20s 484ms/step - loss: 0.1186 - accuracy: 0.9996 - recall: 0.7635 - precision: 0.9604 - f1_score: 0.8889 - IoU: 0.8741 - val_loss: 0.1085 - val_accuracy: 0.9999 - val_recall: 0.7938 - val_precision: 0.9780 - val_f1_score: 0.8988 - val_IoU: 0.8528\n",
      "Epoch 60/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1139 - accuracy: 0.9996 - recall: 0.7653 - precision: 0.9647 - f1_score: 0.8938 - IoU: 0.8775\n",
      "Epoch 60: val_f1_score did not improve from 0.95499\n",
      "41/41 [==============================] - 20s 484ms/step - loss: 0.1139 - accuracy: 0.9996 - recall: 0.7653 - precision: 0.9647 - f1_score: 0.8938 - IoU: 0.8775 - val_loss: 0.0816 - val_accuracy: 0.9999 - val_recall: 0.8810 - val_precision: 0.9885 - val_f1_score: 0.9276 - val_IoU: 0.8987\n",
      "Epoch 61/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1035 - accuracy: 0.9996 - recall: 0.7661 - precision: 0.9751 - f1_score: 0.9035 - IoU: 0.8872\n",
      "Epoch 61: val_f1_score did not improve from 0.95499\n",
      "41/41 [==============================] - 20s 484ms/step - loss: 0.1035 - accuracy: 0.9996 - recall: 0.7661 - precision: 0.9751 - f1_score: 0.9035 - IoU: 0.8872 - val_loss: 0.0555 - val_accuracy: 0.9999 - val_recall: 0.9802 - val_precision: 0.9174 - val_f1_score: 0.9445 - val_IoU: 0.9532\n",
      "Epoch 62/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0997 - accuracy: 0.9997 - recall: 0.7748 - precision: 0.9744 - f1_score: 0.9070 - IoU: 0.8894\n",
      "Epoch 62: val_f1_score improved from 0.95499 to 0.95764, saving model to Trans UNet DA DICE 5-fold model/model_3fold.keras\n",
      "41/41 [==============================] - 20s 495ms/step - loss: 0.0997 - accuracy: 0.9997 - recall: 0.7748 - precision: 0.9744 - f1_score: 0.9070 - IoU: 0.8894 - val_loss: 0.0414 - val_accuracy: 1.0000 - val_recall: 0.9624 - val_precision: 0.9632 - val_f1_score: 0.9576 - val_IoU: 0.9514\n",
      "Epoch 63/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1229 - accuracy: 0.9996 - recall: 0.7737 - precision: 0.9473 - f1_score: 0.8849 - IoU: 0.8723\n",
      "Epoch 63: val_f1_score did not improve from 0.95764\n",
      "41/41 [==============================] - 20s 485ms/step - loss: 0.1229 - accuracy: 0.9996 - recall: 0.7737 - precision: 0.9473 - f1_score: 0.8849 - IoU: 0.8723 - val_loss: 0.1257 - val_accuracy: 0.9999 - val_recall: 0.7894 - val_precision: 0.9764 - val_f1_score: 0.8839 - val_IoU: 0.8379\n",
      "Epoch 64/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1241 - accuracy: 0.9996 - recall: 0.7537 - precision: 0.9476 - f1_score: 0.8839 - IoU: 0.8719\n",
      "Epoch 64: val_f1_score did not improve from 0.95764\n",
      "41/41 [==============================] - 20s 485ms/step - loss: 0.1241 - accuracy: 0.9996 - recall: 0.7537 - precision: 0.9476 - f1_score: 0.8839 - IoU: 0.8719 - val_loss: 0.1578 - val_accuracy: 0.9998 - val_recall: 0.7682 - val_precision: 0.9680 - val_f1_score: 0.8439 - val_IoU: 0.8526\n",
      "Epoch 65/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1213 - accuracy: 0.9996 - recall: 0.7540 - precision: 0.9544 - f1_score: 0.8861 - IoU: 0.8702\n",
      "Epoch 65: val_f1_score did not improve from 0.95764\n",
      "41/41 [==============================] - 20s 485ms/step - loss: 0.1213 - accuracy: 0.9996 - recall: 0.7540 - precision: 0.9544 - f1_score: 0.8861 - IoU: 0.8702 - val_loss: 0.0935 - val_accuracy: 0.9999 - val_recall: 0.8009 - val_precision: 0.9799 - val_f1_score: 0.9053 - val_IoU: 0.8615\n",
      "Epoch 66/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1212 - accuracy: 0.9996 - recall: 0.7552 - precision: 0.9569 - f1_score: 0.8872 - IoU: 0.8746\n",
      "Epoch 66: val_f1_score did not improve from 0.95764\n",
      "41/41 [==============================] - 20s 487ms/step - loss: 0.1212 - accuracy: 0.9996 - recall: 0.7552 - precision: 0.9569 - f1_score: 0.8872 - IoU: 0.8746 - val_loss: 0.0492 - val_accuracy: 0.9999 - val_recall: 0.9592 - val_precision: 0.9587 - val_f1_score: 0.9368 - val_IoU: 0.9471\n",
      "Epoch 67/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1124 - accuracy: 0.9997 - recall: 0.7629 - precision: 0.9666 - f1_score: 0.8949 - IoU: 0.8794\n",
      "Epoch 67: val_f1_score did not improve from 0.95764\n",
      "41/41 [==============================] - 20s 485ms/step - loss: 0.1124 - accuracy: 0.9997 - recall: 0.7629 - precision: 0.9666 - f1_score: 0.8949 - IoU: 0.8794 - val_loss: 0.0770 - val_accuracy: 0.9999 - val_recall: 0.8956 - val_precision: 0.9816 - val_f1_score: 0.9268 - val_IoU: 0.9040\n",
      "Epoch 68/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1075 - accuracy: 0.9996 - recall: 0.7711 - precision: 0.9684 - f1_score: 0.8993 - IoU: 0.8827\n",
      "Epoch 68: val_f1_score did not improve from 0.95764\n",
      "41/41 [==============================] - 20s 484ms/step - loss: 0.1075 - accuracy: 0.9996 - recall: 0.7711 - precision: 0.9684 - f1_score: 0.8993 - IoU: 0.8827 - val_loss: 0.0594 - val_accuracy: 0.9999 - val_recall: 0.9217 - val_precision: 0.9826 - val_f1_score: 0.9426 - val_IoU: 0.9237\n",
      "Epoch 69/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1066 - accuracy: 0.9997 - recall: 0.7741 - precision: 0.9638 - f1_score: 0.8998 - IoU: 0.8850\n",
      "Epoch 69: val_f1_score did not improve from 0.95764\n",
      "41/41 [==============================] - 20s 486ms/step - loss: 0.1066 - accuracy: 0.9997 - recall: 0.7741 - precision: 0.9638 - f1_score: 0.8998 - IoU: 0.8850 - val_loss: 0.0552 - val_accuracy: 0.9999 - val_recall: 0.9328 - val_precision: 0.9779 - val_f1_score: 0.9444 - val_IoU: 0.9327\n",
      "Epoch 70/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0958 - accuracy: 0.9997 - recall: 0.7813 - precision: 0.9850 - f1_score: 0.9104 - IoU: 0.8886\n",
      "Epoch 70: val_f1_score did not improve from 0.95764\n",
      "41/41 [==============================] - 20s 485ms/step - loss: 0.0958 - accuracy: 0.9997 - recall: 0.7813 - precision: 0.9850 - f1_score: 0.9104 - IoU: 0.8886 - val_loss: 0.0583 - val_accuracy: 0.9999 - val_recall: 0.9344 - val_precision: 0.9804 - val_f1_score: 0.9424 - val_IoU: 0.9350\n",
      "Epoch 71/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1067 - accuracy: 0.9997 - recall: 0.7700 - precision: 0.9674 - f1_score: 0.8999 - IoU: 0.8796\n",
      "Epoch 71: val_f1_score did not improve from 0.95764\n",
      "41/41 [==============================] - 20s 486ms/step - loss: 0.1067 - accuracy: 0.9997 - recall: 0.7700 - precision: 0.9674 - f1_score: 0.8999 - IoU: 0.8796 - val_loss: 0.0498 - val_accuracy: 1.0000 - val_recall: 0.9470 - val_precision: 0.9754 - val_f1_score: 0.9521 - val_IoU: 0.9454\n",
      "Epoch 72/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0998 - accuracy: 0.9996 - recall: 0.7793 - precision: 0.9735 - f1_score: 0.9066 - IoU: 0.8881\n",
      "Epoch 72: val_f1_score did not improve from 0.95764\n",
      "41/41 [==============================] - 20s 486ms/step - loss: 0.0998 - accuracy: 0.9996 - recall: 0.7793 - precision: 0.9735 - f1_score: 0.9066 - IoU: 0.8881 - val_loss: 0.0439 - val_accuracy: 1.0000 - val_recall: 0.9702 - val_precision: 0.9553 - val_f1_score: 0.9542 - val_IoU: 0.9595\n",
      "Epoch 73/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0986 - accuracy: 0.9997 - recall: 0.7759 - precision: 0.9786 - f1_score: 0.9076 - IoU: 0.8908\n",
      "Epoch 73: val_f1_score did not improve from 0.95764\n",
      "41/41 [==============================] - 20s 487ms/step - loss: 0.0986 - accuracy: 0.9997 - recall: 0.7759 - precision: 0.9786 - f1_score: 0.9076 - IoU: 0.8908 - val_loss: 0.0449 - val_accuracy: 1.0000 - val_recall: 0.9532 - val_precision: 0.9733 - val_f1_score: 0.9529 - val_IoU: 0.9478\n",
      "Epoch 74/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1014 - accuracy: 0.9997 - recall: 0.7721 - precision: 0.9811 - f1_score: 0.9049 - IoU: 0.8863\n",
      "Epoch 74: val_f1_score did not improve from 0.95764\n",
      "41/41 [==============================] - 20s 485ms/step - loss: 0.1014 - accuracy: 0.9997 - recall: 0.7721 - precision: 0.9811 - f1_score: 0.9049 - IoU: 0.8863 - val_loss: 0.0466 - val_accuracy: 1.0000 - val_recall: 0.9643 - val_precision: 0.9623 - val_f1_score: 0.9562 - val_IoU: 0.9576\n",
      "Epoch 75/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0978 - accuracy: 0.9997 - recall: 0.7721 - precision: 0.9804 - f1_score: 0.9085 - IoU: 0.8903\n",
      "Epoch 75: val_f1_score did not improve from 0.95764\n",
      "41/41 [==============================] - 20s 486ms/step - loss: 0.0978 - accuracy: 0.9997 - recall: 0.7721 - precision: 0.9804 - f1_score: 0.9085 - IoU: 0.8903 - val_loss: 0.0538 - val_accuracy: 0.9999 - val_recall: 0.9282 - val_precision: 0.9794 - val_f1_score: 0.9483 - val_IoU: 0.9334\n",
      "Epoch 76/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0998 - accuracy: 0.9997 - recall: 0.7716 - precision: 0.9794 - f1_score: 0.9064 - IoU: 0.8903\n",
      "Epoch 76: val_f1_score improved from 0.95764 to 0.96293, saving model to Trans UNet DA DICE 5-fold model/model_3fold.keras\n",
      "41/41 [==============================] - 20s 496ms/step - loss: 0.0998 - accuracy: 0.9997 - recall: 0.7716 - precision: 0.9794 - f1_score: 0.9064 - IoU: 0.8903 - val_loss: 0.0381 - val_accuracy: 1.0000 - val_recall: 0.9453 - val_precision: 0.9820 - val_f1_score: 0.9629 - val_IoU: 0.9458\n",
      "Epoch 77/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0998 - accuracy: 0.9996 - recall: 0.7704 - precision: 0.9787 - f1_score: 0.9065 - IoU: 0.8877\n",
      "Epoch 77: val_f1_score did not improve from 0.96293\n",
      "41/41 [==============================] - 20s 485ms/step - loss: 0.0998 - accuracy: 0.9996 - recall: 0.7704 - precision: 0.9787 - f1_score: 0.9065 - IoU: 0.8877 - val_loss: 0.0469 - val_accuracy: 0.9999 - val_recall: 0.9719 - val_precision: 0.9325 - val_f1_score: 0.9529 - val_IoU: 0.9568\n",
      "Epoch 78/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1184 - accuracy: 0.9996 - recall: 0.7632 - precision: 0.9584 - f1_score: 0.8893 - IoU: 0.8713\n",
      "Epoch 78: val_f1_score did not improve from 0.96293\n",
      "41/41 [==============================] - 20s 487ms/step - loss: 0.1184 - accuracy: 0.9996 - recall: 0.7632 - precision: 0.9584 - f1_score: 0.8893 - IoU: 0.8713 - val_loss: 0.1269 - val_accuracy: 0.9999 - val_recall: 0.9639 - val_precision: 0.8331 - val_f1_score: 0.8802 - val_IoU: 0.9108\n",
      "Epoch 79/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1097 - accuracy: 0.9997 - recall: 0.7673 - precision: 0.9662 - f1_score: 0.8971 - IoU: 0.8757\n",
      "Epoch 79: val_f1_score did not improve from 0.96293\n",
      "41/41 [==============================] - 20s 483ms/step - loss: 0.1097 - accuracy: 0.9997 - recall: 0.7673 - precision: 0.9662 - f1_score: 0.8971 - IoU: 0.8757 - val_loss: 0.0377 - val_accuracy: 1.0000 - val_recall: 0.9708 - val_precision: 0.9586 - val_f1_score: 0.9620 - val_IoU: 0.9600\n",
      "Epoch 80/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1004 - accuracy: 0.9997 - recall: 0.7763 - precision: 0.9773 - f1_score: 0.9059 - IoU: 0.8829\n",
      "Epoch 80: val_f1_score did not improve from 0.96293\n",
      "41/41 [==============================] - 20s 483ms/step - loss: 0.1004 - accuracy: 0.9997 - recall: 0.7763 - precision: 0.9773 - f1_score: 0.9059 - IoU: 0.8829 - val_loss: 0.0954 - val_accuracy: 0.9999 - val_recall: 0.9781 - val_precision: 0.8749 - val_f1_score: 0.9081 - val_IoU: 0.9357\n",
      "Epoch 81/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0989 - accuracy: 0.9997 - recall: 0.7759 - precision: 0.9750 - f1_score: 0.9073 - IoU: 0.8874\n",
      "Epoch 81: val_f1_score improved from 0.96293 to 0.96301, saving model to Trans UNet DA DICE 5-fold model/model_3fold.keras\n",
      "41/41 [==============================] - 20s 492ms/step - loss: 0.0989 - accuracy: 0.9997 - recall: 0.7759 - precision: 0.9750 - f1_score: 0.9073 - IoU: 0.8874 - val_loss: 0.0359 - val_accuracy: 1.0000 - val_recall: 0.9731 - val_precision: 0.9593 - val_f1_score: 0.9630 - val_IoU: 0.9621\n",
      "Epoch 82/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1017 - accuracy: 0.9997 - recall: 0.7802 - precision: 0.9759 - f1_score: 0.9045 - IoU: 0.8831\n",
      "Epoch 82: val_f1_score did not improve from 0.96301\n",
      "41/41 [==============================] - 20s 483ms/step - loss: 0.1017 - accuracy: 0.9997 - recall: 0.7802 - precision: 0.9759 - f1_score: 0.9045 - IoU: 0.8831 - val_loss: 0.0367 - val_accuracy: 1.0000 - val_recall: 0.9584 - val_precision: 0.9705 - val_f1_score: 0.9626 - val_IoU: 0.9544\n",
      "Epoch 83/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1080 - accuracy: 0.9997 - recall: 0.7679 - precision: 0.9732 - f1_score: 0.8985 - IoU: 0.8808\n",
      "Epoch 83: val_f1_score did not improve from 0.96301\n",
      "41/41 [==============================] - 20s 483ms/step - loss: 0.1080 - accuracy: 0.9997 - recall: 0.7679 - precision: 0.9732 - f1_score: 0.8985 - IoU: 0.8808 - val_loss: 0.0518 - val_accuracy: 0.9999 - val_recall: 0.9304 - val_precision: 0.9788 - val_f1_score: 0.9494 - val_IoU: 0.9342\n",
      "Epoch 84/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1203 - accuracy: 0.9996 - recall: 0.7549 - precision: 0.9666 - f1_score: 0.8871 - IoU: 0.8752\n",
      "Epoch 84: val_f1_score did not improve from 0.96301\n",
      "41/41 [==============================] - 20s 482ms/step - loss: 0.1203 - accuracy: 0.9996 - recall: 0.7549 - precision: 0.9666 - f1_score: 0.8871 - IoU: 0.8752 - val_loss: 0.0972 - val_accuracy: 0.9999 - val_recall: 0.9090 - val_precision: 0.9741 - val_f1_score: 0.9059 - val_IoU: 0.9293\n",
      "Epoch 85/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1589 - accuracy: 0.9996 - recall: 0.7394 - precision: 0.9063 - f1_score: 0.8508 - IoU: 0.8457\n",
      "Epoch 85: val_f1_score did not improve from 0.96301\n",
      "41/41 [==============================] - 20s 484ms/step - loss: 0.1589 - accuracy: 0.9996 - recall: 0.7394 - precision: 0.9063 - f1_score: 0.8508 - IoU: 0.8457 - val_loss: 0.8213 - val_accuracy: 0.9994 - val_recall: 0.1039 - val_precision: 0.7906 - val_f1_score: 0.2137 - val_IoU: 0.5400\n",
      "Epoch 86/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.2572 - accuracy: 0.9995 - recall: 0.6426 - precision: 0.8503 - f1_score: 0.7583 - IoU: 0.7811\n",
      "Epoch 86: val_f1_score did not improve from 0.96301\n",
      "41/41 [==============================] - 20s 484ms/step - loss: 0.2572 - accuracy: 0.9995 - recall: 0.6426 - precision: 0.8503 - f1_score: 0.7583 - IoU: 0.7811 - val_loss: 0.7019 - val_accuracy: 0.9995 - val_recall: 0.1764 - val_precision: 0.9704 - val_f1_score: 0.2606 - val_IoU: 0.5707\n",
      "Epoch 87/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.2781 - accuracy: 0.9994 - recall: 0.6426 - precision: 0.7971 - f1_score: 0.7390 - IoU: 0.7736\n",
      "Epoch 87: val_f1_score did not improve from 0.96301\n",
      "41/41 [==============================] - 20s 484ms/step - loss: 0.2781 - accuracy: 0.9994 - recall: 0.6426 - precision: 0.7971 - f1_score: 0.7390 - IoU: 0.7736 - val_loss: 0.4152 - val_accuracy: 0.9996 - val_recall: 0.4765 - val_precision: 0.8833 - val_f1_score: 0.5678 - val_IoU: 0.6914\n",
      "Epoch 88/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.2988 - accuracy: 0.9994 - recall: 0.6242 - precision: 0.7825 - f1_score: 0.7190 - IoU: 0.7605\n",
      "Epoch 88: val_f1_score did not improve from 0.96301\n",
      "41/41 [==============================] - 20s 483ms/step - loss: 0.2988 - accuracy: 0.9994 - recall: 0.6242 - precision: 0.7825 - f1_score: 0.7190 - IoU: 0.7605 - val_loss: 0.7385 - val_accuracy: 0.9994 - val_recall: 0.1837 - val_precision: 0.6909 - val_f1_score: 0.2661 - val_IoU: 0.5232\n",
      "Epoch 89/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.2955 - accuracy: 0.9994 - recall: 0.6401 - precision: 0.7553 - f1_score: 0.7226 - IoU: 0.7688\n",
      "Epoch 89: val_f1_score did not improve from 0.96301\n",
      "41/41 [==============================] - 20s 482ms/step - loss: 0.2955 - accuracy: 0.9994 - recall: 0.6401 - precision: 0.7553 - f1_score: 0.7226 - IoU: 0.7688 - val_loss: 0.9144 - val_accuracy: 0.9993 - val_recall: 0.0622 - val_precision: 0.2155 - val_f1_score: 0.0748 - val_IoU: 0.5165\n",
      "Epoch 90/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.3571 - accuracy: 0.9994 - recall: 0.5405 - precision: 0.7854 - f1_score: 0.6638 - IoU: 0.7290\n",
      "Epoch 90: val_f1_score did not improve from 0.96301\n",
      "41/41 [==============================] - 20s 483ms/step - loss: 0.3571 - accuracy: 0.9994 - recall: 0.5405 - precision: 0.7854 - f1_score: 0.6638 - IoU: 0.7290 - val_loss: 0.7014 - val_accuracy: 0.9995 - val_recall: 0.2032 - val_precision: 0.8209 - val_f1_score: 0.2701 - val_IoU: 0.5864\n",
      "Epoch 91/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.2685 - accuracy: 0.9995 - recall: 0.6567 - precision: 0.7981 - f1_score: 0.7472 - IoU: 0.7769\n",
      "Epoch 91: val_f1_score did not improve from 0.96301\n",
      "41/41 [==============================] - 20s 482ms/step - loss: 0.2685 - accuracy: 0.9995 - recall: 0.6567 - precision: 0.7981 - f1_score: 0.7472 - IoU: 0.7769 - val_loss: 0.3932 - val_accuracy: 0.9997 - val_recall: 0.4562 - val_precision: 0.9841 - val_f1_score: 0.6245 - val_IoU: 0.6905\n",
      "Epoch 92/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.2052 - accuracy: 0.9995 - recall: 0.6693 - precision: 0.8990 - f1_score: 0.8075 - IoU: 0.8197\n",
      "Epoch 92: val_f1_score did not improve from 0.96301\n",
      "41/41 [==============================] - 20s 482ms/step - loss: 0.2052 - accuracy: 0.9995 - recall: 0.6693 - precision: 0.8990 - f1_score: 0.8075 - IoU: 0.8197 - val_loss: 0.3858 - val_accuracy: 0.9996 - val_recall: 0.4446 - val_precision: 0.9607 - val_f1_score: 0.6275 - val_IoU: 0.7007\n",
      "Epoch 93/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1779 - accuracy: 0.9996 - recall: 0.7066 - precision: 0.9015 - f1_score: 0.8330 - IoU: 0.8375\n",
      "Epoch 93: val_f1_score did not improve from 0.96301\n",
      "41/41 [==============================] - 20s 483ms/step - loss: 0.1779 - accuracy: 0.9996 - recall: 0.7066 - precision: 0.9015 - f1_score: 0.8330 - IoU: 0.8375 - val_loss: 0.2713 - val_accuracy: 0.9997 - val_recall: 0.7824 - val_precision: 0.7349 - val_f1_score: 0.7115 - val_IoU: 0.8020\n",
      "Epoch 94/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.3307 - accuracy: 0.9994 - recall: 0.5896 - precision: 0.7504 - f1_score: 0.6897 - IoU: 0.7451\n",
      "Epoch 94: val_f1_score did not improve from 0.96301\n",
      "41/41 [==============================] - 20s 484ms/step - loss: 0.3307 - accuracy: 0.9994 - recall: 0.5896 - precision: 0.7504 - f1_score: 0.6897 - IoU: 0.7451 - val_loss: 0.4740 - val_accuracy: 0.9996 - val_recall: 0.3312 - val_precision: 0.9395 - val_f1_score: 0.5405 - val_IoU: 0.6466\n",
      "Epoch 95/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.2438 - accuracy: 0.9995 - recall: 0.6583 - precision: 0.8500 - f1_score: 0.7705 - IoU: 0.7886\n",
      "Epoch 95: val_f1_score did not improve from 0.96301\n",
      "41/41 [==============================] - 20s 482ms/step - loss: 0.2438 - accuracy: 0.9995 - recall: 0.6583 - precision: 0.8500 - f1_score: 0.7705 - IoU: 0.7886 - val_loss: 0.2696 - val_accuracy: 0.9997 - val_recall: 0.6751 - val_precision: 0.8892 - val_f1_score: 0.7458 - val_IoU: 0.8043\n",
      "Epoch 96/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1823 - accuracy: 0.9996 - recall: 0.7124 - precision: 0.8979 - f1_score: 0.8285 - IoU: 0.8332\n",
      "Epoch 96: val_f1_score did not improve from 0.96301\n",
      "41/41 [==============================] - 20s 482ms/step - loss: 0.1823 - accuracy: 0.9996 - recall: 0.7124 - precision: 0.8979 - f1_score: 0.8285 - IoU: 0.8332 - val_loss: 0.1109 - val_accuracy: 0.9999 - val_recall: 0.9279 - val_precision: 0.8683 - val_f1_score: 0.8942 - val_IoU: 0.9093\n",
      "Epoch 97/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.2536 - accuracy: 0.9995 - recall: 0.6489 - precision: 0.8360 - f1_score: 0.7616 - IoU: 0.7834\n",
      "Epoch 97: val_f1_score did not improve from 0.96301\n",
      "41/41 [==============================] - 20s 482ms/step - loss: 0.2536 - accuracy: 0.9995 - recall: 0.6489 - precision: 0.8360 - f1_score: 0.7616 - IoU: 0.7834 - val_loss: 0.6881 - val_accuracy: 0.9978 - val_recall: 0.9392 - val_precision: 0.2144 - val_f1_score: 0.2953 - val_IoU: 0.6248\n",
      "Epoch 98/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.3064 - accuracy: 0.9994 - recall: 0.5967 - precision: 0.7874 - f1_score: 0.7107 - IoU: 0.7568\n",
      "Epoch 98: val_f1_score did not improve from 0.96301\n",
      "41/41 [==============================] - 20s 483ms/step - loss: 0.3064 - accuracy: 0.9994 - recall: 0.5967 - precision: 0.7874 - f1_score: 0.7107 - IoU: 0.7568 - val_loss: 0.3003 - val_accuracy: 0.9996 - val_recall: 0.9513 - val_precision: 0.6196 - val_f1_score: 0.6787 - val_IoU: 0.8256\n",
      "Epoch 99/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.2145 - accuracy: 0.9995 - recall: 0.6643 - precision: 0.8948 - f1_score: 0.7987 - IoU: 0.8166\n",
      "Epoch 99: val_f1_score did not improve from 0.96301\n",
      "41/41 [==============================] - 20s 483ms/step - loss: 0.2145 - accuracy: 0.9995 - recall: 0.6643 - precision: 0.8948 - f1_score: 0.7987 - IoU: 0.8166 - val_loss: 0.2055 - val_accuracy: 0.9998 - val_recall: 0.7929 - val_precision: 0.9304 - val_f1_score: 0.8139 - val_IoU: 0.8598\n",
      "Epoch 100/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1689 - accuracy: 0.9996 - recall: 0.7123 - precision: 0.9192 - f1_score: 0.8411 - IoU: 0.8388\n",
      "Epoch 100: val_f1_score did not improve from 0.96301\n",
      "41/41 [==============================] - 20s 485ms/step - loss: 0.1689 - accuracy: 0.9996 - recall: 0.7123 - precision: 0.9192 - f1_score: 0.8411 - IoU: 0.8388 - val_loss: 0.2814 - val_accuracy: 0.9997 - val_recall: 0.5606 - val_precision: 0.9762 - val_f1_score: 0.7488 - val_IoU: 0.7406\n",
      "Epoch 101/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1536 - accuracy: 0.9996 - recall: 0.7375 - precision: 0.9252 - f1_score: 0.8557 - IoU: 0.8487\n",
      "Epoch 101: val_f1_score did not improve from 0.96301\n",
      "41/41 [==============================] - 20s 482ms/step - loss: 0.1536 - accuracy: 0.9996 - recall: 0.7375 - precision: 0.9252 - f1_score: 0.8557 - IoU: 0.8487 - val_loss: 0.2293 - val_accuracy: 0.9998 - val_recall: 0.6422 - val_precision: 0.9803 - val_f1_score: 0.7854 - val_IoU: 0.7742\n",
      "Epoch 102/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1494 - accuracy: 0.9996 - recall: 0.7335 - precision: 0.9235 - f1_score: 0.8598 - IoU: 0.8530\n",
      "Epoch 102: val_f1_score did not improve from 0.96301\n",
      "41/41 [==============================] - 20s 484ms/step - loss: 0.1494 - accuracy: 0.9996 - recall: 0.7335 - precision: 0.9235 - f1_score: 0.8598 - IoU: 0.8530 - val_loss: 0.2630 - val_accuracy: 0.9997 - val_recall: 0.5676 - val_precision: 0.9890 - val_f1_score: 0.7629 - val_IoU: 0.7282\n",
      "Epoch 103/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.2024 - accuracy: 0.9995 - recall: 0.6972 - precision: 0.8746 - f1_score: 0.8098 - IoU: 0.8173\n",
      "Epoch 103: val_f1_score did not improve from 0.96301\n",
      "41/41 [==============================] - 20s 482ms/step - loss: 0.2024 - accuracy: 0.9995 - recall: 0.6972 - precision: 0.8746 - f1_score: 0.8098 - IoU: 0.8173 - val_loss: 0.2415 - val_accuracy: 0.9998 - val_recall: 0.6130 - val_precision: 0.9827 - val_f1_score: 0.7685 - val_IoU: 0.7481\n",
      "Epoch 104/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1654 - accuracy: 0.9996 - recall: 0.7198 - precision: 0.9166 - f1_score: 0.8445 - IoU: 0.8399\n",
      "Epoch 104: val_f1_score did not improve from 0.96301\n",
      "41/41 [==============================] - 20s 482ms/step - loss: 0.1654 - accuracy: 0.9996 - recall: 0.7198 - precision: 0.9166 - f1_score: 0.8445 - IoU: 0.8399 - val_loss: 0.4426 - val_accuracy: 0.9996 - val_recall: 0.3517 - val_precision: 0.9808 - val_f1_score: 0.5864 - val_IoU: 0.6435\n",
      "Epoch 105/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1636 - accuracy: 0.9996 - recall: 0.7262 - precision: 0.9206 - f1_score: 0.8462 - IoU: 0.8421\n",
      "Epoch 105: val_f1_score did not improve from 0.96301\n",
      "41/41 [==============================] - 20s 482ms/step - loss: 0.1636 - accuracy: 0.9996 - recall: 0.7262 - precision: 0.9206 - f1_score: 0.8462 - IoU: 0.8421 - val_loss: 0.2663 - val_accuracy: 0.9998 - val_recall: 0.6300 - val_precision: 0.9752 - val_f1_score: 0.7574 - val_IoU: 0.7671\n",
      "Epoch 106/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1438 - accuracy: 0.9996 - recall: 0.7395 - precision: 0.9401 - f1_score: 0.8644 - IoU: 0.8586\n",
      "Epoch 106: val_f1_score did not improve from 0.96301\n",
      "41/41 [==============================] - 20s 484ms/step - loss: 0.1438 - accuracy: 0.9996 - recall: 0.7395 - precision: 0.9401 - f1_score: 0.8644 - IoU: 0.8586 - val_loss: 0.1116 - val_accuracy: 0.9999 - val_recall: 0.8476 - val_precision: 0.9740 - val_f1_score: 0.8988 - val_IoU: 0.8765\n",
      "Epoch 107/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1445 - accuracy: 0.9996 - recall: 0.7297 - precision: 0.9364 - f1_score: 0.8643 - IoU: 0.8550\n",
      "Epoch 107: val_f1_score did not improve from 0.96301\n",
      "41/41 [==============================] - 20s 482ms/step - loss: 0.1445 - accuracy: 0.9996 - recall: 0.7297 - precision: 0.9364 - f1_score: 0.8643 - IoU: 0.8550 - val_loss: 0.0779 - val_accuracy: 0.9999 - val_recall: 0.9135 - val_precision: 0.9471 - val_f1_score: 0.9136 - val_IoU: 0.9200\n",
      "Epoch 108/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1362 - accuracy: 0.9996 - recall: 0.7413 - precision: 0.9413 - f1_score: 0.8718 - IoU: 0.8609\n",
      "Epoch 108: val_f1_score did not improve from 0.96301\n",
      "41/41 [==============================] - 20s 482ms/step - loss: 0.1362 - accuracy: 0.9996 - recall: 0.7413 - precision: 0.9413 - f1_score: 0.8718 - IoU: 0.8609 - val_loss: 0.1369 - val_accuracy: 0.9999 - val_recall: 0.8212 - val_precision: 0.9787 - val_f1_score: 0.8733 - val_IoU: 0.8690\n",
      "Epoch 109/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1482 - accuracy: 0.9996 - recall: 0.7524 - precision: 0.9238 - f1_score: 0.8597 - IoU: 0.8557\n",
      "Epoch 109: val_f1_score did not improve from 0.96301\n",
      "41/41 [==============================] - 20s 484ms/step - loss: 0.1482 - accuracy: 0.9996 - recall: 0.7524 - precision: 0.9238 - f1_score: 0.8597 - IoU: 0.8557 - val_loss: 0.0911 - val_accuracy: 0.9999 - val_recall: 0.8822 - val_precision: 0.9600 - val_f1_score: 0.9103 - val_IoU: 0.8995\n",
      "Epoch 110/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1271 - accuracy: 0.9996 - recall: 0.7441 - precision: 0.9581 - f1_score: 0.8806 - IoU: 0.8670\n",
      "Epoch 110: val_f1_score did not improve from 0.96301\n",
      "41/41 [==============================] - 20s 481ms/step - loss: 0.1271 - accuracy: 0.9996 - recall: 0.7441 - precision: 0.9581 - f1_score: 0.8806 - IoU: 0.8670 - val_loss: 0.0880 - val_accuracy: 0.9999 - val_recall: 0.8981 - val_precision: 0.9615 - val_f1_score: 0.9067 - val_IoU: 0.9066\n",
      "Epoch 111/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1470 - accuracy: 0.9996 - recall: 0.7346 - precision: 0.9340 - f1_score: 0.8615 - IoU: 0.8543\n",
      "Epoch 111: val_f1_score did not improve from 0.96301\n",
      "41/41 [==============================] - 20s 482ms/step - loss: 0.1470 - accuracy: 0.9996 - recall: 0.7346 - precision: 0.9340 - f1_score: 0.8615 - IoU: 0.8543 - val_loss: 0.1548 - val_accuracy: 0.9998 - val_recall: 0.7690 - val_precision: 0.9697 - val_f1_score: 0.8539 - val_IoU: 0.8427\n",
      "Epoch 112/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1307 - accuracy: 0.9996 - recall: 0.7571 - precision: 0.9503 - f1_score: 0.8772 - IoU: 0.8602\n",
      "Epoch 112: val_f1_score did not improve from 0.96301\n",
      "41/41 [==============================] - 20s 482ms/step - loss: 0.1307 - accuracy: 0.9996 - recall: 0.7571 - precision: 0.9503 - f1_score: 0.8772 - IoU: 0.8602 - val_loss: 0.2058 - val_accuracy: 0.9998 - val_recall: 0.6745 - val_precision: 0.9800 - val_f1_score: 0.8033 - val_IoU: 0.7902\n",
      "Epoch 113/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1236 - accuracy: 0.9996 - recall: 0.7445 - precision: 0.9628 - f1_score: 0.8840 - IoU: 0.8660\n",
      "Epoch 113: val_f1_score did not improve from 0.96301\n",
      "41/41 [==============================] - 20s 482ms/step - loss: 0.1236 - accuracy: 0.9996 - recall: 0.7445 - precision: 0.9628 - f1_score: 0.8840 - IoU: 0.8660 - val_loss: 0.0566 - val_accuracy: 0.9999 - val_recall: 0.9494 - val_precision: 0.9473 - val_f1_score: 0.9404 - val_IoU: 0.9457\n",
      "Epoch 114/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1164 - accuracy: 0.9996 - recall: 0.7616 - precision: 0.9641 - f1_score: 0.8907 - IoU: 0.8745\n",
      "Epoch 114: val_f1_score did not improve from 0.96301\n",
      "41/41 [==============================] - 20s 482ms/step - loss: 0.1164 - accuracy: 0.9996 - recall: 0.7616 - precision: 0.9641 - f1_score: 0.8907 - IoU: 0.8745 - val_loss: 0.0626 - val_accuracy: 0.9999 - val_recall: 0.9532 - val_precision: 0.9516 - val_f1_score: 0.9366 - val_IoU: 0.9467\n",
      "Epoch 115/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1159 - accuracy: 0.9996 - recall: 0.7670 - precision: 0.9499 - f1_score: 0.8911 - IoU: 0.8744\n",
      "Epoch 115: val_f1_score did not improve from 0.96301\n",
      "41/41 [==============================] - 20s 482ms/step - loss: 0.1159 - accuracy: 0.9996 - recall: 0.7670 - precision: 0.9499 - f1_score: 0.8911 - IoU: 0.8744 - val_loss: 0.0481 - val_accuracy: 0.9999 - val_recall: 0.9382 - val_precision: 0.9673 - val_f1_score: 0.9540 - val_IoU: 0.9409\n",
      "Epoch 116/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1108 - accuracy: 0.9997 - recall: 0.7631 - precision: 0.9697 - f1_score: 0.8956 - IoU: 0.8792\n",
      "Epoch 116: val_f1_score did not improve from 0.96301\n",
      "41/41 [==============================] - 20s 484ms/step - loss: 0.1108 - accuracy: 0.9997 - recall: 0.7631 - precision: 0.9697 - f1_score: 0.8956 - IoU: 0.8792 - val_loss: 0.1093 - val_accuracy: 0.9999 - val_recall: 0.8773 - val_precision: 0.9835 - val_f1_score: 0.8913 - val_IoU: 0.9075\n",
      "Epoch 117/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1174 - accuracy: 0.9996 - recall: 0.7642 - precision: 0.9546 - f1_score: 0.8895 - IoU: 0.8702\n",
      "Epoch 117: val_f1_score did not improve from 0.96301\n",
      "41/41 [==============================] - 20s 484ms/step - loss: 0.1174 - accuracy: 0.9996 - recall: 0.7642 - precision: 0.9546 - f1_score: 0.8895 - IoU: 0.8702 - val_loss: 0.0728 - val_accuracy: 0.9999 - val_recall: 0.9621 - val_precision: 0.9234 - val_f1_score: 0.9170 - val_IoU: 0.9430\n",
      "Epoch 118/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1114 - accuracy: 0.9996 - recall: 0.7597 - precision: 0.9741 - f1_score: 0.8952 - IoU: 0.8782\n",
      "Epoch 118: val_f1_score did not improve from 0.96301\n",
      "41/41 [==============================] - 20s 482ms/step - loss: 0.1114 - accuracy: 0.9996 - recall: 0.7597 - precision: 0.9741 - f1_score: 0.8952 - IoU: 0.8782 - val_loss: 0.0529 - val_accuracy: 0.9999 - val_recall: 0.9077 - val_precision: 0.9754 - val_f1_score: 0.9491 - val_IoU: 0.9217\n",
      "Epoch 119/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1133 - accuracy: 0.9997 - recall: 0.7655 - precision: 0.9704 - f1_score: 0.8933 - IoU: 0.8756\n",
      "Epoch 119: val_f1_score did not improve from 0.96301\n",
      "41/41 [==============================] - 20s 482ms/step - loss: 0.1133 - accuracy: 0.9997 - recall: 0.7655 - precision: 0.9704 - f1_score: 0.8933 - IoU: 0.8756 - val_loss: 0.1005 - val_accuracy: 0.9999 - val_recall: 0.8275 - val_precision: 0.9720 - val_f1_score: 0.9067 - val_IoU: 0.8680\n",
      "Epoch 120/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1209 - accuracy: 0.9996 - recall: 0.7580 - precision: 0.9595 - f1_score: 0.8858 - IoU: 0.8680\n",
      "Epoch 120: val_f1_score did not improve from 0.96301\n",
      "41/41 [==============================] - 20s 483ms/step - loss: 0.1209 - accuracy: 0.9996 - recall: 0.7580 - precision: 0.9595 - f1_score: 0.8858 - IoU: 0.8680 - val_loss: 0.0926 - val_accuracy: 0.9999 - val_recall: 0.8339 - val_precision: 0.9561 - val_f1_score: 0.9104 - val_IoU: 0.8742\n",
      "Epoch 121/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1185 - accuracy: 0.9996 - recall: 0.7573 - precision: 0.9615 - f1_score: 0.8885 - IoU: 0.8697\n",
      "Epoch 121: val_f1_score did not improve from 0.96301\n",
      "41/41 [==============================] - 20s 484ms/step - loss: 0.1185 - accuracy: 0.9996 - recall: 0.7573 - precision: 0.9615 - f1_score: 0.8885 - IoU: 0.8697 - val_loss: 0.0871 - val_accuracy: 0.9999 - val_recall: 0.9020 - val_precision: 0.9716 - val_f1_score: 0.9155 - val_IoU: 0.9210\n",
      "Epoch 122/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1124 - accuracy: 0.9996 - recall: 0.7692 - precision: 0.9539 - f1_score: 0.8941 - IoU: 0.8748\n",
      "Epoch 122: val_f1_score did not improve from 0.96301\n",
      "41/41 [==============================] - 20s 482ms/step - loss: 0.1124 - accuracy: 0.9996 - recall: 0.7692 - precision: 0.9539 - f1_score: 0.8941 - IoU: 0.8748 - val_loss: 0.0483 - val_accuracy: 0.9999 - val_recall: 0.9276 - val_precision: 0.9763 - val_f1_score: 0.9534 - val_IoU: 0.9370\n",
      "Epoch 123/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1011 - accuracy: 0.9996 - recall: 0.7717 - precision: 0.9767 - f1_score: 0.9049 - IoU: 0.8811\n",
      "Epoch 123: val_f1_score did not improve from 0.96301\n",
      "41/41 [==============================] - 20s 483ms/step - loss: 0.1011 - accuracy: 0.9996 - recall: 0.7717 - precision: 0.9767 - f1_score: 0.9049 - IoU: 0.8811 - val_loss: 0.0454 - val_accuracy: 0.9999 - val_recall: 0.9538 - val_precision: 0.9619 - val_f1_score: 0.9544 - val_IoU: 0.9529\n",
      "Epoch 124/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0993 - accuracy: 0.9997 - recall: 0.7815 - precision: 0.9752 - f1_score: 0.9065 - IoU: 0.8819\n",
      "Epoch 124: val_f1_score did not improve from 0.96301\n",
      "41/41 [==============================] - 20s 482ms/step - loss: 0.0993 - accuracy: 0.9997 - recall: 0.7815 - precision: 0.9752 - f1_score: 0.9065 - IoU: 0.8819 - val_loss: 0.0623 - val_accuracy: 0.9999 - val_recall: 0.8919 - val_precision: 0.9790 - val_f1_score: 0.9414 - val_IoU: 0.9010\n",
      "Epoch 125/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1040 - accuracy: 0.9996 - recall: 0.7704 - precision: 0.9736 - f1_score: 0.9022 - IoU: 0.8814\n",
      "Epoch 125: val_f1_score improved from 0.96301 to 0.96684, saving model to Trans UNet DA DICE 5-fold model/model_3fold.keras\n",
      "41/41 [==============================] - 20s 493ms/step - loss: 0.1040 - accuracy: 0.9996 - recall: 0.7704 - precision: 0.9736 - f1_score: 0.9022 - IoU: 0.8814 - val_loss: 0.0340 - val_accuracy: 1.0000 - val_recall: 0.9574 - val_precision: 0.9765 - val_f1_score: 0.9668 - val_IoU: 0.9520\n",
      "Epoch 126/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0992 - accuracy: 0.9997 - recall: 0.7724 - precision: 0.9761 - f1_score: 0.9068 - IoU: 0.8836\n",
      "Epoch 126: val_f1_score did not improve from 0.96684\n",
      "41/41 [==============================] - 20s 486ms/step - loss: 0.0992 - accuracy: 0.9997 - recall: 0.7724 - precision: 0.9761 - f1_score: 0.9068 - IoU: 0.8836 - val_loss: 0.0337 - val_accuracy: 1.0000 - val_recall: 0.9691 - val_precision: 0.9675 - val_f1_score: 0.9663 - val_IoU: 0.9621\n",
      "Epoch 127/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0987 - accuracy: 0.9997 - recall: 0.7826 - precision: 0.9746 - f1_score: 0.9072 - IoU: 0.8810\n",
      "Epoch 127: val_f1_score did not improve from 0.96684\n",
      "41/41 [==============================] - 20s 491ms/step - loss: 0.0987 - accuracy: 0.9997 - recall: 0.7826 - precision: 0.9746 - f1_score: 0.9072 - IoU: 0.8810 - val_loss: 0.0375 - val_accuracy: 1.0000 - val_recall: 0.9767 - val_precision: 0.9555 - val_f1_score: 0.9605 - val_IoU: 0.9667\n",
      "Epoch 128/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0958 - accuracy: 0.9997 - recall: 0.7851 - precision: 0.9815 - f1_score: 0.9098 - IoU: 0.8813\n",
      "Epoch 128: val_f1_score did not improve from 0.96684\n",
      "41/41 [==============================] - 20s 487ms/step - loss: 0.0958 - accuracy: 0.9997 - recall: 0.7851 - precision: 0.9815 - f1_score: 0.9098 - IoU: 0.8813 - val_loss: 0.0454 - val_accuracy: 1.0000 - val_recall: 0.9865 - val_precision: 0.9391 - val_f1_score: 0.9528 - val_IoU: 0.9691\n",
      "Epoch 129/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1040 - accuracy: 0.9996 - recall: 0.7727 - precision: 0.9705 - f1_score: 0.9021 - IoU: 0.8754\n",
      "Epoch 129: val_f1_score did not improve from 0.96684\n",
      "41/41 [==============================] - 20s 485ms/step - loss: 0.1040 - accuracy: 0.9996 - recall: 0.7727 - precision: 0.9705 - f1_score: 0.9021 - IoU: 0.8754 - val_loss: 0.0453 - val_accuracy: 1.0000 - val_recall: 0.9832 - val_precision: 0.9399 - val_f1_score: 0.9539 - val_IoU: 0.9660\n",
      "Epoch 130/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1009 - accuracy: 0.9997 - recall: 0.7779 - precision: 0.9695 - f1_score: 0.9052 - IoU: 0.8819\n",
      "Epoch 130: val_f1_score did not improve from 0.96684\n",
      "41/41 [==============================] - 20s 486ms/step - loss: 0.1009 - accuracy: 0.9997 - recall: 0.7779 - precision: 0.9695 - f1_score: 0.9052 - IoU: 0.8819 - val_loss: 0.0444 - val_accuracy: 1.0000 - val_recall: 0.9589 - val_precision: 0.9649 - val_f1_score: 0.9449 - val_IoU: 0.9519\n",
      "Epoch 131/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1041 - accuracy: 0.9997 - recall: 0.7770 - precision: 0.9697 - f1_score: 0.9020 - IoU: 0.8750\n",
      "Epoch 131: val_f1_score did not improve from 0.96684\n",
      "41/41 [==============================] - 20s 485ms/step - loss: 0.1041 - accuracy: 0.9997 - recall: 0.7770 - precision: 0.9697 - f1_score: 0.9020 - IoU: 0.8750 - val_loss: 0.0389 - val_accuracy: 1.0000 - val_recall: 0.9723 - val_precision: 0.9602 - val_f1_score: 0.9603 - val_IoU: 0.9636\n",
      "Epoch 132/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1031 - accuracy: 0.9997 - recall: 0.7710 - precision: 0.9764 - f1_score: 0.9031 - IoU: 0.8790\n",
      "Epoch 132: val_f1_score did not improve from 0.96684\n",
      "41/41 [==============================] - 20s 487ms/step - loss: 0.1031 - accuracy: 0.9997 - recall: 0.7710 - precision: 0.9764 - f1_score: 0.9031 - IoU: 0.8790 - val_loss: 0.0367 - val_accuracy: 1.0000 - val_recall: 0.9565 - val_precision: 0.9721 - val_f1_score: 0.9635 - val_IoU: 0.9535\n",
      "Epoch 133/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1019 - accuracy: 0.9997 - recall: 0.7702 - precision: 0.9776 - f1_score: 0.9041 - IoU: 0.8808\n",
      "Epoch 133: val_f1_score did not improve from 0.96684\n",
      "41/41 [==============================] - 20s 485ms/step - loss: 0.1019 - accuracy: 0.9997 - recall: 0.7702 - precision: 0.9776 - f1_score: 0.9041 - IoU: 0.8808 - val_loss: 0.0436 - val_accuracy: 0.9999 - val_recall: 0.9438 - val_precision: 0.9712 - val_f1_score: 0.9574 - val_IoU: 0.9466\n",
      "Epoch 134/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0942 - accuracy: 0.9997 - recall: 0.7754 - precision: 0.9816 - f1_score: 0.9114 - IoU: 0.8874\n",
      "Epoch 134: val_f1_score did not improve from 0.96684\n",
      "41/41 [==============================] - 20s 486ms/step - loss: 0.0942 - accuracy: 0.9997 - recall: 0.7754 - precision: 0.9816 - f1_score: 0.9114 - IoU: 0.8874 - val_loss: 0.0396 - val_accuracy: 1.0000 - val_recall: 0.9700 - val_precision: 0.9621 - val_f1_score: 0.9613 - val_IoU: 0.9619\n",
      "Epoch 135/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1014 - accuracy: 0.9997 - recall: 0.7697 - precision: 0.9780 - f1_score: 0.9043 - IoU: 0.8786\n",
      "Epoch 135: val_f1_score did not improve from 0.96684\n",
      "41/41 [==============================] - 20s 486ms/step - loss: 0.1014 - accuracy: 0.9997 - recall: 0.7697 - precision: 0.9780 - f1_score: 0.9043 - IoU: 0.8786 - val_loss: 0.0376 - val_accuracy: 1.0000 - val_recall: 0.9711 - val_precision: 0.9628 - val_f1_score: 0.9621 - val_IoU: 0.9620\n",
      "Epoch 136/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1031 - accuracy: 0.9996 - recall: 0.7689 - precision: 0.9699 - f1_score: 0.9029 - IoU: 0.8785\n",
      "Epoch 136: val_f1_score did not improve from 0.96684\n",
      "41/41 [==============================] - 20s 486ms/step - loss: 0.1031 - accuracy: 0.9996 - recall: 0.7689 - precision: 0.9699 - f1_score: 0.9029 - IoU: 0.8785 - val_loss: 0.0463 - val_accuracy: 1.0000 - val_recall: 0.9601 - val_precision: 0.9639 - val_f1_score: 0.9547 - val_IoU: 0.9542\n",
      "Epoch 137/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0984 - accuracy: 0.9997 - recall: 0.7772 - precision: 0.9739 - f1_score: 0.9075 - IoU: 0.8842\n",
      "Epoch 137: val_f1_score did not improve from 0.96684\n",
      "41/41 [==============================] - 20s 486ms/step - loss: 0.0984 - accuracy: 0.9997 - recall: 0.7772 - precision: 0.9739 - f1_score: 0.9075 - IoU: 0.8842 - val_loss: 0.0333 - val_accuracy: 1.0000 - val_recall: 0.9600 - val_precision: 0.9740 - val_f1_score: 0.9661 - val_IoU: 0.9584\n",
      "Epoch 138/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1193 - accuracy: 0.9996 - recall: 0.7598 - precision: 0.9595 - f1_score: 0.8875 - IoU: 0.8691\n",
      "Epoch 138: val_f1_score did not improve from 0.96684\n",
      "41/41 [==============================] - 20s 486ms/step - loss: 0.1193 - accuracy: 0.9996 - recall: 0.7598 - precision: 0.9595 - f1_score: 0.8875 - IoU: 0.8691 - val_loss: 0.0609 - val_accuracy: 0.9999 - val_recall: 0.9871 - val_precision: 0.9160 - val_f1_score: 0.9394 - val_IoU: 0.9595\n",
      "Epoch 139/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1013 - accuracy: 0.9997 - recall: 0.7777 - precision: 0.9766 - f1_score: 0.9042 - IoU: 0.8777\n",
      "Epoch 139: val_f1_score did not improve from 0.96684\n",
      "41/41 [==============================] - 20s 485ms/step - loss: 0.1013 - accuracy: 0.9997 - recall: 0.7777 - precision: 0.9766 - f1_score: 0.9042 - IoU: 0.8777 - val_loss: 0.0353 - val_accuracy: 1.0000 - val_recall: 0.9709 - val_precision: 0.9659 - val_f1_score: 0.9643 - val_IoU: 0.9626\n",
      "Epoch 140/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0921 - accuracy: 0.9997 - recall: 0.7792 - precision: 0.9876 - f1_score: 0.9134 - IoU: 0.8878\n",
      "Epoch 140: val_f1_score did not improve from 0.96684\n",
      "41/41 [==============================] - 20s 487ms/step - loss: 0.0921 - accuracy: 0.9997 - recall: 0.7792 - precision: 0.9876 - f1_score: 0.9134 - IoU: 0.8878 - val_loss: 0.0400 - val_accuracy: 1.0000 - val_recall: 0.9432 - val_precision: 0.9771 - val_f1_score: 0.9611 - val_IoU: 0.9470\n",
      "Epoch 141/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1021 - accuracy: 0.9997 - recall: 0.7735 - precision: 0.9674 - f1_score: 0.9037 - IoU: 0.8783\n",
      "Epoch 141: val_f1_score did not improve from 0.96684\n",
      "41/41 [==============================] - 20s 486ms/step - loss: 0.1021 - accuracy: 0.9997 - recall: 0.7735 - precision: 0.9674 - f1_score: 0.9037 - IoU: 0.8783 - val_loss: 0.0365 - val_accuracy: 1.0000 - val_recall: 0.9466 - val_precision: 0.9765 - val_f1_score: 0.9637 - val_IoU: 0.9451\n",
      "Epoch 142/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1080 - accuracy: 0.9997 - recall: 0.7771 - precision: 0.9654 - f1_score: 0.8980 - IoU: 0.8725\n",
      "Epoch 142: val_f1_score did not improve from 0.96684\n",
      "41/41 [==============================] - 20s 485ms/step - loss: 0.1080 - accuracy: 0.9997 - recall: 0.7771 - precision: 0.9654 - f1_score: 0.8980 - IoU: 0.8725 - val_loss: 0.1053 - val_accuracy: 0.9999 - val_recall: 0.9704 - val_precision: 0.8722 - val_f1_score: 0.8782 - val_IoU: 0.9253\n",
      "Epoch 143/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0987 - accuracy: 0.9996 - recall: 0.7741 - precision: 0.9683 - f1_score: 0.9075 - IoU: 0.8834\n",
      "Epoch 143: val_f1_score did not improve from 0.96684\n",
      "41/41 [==============================] - 20s 486ms/step - loss: 0.0987 - accuracy: 0.9996 - recall: 0.7741 - precision: 0.9683 - f1_score: 0.9075 - IoU: 0.8834 - val_loss: 0.0568 - val_accuracy: 0.9999 - val_recall: 0.9096 - val_precision: 0.9750 - val_f1_score: 0.9459 - val_IoU: 0.9040\n",
      "Epoch 144/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0924 - accuracy: 0.9997 - recall: 0.7809 - precision: 0.9864 - f1_score: 0.9130 - IoU: 0.8835\n",
      "Epoch 144: val_f1_score did not improve from 0.96684\n",
      "41/41 [==============================] - 20s 486ms/step - loss: 0.0924 - accuracy: 0.9997 - recall: 0.7809 - precision: 0.9864 - f1_score: 0.9130 - IoU: 0.8835 - val_loss: 0.0400 - val_accuracy: 1.0000 - val_recall: 0.9608 - val_precision: 0.9728 - val_f1_score: 0.9602 - val_IoU: 0.9582\n",
      "Epoch 145/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1010 - accuracy: 0.9996 - recall: 0.7728 - precision: 0.9689 - f1_score: 0.9050 - IoU: 0.8785\n",
      "Epoch 145: val_f1_score did not improve from 0.96684\n",
      "41/41 [==============================] - 20s 486ms/step - loss: 0.1010 - accuracy: 0.9996 - recall: 0.7728 - precision: 0.9689 - f1_score: 0.9050 - IoU: 0.8785 - val_loss: 0.0502 - val_accuracy: 0.9999 - val_recall: 0.9137 - val_precision: 0.9831 - val_f1_score: 0.9530 - val_IoU: 0.9223\n",
      "Epoch 146/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1005 - accuracy: 0.9996 - recall: 0.7721 - precision: 0.9724 - f1_score: 0.9055 - IoU: 0.8792\n",
      "Epoch 146: val_f1_score did not improve from 0.96684\n",
      "41/41 [==============================] - 20s 486ms/step - loss: 0.1005 - accuracy: 0.9996 - recall: 0.7721 - precision: 0.9724 - f1_score: 0.9055 - IoU: 0.8792 - val_loss: 0.0708 - val_accuracy: 0.9999 - val_recall: 0.9087 - val_precision: 0.9695 - val_f1_score: 0.9341 - val_IoU: 0.9291\n",
      "Epoch 147/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0970 - accuracy: 0.9997 - recall: 0.7772 - precision: 0.9749 - f1_score: 0.9085 - IoU: 0.8842\n",
      "Epoch 147: val_f1_score did not improve from 0.96684\n",
      "41/41 [==============================] - 20s 488ms/step - loss: 0.0970 - accuracy: 0.9997 - recall: 0.7772 - precision: 0.9749 - f1_score: 0.9085 - IoU: 0.8842 - val_loss: 0.0402 - val_accuracy: 1.0000 - val_recall: 0.9658 - val_precision: 0.9665 - val_f1_score: 0.9595 - val_IoU: 0.9621\n",
      "Epoch 148/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1008 - accuracy: 0.9997 - recall: 0.7689 - precision: 0.9768 - f1_score: 0.9050 - IoU: 0.8775\n",
      "Epoch 148: val_f1_score did not improve from 0.96684\n",
      "41/41 [==============================] - 20s 486ms/step - loss: 0.1008 - accuracy: 0.9997 - recall: 0.7689 - precision: 0.9768 - f1_score: 0.9050 - IoU: 0.8775 - val_loss: 0.0403 - val_accuracy: 1.0000 - val_recall: 0.9799 - val_precision: 0.9546 - val_f1_score: 0.9584 - val_IoU: 0.9674\n",
      "Epoch 149/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1011 - accuracy: 0.9997 - recall: 0.7788 - precision: 0.9745 - f1_score: 0.9049 - IoU: 0.8783\n",
      "Epoch 149: val_f1_score did not improve from 0.96684\n",
      "41/41 [==============================] - 20s 486ms/step - loss: 0.1011 - accuracy: 0.9997 - recall: 0.7788 - precision: 0.9745 - f1_score: 0.9049 - IoU: 0.8783 - val_loss: 0.0367 - val_accuracy: 1.0000 - val_recall: 0.9818 - val_precision: 0.9560 - val_f1_score: 0.9614 - val_IoU: 0.9694\n",
      "Epoch 150/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0964 - accuracy: 0.9997 - recall: 0.7822 - precision: 0.9827 - f1_score: 0.9093 - IoU: 0.8851\n",
      "Epoch 150: val_f1_score did not improve from 0.96684\n",
      "41/41 [==============================] - 20s 486ms/step - loss: 0.0964 - accuracy: 0.9997 - recall: 0.7822 - precision: 0.9827 - f1_score: 0.9093 - IoU: 0.8851 - val_loss: 0.0365 - val_accuracy: 1.0000 - val_recall: 0.9676 - val_precision: 0.9673 - val_f1_score: 0.9634 - val_IoU: 0.9620\n",
      "O modelo demorou 3044.06 segundos para treinar.\n",
      "Fold: 4\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 14:24:50.993761: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - ETA: 0s - loss: 1.0590 - accuracy: 0.7862 - recall: 0.9101 - precision: 0.0034 - f1_score: 0.0056 - IoU: 0.5007\n",
      "Epoch 1: val_f1_score improved from -inf to 0.00163, saving model to Trans UNet DA DICE 5-fold model/model_4fold.keras\n",
      "41/41 [==============================] - 32s 561ms/step - loss: 1.0590 - accuracy: 0.7862 - recall: 0.9101 - precision: 0.0034 - f1_score: 0.0056 - IoU: 0.5007 - val_loss: 0.9982 - val_accuracy: 0.3624 - val_recall: 1.0000 - val_precision: 9.1653e-04 - val_f1_score: 0.0016 - val_IoU: 0.1969\n",
      "Epoch 2/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.0515 - accuracy: 0.9814 - recall: 0.9511 - precision: 0.0408 - f1_score: 0.0774 - IoU: 0.5467\n",
      "Epoch 2: val_f1_score improved from 0.00163 to 0.02149, saving model to Trans UNet DA DICE 5-fold model/model_4fold.keras\n",
      "41/41 [==============================] - 43s 500ms/step - loss: 1.0515 - accuracy: 0.9814 - recall: 0.9511 - precision: 0.0408 - f1_score: 0.0774 - IoU: 0.5467 - val_loss: 0.9764 - val_accuracy: 0.9528 - val_recall: 0.9822 - val_precision: 0.0120 - val_f1_score: 0.0215 - val_IoU: 0.5629\n",
      "Epoch 3/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.0370 - accuracy: 0.9938 - recall: 0.9218 - precision: 0.1143 - f1_score: 0.1973 - IoU: 0.6007\n",
      "Epoch 3: val_f1_score did not improve from 0.02149\n",
      "41/41 [==============================] - 20s 487ms/step - loss: 1.0370 - accuracy: 0.9938 - recall: 0.9218 - precision: 0.1143 - f1_score: 0.1973 - IoU: 0.6007 - val_loss: 0.9991 - val_accuracy: 0.4814 - val_recall: 0.3841 - val_precision: 4.3340e-04 - val_f1_score: 8.1599e-04 - val_IoU: 0.5056\n",
      "Epoch 4/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.9991 - accuracy: 0.9968 - recall: 0.8938 - precision: 0.2029 - f1_score: 0.3109 - IoU: 0.6317\n",
      "Epoch 4: val_f1_score did not improve from 0.02149\n",
      "41/41 [==============================] - 20s 486ms/step - loss: 0.9991 - accuracy: 0.9968 - recall: 0.8938 - precision: 0.2029 - f1_score: 0.3109 - IoU: 0.6317 - val_loss: 0.9998 - val_accuracy: 0.9950 - val_recall: 1.9526e-04 - val_precision: 2.5729e-05 - val_f1_score: 3.7798e-05 - val_IoU: 0.4997\n",
      "Epoch 5/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.8829 - accuracy: 0.9986 - recall: 0.8411 - precision: 0.4063 - f1_score: 0.5077 - IoU: 0.6875\n",
      "Epoch 5: val_f1_score did not improve from 0.02149\n",
      "41/41 [==============================] - 20s 486ms/step - loss: 0.8829 - accuracy: 0.9986 - recall: 0.8411 - precision: 0.4063 - f1_score: 0.5077 - IoU: 0.6875 - val_loss: 0.9949 - val_accuracy: 0.9994 - val_recall: 0.0015 - val_precision: 1.0000 - val_f1_score: 0.0043 - val_IoU: 0.4997\n",
      "Epoch 6/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.6425 - accuracy: 0.9993 - recall: 0.7659 - precision: 0.6227 - f1_score: 0.6651 - IoU: 0.7526\n",
      "Epoch 6: val_f1_score did not improve from 0.02149\n",
      "41/41 [==============================] - 20s 487ms/step - loss: 0.6425 - accuracy: 0.9993 - recall: 0.7659 - precision: 0.6227 - f1_score: 0.6651 - IoU: 0.7526 - val_loss: 1.0000 - val_accuracy: 0.9994 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_IoU: 0.4997\n",
      "Epoch 7/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.3907 - accuracy: 0.9995 - recall: 0.7385 - precision: 0.7925 - f1_score: 0.7660 - IoU: 0.8083\n",
      "Epoch 7: val_f1_score improved from 0.02149 to 0.43295, saving model to Trans UNet DA DICE 5-fold model/model_4fold.keras\n",
      "41/41 [==============================] - 20s 497ms/step - loss: 0.3907 - accuracy: 0.9995 - recall: 0.7385 - precision: 0.7925 - f1_score: 0.7660 - IoU: 0.8083 - val_loss: 0.5398 - val_accuracy: 0.9988 - val_recall: 0.9611 - val_precision: 0.3262 - val_f1_score: 0.4329 - val_IoU: 0.7920\n",
      "Epoch 8/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.3270 - accuracy: 0.9995 - recall: 0.7120 - precision: 0.7863 - f1_score: 0.7547 - IoU: 0.8020\n",
      "Epoch 8: val_f1_score did not improve from 0.43295\n",
      "41/41 [==============================] - 20s 490ms/step - loss: 0.3270 - accuracy: 0.9995 - recall: 0.7120 - precision: 0.7863 - f1_score: 0.7547 - IoU: 0.8020 - val_loss: 0.9406 - val_accuracy: 0.9994 - val_recall: 0.0412 - val_precision: 0.8934 - val_f1_score: 0.0524 - val_IoU: 0.5118\n",
      "Epoch 9/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.2443 - accuracy: 0.9995 - recall: 0.7024 - precision: 0.8940 - f1_score: 0.8099 - IoU: 0.8354\n",
      "Epoch 9: val_f1_score did not improve from 0.43295\n",
      "41/41 [==============================] - 20s 489ms/step - loss: 0.2443 - accuracy: 0.9995 - recall: 0.7024 - precision: 0.8940 - f1_score: 0.8099 - IoU: 0.8354 - val_loss: 0.9996 - val_accuracy: 0.9994 - val_recall: 3.9052e-05 - val_precision: 1.0000 - val_f1_score: 1.3280e-04 - val_IoU: 0.4997\n",
      "Epoch 10/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1842 - accuracy: 0.9996 - recall: 0.7522 - precision: 0.9235 - f1_score: 0.8551 - IoU: 0.8680\n",
      "Epoch 10: val_f1_score improved from 0.43295 to 0.78660, saving model to Trans UNet DA DICE 5-fold model/model_4fold.keras\n",
      "41/41 [==============================] - 20s 498ms/step - loss: 0.1842 - accuracy: 0.9996 - recall: 0.7522 - precision: 0.9235 - f1_score: 0.8551 - IoU: 0.8680 - val_loss: 0.2414 - val_accuracy: 0.9998 - val_recall: 0.6454 - val_precision: 0.9405 - val_f1_score: 0.7866 - val_IoU: 0.7380\n",
      "Epoch 11/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1407 - accuracy: 0.9996 - recall: 0.7695 - precision: 0.9609 - f1_score: 0.8885 - IoU: 0.8924\n",
      "Epoch 11: val_f1_score improved from 0.78660 to 0.90355, saving model to Trans UNet DA DICE 5-fold model/model_4fold.keras\n",
      "41/41 [==============================] - 20s 496ms/step - loss: 0.1407 - accuracy: 0.9996 - recall: 0.7695 - precision: 0.9609 - f1_score: 0.8885 - IoU: 0.8924 - val_loss: 0.0843 - val_accuracy: 0.9999 - val_recall: 0.9684 - val_precision: 0.9120 - val_f1_score: 0.9035 - val_IoU: 0.9223\n",
      "Epoch 12/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1605 - accuracy: 0.9996 - recall: 0.7564 - precision: 0.9304 - f1_score: 0.8648 - IoU: 0.8769\n",
      "Epoch 12: val_f1_score did not improve from 0.90355\n",
      "41/41 [==============================] - 20s 487ms/step - loss: 0.1605 - accuracy: 0.9996 - recall: 0.7564 - precision: 0.9304 - f1_score: 0.8648 - IoU: 0.8769 - val_loss: 0.9786 - val_accuracy: 0.9994 - val_recall: 0.0151 - val_precision: 0.9949 - val_f1_score: 0.0188 - val_IoU: 0.5017\n",
      "Epoch 13/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1725 - accuracy: 0.9996 - recall: 0.7418 - precision: 0.9186 - f1_score: 0.8511 - IoU: 0.8592\n",
      "Epoch 13: val_f1_score did not improve from 0.90355\n",
      "41/41 [==============================] - 20s 488ms/step - loss: 0.1725 - accuracy: 0.9996 - recall: 0.7418 - precision: 0.9186 - f1_score: 0.8511 - IoU: 0.8592 - val_loss: 0.3222 - val_accuracy: 0.9997 - val_recall: 0.5605 - val_precision: 0.9516 - val_f1_score: 0.6901 - val_IoU: 0.6955\n",
      "Epoch 14/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1439 - accuracy: 0.9996 - recall: 0.7451 - precision: 0.9593 - f1_score: 0.8757 - IoU: 0.8814\n",
      "Epoch 14: val_f1_score did not improve from 0.90355\n",
      "41/41 [==============================] - 20s 488ms/step - loss: 0.1439 - accuracy: 0.9996 - recall: 0.7451 - precision: 0.9593 - f1_score: 0.8757 - IoU: 0.8814 - val_loss: 0.9398 - val_accuracy: 0.9994 - val_recall: 0.0328 - val_precision: 0.9964 - val_f1_score: 0.0584 - val_IoU: 0.5050\n",
      "Epoch 15/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1378 - accuracy: 0.9996 - recall: 0.7658 - precision: 0.9493 - f1_score: 0.8802 - IoU: 0.8817\n",
      "Epoch 15: val_f1_score did not improve from 0.90355\n",
      "41/41 [==============================] - 20s 490ms/step - loss: 0.1378 - accuracy: 0.9996 - recall: 0.7658 - precision: 0.9493 - f1_score: 0.8802 - IoU: 0.8817 - val_loss: 0.2107 - val_accuracy: 0.9998 - val_recall: 0.6880 - val_precision: 0.9883 - val_f1_score: 0.7971 - val_IoU: 0.7579\n",
      "Epoch 16/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1172 - accuracy: 0.9996 - recall: 0.7774 - precision: 0.9698 - f1_score: 0.8976 - IoU: 0.8935\n",
      "Epoch 16: val_f1_score did not improve from 0.90355\n",
      "41/41 [==============================] - 20s 490ms/step - loss: 0.1172 - accuracy: 0.9996 - recall: 0.7774 - precision: 0.9698 - f1_score: 0.8976 - IoU: 0.8935 - val_loss: 0.1265 - val_accuracy: 0.9999 - val_recall: 0.8335 - val_precision: 0.9597 - val_f1_score: 0.8572 - val_IoU: 0.8285\n",
      "Epoch 17/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1117 - accuracy: 0.9997 - recall: 0.7711 - precision: 0.9763 - f1_score: 0.9018 - IoU: 0.8975\n",
      "Epoch 17: val_f1_score did not improve from 0.90355\n",
      "41/41 [==============================] - 20s 491ms/step - loss: 0.1117 - accuracy: 0.9997 - recall: 0.7711 - precision: 0.9763 - f1_score: 0.9018 - IoU: 0.8975 - val_loss: 0.1137 - val_accuracy: 0.9999 - val_recall: 0.8233 - val_precision: 0.9818 - val_f1_score: 0.8825 - val_IoU: 0.8313\n",
      "Epoch 18/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1046 - accuracy: 0.9997 - recall: 0.7800 - precision: 0.9852 - f1_score: 0.9078 - IoU: 0.9000\n",
      "Epoch 18: val_f1_score did not improve from 0.90355\n",
      "41/41 [==============================] - 20s 491ms/step - loss: 0.1046 - accuracy: 0.9997 - recall: 0.7800 - precision: 0.9852 - f1_score: 0.9078 - IoU: 0.9000 - val_loss: 0.1581 - val_accuracy: 0.9998 - val_recall: 0.9546 - val_precision: 0.7985 - val_f1_score: 0.8238 - val_IoU: 0.8978\n",
      "Epoch 19/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1099 - accuracy: 0.9997 - recall: 0.7771 - precision: 0.9708 - f1_score: 0.9022 - IoU: 0.8951\n",
      "Epoch 19: val_f1_score did not improve from 0.90355\n",
      "41/41 [==============================] - 20s 488ms/step - loss: 0.1099 - accuracy: 0.9997 - recall: 0.7771 - precision: 0.9708 - f1_score: 0.9022 - IoU: 0.8951 - val_loss: 0.1926 - val_accuracy: 0.9998 - val_recall: 0.8519 - val_precision: 0.8092 - val_f1_score: 0.7430 - val_IoU: 0.8051\n",
      "Epoch 20/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1208 - accuracy: 0.9996 - recall: 0.7699 - precision: 0.9691 - f1_score: 0.8914 - IoU: 0.8887\n",
      "Epoch 20: val_f1_score did not improve from 0.90355\n",
      "41/41 [==============================] - 20s 487ms/step - loss: 0.1208 - accuracy: 0.9996 - recall: 0.7699 - precision: 0.9691 - f1_score: 0.8914 - IoU: 0.8887 - val_loss: 0.1336 - val_accuracy: 0.9999 - val_recall: 0.9533 - val_precision: 0.8547 - val_f1_score: 0.8504 - val_IoU: 0.9083\n",
      "Epoch 21/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1154 - accuracy: 0.9997 - recall: 0.7708 - precision: 0.9690 - f1_score: 0.8957 - IoU: 0.8913\n",
      "Epoch 21: val_f1_score did not improve from 0.90355\n",
      "41/41 [==============================] - 20s 493ms/step - loss: 0.1154 - accuracy: 0.9997 - recall: 0.7708 - precision: 0.9690 - f1_score: 0.8957 - IoU: 0.8913 - val_loss: 0.1875 - val_accuracy: 0.9998 - val_recall: 0.6998 - val_precision: 0.9884 - val_f1_score: 0.8304 - val_IoU: 0.7742\n",
      "Epoch 22/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1041 - accuracy: 0.9997 - recall: 0.7768 - precision: 0.9832 - f1_score: 0.9058 - IoU: 0.9006\n",
      "Epoch 22: val_f1_score did not improve from 0.90355\n",
      "41/41 [==============================] - 20s 489ms/step - loss: 0.1041 - accuracy: 0.9997 - recall: 0.7768 - precision: 0.9832 - f1_score: 0.9058 - IoU: 0.9006 - val_loss: 0.2482 - val_accuracy: 0.9998 - val_recall: 0.6194 - val_precision: 0.9858 - val_f1_score: 0.7571 - val_IoU: 0.7254\n",
      "Epoch 23/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1028 - accuracy: 0.9997 - recall: 0.7703 - precision: 0.9829 - f1_score: 0.9070 - IoU: 0.8976\n",
      "Epoch 23: val_f1_score did not improve from 0.90355\n",
      "41/41 [==============================] - 20s 491ms/step - loss: 0.1028 - accuracy: 0.9997 - recall: 0.7703 - precision: 0.9829 - f1_score: 0.9070 - IoU: 0.8976 - val_loss: 0.5451 - val_accuracy: 0.9996 - val_recall: 0.3205 - val_precision: 0.9919 - val_f1_score: 0.4894 - val_IoU: 0.5912\n",
      "Epoch 24/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1309 - accuracy: 0.9996 - recall: 0.7656 - precision: 0.9513 - f1_score: 0.8800 - IoU: 0.8785\n",
      "Epoch 24: val_f1_score did not improve from 0.90355\n",
      "41/41 [==============================] - 20s 489ms/step - loss: 0.1309 - accuracy: 0.9996 - recall: 0.7656 - precision: 0.9513 - f1_score: 0.8800 - IoU: 0.8785 - val_loss: 0.9678 - val_accuracy: 0.9994 - val_recall: 0.0221 - val_precision: 0.9965 - val_f1_score: 0.0311 - val_IoU: 0.5055\n",
      "Epoch 25/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1128 - accuracy: 0.9996 - recall: 0.7741 - precision: 0.9712 - f1_score: 0.8971 - IoU: 0.8918\n",
      "Epoch 25: val_f1_score did not improve from 0.90355\n",
      "41/41 [==============================] - 20s 488ms/step - loss: 0.1128 - accuracy: 0.9996 - recall: 0.7741 - precision: 0.9712 - f1_score: 0.8971 - IoU: 0.8918 - val_loss: 0.3230 - val_accuracy: 0.9997 - val_recall: 0.5538 - val_precision: 0.9910 - val_f1_score: 0.6882 - val_IoU: 0.7000\n",
      "Epoch 26/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1120 - accuracy: 0.9997 - recall: 0.7654 - precision: 0.9751 - f1_score: 0.8974 - IoU: 0.8927\n",
      "Epoch 26: val_f1_score did not improve from 0.90355\n",
      "41/41 [==============================] - 20s 487ms/step - loss: 0.1120 - accuracy: 0.9997 - recall: 0.7654 - precision: 0.9751 - f1_score: 0.8974 - IoU: 0.8927 - val_loss: 0.1695 - val_accuracy: 0.9998 - val_recall: 0.7407 - val_precision: 0.9906 - val_f1_score: 0.8121 - val_IoU: 0.7706\n",
      "Epoch 27/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1016 - accuracy: 0.9997 - recall: 0.7759 - precision: 0.9787 - f1_score: 0.9068 - IoU: 0.8976\n",
      "Epoch 27: val_f1_score improved from 0.90355 to 0.96094, saving model to Trans UNet DA DICE 5-fold model/model_4fold.keras\n",
      "41/41 [==============================] - 20s 499ms/step - loss: 0.1016 - accuracy: 0.9997 - recall: 0.7759 - precision: 0.9787 - f1_score: 0.9068 - IoU: 0.8976 - val_loss: 0.0393 - val_accuracy: 1.0000 - val_recall: 0.9777 - val_precision: 0.9520 - val_f1_score: 0.9609 - val_IoU: 0.9555\n",
      "Epoch 28/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0899 - accuracy: 0.9997 - recall: 0.7922 - precision: 0.9875 - f1_score: 0.9180 - IoU: 0.9061\n",
      "Epoch 28: val_f1_score did not improve from 0.96094\n",
      "41/41 [==============================] - 20s 488ms/step - loss: 0.0899 - accuracy: 0.9997 - recall: 0.7922 - precision: 0.9875 - f1_score: 0.9180 - IoU: 0.9061 - val_loss: 0.0429 - val_accuracy: 1.0000 - val_recall: 0.9625 - val_precision: 0.9696 - val_f1_score: 0.9502 - val_IoU: 0.9390\n",
      "Epoch 29/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0907 - accuracy: 0.9997 - recall: 0.7782 - precision: 0.9918 - f1_score: 0.9168 - IoU: 0.9044\n",
      "Epoch 29: val_f1_score did not improve from 0.96094\n",
      "41/41 [==============================] - 20s 486ms/step - loss: 0.0907 - accuracy: 0.9997 - recall: 0.7782 - precision: 0.9918 - f1_score: 0.9168 - IoU: 0.9044 - val_loss: 0.0560 - val_accuracy: 1.0000 - val_recall: 0.9680 - val_precision: 0.9479 - val_f1_score: 0.9078 - val_IoU: 0.9431\n",
      "Epoch 30/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0947 - accuracy: 0.9997 - recall: 0.7830 - precision: 0.9866 - f1_score: 0.9129 - IoU: 0.9032\n",
      "Epoch 30: val_f1_score did not improve from 0.96094\n",
      "41/41 [==============================] - 20s 487ms/step - loss: 0.0947 - accuracy: 0.9997 - recall: 0.7830 - precision: 0.9866 - f1_score: 0.9129 - IoU: 0.9032 - val_loss: 0.0404 - val_accuracy: 1.0000 - val_recall: 0.9695 - val_precision: 0.9617 - val_f1_score: 0.9550 - val_IoU: 0.9387\n",
      "Epoch 31/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0938 - accuracy: 0.9997 - recall: 0.7864 - precision: 0.9862 - f1_score: 0.9138 - IoU: 0.9008\n",
      "Epoch 31: val_f1_score did not improve from 0.96094\n",
      "41/41 [==============================] - 20s 487ms/step - loss: 0.0938 - accuracy: 0.9997 - recall: 0.7864 - precision: 0.9862 - f1_score: 0.9138 - IoU: 0.9008 - val_loss: 0.0842 - val_accuracy: 0.9999 - val_recall: 0.8804 - val_precision: 0.9874 - val_f1_score: 0.8967 - val_IoU: 0.8594\n",
      "Epoch 32/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1010 - accuracy: 0.9997 - recall: 0.7754 - precision: 0.9814 - f1_score: 0.9067 - IoU: 0.8963\n",
      "Epoch 32: val_f1_score did not improve from 0.96094\n",
      "41/41 [==============================] - 20s 491ms/step - loss: 0.1010 - accuracy: 0.9997 - recall: 0.7754 - precision: 0.9814 - f1_score: 0.9067 - IoU: 0.8963 - val_loss: 0.0728 - val_accuracy: 0.9999 - val_recall: 0.8964 - val_precision: 0.9837 - val_f1_score: 0.9330 - val_IoU: 0.9074\n",
      "Epoch 33/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0942 - accuracy: 0.9996 - recall: 0.7802 - precision: 0.9853 - f1_score: 0.9133 - IoU: 0.9029\n",
      "Epoch 33: val_f1_score did not improve from 0.96094\n",
      "41/41 [==============================] - 20s 489ms/step - loss: 0.0942 - accuracy: 0.9996 - recall: 0.7802 - precision: 0.9853 - f1_score: 0.9133 - IoU: 0.9029 - val_loss: 0.0632 - val_accuracy: 0.9999 - val_recall: 0.9875 - val_precision: 0.9126 - val_f1_score: 0.8964 - val_IoU: 0.9590\n",
      "Epoch 34/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0952 - accuracy: 0.9997 - recall: 0.7844 - precision: 0.9836 - f1_score: 0.9119 - IoU: 0.8986\n",
      "Epoch 34: val_f1_score improved from 0.96094 to 0.96495, saving model to Trans UNet DA DICE 5-fold model/model_4fold.keras\n",
      "41/41 [==============================] - 20s 499ms/step - loss: 0.0952 - accuracy: 0.9997 - recall: 0.7844 - precision: 0.9836 - f1_score: 0.9119 - IoU: 0.8986 - val_loss: 0.0347 - val_accuracy: 1.0000 - val_recall: 0.9705 - val_precision: 0.9675 - val_f1_score: 0.9649 - val_IoU: 0.9461\n",
      "Epoch 35/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0909 - accuracy: 0.9997 - recall: 0.7805 - precision: 0.9872 - f1_score: 0.9161 - IoU: 0.9024\n",
      "Epoch 35: val_f1_score did not improve from 0.96495\n",
      "41/41 [==============================] - 20s 490ms/step - loss: 0.0909 - accuracy: 0.9997 - recall: 0.7805 - precision: 0.9872 - f1_score: 0.9161 - IoU: 0.9024 - val_loss: 0.0368 - val_accuracy: 1.0000 - val_recall: 0.9573 - val_precision: 0.9753 - val_f1_score: 0.9627 - val_IoU: 0.9359\n",
      "Epoch 36/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0905 - accuracy: 0.9997 - recall: 0.7883 - precision: 0.9854 - f1_score: 0.9162 - IoU: 0.9020\n",
      "Epoch 36: val_f1_score did not improve from 0.96495\n",
      "41/41 [==============================] - 20s 492ms/step - loss: 0.0905 - accuracy: 0.9997 - recall: 0.7883 - precision: 0.9854 - f1_score: 0.9162 - IoU: 0.9020 - val_loss: 0.0787 - val_accuracy: 0.9999 - val_recall: 0.8729 - val_precision: 0.9839 - val_f1_score: 0.9254 - val_IoU: 0.8542\n",
      "Epoch 37/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0946 - accuracy: 0.9997 - recall: 0.7812 - precision: 0.9851 - f1_score: 0.9122 - IoU: 0.9001\n",
      "Epoch 37: val_f1_score improved from 0.96495 to 0.96530, saving model to Trans UNet DA DICE 5-fold model/model_4fold.keras\n",
      "41/41 [==============================] - 20s 497ms/step - loss: 0.0946 - accuracy: 0.9997 - recall: 0.7812 - precision: 0.9851 - f1_score: 0.9122 - IoU: 0.9001 - val_loss: 0.0351 - val_accuracy: 1.0000 - val_recall: 0.9621 - val_precision: 0.9750 - val_f1_score: 0.9653 - val_IoU: 0.9390\n",
      "Epoch 38/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0969 - accuracy: 0.9997 - recall: 0.7828 - precision: 0.9802 - f1_score: 0.9100 - IoU: 0.8954\n",
      "Epoch 38: val_f1_score did not improve from 0.96530\n",
      "41/41 [==============================] - 20s 489ms/step - loss: 0.0969 - accuracy: 0.9997 - recall: 0.7828 - precision: 0.9802 - f1_score: 0.9100 - IoU: 0.8954 - val_loss: 0.0454 - val_accuracy: 1.0000 - val_recall: 0.9522 - val_precision: 0.9772 - val_f1_score: 0.9315 - val_IoU: 0.9347\n",
      "Epoch 39/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0860 - accuracy: 0.9997 - recall: 0.7886 - precision: 0.9920 - f1_score: 0.9205 - IoU: 0.9043\n",
      "Epoch 39: val_f1_score did not improve from 0.96530\n",
      "41/41 [==============================] - 20s 487ms/step - loss: 0.0860 - accuracy: 0.9997 - recall: 0.7886 - precision: 0.9920 - f1_score: 0.9205 - IoU: 0.9043 - val_loss: 0.0379 - val_accuracy: 1.0000 - val_recall: 0.9573 - val_precision: 0.9769 - val_f1_score: 0.9559 - val_IoU: 0.9386\n",
      "Epoch 40/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0903 - accuracy: 0.9997 - recall: 0.7862 - precision: 0.9887 - f1_score: 0.9161 - IoU: 0.8976\n",
      "Epoch 40: val_f1_score did not improve from 0.96530\n",
      "41/41 [==============================] - 20s 489ms/step - loss: 0.0903 - accuracy: 0.9997 - recall: 0.7862 - precision: 0.9887 - f1_score: 0.9161 - IoU: 0.8976 - val_loss: 0.0402 - val_accuracy: 1.0000 - val_recall: 0.9491 - val_precision: 0.9763 - val_f1_score: 0.9602 - val_IoU: 0.9330\n",
      "Epoch 41/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0875 - accuracy: 0.9997 - recall: 0.7887 - precision: 0.9874 - f1_score: 0.9189 - IoU: 0.8993\n",
      "Epoch 41: val_f1_score did not improve from 0.96530\n",
      "41/41 [==============================] - 20s 486ms/step - loss: 0.0875 - accuracy: 0.9997 - recall: 0.7887 - precision: 0.9874 - f1_score: 0.9189 - IoU: 0.8993 - val_loss: 0.0347 - val_accuracy: 1.0000 - val_recall: 0.9597 - val_precision: 0.9777 - val_f1_score: 0.9652 - val_IoU: 0.9407\n",
      "Epoch 42/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0879 - accuracy: 0.9997 - recall: 0.7847 - precision: 0.9887 - f1_score: 0.9184 - IoU: 0.9022\n",
      "Epoch 42: val_f1_score improved from 0.96530 to 0.96831, saving model to Trans UNet DA DICE 5-fold model/model_4fold.keras\n",
      "41/41 [==============================] - 21s 503ms/step - loss: 0.0879 - accuracy: 0.9997 - recall: 0.7847 - precision: 0.9887 - f1_score: 0.9184 - IoU: 0.9022 - val_loss: 0.0322 - val_accuracy: 1.0000 - val_recall: 0.9732 - val_precision: 0.9691 - val_f1_score: 0.9683 - val_IoU: 0.9529\n",
      "Epoch 43/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0904 - accuracy: 0.9997 - recall: 0.7887 - precision: 0.9890 - f1_score: 0.9158 - IoU: 0.9004\n",
      "Epoch 43: val_f1_score did not improve from 0.96831\n",
      "41/41 [==============================] - 20s 488ms/step - loss: 0.0904 - accuracy: 0.9997 - recall: 0.7887 - precision: 0.9890 - f1_score: 0.9158 - IoU: 0.9004 - val_loss: 0.0354 - val_accuracy: 1.0000 - val_recall: 0.9788 - val_precision: 0.9572 - val_f1_score: 0.9646 - val_IoU: 0.9529\n",
      "Epoch 44/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0885 - accuracy: 0.9997 - recall: 0.7861 - precision: 0.9891 - f1_score: 0.9176 - IoU: 0.9016\n",
      "Epoch 44: val_f1_score did not improve from 0.96831\n",
      "41/41 [==============================] - 20s 490ms/step - loss: 0.0885 - accuracy: 0.9997 - recall: 0.7861 - precision: 0.9891 - f1_score: 0.9176 - IoU: 0.9016 - val_loss: 0.0330 - val_accuracy: 1.0000 - val_recall: 0.9743 - val_precision: 0.9675 - val_f1_score: 0.9677 - val_IoU: 0.9511\n",
      "Epoch 45/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0891 - accuracy: 0.9997 - recall: 0.7834 - precision: 0.9893 - f1_score: 0.9170 - IoU: 0.9026\n",
      "Epoch 45: val_f1_score did not improve from 0.96831\n",
      "41/41 [==============================] - 20s 494ms/step - loss: 0.0891 - accuracy: 0.9997 - recall: 0.7834 - precision: 0.9893 - f1_score: 0.9170 - IoU: 0.9026 - val_loss: 0.0317 - val_accuracy: 1.0000 - val_recall: 0.9655 - val_precision: 0.9768 - val_f1_score: 0.9673 - val_IoU: 0.9416\n",
      "Epoch 46/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0911 - accuracy: 0.9997 - recall: 0.7846 - precision: 0.9855 - f1_score: 0.9153 - IoU: 0.8989\n",
      "Epoch 46: val_f1_score did not improve from 0.96831\n",
      "41/41 [==============================] - 20s 487ms/step - loss: 0.0911 - accuracy: 0.9997 - recall: 0.7846 - precision: 0.9855 - f1_score: 0.9153 - IoU: 0.8989 - val_loss: 0.0558 - val_accuracy: 0.9999 - val_recall: 0.9619 - val_precision: 0.9531 - val_f1_score: 0.9190 - val_IoU: 0.9380\n",
      "Epoch 47/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0907 - accuracy: 0.9997 - recall: 0.7851 - precision: 0.9860 - f1_score: 0.9154 - IoU: 0.8990\n",
      "Epoch 47: val_f1_score did not improve from 0.96831\n",
      "41/41 [==============================] - 20s 488ms/step - loss: 0.0907 - accuracy: 0.9997 - recall: 0.7851 - precision: 0.9860 - f1_score: 0.9154 - IoU: 0.8990 - val_loss: 0.0388 - val_accuracy: 1.0000 - val_recall: 0.9460 - val_precision: 0.9793 - val_f1_score: 0.9626 - val_IoU: 0.9199\n",
      "Epoch 48/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1114 - accuracy: 0.9996 - recall: 0.7657 - precision: 0.9699 - f1_score: 0.8958 - IoU: 0.8825\n",
      "Epoch 48: val_f1_score did not improve from 0.96831\n",
      "41/41 [==============================] - 20s 487ms/step - loss: 0.1114 - accuracy: 0.9996 - recall: 0.7657 - precision: 0.9699 - f1_score: 0.8958 - IoU: 0.8825 - val_loss: 0.2122 - val_accuracy: 0.9998 - val_recall: 0.7294 - val_precision: 0.9294 - val_f1_score: 0.7536 - val_IoU: 0.8319\n",
      "Epoch 49/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0969 - accuracy: 0.9997 - recall: 0.7788 - precision: 0.9799 - f1_score: 0.9098 - IoU: 0.8937\n",
      "Epoch 49: val_f1_score did not improve from 0.96831\n",
      "41/41 [==============================] - 20s 492ms/step - loss: 0.0969 - accuracy: 0.9997 - recall: 0.7788 - precision: 0.9799 - f1_score: 0.9098 - IoU: 0.8937 - val_loss: 0.0575 - val_accuracy: 0.9999 - val_recall: 0.9237 - val_precision: 0.9693 - val_f1_score: 0.9444 - val_IoU: 0.9193\n",
      "Epoch 50/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0962 - accuracy: 0.9997 - recall: 0.7737 - precision: 0.9881 - f1_score: 0.9102 - IoU: 0.8929\n",
      "Epoch 50: val_f1_score did not improve from 0.96831\n",
      "41/41 [==============================] - 20s 487ms/step - loss: 0.0962 - accuracy: 0.9997 - recall: 0.7737 - precision: 0.9881 - f1_score: 0.9102 - IoU: 0.8929 - val_loss: 0.4185 - val_accuracy: 0.9997 - val_recall: 0.4417 - val_precision: 0.9950 - val_f1_score: 0.6220 - val_IoU: 0.6644\n",
      "Epoch 51/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0963 - accuracy: 0.9996 - recall: 0.7791 - precision: 0.9803 - f1_score: 0.9104 - IoU: 0.8958\n",
      "Epoch 51: val_f1_score did not improve from 0.96831\n",
      "41/41 [==============================] - 20s 490ms/step - loss: 0.0963 - accuracy: 0.9996 - recall: 0.7791 - precision: 0.9803 - f1_score: 0.9104 - IoU: 0.8958 - val_loss: 0.0381 - val_accuracy: 1.0000 - val_recall: 0.9741 - val_precision: 0.9603 - val_f1_score: 0.9593 - val_IoU: 0.9544\n",
      "Epoch 52/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1051 - accuracy: 0.9996 - recall: 0.7706 - precision: 0.9703 - f1_score: 0.9022 - IoU: 0.8879\n",
      "Epoch 52: val_f1_score did not improve from 0.96831\n",
      "41/41 [==============================] - 20s 487ms/step - loss: 0.1051 - accuracy: 0.9996 - recall: 0.7706 - precision: 0.9703 - f1_score: 0.9022 - IoU: 0.8879 - val_loss: 0.0531 - val_accuracy: 0.9999 - val_recall: 0.9532 - val_precision: 0.9498 - val_f1_score: 0.9485 - val_IoU: 0.9364\n",
      "Epoch 53/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0979 - accuracy: 0.9997 - recall: 0.7836 - precision: 0.9809 - f1_score: 0.9085 - IoU: 0.8921\n",
      "Epoch 53: val_f1_score did not improve from 0.96831\n",
      "41/41 [==============================] - 20s 488ms/step - loss: 0.0979 - accuracy: 0.9997 - recall: 0.7836 - precision: 0.9809 - f1_score: 0.9085 - IoU: 0.8921 - val_loss: 0.0399 - val_accuracy: 1.0000 - val_recall: 0.9806 - val_precision: 0.9456 - val_f1_score: 0.9612 - val_IoU: 0.9631\n",
      "Epoch 54/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0922 - accuracy: 0.9997 - recall: 0.7822 - precision: 0.9853 - f1_score: 0.9137 - IoU: 0.8960\n",
      "Epoch 54: val_f1_score did not improve from 0.96831\n",
      "41/41 [==============================] - 20s 488ms/step - loss: 0.0922 - accuracy: 0.9997 - recall: 0.7822 - precision: 0.9853 - f1_score: 0.9137 - IoU: 0.8960 - val_loss: 0.0394 - val_accuracy: 1.0000 - val_recall: 0.9422 - val_precision: 0.9851 - val_f1_score: 0.9586 - val_IoU: 0.9313\n",
      "Epoch 55/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1091 - accuracy: 0.9996 - recall: 0.7650 - precision: 0.9664 - f1_score: 0.8981 - IoU: 0.8870\n",
      "Epoch 55: val_f1_score did not improve from 0.96831\n",
      "41/41 [==============================] - 20s 489ms/step - loss: 0.1091 - accuracy: 0.9996 - recall: 0.7650 - precision: 0.9664 - f1_score: 0.8981 - IoU: 0.8870 - val_loss: 0.9496 - val_accuracy: 0.9994 - val_recall: 0.0349 - val_precision: 0.9978 - val_f1_score: 0.0440 - val_IoU: 0.5120\n",
      "Epoch 56/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1038 - accuracy: 0.9996 - recall: 0.7733 - precision: 0.9699 - f1_score: 0.9028 - IoU: 0.8854\n",
      "Epoch 56: val_f1_score did not improve from 0.96831\n",
      "41/41 [==============================] - 20s 499ms/step - loss: 0.1038 - accuracy: 0.9996 - recall: 0.7733 - precision: 0.9699 - f1_score: 0.9028 - IoU: 0.8854 - val_loss: 0.8862 - val_accuracy: 0.9995 - val_recall: 0.0822 - val_precision: 0.9962 - val_f1_score: 0.0993 - val_IoU: 0.5256\n",
      "Epoch 57/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1375 - accuracy: 0.9996 - recall: 0.7561 - precision: 0.9470 - f1_score: 0.8714 - IoU: 0.8657\n",
      "Epoch 57: val_f1_score did not improve from 0.96831\n",
      "41/41 [==============================] - 21s 520ms/step - loss: 0.1375 - accuracy: 0.9996 - recall: 0.7561 - precision: 0.9470 - f1_score: 0.8714 - IoU: 0.8657 - val_loss: 0.1915 - val_accuracy: 0.9998 - val_recall: 0.9596 - val_precision: 0.7566 - val_f1_score: 0.7908 - val_IoU: 0.8778\n",
      "Epoch 58/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1041 - accuracy: 0.9997 - recall: 0.7645 - precision: 0.9768 - f1_score: 0.9024 - IoU: 0.8875\n",
      "Epoch 58: val_f1_score did not improve from 0.96831\n",
      "41/41 [==============================] - 21s 520ms/step - loss: 0.1041 - accuracy: 0.9997 - recall: 0.7645 - precision: 0.9768 - f1_score: 0.9024 - IoU: 0.8875 - val_loss: 0.0650 - val_accuracy: 0.9999 - val_recall: 0.9488 - val_precision: 0.9410 - val_f1_score: 0.9344 - val_IoU: 0.9365\n",
      "Epoch 59/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0925 - accuracy: 0.9997 - recall: 0.7844 - precision: 0.9843 - f1_score: 0.9137 - IoU: 0.8950\n",
      "Epoch 59: val_f1_score did not improve from 0.96831\n",
      "41/41 [==============================] - 21s 516ms/step - loss: 0.0925 - accuracy: 0.9997 - recall: 0.7844 - precision: 0.9843 - f1_score: 0.9137 - IoU: 0.8950 - val_loss: 0.0481 - val_accuracy: 1.0000 - val_recall: 0.9340 - val_precision: 0.9806 - val_f1_score: 0.9529 - val_IoU: 0.9273\n",
      "Epoch 60/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0944 - accuracy: 0.9997 - recall: 0.7786 - precision: 0.9832 - f1_score: 0.9116 - IoU: 0.8931\n",
      "Epoch 60: val_f1_score did not improve from 0.96831\n",
      "41/41 [==============================] - 22s 527ms/step - loss: 0.0944 - accuracy: 0.9997 - recall: 0.7786 - precision: 0.9832 - f1_score: 0.9116 - IoU: 0.8931 - val_loss: 0.1559 - val_accuracy: 0.9999 - val_recall: 0.8029 - val_precision: 0.9908 - val_f1_score: 0.8494 - val_IoU: 0.8424\n",
      "Epoch 61/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0840 - accuracy: 0.9997 - recall: 0.7880 - precision: 0.9952 - f1_score: 0.9215 - IoU: 0.9011\n",
      "Epoch 61: val_f1_score did not improve from 0.96831\n",
      "41/41 [==============================] - 21s 518ms/step - loss: 0.0840 - accuracy: 0.9997 - recall: 0.7880 - precision: 0.9952 - f1_score: 0.9215 - IoU: 0.9011 - val_loss: 0.0344 - val_accuracy: 1.0000 - val_recall: 0.9546 - val_precision: 0.9809 - val_f1_score: 0.9648 - val_IoU: 0.9436\n",
      "Epoch 62/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0880 - accuracy: 0.9997 - recall: 0.7843 - precision: 0.9893 - f1_score: 0.9177 - IoU: 0.8972\n",
      "Epoch 62: val_f1_score did not improve from 0.96831\n",
      "41/41 [==============================] - 20s 494ms/step - loss: 0.0880 - accuracy: 0.9997 - recall: 0.7843 - precision: 0.9893 - f1_score: 0.9177 - IoU: 0.8972 - val_loss: 0.0358 - val_accuracy: 1.0000 - val_recall: 0.9654 - val_precision: 0.9714 - val_f1_score: 0.9571 - val_IoU: 0.9519\n",
      "Epoch 63/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0915 - accuracy: 0.9997 - recall: 0.7805 - precision: 0.9786 - f1_score: 0.9144 - IoU: 0.8981\n",
      "Epoch 63: val_f1_score did not improve from 0.96831\n",
      "41/41 [==============================] - 21s 522ms/step - loss: 0.0915 - accuracy: 0.9997 - recall: 0.7805 - precision: 0.9786 - f1_score: 0.9144 - IoU: 0.8981 - val_loss: 0.1794 - val_accuracy: 0.9998 - val_recall: 0.9624 - val_precision: 0.7540 - val_f1_score: 0.7783 - val_IoU: 0.8792\n",
      "Epoch 64/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0940 - accuracy: 0.9997 - recall: 0.7809 - precision: 0.9838 - f1_score: 0.9118 - IoU: 0.8943\n",
      "Epoch 64: val_f1_score did not improve from 0.96831\n",
      "41/41 [==============================] - 21s 522ms/step - loss: 0.0940 - accuracy: 0.9997 - recall: 0.7809 - precision: 0.9838 - f1_score: 0.9118 - IoU: 0.8943 - val_loss: 0.0476 - val_accuracy: 1.0000 - val_recall: 0.9869 - val_precision: 0.9320 - val_f1_score: 0.9274 - val_IoU: 0.9626\n",
      "Epoch 65/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0863 - accuracy: 0.9997 - recall: 0.7884 - precision: 0.9883 - f1_score: 0.9192 - IoU: 0.8973\n",
      "Epoch 65: val_f1_score did not improve from 0.96831\n",
      "41/41 [==============================] - 24s 590ms/step - loss: 0.0863 - accuracy: 0.9997 - recall: 0.7884 - precision: 0.9883 - f1_score: 0.9192 - IoU: 0.8973 - val_loss: 0.0357 - val_accuracy: 1.0000 - val_recall: 0.9642 - val_precision: 0.9737 - val_f1_score: 0.9551 - val_IoU: 0.9516\n",
      "Epoch 66/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0866 - accuracy: 0.9997 - recall: 0.7849 - precision: 0.9888 - f1_score: 0.9189 - IoU: 0.8994\n",
      "Epoch 66: val_f1_score did not improve from 0.96831\n",
      "41/41 [==============================] - 24s 594ms/step - loss: 0.0866 - accuracy: 0.9997 - recall: 0.7849 - precision: 0.9888 - f1_score: 0.9189 - IoU: 0.8994 - val_loss: 0.0391 - val_accuracy: 1.0000 - val_recall: 0.9711 - val_precision: 0.9599 - val_f1_score: 0.9492 - val_IoU: 0.9528\n",
      "Epoch 67/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0860 - accuracy: 0.9997 - recall: 0.7888 - precision: 0.9882 - f1_score: 0.9194 - IoU: 0.8956\n",
      "Epoch 67: val_f1_score did not improve from 0.96831\n",
      "41/41 [==============================] - 24s 583ms/step - loss: 0.0860 - accuracy: 0.9997 - recall: 0.7888 - precision: 0.9882 - f1_score: 0.9194 - IoU: 0.8956 - val_loss: 0.0340 - val_accuracy: 1.0000 - val_recall: 0.9587 - val_precision: 0.9790 - val_f1_score: 0.9642 - val_IoU: 0.9484\n",
      "Epoch 68/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0815 - accuracy: 0.9997 - recall: 0.7919 - precision: 0.9948 - f1_score: 0.9238 - IoU: 0.9014\n",
      "Epoch 68: val_f1_score did not improve from 0.96831\n",
      "41/41 [==============================] - 24s 588ms/step - loss: 0.0815 - accuracy: 0.9997 - recall: 0.7919 - precision: 0.9948 - f1_score: 0.9238 - IoU: 0.9014 - val_loss: 0.0463 - val_accuracy: 1.0000 - val_recall: 0.9324 - val_precision: 0.9838 - val_f1_score: 0.9439 - val_IoU: 0.9266\n",
      "Epoch 69/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0930 - accuracy: 0.9997 - recall: 0.7848 - precision: 0.9810 - f1_score: 0.9127 - IoU: 0.8896\n",
      "Epoch 69: val_f1_score did not improve from 0.96831\n",
      "41/41 [==============================] - 22s 531ms/step - loss: 0.0930 - accuracy: 0.9997 - recall: 0.7848 - precision: 0.9810 - f1_score: 0.9127 - IoU: 0.8896 - val_loss: 0.0455 - val_accuracy: 0.9999 - val_recall: 0.9231 - val_precision: 0.9888 - val_f1_score: 0.9554 - val_IoU: 0.9220\n",
      "Epoch 70/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0852 - accuracy: 0.9997 - recall: 0.7889 - precision: 0.9901 - f1_score: 0.9200 - IoU: 0.8985\n",
      "Epoch 70: val_f1_score did not improve from 0.96831\n",
      "41/41 [==============================] - 21s 516ms/step - loss: 0.0852 - accuracy: 0.9997 - recall: 0.7889 - precision: 0.9901 - f1_score: 0.9200 - IoU: 0.8985 - val_loss: 0.0388 - val_accuracy: 1.0000 - val_recall: 0.9401 - val_precision: 0.9860 - val_f1_score: 0.9596 - val_IoU: 0.9350\n",
      "Epoch 71/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0822 - accuracy: 0.9996 - recall: 0.7926 - precision: 0.9903 - f1_score: 0.9233 - IoU: 0.9017\n",
      "Epoch 71: val_f1_score did not improve from 0.96831\n",
      "41/41 [==============================] - 21s 523ms/step - loss: 0.0822 - accuracy: 0.9996 - recall: 0.7926 - precision: 0.9903 - f1_score: 0.9233 - IoU: 0.9017 - val_loss: 0.0426 - val_accuracy: 1.0000 - val_recall: 0.9618 - val_precision: 0.9603 - val_f1_score: 0.9495 - val_IoU: 0.9465\n",
      "Epoch 72/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0844 - accuracy: 0.9997 - recall: 0.7865 - precision: 0.9952 - f1_score: 0.9207 - IoU: 0.8984\n",
      "Epoch 72: val_f1_score did not improve from 0.96831\n",
      "41/41 [==============================] - 21s 521ms/step - loss: 0.0844 - accuracy: 0.9997 - recall: 0.7865 - precision: 0.9952 - f1_score: 0.9207 - IoU: 0.8984 - val_loss: 0.0336 - val_accuracy: 1.0000 - val_recall: 0.9596 - val_precision: 0.9781 - val_f1_score: 0.9659 - val_IoU: 0.9474\n",
      "Epoch 73/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0863 - accuracy: 0.9997 - recall: 0.7854 - precision: 0.9892 - f1_score: 0.9190 - IoU: 0.8971\n",
      "Epoch 73: val_f1_score did not improve from 0.96831\n",
      "41/41 [==============================] - 24s 589ms/step - loss: 0.0863 - accuracy: 0.9997 - recall: 0.7854 - precision: 0.9892 - f1_score: 0.9190 - IoU: 0.8971 - val_loss: 0.0306 - val_accuracy: 1.0000 - val_recall: 0.9698 - val_precision: 0.9729 - val_f1_score: 0.9671 - val_IoU: 0.9564\n",
      "Epoch 74/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0845 - accuracy: 0.9997 - recall: 0.7862 - precision: 0.9902 - f1_score: 0.9209 - IoU: 0.8991\n",
      "Epoch 74: val_f1_score improved from 0.96831 to 0.97128, saving model to Trans UNet DA DICE 5-fold model/model_4fold.keras\n",
      "41/41 [==============================] - 24s 574ms/step - loss: 0.0845 - accuracy: 0.9997 - recall: 0.7862 - precision: 0.9902 - f1_score: 0.9209 - IoU: 0.8991 - val_loss: 0.0280 - val_accuracy: 1.0000 - val_recall: 0.9770 - val_precision: 0.9705 - val_f1_score: 0.9713 - val_IoU: 0.9609\n",
      "Epoch 75/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0878 - accuracy: 0.9997 - recall: 0.7906 - precision: 0.9825 - f1_score: 0.9176 - IoU: 0.8929\n",
      "Epoch 75: val_f1_score did not improve from 0.97128\n",
      "41/41 [==============================] - 22s 544ms/step - loss: 0.0878 - accuracy: 0.9997 - recall: 0.7906 - precision: 0.9825 - f1_score: 0.9176 - IoU: 0.8929 - val_loss: 0.0298 - val_accuracy: 1.0000 - val_recall: 0.9724 - val_precision: 0.9735 - val_f1_score: 0.9677 - val_IoU: 0.9572\n",
      "Epoch 76/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0812 - accuracy: 0.9997 - recall: 0.7877 - precision: 0.9960 - f1_score: 0.9240 - IoU: 0.9019\n",
      "Epoch 76: val_f1_score did not improve from 0.97128\n",
      "41/41 [==============================] - 21s 516ms/step - loss: 0.0812 - accuracy: 0.9997 - recall: 0.7877 - precision: 0.9960 - f1_score: 0.9240 - IoU: 0.9019 - val_loss: 0.0320 - val_accuracy: 1.0000 - val_recall: 0.9675 - val_precision: 0.9737 - val_f1_score: 0.9668 - val_IoU: 0.9541\n",
      "Epoch 77/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0872 - accuracy: 0.9997 - recall: 0.7880 - precision: 0.9871 - f1_score: 0.9181 - IoU: 0.8941\n",
      "Epoch 77: val_f1_score did not improve from 0.97128\n",
      "41/41 [==============================] - 21s 515ms/step - loss: 0.0872 - accuracy: 0.9997 - recall: 0.7880 - precision: 0.9871 - f1_score: 0.9181 - IoU: 0.8941 - val_loss: 0.0442 - val_accuracy: 1.0000 - val_recall: 0.9680 - val_precision: 0.9632 - val_f1_score: 0.9408 - val_IoU: 0.9501\n",
      "Epoch 78/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0947 - accuracy: 0.9997 - recall: 0.7817 - precision: 0.9862 - f1_score: 0.9111 - IoU: 0.8918\n",
      "Epoch 78: val_f1_score did not improve from 0.97128\n",
      "41/41 [==============================] - 21s 516ms/step - loss: 0.0947 - accuracy: 0.9997 - recall: 0.7817 - precision: 0.9862 - f1_score: 0.9111 - IoU: 0.8918 - val_loss: 0.0764 - val_accuracy: 0.9999 - val_recall: 0.9421 - val_precision: 0.9231 - val_f1_score: 0.8970 - val_IoU: 0.9080\n",
      "Epoch 79/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0938 - accuracy: 0.9997 - recall: 0.7796 - precision: 0.9844 - f1_score: 0.9120 - IoU: 0.8909\n",
      "Epoch 79: val_f1_score did not improve from 0.97128\n",
      "41/41 [==============================] - 21s 519ms/step - loss: 0.0938 - accuracy: 0.9997 - recall: 0.7796 - precision: 0.9844 - f1_score: 0.9120 - IoU: 0.8909 - val_loss: 0.5511 - val_accuracy: 0.9996 - val_recall: 0.3220 - val_precision: 0.9650 - val_f1_score: 0.4836 - val_IoU: 0.6412\n",
      "Epoch 80/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1038 - accuracy: 0.9996 - recall: 0.7748 - precision: 0.9781 - f1_score: 0.9027 - IoU: 0.8880\n",
      "Epoch 80: val_f1_score did not improve from 0.97128\n",
      "41/41 [==============================] - 21s 510ms/step - loss: 0.1038 - accuracy: 0.9996 - recall: 0.7748 - precision: 0.9781 - f1_score: 0.9027 - IoU: 0.8880 - val_loss: 0.5178 - val_accuracy: 0.9988 - val_recall: 0.9922 - val_precision: 0.3246 - val_f1_score: 0.4461 - val_IoU: 0.6907\n",
      "Epoch 81/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0988 - accuracy: 0.9997 - recall: 0.7782 - precision: 0.9773 - f1_score: 0.9071 - IoU: 0.8877\n",
      "Epoch 81: val_f1_score did not improve from 0.97128\n",
      "41/41 [==============================] - 21s 512ms/step - loss: 0.0988 - accuracy: 0.9997 - recall: 0.7782 - precision: 0.9773 - f1_score: 0.9071 - IoU: 0.8877 - val_loss: 0.2976 - val_accuracy: 0.9997 - val_recall: 0.5767 - val_precision: 0.9861 - val_f1_score: 0.6952 - val_IoU: 0.7504\n",
      "Epoch 82/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1208 - accuracy: 0.9996 - recall: 0.7564 - precision: 0.9564 - f1_score: 0.8866 - IoU: 0.8748\n",
      "Epoch 82: val_f1_score did not improve from 0.97128\n",
      "41/41 [==============================] - 21s 523ms/step - loss: 0.1208 - accuracy: 0.9996 - recall: 0.7564 - precision: 0.9564 - f1_score: 0.8866 - IoU: 0.8748 - val_loss: 0.1200 - val_accuracy: 0.9999 - val_recall: 0.8200 - val_precision: 0.9324 - val_f1_score: 0.8880 - val_IoU: 0.8824\n",
      "Epoch 83/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0971 - accuracy: 0.9997 - recall: 0.7823 - precision: 0.9795 - f1_score: 0.9088 - IoU: 0.8877\n",
      "Epoch 83: val_f1_score did not improve from 0.97128\n",
      "41/41 [==============================] - 22s 528ms/step - loss: 0.0971 - accuracy: 0.9997 - recall: 0.7823 - precision: 0.9795 - f1_score: 0.9088 - IoU: 0.8877 - val_loss: 0.0366 - val_accuracy: 1.0000 - val_recall: 0.9721 - val_precision: 0.9619 - val_f1_score: 0.9647 - val_IoU: 0.9603\n",
      "Epoch 84/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0937 - accuracy: 0.9997 - recall: 0.7793 - precision: 0.9865 - f1_score: 0.9120 - IoU: 0.8920\n",
      "Epoch 84: val_f1_score did not improve from 0.97128\n",
      "41/41 [==============================] - 21s 507ms/step - loss: 0.0937 - accuracy: 0.9997 - recall: 0.7793 - precision: 0.9865 - f1_score: 0.9120 - IoU: 0.8920 - val_loss: 0.0359 - val_accuracy: 1.0000 - val_recall: 0.9787 - val_precision: 0.9518 - val_f1_score: 0.9637 - val_IoU: 0.9608\n",
      "Epoch 85/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0925 - accuracy: 0.9997 - recall: 0.7824 - precision: 0.9828 - f1_score: 0.9132 - IoU: 0.8930\n",
      "Epoch 85: val_f1_score did not improve from 0.97128\n",
      "41/41 [==============================] - 21s 504ms/step - loss: 0.0925 - accuracy: 0.9997 - recall: 0.7824 - precision: 0.9828 - f1_score: 0.9132 - IoU: 0.8930 - val_loss: 0.0392 - val_accuracy: 1.0000 - val_recall: 0.9819 - val_precision: 0.9511 - val_f1_score: 0.9624 - val_IoU: 0.9636\n",
      "Epoch 86/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0887 - accuracy: 0.9997 - recall: 0.7849 - precision: 0.9841 - f1_score: 0.9168 - IoU: 0.8952\n",
      "Epoch 86: val_f1_score did not improve from 0.97128\n",
      "41/41 [==============================] - 21s 518ms/step - loss: 0.0887 - accuracy: 0.9997 - recall: 0.7849 - precision: 0.9841 - f1_score: 0.9168 - IoU: 0.8952 - val_loss: 0.0399 - val_accuracy: 1.0000 - val_recall: 0.9408 - val_precision: 0.9854 - val_f1_score: 0.9566 - val_IoU: 0.9334\n",
      "Epoch 87/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0856 - accuracy: 0.9997 - recall: 0.7899 - precision: 0.9882 - f1_score: 0.9198 - IoU: 0.8963\n",
      "Epoch 87: val_f1_score did not improve from 0.97128\n",
      "41/41 [==============================] - 23s 565ms/step - loss: 0.0856 - accuracy: 0.9997 - recall: 0.7899 - precision: 0.9882 - f1_score: 0.9198 - IoU: 0.8963 - val_loss: 0.0530 - val_accuracy: 0.9999 - val_recall: 0.9142 - val_precision: 0.9912 - val_f1_score: 0.9324 - val_IoU: 0.9121\n",
      "Epoch 88/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0890 - accuracy: 0.9997 - recall: 0.7843 - precision: 0.9871 - f1_score: 0.9164 - IoU: 0.8947\n",
      "Epoch 88: val_f1_score did not improve from 0.97128\n",
      "41/41 [==============================] - 20s 488ms/step - loss: 0.0890 - accuracy: 0.9997 - recall: 0.7843 - precision: 0.9871 - f1_score: 0.9164 - IoU: 0.8947 - val_loss: 0.0310 - val_accuracy: 1.0000 - val_recall: 0.9711 - val_precision: 0.9744 - val_f1_score: 0.9632 - val_IoU: 0.9553\n",
      "Epoch 89/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0856 - accuracy: 0.9997 - recall: 0.7858 - precision: 0.9882 - f1_score: 0.9197 - IoU: 0.8957\n",
      "Epoch 89: val_f1_score did not improve from 0.97128\n",
      "41/41 [==============================] - 20s 494ms/step - loss: 0.0856 - accuracy: 0.9997 - recall: 0.7858 - precision: 0.9882 - f1_score: 0.9197 - IoU: 0.8957 - val_loss: 0.0305 - val_accuracy: 1.0000 - val_recall: 0.9688 - val_precision: 0.9740 - val_f1_score: 0.9684 - val_IoU: 0.9545\n",
      "Epoch 90/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0863 - accuracy: 0.9997 - recall: 0.7863 - precision: 0.9882 - f1_score: 0.9191 - IoU: 0.8979\n",
      "Epoch 90: val_f1_score did not improve from 0.97128\n",
      "41/41 [==============================] - 21s 513ms/step - loss: 0.0863 - accuracy: 0.9997 - recall: 0.7863 - precision: 0.9882 - f1_score: 0.9191 - IoU: 0.8979 - val_loss: 0.0323 - val_accuracy: 1.0000 - val_recall: 0.9638 - val_precision: 0.9764 - val_f1_score: 0.9644 - val_IoU: 0.9495\n",
      "Epoch 91/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0860 - accuracy: 0.9997 - recall: 0.7891 - precision: 0.9880 - f1_score: 0.9193 - IoU: 0.8940\n",
      "Epoch 91: val_f1_score did not improve from 0.97128\n",
      "41/41 [==============================] - 20s 488ms/step - loss: 0.0860 - accuracy: 0.9997 - recall: 0.7891 - precision: 0.9880 - f1_score: 0.9193 - IoU: 0.8940 - val_loss: 0.0391 - val_accuracy: 1.0000 - val_recall: 0.9512 - val_precision: 0.9808 - val_f1_score: 0.9494 - val_IoU: 0.9438\n",
      "Epoch 92/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0873 - accuracy: 0.9997 - recall: 0.7852 - precision: 0.9893 - f1_score: 0.9177 - IoU: 0.8924\n",
      "Epoch 92: val_f1_score did not improve from 0.97128\n",
      "41/41 [==============================] - 21s 525ms/step - loss: 0.0873 - accuracy: 0.9997 - recall: 0.7852 - precision: 0.9893 - f1_score: 0.9177 - IoU: 0.8924 - val_loss: 0.0320 - val_accuracy: 1.0000 - val_recall: 0.9694 - val_precision: 0.9736 - val_f1_score: 0.9585 - val_IoU: 0.9563\n",
      "Epoch 93/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0833 - accuracy: 0.9997 - recall: 0.7936 - precision: 0.9906 - f1_score: 0.9220 - IoU: 0.8959\n",
      "Epoch 93: val_f1_score did not improve from 0.97128\n",
      "41/41 [==============================] - 20s 498ms/step - loss: 0.0833 - accuracy: 0.9997 - recall: 0.7936 - precision: 0.9906 - f1_score: 0.9220 - IoU: 0.8959 - val_loss: 0.0276 - val_accuracy: 1.0000 - val_recall: 0.9802 - val_precision: 0.9679 - val_f1_score: 0.9710 - val_IoU: 0.9642\n",
      "Epoch 94/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0842 - accuracy: 0.9997 - recall: 0.7923 - precision: 0.9891 - f1_score: 0.9208 - IoU: 0.8939\n",
      "Epoch 94: val_f1_score did not improve from 0.97128\n",
      "41/41 [==============================] - 21s 515ms/step - loss: 0.0842 - accuracy: 0.9997 - recall: 0.7923 - precision: 0.9891 - f1_score: 0.9208 - IoU: 0.8939 - val_loss: 0.0320 - val_accuracy: 1.0000 - val_recall: 0.9543 - val_precision: 0.9848 - val_f1_score: 0.9667 - val_IoU: 0.9478\n",
      "Epoch 95/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0828 - accuracy: 0.9997 - recall: 0.7879 - precision: 0.9902 - f1_score: 0.9224 - IoU: 0.8996\n",
      "Epoch 95: val_f1_score did not improve from 0.97128\n",
      "41/41 [==============================] - 21s 509ms/step - loss: 0.0828 - accuracy: 0.9997 - recall: 0.7879 - precision: 0.9902 - f1_score: 0.9224 - IoU: 0.8996 - val_loss: 0.0285 - val_accuracy: 1.0000 - val_recall: 0.9673 - val_precision: 0.9797 - val_f1_score: 0.9700 - val_IoU: 0.9553\n",
      "Epoch 96/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0818 - accuracy: 0.9997 - recall: 0.7827 - precision: 0.9953 - f1_score: 0.9232 - IoU: 0.8970\n",
      "Epoch 96: val_f1_score did not improve from 0.97128\n",
      "41/41 [==============================] - 21s 511ms/step - loss: 0.0818 - accuracy: 0.9997 - recall: 0.7827 - precision: 0.9953 - f1_score: 0.9232 - IoU: 0.8970 - val_loss: 0.0295 - val_accuracy: 1.0000 - val_recall: 0.9631 - val_precision: 0.9821 - val_f1_score: 0.9690 - val_IoU: 0.9534\n",
      "Epoch 97/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0869 - accuracy: 0.9997 - recall: 0.7897 - precision: 0.9883 - f1_score: 0.9182 - IoU: 0.8929\n",
      "Epoch 97: val_f1_score did not improve from 0.97128\n",
      "41/41 [==============================] - 21s 505ms/step - loss: 0.0869 - accuracy: 0.9997 - recall: 0.7897 - precision: 0.9883 - f1_score: 0.9182 - IoU: 0.8929 - val_loss: 0.0370 - val_accuracy: 1.0000 - val_recall: 0.9427 - val_precision: 0.9867 - val_f1_score: 0.9628 - val_IoU: 0.9380\n",
      "Epoch 98/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0844 - accuracy: 0.9997 - recall: 0.7876 - precision: 0.9887 - f1_score: 0.9207 - IoU: 0.8950\n",
      "Epoch 98: val_f1_score did not improve from 0.97128\n",
      "41/41 [==============================] - 21s 502ms/step - loss: 0.0844 - accuracy: 0.9997 - recall: 0.7876 - precision: 0.9887 - f1_score: 0.9207 - IoU: 0.8950 - val_loss: 0.0325 - val_accuracy: 1.0000 - val_recall: 0.9540 - val_precision: 0.9854 - val_f1_score: 0.9680 - val_IoU: 0.9486\n",
      "Epoch 99/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0818 - accuracy: 0.9997 - recall: 0.7948 - precision: 0.9901 - f1_score: 0.9232 - IoU: 0.8970\n",
      "Epoch 99: val_f1_score improved from 0.97128 to 0.97176, saving model to Trans UNet DA DICE 5-fold model/model_4fold.keras\n",
      "41/41 [==============================] - 20s 500ms/step - loss: 0.0818 - accuracy: 0.9997 - recall: 0.7948 - precision: 0.9901 - f1_score: 0.9232 - IoU: 0.8970 - val_loss: 0.0274 - val_accuracy: 1.0000 - val_recall: 0.9771 - val_precision: 0.9720 - val_f1_score: 0.9718 - val_IoU: 0.9637\n",
      "Epoch 100/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0831 - accuracy: 0.9997 - recall: 0.7848 - precision: 0.9910 - f1_score: 0.9219 - IoU: 0.8968\n",
      "Epoch 100: val_f1_score did not improve from 0.97176\n",
      "41/41 [==============================] - 20s 499ms/step - loss: 0.0831 - accuracy: 0.9997 - recall: 0.7848 - precision: 0.9910 - f1_score: 0.9219 - IoU: 0.8968 - val_loss: 0.0296 - val_accuracy: 1.0000 - val_recall: 0.9857 - val_precision: 0.9593 - val_f1_score: 0.9663 - val_IoU: 0.9708\n",
      "Epoch 101/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0820 - accuracy: 0.9997 - recall: 0.7905 - precision: 0.9910 - f1_score: 0.9229 - IoU: 0.8952\n",
      "Epoch 101: val_f1_score did not improve from 0.97176\n",
      "41/41 [==============================] - 21s 510ms/step - loss: 0.0820 - accuracy: 0.9997 - recall: 0.7905 - precision: 0.9910 - f1_score: 0.9229 - IoU: 0.8952 - val_loss: 0.0281 - val_accuracy: 1.0000 - val_recall: 0.9680 - val_precision: 0.9788 - val_f1_score: 0.9699 - val_IoU: 0.9583\n",
      "Epoch 102/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0854 - accuracy: 0.9997 - recall: 0.7896 - precision: 0.9894 - f1_score: 0.9198 - IoU: 0.8888\n",
      "Epoch 102: val_f1_score did not improve from 0.97176\n",
      "41/41 [==============================] - 20s 494ms/step - loss: 0.0854 - accuracy: 0.9997 - recall: 0.7896 - precision: 0.9894 - f1_score: 0.9198 - IoU: 0.8888 - val_loss: 0.0274 - val_accuracy: 1.0000 - val_recall: 0.9679 - val_precision: 0.9810 - val_f1_score: 0.9717 - val_IoU: 0.9583\n",
      "Epoch 103/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0858 - accuracy: 0.9997 - recall: 0.7851 - precision: 0.9849 - f1_score: 0.9192 - IoU: 0.8956\n",
      "Epoch 103: val_f1_score did not improve from 0.97176\n",
      "41/41 [==============================] - 21s 501ms/step - loss: 0.0858 - accuracy: 0.9997 - recall: 0.7851 - precision: 0.9849 - f1_score: 0.9192 - IoU: 0.8956 - val_loss: 0.0285 - val_accuracy: 1.0000 - val_recall: 0.9757 - val_precision: 0.9723 - val_f1_score: 0.9706 - val_IoU: 0.9629\n",
      "Epoch 104/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0832 - accuracy: 0.9997 - recall: 0.7873 - precision: 0.9951 - f1_score: 0.9219 - IoU: 0.8948\n",
      "Epoch 104: val_f1_score did not improve from 0.97176\n",
      "41/41 [==============================] - 21s 518ms/step - loss: 0.0832 - accuracy: 0.9997 - recall: 0.7873 - precision: 0.9951 - f1_score: 0.9219 - IoU: 0.8948 - val_loss: 0.0299 - val_accuracy: 1.0000 - val_recall: 0.9620 - val_precision: 0.9831 - val_f1_score: 0.9690 - val_IoU: 0.9528\n",
      "Epoch 105/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0877 - accuracy: 0.9997 - recall: 0.7872 - precision: 0.9840 - f1_score: 0.9173 - IoU: 0.8917\n",
      "Epoch 105: val_f1_score did not improve from 0.97176\n",
      "41/41 [==============================] - 22s 534ms/step - loss: 0.0877 - accuracy: 0.9997 - recall: 0.7872 - precision: 0.9840 - f1_score: 0.9173 - IoU: 0.8917 - val_loss: 0.0366 - val_accuracy: 1.0000 - val_recall: 0.9508 - val_precision: 0.9846 - val_f1_score: 0.9605 - val_IoU: 0.9481\n",
      "Epoch 106/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0812 - accuracy: 0.9997 - recall: 0.7915 - precision: 0.9958 - f1_score: 0.9238 - IoU: 0.8967\n",
      "Epoch 106: val_f1_score did not improve from 0.97176\n",
      "41/41 [==============================] - 20s 490ms/step - loss: 0.0812 - accuracy: 0.9997 - recall: 0.7915 - precision: 0.9958 - f1_score: 0.9238 - IoU: 0.8967 - val_loss: 0.0327 - val_accuracy: 1.0000 - val_recall: 0.9693 - val_precision: 0.9765 - val_f1_score: 0.9540 - val_IoU: 0.9594\n",
      "Epoch 107/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0828 - accuracy: 0.9997 - recall: 0.7943 - precision: 0.9883 - f1_score: 0.9222 - IoU: 0.8906\n",
      "Epoch 107: val_f1_score did not improve from 0.97176\n",
      "41/41 [==============================] - 21s 520ms/step - loss: 0.0828 - accuracy: 0.9997 - recall: 0.7943 - precision: 0.9883 - f1_score: 0.9222 - IoU: 0.8906 - val_loss: 0.0799 - val_accuracy: 0.9999 - val_recall: 0.9855 - val_precision: 0.8698 - val_f1_score: 0.8918 - val_IoU: 0.9398\n",
      "Epoch 108/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0847 - accuracy: 0.9997 - recall: 0.7872 - precision: 0.9891 - f1_score: 0.9204 - IoU: 0.8924\n",
      "Epoch 108: val_f1_score did not improve from 0.97176\n",
      "41/41 [==============================] - 21s 520ms/step - loss: 0.0847 - accuracy: 0.9997 - recall: 0.7872 - precision: 0.9891 - f1_score: 0.9204 - IoU: 0.8924 - val_loss: 0.0282 - val_accuracy: 1.0000 - val_recall: 0.9730 - val_precision: 0.9750 - val_f1_score: 0.9704 - val_IoU: 0.9626\n",
      "Epoch 109/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0835 - accuracy: 0.9997 - recall: 0.7963 - precision: 0.9840 - f1_score: 0.9216 - IoU: 0.8916\n",
      "Epoch 109: val_f1_score did not improve from 0.97176\n",
      "41/41 [==============================] - 24s 595ms/step - loss: 0.0835 - accuracy: 0.9997 - recall: 0.7963 - precision: 0.9840 - f1_score: 0.9216 - IoU: 0.8916 - val_loss: 0.0280 - val_accuracy: 1.0000 - val_recall: 0.9686 - val_precision: 0.9795 - val_f1_score: 0.9699 - val_IoU: 0.9582\n",
      "Epoch 110/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0830 - accuracy: 0.9997 - recall: 0.7932 - precision: 0.9886 - f1_score: 0.9220 - IoU: 0.8932\n",
      "Epoch 110: val_f1_score did not improve from 0.97176\n",
      "41/41 [==============================] - 22s 533ms/step - loss: 0.0830 - accuracy: 0.9997 - recall: 0.7932 - precision: 0.9886 - f1_score: 0.9220 - IoU: 0.8932 - val_loss: 0.0603 - val_accuracy: 0.9999 - val_recall: 0.9154 - val_precision: 0.9590 - val_f1_score: 0.9384 - val_IoU: 0.9334\n",
      "Epoch 111/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0798 - accuracy: 0.9997 - recall: 0.7909 - precision: 0.9953 - f1_score: 0.9250 - IoU: 0.8943\n",
      "Epoch 111: val_f1_score did not improve from 0.97176\n",
      "41/41 [==============================] - 23s 562ms/step - loss: 0.0798 - accuracy: 0.9997 - recall: 0.7909 - precision: 0.9953 - f1_score: 0.9250 - IoU: 0.8943 - val_loss: 0.0334 - val_accuracy: 1.0000 - val_recall: 0.9638 - val_precision: 0.9733 - val_f1_score: 0.9655 - val_IoU: 0.9583\n",
      "Epoch 112/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0847 - accuracy: 0.9997 - recall: 0.7880 - precision: 0.9896 - f1_score: 0.9203 - IoU: 0.8936\n",
      "Epoch 112: val_f1_score did not improve from 0.97176\n",
      "41/41 [==============================] - 23s 564ms/step - loss: 0.0847 - accuracy: 0.9997 - recall: 0.7880 - precision: 0.9896 - f1_score: 0.9203 - IoU: 0.8936 - val_loss: 0.0409 - val_accuracy: 1.0000 - val_recall: 0.9362 - val_precision: 0.9901 - val_f1_score: 0.9528 - val_IoU: 0.9371\n",
      "Epoch 113/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0869 - accuracy: 0.9997 - recall: 0.7867 - precision: 0.9880 - f1_score: 0.9182 - IoU: 0.8856\n",
      "Epoch 113: val_f1_score did not improve from 0.97176\n",
      "41/41 [==============================] - 21s 509ms/step - loss: 0.0869 - accuracy: 0.9997 - recall: 0.7867 - precision: 0.9880 - f1_score: 0.9182 - IoU: 0.8856 - val_loss: 0.0667 - val_accuracy: 0.9999 - val_recall: 0.9648 - val_precision: 0.9214 - val_f1_score: 0.9041 - val_IoU: 0.9409\n",
      "Epoch 114/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0842 - accuracy: 0.9996 - recall: 0.7838 - precision: 0.9899 - f1_score: 0.9211 - IoU: 0.8931\n",
      "Epoch 114: val_f1_score did not improve from 0.97176\n",
      "41/41 [==============================] - 23s 568ms/step - loss: 0.0842 - accuracy: 0.9996 - recall: 0.7838 - precision: 0.9899 - f1_score: 0.9211 - IoU: 0.8931 - val_loss: 0.0714 - val_accuracy: 0.9999 - val_recall: 0.9728 - val_precision: 0.9201 - val_f1_score: 0.9144 - val_IoU: 0.9447\n",
      "Epoch 115/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0975 - accuracy: 0.9997 - recall: 0.7795 - precision: 0.9738 - f1_score: 0.9081 - IoU: 0.8869\n",
      "Epoch 115: val_f1_score did not improve from 0.97176\n",
      "41/41 [==============================] - 25s 625ms/step - loss: 0.0975 - accuracy: 0.9997 - recall: 0.7795 - precision: 0.9738 - f1_score: 0.9081 - IoU: 0.8869 - val_loss: 0.5679 - val_accuracy: 0.9996 - val_recall: 0.2545 - val_precision: 0.9941 - val_f1_score: 0.4454 - val_IoU: 0.6101\n",
      "Epoch 116/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0924 - accuracy: 0.9997 - recall: 0.7808 - precision: 0.9857 - f1_score: 0.9134 - IoU: 0.8909\n",
      "Epoch 116: val_f1_score did not improve from 0.97176\n",
      "41/41 [==============================] - 25s 609ms/step - loss: 0.0924 - accuracy: 0.9997 - recall: 0.7808 - precision: 0.9857 - f1_score: 0.9134 - IoU: 0.8909 - val_loss: 0.0947 - val_accuracy: 0.9999 - val_recall: 0.9876 - val_precision: 0.8308 - val_f1_score: 0.9124 - val_IoU: 0.9259\n",
      "Epoch 117/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1243 - accuracy: 0.9996 - recall: 0.7658 - precision: 0.9283 - f1_score: 0.8831 - IoU: 0.8667\n",
      "Epoch 117: val_f1_score did not improve from 0.97176\n",
      "41/41 [==============================] - 26s 628ms/step - loss: 0.1243 - accuracy: 0.9996 - recall: 0.7658 - precision: 0.9283 - f1_score: 0.8831 - IoU: 0.8667 - val_loss: 0.9324 - val_accuracy: 0.9791 - val_recall: 0.9977 - val_precision: 0.0272 - val_f1_score: 0.0628 - val_IoU: 0.5102\n",
      "Epoch 118/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1011 - accuracy: 0.9996 - recall: 0.7714 - precision: 0.9757 - f1_score: 0.9051 - IoU: 0.8843\n",
      "Epoch 118: val_f1_score did not improve from 0.97176\n",
      "41/41 [==============================] - 25s 620ms/step - loss: 0.1011 - accuracy: 0.9996 - recall: 0.7714 - precision: 0.9757 - f1_score: 0.9051 - IoU: 0.8843 - val_loss: 0.1456 - val_accuracy: 0.9999 - val_recall: 0.8289 - val_precision: 0.9650 - val_f1_score: 0.8320 - val_IoU: 0.8933\n",
      "Epoch 119/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0900 - accuracy: 0.9997 - recall: 0.7812 - precision: 0.9861 - f1_score: 0.9152 - IoU: 0.8905\n",
      "Epoch 119: val_f1_score did not improve from 0.97176\n",
      "41/41 [==============================] - 27s 653ms/step - loss: 0.0900 - accuracy: 0.9997 - recall: 0.7812 - precision: 0.9861 - f1_score: 0.9152 - IoU: 0.8905 - val_loss: 0.6297 - val_accuracy: 0.9996 - val_recall: 0.2932 - val_precision: 0.9865 - val_f1_score: 0.3223 - val_IoU: 0.6349\n",
      "Epoch 120/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1220 - accuracy: 0.9996 - recall: 0.7532 - precision: 0.9660 - f1_score: 0.8853 - IoU: 0.8725\n",
      "Epoch 120: val_f1_score did not improve from 0.97176\n",
      "41/41 [==============================] - 28s 679ms/step - loss: 0.1220 - accuracy: 0.9996 - recall: 0.7532 - precision: 0.9660 - f1_score: 0.8853 - IoU: 0.8725 - val_loss: 0.1870 - val_accuracy: 0.9997 - val_recall: 0.9847 - val_precision: 0.6622 - val_f1_score: 0.8281 - val_IoU: 0.8880\n",
      "Epoch 121/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1108 - accuracy: 0.9996 - recall: 0.7661 - precision: 0.9646 - f1_score: 0.8958 - IoU: 0.8755\n",
      "Epoch 121: val_f1_score did not improve from 0.97176\n",
      "41/41 [==============================] - 28s 686ms/step - loss: 0.1108 - accuracy: 0.9996 - recall: 0.7661 - precision: 0.9646 - f1_score: 0.8958 - IoU: 0.8755 - val_loss: 0.7129 - val_accuracy: 0.9995 - val_recall: 0.1752 - val_precision: 0.9855 - val_f1_score: 0.3209 - val_IoU: 0.5738\n",
      "Epoch 122/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0922 - accuracy: 0.9997 - recall: 0.7838 - precision: 0.9854 - f1_score: 0.9133 - IoU: 0.8880\n",
      "Epoch 122: val_f1_score did not improve from 0.97176\n",
      "41/41 [==============================] - 27s 652ms/step - loss: 0.0922 - accuracy: 0.9997 - recall: 0.7838 - precision: 0.9854 - f1_score: 0.9133 - IoU: 0.8880 - val_loss: 0.5329 - val_accuracy: 0.9996 - val_recall: 0.3245 - val_precision: 0.9934 - val_f1_score: 0.4886 - val_IoU: 0.6352\n",
      "Epoch 123/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0881 - accuracy: 0.9997 - recall: 0.7842 - precision: 0.9863 - f1_score: 0.9172 - IoU: 0.8907\n",
      "Epoch 123: val_f1_score did not improve from 0.97176\n",
      "41/41 [==============================] - 23s 557ms/step - loss: 0.0881 - accuracy: 0.9997 - recall: 0.7842 - precision: 0.9863 - f1_score: 0.9172 - IoU: 0.8907 - val_loss: 0.0370 - val_accuracy: 1.0000 - val_recall: 0.9609 - val_precision: 0.9713 - val_f1_score: 0.9521 - val_IoU: 0.9538\n",
      "Epoch 124/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0862 - accuracy: 0.9997 - recall: 0.7910 - precision: 0.9872 - f1_score: 0.9190 - IoU: 0.8906\n",
      "Epoch 124: val_f1_score did not improve from 0.97176\n",
      "41/41 [==============================] - 29s 712ms/step - loss: 0.0862 - accuracy: 0.9997 - recall: 0.7910 - precision: 0.9872 - f1_score: 0.9190 - IoU: 0.8906 - val_loss: 0.0355 - val_accuracy: 1.0000 - val_recall: 0.9599 - val_precision: 0.9793 - val_f1_score: 0.9532 - val_IoU: 0.9518\n",
      "Epoch 125/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0843 - accuracy: 0.9997 - recall: 0.7869 - precision: 0.9892 - f1_score: 0.9209 - IoU: 0.8911\n",
      "Epoch 125: val_f1_score did not improve from 0.97176\n",
      "41/41 [==============================] - 25s 610ms/step - loss: 0.0843 - accuracy: 0.9997 - recall: 0.7869 - precision: 0.9892 - f1_score: 0.9209 - IoU: 0.8911 - val_loss: 0.0431 - val_accuracy: 1.0000 - val_recall: 0.9760 - val_precision: 0.9613 - val_f1_score: 0.9130 - val_IoU: 0.9610\n",
      "Epoch 126/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0827 - accuracy: 0.9997 - recall: 0.7869 - precision: 0.9899 - f1_score: 0.9223 - IoU: 0.8936\n",
      "Epoch 126: val_f1_score did not improve from 0.97176\n",
      "41/41 [==============================] - 21s 504ms/step - loss: 0.0827 - accuracy: 0.9997 - recall: 0.7869 - precision: 0.9899 - f1_score: 0.9223 - IoU: 0.8936 - val_loss: 0.0341 - val_accuracy: 1.0000 - val_recall: 0.9645 - val_precision: 0.9789 - val_f1_score: 0.9506 - val_IoU: 0.9561\n",
      "Epoch 127/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0843 - accuracy: 0.9997 - recall: 0.7882 - precision: 0.9895 - f1_score: 0.9208 - IoU: 0.8929\n",
      "Epoch 127: val_f1_score did not improve from 0.97176\n",
      "41/41 [==============================] - 22s 550ms/step - loss: 0.0843 - accuracy: 0.9997 - recall: 0.7882 - precision: 0.9895 - f1_score: 0.9208 - IoU: 0.8929 - val_loss: 0.0324 - val_accuracy: 1.0000 - val_recall: 0.9595 - val_precision: 0.9828 - val_f1_score: 0.9592 - val_IoU: 0.9531\n",
      "Epoch 128/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0851 - accuracy: 0.9997 - recall: 0.7852 - precision: 0.9896 - f1_score: 0.9199 - IoU: 0.8920\n",
      "Epoch 128: val_f1_score did not improve from 0.97176\n",
      "41/41 [==============================] - 21s 517ms/step - loss: 0.0851 - accuracy: 0.9997 - recall: 0.7852 - precision: 0.9896 - f1_score: 0.9199 - IoU: 0.8920 - val_loss: 0.0308 - val_accuracy: 1.0000 - val_recall: 0.9778 - val_precision: 0.9689 - val_f1_score: 0.9567 - val_IoU: 0.9660\n",
      "Epoch 129/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0827 - accuracy: 0.9997 - recall: 0.7895 - precision: 0.9893 - f1_score: 0.9225 - IoU: 0.8956\n",
      "Epoch 129: val_f1_score did not improve from 0.97176\n",
      "41/41 [==============================] - 25s 603ms/step - loss: 0.0827 - accuracy: 0.9997 - recall: 0.7895 - precision: 0.9893 - f1_score: 0.9225 - IoU: 0.8956 - val_loss: 0.0446 - val_accuracy: 1.0000 - val_recall: 0.9283 - val_precision: 0.9875 - val_f1_score: 0.9511 - val_IoU: 0.9340\n",
      "Epoch 130/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0888 - accuracy: 0.9997 - recall: 0.7877 - precision: 0.9893 - f1_score: 0.9164 - IoU: 0.8863\n",
      "Epoch 130: val_f1_score did not improve from 0.97176\n",
      "41/41 [==============================] - 23s 565ms/step - loss: 0.0888 - accuracy: 0.9997 - recall: 0.7877 - precision: 0.9893 - f1_score: 0.9164 - IoU: 0.8863 - val_loss: 0.0407 - val_accuracy: 1.0000 - val_recall: 0.9724 - val_precision: 0.9618 - val_f1_score: 0.9494 - val_IoU: 0.9596\n",
      "Epoch 131/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0875 - accuracy: 0.9997 - recall: 0.7807 - precision: 0.9883 - f1_score: 0.9176 - IoU: 0.8908\n",
      "Epoch 131: val_f1_score did not improve from 0.97176\n",
      "41/41 [==============================] - 22s 532ms/step - loss: 0.0875 - accuracy: 0.9997 - recall: 0.7807 - precision: 0.9883 - f1_score: 0.9176 - IoU: 0.8908 - val_loss: 0.1208 - val_accuracy: 0.9999 - val_recall: 0.9715 - val_precision: 0.8591 - val_f1_score: 0.8161 - val_IoU: 0.9161\n",
      "Epoch 132/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0919 - accuracy: 0.9997 - recall: 0.7879 - precision: 0.9799 - f1_score: 0.9134 - IoU: 0.8883\n",
      "Epoch 132: val_f1_score did not improve from 0.97176\n",
      "41/41 [==============================] - 23s 562ms/step - loss: 0.0919 - accuracy: 0.9997 - recall: 0.7879 - precision: 0.9799 - f1_score: 0.9134 - IoU: 0.8883 - val_loss: 0.0942 - val_accuracy: 0.9999 - val_recall: 0.9697 - val_precision: 0.8957 - val_f1_score: 0.8404 - val_IoU: 0.9343\n",
      "Epoch 133/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0869 - accuracy: 0.9997 - recall: 0.7853 - precision: 0.9878 - f1_score: 0.9183 - IoU: 0.8918\n",
      "Epoch 133: val_f1_score did not improve from 0.97176\n",
      "41/41 [==============================] - 22s 527ms/step - loss: 0.0869 - accuracy: 0.9997 - recall: 0.7853 - precision: 0.9878 - f1_score: 0.9183 - IoU: 0.8918 - val_loss: 0.0974 - val_accuracy: 0.9999 - val_recall: 0.9854 - val_precision: 0.8756 - val_f1_score: 0.8383 - val_IoU: 0.9447\n",
      "Epoch 134/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0840 - accuracy: 0.9997 - recall: 0.7859 - precision: 0.9895 - f1_score: 0.9208 - IoU: 0.8909\n",
      "Epoch 134: val_f1_score did not improve from 0.97176\n",
      "41/41 [==============================] - 22s 541ms/step - loss: 0.0840 - accuracy: 0.9997 - recall: 0.7859 - precision: 0.9895 - f1_score: 0.9208 - IoU: 0.8909 - val_loss: 0.0326 - val_accuracy: 1.0000 - val_recall: 0.9695 - val_precision: 0.9744 - val_f1_score: 0.9554 - val_IoU: 0.9602\n",
      "Epoch 135/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0826 - accuracy: 0.9997 - recall: 0.7958 - precision: 0.9895 - f1_score: 0.9223 - IoU: 0.8910\n",
      "Epoch 135: val_f1_score did not improve from 0.97176\n",
      "41/41 [==============================] - 23s 554ms/step - loss: 0.0826 - accuracy: 0.9997 - recall: 0.7958 - precision: 0.9895 - f1_score: 0.9223 - IoU: 0.8910 - val_loss: 0.0307 - val_accuracy: 1.0000 - val_recall: 0.9636 - val_precision: 0.9813 - val_f1_score: 0.9633 - val_IoU: 0.9570\n",
      "Epoch 136/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0852 - accuracy: 0.9997 - recall: 0.7838 - precision: 0.9892 - f1_score: 0.9198 - IoU: 0.8939\n",
      "Epoch 136: val_f1_score did not improve from 0.97176\n",
      "41/41 [==============================] - 27s 665ms/step - loss: 0.0852 - accuracy: 0.9997 - recall: 0.7838 - precision: 0.9892 - f1_score: 0.9198 - IoU: 0.8939 - val_loss: 0.0308 - val_accuracy: 1.0000 - val_recall: 0.9775 - val_precision: 0.9697 - val_f1_score: 0.9580 - val_IoU: 0.9658\n",
      "Epoch 137/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0822 - accuracy: 0.9997 - recall: 0.7940 - precision: 0.9891 - f1_score: 0.9227 - IoU: 0.8915\n",
      "Epoch 137: val_f1_score did not improve from 0.97176\n",
      "41/41 [==============================] - 34s 835ms/step - loss: 0.0822 - accuracy: 0.9997 - recall: 0.7940 - precision: 0.9891 - f1_score: 0.9227 - IoU: 0.8915 - val_loss: 0.0315 - val_accuracy: 1.0000 - val_recall: 0.9534 - val_precision: 0.9869 - val_f1_score: 0.9673 - val_IoU: 0.9513\n",
      "Epoch 138/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0820 - accuracy: 0.9997 - recall: 0.7835 - precision: 0.9961 - f1_score: 0.9228 - IoU: 0.8920\n",
      "Epoch 138: val_f1_score did not improve from 0.97176\n",
      "41/41 [==============================] - 31s 758ms/step - loss: 0.0820 - accuracy: 0.9997 - recall: 0.7835 - precision: 0.9961 - f1_score: 0.9228 - IoU: 0.8920 - val_loss: 0.0263 - val_accuracy: 1.0000 - val_recall: 0.9731 - val_precision: 0.9779 - val_f1_score: 0.9709 - val_IoU: 0.9635\n",
      "Epoch 139/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0809 - accuracy: 0.9997 - recall: 0.7952 - precision: 0.9906 - f1_score: 0.9241 - IoU: 0.8919\n",
      "Epoch 139: val_f1_score did not improve from 0.97176\n",
      "41/41 [==============================] - 28s 684ms/step - loss: 0.0809 - accuracy: 0.9997 - recall: 0.7952 - precision: 0.9906 - f1_score: 0.9241 - IoU: 0.8919 - val_loss: 0.0264 - val_accuracy: 1.0000 - val_recall: 0.9762 - val_precision: 0.9742 - val_f1_score: 0.9718 - val_IoU: 0.9655\n",
      "Epoch 140/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0825 - accuracy: 0.9997 - recall: 0.7905 - precision: 0.9903 - f1_score: 0.9222 - IoU: 0.8925\n",
      "Epoch 140: val_f1_score did not improve from 0.97176\n",
      "41/41 [==============================] - 22s 542ms/step - loss: 0.0825 - accuracy: 0.9997 - recall: 0.7905 - precision: 0.9903 - f1_score: 0.9222 - IoU: 0.8925 - val_loss: 0.0268 - val_accuracy: 1.0000 - val_recall: 0.9692 - val_precision: 0.9802 - val_f1_score: 0.9711 - val_IoU: 0.9629\n",
      "Epoch 141/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0821 - accuracy: 0.9997 - recall: 0.7870 - precision: 0.9907 - f1_score: 0.9228 - IoU: 0.8938\n",
      "Epoch 141: val_f1_score did not improve from 0.97176\n",
      "41/41 [==============================] - 22s 548ms/step - loss: 0.0821 - accuracy: 0.9997 - recall: 0.7870 - precision: 0.9907 - f1_score: 0.9228 - IoU: 0.8938 - val_loss: 0.0288 - val_accuracy: 1.0000 - val_recall: 0.9625 - val_precision: 0.9834 - val_f1_score: 0.9701 - val_IoU: 0.9575\n",
      "Epoch 142/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0851 - accuracy: 0.9997 - recall: 0.7920 - precision: 0.9846 - f1_score: 0.9197 - IoU: 0.8876\n",
      "Epoch 142: val_f1_score did not improve from 0.97176\n",
      "41/41 [==============================] - 23s 565ms/step - loss: 0.0851 - accuracy: 0.9997 - recall: 0.7920 - precision: 0.9846 - f1_score: 0.9197 - IoU: 0.8876 - val_loss: 0.0290 - val_accuracy: 1.0000 - val_recall: 0.9627 - val_precision: 0.9831 - val_f1_score: 0.9662 - val_IoU: 0.9585\n",
      "Epoch 143/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0836 - accuracy: 0.9996 - recall: 0.7873 - precision: 0.9898 - f1_score: 0.9215 - IoU: 0.8921\n",
      "Epoch 143: val_f1_score did not improve from 0.97176\n",
      "41/41 [==============================] - 25s 609ms/step - loss: 0.0836 - accuracy: 0.9996 - recall: 0.7873 - precision: 0.9898 - f1_score: 0.9215 - IoU: 0.8921 - val_loss: 0.0281 - val_accuracy: 1.0000 - val_recall: 0.9867 - val_precision: 0.9584 - val_f1_score: 0.9706 - val_IoU: 0.9749\n",
      "Epoch 144/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0833 - accuracy: 0.9997 - recall: 0.7888 - precision: 0.9893 - f1_score: 0.9216 - IoU: 0.8873\n",
      "Epoch 144: val_f1_score did not improve from 0.97176\n",
      "41/41 [==============================] - 24s 596ms/step - loss: 0.0833 - accuracy: 0.9997 - recall: 0.7888 - precision: 0.9893 - f1_score: 0.9216 - IoU: 0.8873 - val_loss: 0.0281 - val_accuracy: 1.0000 - val_recall: 0.9620 - val_precision: 0.9849 - val_f1_score: 0.9697 - val_IoU: 0.9566\n",
      "Epoch 145/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0811 - accuracy: 0.9997 - recall: 0.7934 - precision: 0.9904 - f1_score: 0.9239 - IoU: 0.8952\n",
      "Epoch 145: val_f1_score improved from 0.97176 to 0.97178, saving model to Trans UNet DA DICE 5-fold model/model_4fold.keras\n",
      "41/41 [==============================] - 29s 719ms/step - loss: 0.0811 - accuracy: 0.9997 - recall: 0.7934 - precision: 0.9904 - f1_score: 0.9239 - IoU: 0.8952 - val_loss: 0.0264 - val_accuracy: 1.0000 - val_recall: 0.9715 - val_precision: 0.9788 - val_f1_score: 0.9718 - val_IoU: 0.9621\n",
      "Epoch 146/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0851 - accuracy: 0.9997 - recall: 0.7881 - precision: 0.9882 - f1_score: 0.9199 - IoU: 0.8899\n",
      "Epoch 146: val_f1_score did not improve from 0.97178\n",
      "41/41 [==============================] - 28s 677ms/step - loss: 0.0851 - accuracy: 0.9997 - recall: 0.7881 - precision: 0.9882 - f1_score: 0.9199 - IoU: 0.8899 - val_loss: 0.0287 - val_accuracy: 1.0000 - val_recall: 0.9675 - val_precision: 0.9782 - val_f1_score: 0.9712 - val_IoU: 0.9595\n",
      "Epoch 147/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0846 - accuracy: 0.9997 - recall: 0.7875 - precision: 0.9890 - f1_score: 0.9203 - IoU: 0.8908\n",
      "Epoch 147: val_f1_score did not improve from 0.97178\n",
      "41/41 [==============================] - 29s 706ms/step - loss: 0.0846 - accuracy: 0.9997 - recall: 0.7875 - precision: 0.9890 - f1_score: 0.9203 - IoU: 0.8908 - val_loss: 0.0644 - val_accuracy: 0.9999 - val_recall: 0.8913 - val_precision: 0.9899 - val_f1_score: 0.9386 - val_IoU: 0.9170\n",
      "Epoch 148/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0832 - accuracy: 0.9997 - recall: 0.7924 - precision: 0.9903 - f1_score: 0.9217 - IoU: 0.8922\n",
      "Epoch 148: val_f1_score did not improve from 0.97178\n",
      "41/41 [==============================] - 26s 623ms/step - loss: 0.0832 - accuracy: 0.9997 - recall: 0.7924 - precision: 0.9903 - f1_score: 0.9217 - IoU: 0.8922 - val_loss: 0.0713 - val_accuracy: 0.9999 - val_recall: 0.8709 - val_precision: 0.9883 - val_f1_score: 0.9332 - val_IoU: 0.9060\n",
      "Epoch 149/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0894 - accuracy: 0.9997 - recall: 0.7881 - precision: 0.9859 - f1_score: 0.9160 - IoU: 0.8855\n",
      "Epoch 149: val_f1_score did not improve from 0.97178\n",
      "41/41 [==============================] - 26s 633ms/step - loss: 0.0894 - accuracy: 0.9997 - recall: 0.7881 - precision: 0.9859 - f1_score: 0.9160 - IoU: 0.8855 - val_loss: 0.3329 - val_accuracy: 0.9995 - val_recall: 0.9773 - val_precision: 0.5418 - val_f1_score: 0.6254 - val_IoU: 0.7936\n",
      "Epoch 150/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1523 - accuracy: 0.9996 - recall: 0.7388 - precision: 0.9376 - f1_score: 0.8568 - IoU: 0.8525\n",
      "Epoch 150: val_f1_score did not improve from 0.97178\n",
      "41/41 [==============================] - 28s 679ms/step - loss: 0.1523 - accuracy: 0.9996 - recall: 0.7388 - precision: 0.9376 - f1_score: 0.8568 - IoU: 0.8525 - val_loss: 0.3352 - val_accuracy: 0.9996 - val_recall: 0.6709 - val_precision: 0.6764 - val_f1_score: 0.6633 - val_IoU: 0.7739\n",
      "O modelo demorou 3320.31 segundos para treinar.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mbouzon/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mbouzon/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mbouzon/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mbouzon/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mbouzon/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mbouzon/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mbouzon/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mbouzon/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mbouzon/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mbouzon/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mbouzon/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mbouzon/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mbouzon/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mbouzon/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mbouzon/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mbouzon/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mbouzon/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mbouzon/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mbouzon/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mbouzon/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mbouzon/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mbouzon/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mbouzon/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mbouzon/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mbouzon/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mbouzon/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mbouzon/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mbouzon/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mbouzon/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mbouzon/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 5\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 15:20:35.382259: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - ETA: 0s - loss: 1.0599 - accuracy: 0.7245 - recall: 0.9889 - precision: 0.0029 - f1_score: 0.0050 - IoU: 0.5140\n",
      "Epoch 1: val_f1_score improved from -inf to 0.00129, saving model to Trans UNet DA DICE 5-fold model/model_5fold.keras\n",
      "41/41 [==============================] - 39s 722ms/step - loss: 1.0599 - accuracy: 0.7245 - recall: 0.9889 - precision: 0.0029 - f1_score: 0.0050 - IoU: 0.5140 - val_loss: 0.9986 - val_accuracy: 0.1733 - val_recall: 1.0000 - val_precision: 7.2069e-04 - val_f1_score: 0.0013 - val_IoU: 0.2142\n",
      "Epoch 2/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.0587 - accuracy: 0.9631 - recall: 0.9883 - precision: 0.0215 - f1_score: 0.0446 - IoU: 0.5242\n",
      "Epoch 2: val_f1_score improved from 0.00129 to 0.00156, saving model to Trans UNet DA DICE 5-fold model/model_5fold.keras\n",
      "41/41 [==============================] - 30s 733ms/step - loss: 1.0587 - accuracy: 0.9631 - recall: 0.9883 - precision: 0.0215 - f1_score: 0.0446 - IoU: 0.5242 - val_loss: 0.9983 - val_accuracy: 0.3141 - val_recall: 1.0000 - val_precision: 8.6853e-04 - val_f1_score: 0.0016 - val_IoU: 0.4395\n",
      "Epoch 3/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.0580 - accuracy: 0.9849 - recall: 0.9864 - precision: 0.0522 - f1_score: 0.0830 - IoU: 0.5473\n",
      "Epoch 3: val_f1_score improved from 0.00156 to 0.00252, saving model to Trans UNet DA DICE 5-fold model/model_5fold.keras\n",
      "41/41 [==============================] - 27s 666ms/step - loss: 1.0580 - accuracy: 0.9849 - recall: 0.9864 - precision: 0.0522 - f1_score: 0.0830 - IoU: 0.5473 - val_loss: 0.9973 - val_accuracy: 0.5718 - val_recall: 0.9999 - val_precision: 0.0014 - val_f1_score: 0.0025 - val_IoU: 0.4983\n",
      "Epoch 4/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.0542 - accuracy: 0.9916 - recall: 0.9816 - precision: 0.0895 - f1_score: 0.1471 - IoU: 0.5706\n",
      "Epoch 4: val_f1_score did not improve from 0.00252\n",
      "41/41 [==============================] - 25s 621ms/step - loss: 1.0542 - accuracy: 0.9916 - recall: 0.9816 - precision: 0.0895 - f1_score: 0.1471 - IoU: 0.5706 - val_loss: 0.9971 - val_accuracy: 0.5645 - val_recall: 0.9996 - val_precision: 0.0014 - val_f1_score: 0.0025 - val_IoU: 0.4899\n",
      "Epoch 5/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.0493 - accuracy: 0.9937 - recall: 0.9672 - precision: 0.1169 - f1_score: 0.1783 - IoU: 0.5820\n",
      "Epoch 5: val_f1_score did not improve from 0.00252\n",
      "41/41 [==============================] - 26s 643ms/step - loss: 1.0493 - accuracy: 0.9937 - recall: 0.9672 - precision: 0.1169 - f1_score: 0.1783 - IoU: 0.5820 - val_loss: 0.9988 - val_accuracy: 0.0404 - val_recall: 0.9959 - val_precision: 6.1841e-04 - val_f1_score: 0.0011 - val_IoU: 0.4767\n",
      "Epoch 6/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.0353 - accuracy: 0.9965 - recall: 0.9509 - precision: 0.1971 - f1_score: 0.2949 - IoU: 0.6130\n",
      "Epoch 6: val_f1_score did not improve from 0.00252\n",
      "41/41 [==============================] - 23s 569ms/step - loss: 1.0353 - accuracy: 0.9965 - recall: 0.9509 - precision: 0.1971 - f1_score: 0.2949 - IoU: 0.6130 - val_loss: 0.9977 - val_accuracy: 0.9925 - val_recall: 0.0173 - val_precision: 0.0015 - val_f1_score: 0.0023 - val_IoU: 0.4997\n",
      "Epoch 7/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.9964 - accuracy: 0.9978 - recall: 0.8974 - precision: 0.2862 - f1_score: 0.3915 - IoU: 0.6379\n",
      "Epoch 7: val_f1_score did not improve from 0.00252\n",
      "41/41 [==============================] - 27s 662ms/step - loss: 0.9964 - accuracy: 0.9978 - recall: 0.8974 - precision: 0.2862 - f1_score: 0.3915 - IoU: 0.6379 - val_loss: 0.9988 - val_accuracy: 0.0059 - val_recall: 1.0000 - val_precision: 5.9941e-04 - val_f1_score: 0.0011 - val_IoU: 0.0098\n",
      "Epoch 8/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.8817 - accuracy: 0.9987 - recall: 0.8560 - precision: 0.4239 - f1_score: 0.5474 - IoU: 0.6867\n",
      "Epoch 8: val_f1_score did not improve from 0.00252\n",
      "41/41 [==============================] - 27s 662ms/step - loss: 0.8817 - accuracy: 0.9987 - recall: 0.8560 - precision: 0.4239 - f1_score: 0.5474 - IoU: 0.6867 - val_loss: 1.0000 - val_accuracy: 0.9994 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_IoU: 0.4997\n",
      "Epoch 9/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.6379 - accuracy: 0.9993 - recall: 0.7789 - precision: 0.6849 - f1_score: 0.6944 - IoU: 0.7610\n",
      "Epoch 9: val_f1_score improved from 0.00252 to 0.03576, saving model to Trans UNet DA DICE 5-fold model/model_5fold.keras\n",
      "41/41 [==============================] - 26s 625ms/step - loss: 0.6379 - accuracy: 0.9993 - recall: 0.7789 - precision: 0.6849 - f1_score: 0.6944 - IoU: 0.7610 - val_loss: 0.9989 - val_accuracy: 0.9990 - val_recall: 0.0250 - val_precision: 0.0388 - val_f1_score: 0.0358 - val_IoU: 0.5002\n",
      "Epoch 10/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.3813 - accuracy: 0.9995 - recall: 0.7514 - precision: 0.8498 - f1_score: 0.7932 - IoU: 0.8221\n",
      "Epoch 10: val_f1_score did not improve from 0.03576\n",
      "41/41 [==============================] - 23s 571ms/step - loss: 0.3813 - accuracy: 0.9995 - recall: 0.7514 - precision: 0.8498 - f1_score: 0.7932 - IoU: 0.8221 - val_loss: 0.9994 - val_accuracy: 0.9994 - val_recall: 4.5975e-04 - val_precision: 1.0000 - val_f1_score: 6.4043e-04 - val_IoU: 0.4997\n",
      "Epoch 11/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.3765 - accuracy: 0.9994 - recall: 0.6593 - precision: 0.7761 - f1_score: 0.7174 - IoU: 0.7699\n",
      "Epoch 11: val_f1_score did not improve from 0.03576\n",
      "41/41 [==============================] - 23s 562ms/step - loss: 0.3765 - accuracy: 0.9994 - recall: 0.6593 - precision: 0.7761 - f1_score: 0.7174 - IoU: 0.7699 - val_loss: 0.9999 - val_accuracy: 0.9994 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_IoU: 0.4997\n",
      "Epoch 12/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.2145 - accuracy: 0.9996 - recall: 0.7478 - precision: 0.9165 - f1_score: 0.8443 - IoU: 0.8509\n",
      "Epoch 12: val_f1_score did not improve from 0.03576\n",
      "41/41 [==============================] - 23s 558ms/step - loss: 0.2145 - accuracy: 0.9996 - recall: 0.7478 - precision: 0.9165 - f1_score: 0.8443 - IoU: 0.8509 - val_loss: 0.9999 - val_accuracy: 0.9994 - val_recall: 0.0016 - val_precision: 1.0000 - val_f1_score: 0.0019 - val_IoU: 0.4997\n",
      "Epoch 13/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1982 - accuracy: 0.9996 - recall: 0.7284 - precision: 0.9276 - f1_score: 0.8443 - IoU: 0.8523\n",
      "Epoch 13: val_f1_score did not improve from 0.03576\n",
      "41/41 [==============================] - 25s 610ms/step - loss: 0.1982 - accuracy: 0.9996 - recall: 0.7284 - precision: 0.9276 - f1_score: 0.8443 - IoU: 0.8523 - val_loss: 0.9993 - val_accuracy: 0.9994 - val_recall: 0.0142 - val_precision: 0.9973 - val_f1_score: 0.0183 - val_IoU: 0.5015\n",
      "Epoch 14/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1584 - accuracy: 0.9996 - recall: 0.7532 - precision: 0.9522 - f1_score: 0.8743 - IoU: 0.8725\n",
      "Epoch 14: val_f1_score improved from 0.03576 to 0.42073, saving model to Trans UNet DA DICE 5-fold model/model_5fold.keras\n",
      "41/41 [==============================] - 25s 616ms/step - loss: 0.1584 - accuracy: 0.9996 - recall: 0.7532 - precision: 0.9522 - f1_score: 0.8743 - IoU: 0.8725 - val_loss: 0.9729 - val_accuracy: 0.9995 - val_recall: 0.2388 - val_precision: 0.9952 - val_f1_score: 0.4207 - val_IoU: 0.5467\n",
      "Epoch 15/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1729 - accuracy: 0.9996 - recall: 0.7439 - precision: 0.9311 - f1_score: 0.8547 - IoU: 0.8565\n",
      "Epoch 15: val_f1_score improved from 0.42073 to 0.80394, saving model to Trans UNet DA DICE 5-fold model/model_5fold.keras\n",
      "41/41 [==============================] - 26s 643ms/step - loss: 0.1729 - accuracy: 0.9996 - recall: 0.7439 - precision: 0.9311 - f1_score: 0.8547 - IoU: 0.8565 - val_loss: 0.8361 - val_accuracy: 0.9998 - val_recall: 0.6490 - val_precision: 0.9826 - val_f1_score: 0.8039 - val_IoU: 0.7405\n",
      "Epoch 16/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1390 - accuracy: 0.9996 - recall: 0.7573 - precision: 0.9635 - f1_score: 0.8835 - IoU: 0.8750\n",
      "Epoch 16: val_f1_score improved from 0.80394 to 0.81118, saving model to Trans UNet DA DICE 5-fold model/model_5fold.keras\n",
      "41/41 [==============================] - 25s 610ms/step - loss: 0.1390 - accuracy: 0.9996 - recall: 0.7573 - precision: 0.9635 - f1_score: 0.8835 - IoU: 0.8750 - val_loss: 0.5612 - val_accuracy: 0.9998 - val_recall: 0.6933 - val_precision: 0.9933 - val_f1_score: 0.8112 - val_IoU: 0.7342\n",
      "Epoch 17/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1192 - accuracy: 0.9996 - recall: 0.7741 - precision: 0.9746 - f1_score: 0.8998 - IoU: 0.8899\n",
      "Epoch 17: val_f1_score improved from 0.81118 to 0.90326, saving model to Trans UNet DA DICE 5-fold model/model_5fold.keras\n",
      "41/41 [==============================] - 24s 578ms/step - loss: 0.1192 - accuracy: 0.9996 - recall: 0.7741 - precision: 0.9746 - f1_score: 0.8998 - IoU: 0.8899 - val_loss: 0.3041 - val_accuracy: 0.9999 - val_recall: 0.8532 - val_precision: 0.9854 - val_f1_score: 0.9033 - val_IoU: 0.8742\n",
      "Epoch 18/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1219 - accuracy: 0.9996 - recall: 0.7682 - precision: 0.9740 - f1_score: 0.8960 - IoU: 0.8844\n",
      "Epoch 18: val_f1_score improved from 0.90326 to 0.93830, saving model to Trans UNet DA DICE 5-fold model/model_5fold.keras\n",
      "41/41 [==============================] - 24s 575ms/step - loss: 0.1219 - accuracy: 0.9996 - recall: 0.7682 - precision: 0.9740 - f1_score: 0.8960 - IoU: 0.8844 - val_loss: 0.1658 - val_accuracy: 0.9999 - val_recall: 0.9392 - val_precision: 0.9539 - val_f1_score: 0.9383 - val_IoU: 0.9270\n",
      "Epoch 19/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1198 - accuracy: 0.9996 - recall: 0.7704 - precision: 0.9700 - f1_score: 0.8961 - IoU: 0.8810\n",
      "Epoch 19: val_f1_score did not improve from 0.93830\n",
      "41/41 [==============================] - 25s 605ms/step - loss: 0.1198 - accuracy: 0.9996 - recall: 0.7704 - precision: 0.9700 - f1_score: 0.8961 - IoU: 0.8810 - val_loss: 0.2652 - val_accuracy: 0.9998 - val_recall: 0.6499 - val_precision: 0.9907 - val_f1_score: 0.8037 - val_IoU: 0.7365\n",
      "Epoch 20/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1161 - accuracy: 0.9996 - recall: 0.7678 - precision: 0.9703 - f1_score: 0.8984 - IoU: 0.8843\n",
      "Epoch 20: val_f1_score did not improve from 0.93830\n",
      "41/41 [==============================] - 25s 611ms/step - loss: 0.1161 - accuracy: 0.9996 - recall: 0.7678 - precision: 0.9703 - f1_score: 0.8984 - IoU: 0.8843 - val_loss: 0.3083 - val_accuracy: 0.9996 - val_recall: 0.9717 - val_precision: 0.6102 - val_f1_score: 0.6554 - val_IoU: 0.8219\n",
      "Epoch 21/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1511 - accuracy: 0.9996 - recall: 0.7329 - precision: 0.9478 - f1_score: 0.8648 - IoU: 0.8611\n",
      "Epoch 21: val_f1_score did not improve from 0.93830\n",
      "41/41 [==============================] - 23s 568ms/step - loss: 0.1511 - accuracy: 0.9996 - recall: 0.7329 - precision: 0.9478 - f1_score: 0.8648 - IoU: 0.8611 - val_loss: 0.8810 - val_accuracy: 0.9994 - val_recall: 0.0629 - val_precision: 0.9838 - val_f1_score: 0.1489 - val_IoU: 0.5195\n",
      "Epoch 22/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1864 - accuracy: 0.9996 - recall: 0.7188 - precision: 0.8950 - f1_score: 0.8307 - IoU: 0.8390\n",
      "Epoch 22: val_f1_score did not improve from 0.93830\n",
      "41/41 [==============================] - 22s 532ms/step - loss: 0.1864 - accuracy: 0.9996 - recall: 0.7188 - precision: 0.8950 - f1_score: 0.8307 - IoU: 0.8390 - val_loss: 0.9935 - val_accuracy: 0.9994 - val_recall: 0.0041 - val_precision: 1.0000 - val_f1_score: 0.0054 - val_IoU: 0.5001\n",
      "Epoch 23/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1526 - accuracy: 0.9996 - recall: 0.7392 - precision: 0.9407 - f1_score: 0.8617 - IoU: 0.8628\n",
      "Epoch 23: val_f1_score did not improve from 0.93830\n",
      "41/41 [==============================] - 21s 512ms/step - loss: 0.1526 - accuracy: 0.9996 - recall: 0.7392 - precision: 0.9407 - f1_score: 0.8617 - IoU: 0.8628 - val_loss: 0.5435 - val_accuracy: 0.9996 - val_recall: 0.3280 - val_precision: 0.9850 - val_f1_score: 0.5012 - val_IoU: 0.6330\n",
      "Epoch 24/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1361 - accuracy: 0.9996 - recall: 0.7468 - precision: 0.9530 - f1_score: 0.8768 - IoU: 0.8689\n",
      "Epoch 24: val_f1_score did not improve from 0.93830\n",
      "41/41 [==============================] - 23s 566ms/step - loss: 0.1361 - accuracy: 0.9996 - recall: 0.7468 - precision: 0.9530 - f1_score: 0.8768 - IoU: 0.8689 - val_loss: 0.1312 - val_accuracy: 0.9999 - val_recall: 0.8438 - val_precision: 0.9800 - val_f1_score: 0.8837 - val_IoU: 0.8844\n",
      "Epoch 25/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1231 - accuracy: 0.9996 - recall: 0.7546 - precision: 0.9695 - f1_score: 0.8886 - IoU: 0.8788\n",
      "Epoch 25: val_f1_score did not improve from 0.93830\n",
      "41/41 [==============================] - 25s 604ms/step - loss: 0.1231 - accuracy: 0.9996 - recall: 0.7546 - precision: 0.9695 - f1_score: 0.8886 - IoU: 0.8788 - val_loss: 0.2036 - val_accuracy: 0.9998 - val_recall: 0.9618 - val_precision: 0.7460 - val_f1_score: 0.7950 - val_IoU: 0.8783\n",
      "Epoch 26/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1129 - accuracy: 0.9996 - recall: 0.7708 - precision: 0.9691 - f1_score: 0.8979 - IoU: 0.8808\n",
      "Epoch 26: val_f1_score did not improve from 0.93830\n",
      "41/41 [==============================] - 23s 560ms/step - loss: 0.1129 - accuracy: 0.9996 - recall: 0.7708 - precision: 0.9691 - f1_score: 0.8979 - IoU: 0.8808 - val_loss: 0.0933 - val_accuracy: 0.9999 - val_recall: 0.9654 - val_precision: 0.8953 - val_f1_score: 0.8643 - val_IoU: 0.9310\n",
      "Epoch 27/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1094 - accuracy: 0.9996 - recall: 0.7775 - precision: 0.9706 - f1_score: 0.9010 - IoU: 0.8860\n",
      "Epoch 27: val_f1_score improved from 0.93830 to 0.95879, saving model to Trans UNet DA DICE 5-fold model/model_5fold.keras\n",
      "41/41 [==============================] - 27s 668ms/step - loss: 0.1094 - accuracy: 0.9996 - recall: 0.7775 - precision: 0.9706 - f1_score: 0.9010 - IoU: 0.8860 - val_loss: 0.0463 - val_accuracy: 1.0000 - val_recall: 0.9544 - val_precision: 0.9652 - val_f1_score: 0.9588 - val_IoU: 0.9434\n",
      "Epoch 28/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1044 - accuracy: 0.9996 - recall: 0.7652 - precision: 0.9852 - f1_score: 0.9052 - IoU: 0.8874\n",
      "Epoch 28: val_f1_score did not improve from 0.95879\n",
      "41/41 [==============================] - 25s 617ms/step - loss: 0.1044 - accuracy: 0.9996 - recall: 0.7652 - precision: 0.9852 - f1_score: 0.9052 - IoU: 0.8874 - val_loss: 0.2141 - val_accuracy: 0.9998 - val_recall: 0.9730 - val_precision: 0.7221 - val_f1_score: 0.7422 - val_IoU: 0.8692\n",
      "Epoch 29/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1186 - accuracy: 0.9997 - recall: 0.7654 - precision: 0.9645 - f1_score: 0.8913 - IoU: 0.8748\n",
      "Epoch 29: val_f1_score did not improve from 0.95879\n",
      "41/41 [==============================] - 23s 559ms/step - loss: 0.1186 - accuracy: 0.9997 - recall: 0.7654 - precision: 0.9645 - f1_score: 0.8913 - IoU: 0.8748 - val_loss: 0.0736 - val_accuracy: 0.9999 - val_recall: 0.9104 - val_precision: 0.9525 - val_f1_score: 0.9275 - val_IoU: 0.9088\n",
      "Epoch 30/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1006 - accuracy: 0.9996 - recall: 0.7830 - precision: 0.9774 - f1_score: 0.9086 - IoU: 0.8918\n",
      "Epoch 30: val_f1_score did not improve from 0.95879\n",
      "41/41 [==============================] - 21s 522ms/step - loss: 0.1006 - accuracy: 0.9996 - recall: 0.7830 - precision: 0.9774 - f1_score: 0.9086 - IoU: 0.8918 - val_loss: 0.0972 - val_accuracy: 0.9999 - val_recall: 0.9792 - val_precision: 0.8850 - val_f1_score: 0.9057 - val_IoU: 0.9416\n",
      "Epoch 31/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1679 - accuracy: 0.9996 - recall: 0.7341 - precision: 0.9283 - f1_score: 0.8445 - IoU: 0.8424\n",
      "Epoch 31: val_f1_score did not improve from 0.95879\n",
      "41/41 [==============================] - 22s 548ms/step - loss: 0.1679 - accuracy: 0.9996 - recall: 0.7341 - precision: 0.9283 - f1_score: 0.8445 - IoU: 0.8424 - val_loss: 0.1964 - val_accuracy: 0.9998 - val_recall: 0.6978 - val_precision: 0.9473 - val_f1_score: 0.8127 - val_IoU: 0.8174\n",
      "Epoch 32/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1030 - accuracy: 0.9996 - recall: 0.7679 - precision: 0.9830 - f1_score: 0.9060 - IoU: 0.8894\n",
      "Epoch 32: val_f1_score did not improve from 0.95879\n",
      "41/41 [==============================] - 23s 572ms/step - loss: 0.1030 - accuracy: 0.9996 - recall: 0.7679 - precision: 0.9830 - f1_score: 0.9060 - IoU: 0.8894 - val_loss: 0.0724 - val_accuracy: 0.9999 - val_recall: 0.9162 - val_precision: 0.9382 - val_f1_score: 0.9322 - val_IoU: 0.9196\n",
      "Epoch 33/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1004 - accuracy: 0.9997 - recall: 0.7803 - precision: 0.9794 - f1_score: 0.9080 - IoU: 0.8873\n",
      "Epoch 33: val_f1_score did not improve from 0.95879\n",
      "41/41 [==============================] - 23s 552ms/step - loss: 0.1004 - accuracy: 0.9997 - recall: 0.7803 - precision: 0.9794 - f1_score: 0.9080 - IoU: 0.8873 - val_loss: 0.0776 - val_accuracy: 0.9999 - val_recall: 0.8854 - val_precision: 0.9561 - val_f1_score: 0.9171 - val_IoU: 0.9088\n",
      "Epoch 34/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1062 - accuracy: 0.9996 - recall: 0.7656 - precision: 0.9787 - f1_score: 0.9023 - IoU: 0.8844\n",
      "Epoch 34: val_f1_score did not improve from 0.95879\n",
      "41/41 [==============================] - 23s 555ms/step - loss: 0.1062 - accuracy: 0.9996 - recall: 0.7656 - precision: 0.9787 - f1_score: 0.9023 - IoU: 0.8844 - val_loss: 0.1409 - val_accuracy: 0.9999 - val_recall: 0.9503 - val_precision: 0.8570 - val_f1_score: 0.8045 - val_IoU: 0.9079\n",
      "Epoch 35/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0956 - accuracy: 0.9996 - recall: 0.7813 - precision: 0.9845 - f1_score: 0.9121 - IoU: 0.8899\n",
      "Epoch 35: val_f1_score did not improve from 0.95879\n",
      "41/41 [==============================] - 23s 550ms/step - loss: 0.0956 - accuracy: 0.9996 - recall: 0.7813 - precision: 0.9845 - f1_score: 0.9121 - IoU: 0.8899 - val_loss: 0.0547 - val_accuracy: 0.9999 - val_recall: 0.9592 - val_precision: 0.9499 - val_f1_score: 0.9207 - val_IoU: 0.9434\n",
      "Epoch 36/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1039 - accuracy: 0.9996 - recall: 0.7795 - precision: 0.9744 - f1_score: 0.9040 - IoU: 0.8811\n",
      "Epoch 36: val_f1_score did not improve from 0.95879\n",
      "41/41 [==============================] - 24s 582ms/step - loss: 0.1039 - accuracy: 0.9996 - recall: 0.7795 - precision: 0.9744 - f1_score: 0.9040 - IoU: 0.8811 - val_loss: 0.1701 - val_accuracy: 0.9998 - val_recall: 0.9689 - val_precision: 0.8068 - val_f1_score: 0.7886 - val_IoU: 0.9014\n",
      "Epoch 37/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0917 - accuracy: 0.9997 - recall: 0.7778 - precision: 0.9890 - f1_score: 0.9156 - IoU: 0.8957\n",
      "Epoch 37: val_f1_score improved from 0.95879 to 0.96641, saving model to Trans UNet DA DICE 5-fold model/model_5fold.keras\n",
      "41/41 [==============================] - 23s 556ms/step - loss: 0.0917 - accuracy: 0.9997 - recall: 0.7778 - precision: 0.9890 - f1_score: 0.9156 - IoU: 0.8957 - val_loss: 0.0339 - val_accuracy: 1.0000 - val_recall: 0.9700 - val_precision: 0.9688 - val_f1_score: 0.9664 - val_IoU: 0.9571\n",
      "Epoch 38/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0957 - accuracy: 0.9997 - recall: 0.7828 - precision: 0.9837 - f1_score: 0.9117 - IoU: 0.8880\n",
      "Epoch 38: val_f1_score did not improve from 0.96641\n",
      "41/41 [==============================] - 23s 551ms/step - loss: 0.0957 - accuracy: 0.9997 - recall: 0.7828 - precision: 0.9837 - f1_score: 0.9117 - IoU: 0.8880 - val_loss: 0.5804 - val_accuracy: 0.9996 - val_recall: 0.3344 - val_precision: 0.9944 - val_f1_score: 0.3776 - val_IoU: 0.6247\n",
      "Epoch 39/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1013 - accuracy: 0.9996 - recall: 0.7711 - precision: 0.9814 - f1_score: 0.9064 - IoU: 0.8863\n",
      "Epoch 39: val_f1_score did not improve from 0.96641\n",
      "41/41 [==============================] - 25s 599ms/step - loss: 0.1013 - accuracy: 0.9996 - recall: 0.7711 - precision: 0.9814 - f1_score: 0.9064 - IoU: 0.8863 - val_loss: 0.1988 - val_accuracy: 0.9998 - val_recall: 0.6720 - val_precision: 0.9928 - val_f1_score: 0.8243 - val_IoU: 0.7802\n",
      "Epoch 40/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0990 - accuracy: 0.9997 - recall: 0.7773 - precision: 0.9806 - f1_score: 0.9083 - IoU: 0.8868\n",
      "Epoch 40: val_f1_score did not improve from 0.96641\n",
      "41/41 [==============================] - 27s 653ms/step - loss: 0.0990 - accuracy: 0.9997 - recall: 0.7773 - precision: 0.9806 - f1_score: 0.9083 - IoU: 0.8868 - val_loss: 0.3250 - val_accuracy: 0.9997 - val_recall: 0.5320 - val_precision: 0.9922 - val_f1_score: 0.6843 - val_IoU: 0.7254\n",
      "Epoch 41/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0961 - accuracy: 0.9997 - recall: 0.7810 - precision: 0.9855 - f1_score: 0.9110 - IoU: 0.8898\n",
      "Epoch 41: val_f1_score did not improve from 0.96641\n",
      "41/41 [==============================] - 25s 619ms/step - loss: 0.0961 - accuracy: 0.9997 - recall: 0.7810 - precision: 0.9855 - f1_score: 0.9110 - IoU: 0.8898 - val_loss: 0.0336 - val_accuracy: 1.0000 - val_recall: 0.9728 - val_precision: 0.9684 - val_f1_score: 0.9626 - val_IoU: 0.9596\n",
      "Epoch 42/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0959 - accuracy: 0.9997 - recall: 0.7823 - precision: 0.9849 - f1_score: 0.9109 - IoU: 0.8899\n",
      "Epoch 42: val_f1_score did not improve from 0.96641\n",
      "41/41 [==============================] - 23s 566ms/step - loss: 0.0959 - accuracy: 0.9997 - recall: 0.7823 - precision: 0.9849 - f1_score: 0.9109 - IoU: 0.8899 - val_loss: 0.0346 - val_accuracy: 1.0000 - val_recall: 0.9727 - val_precision: 0.9677 - val_f1_score: 0.9592 - val_IoU: 0.9613\n",
      "Epoch 43/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0917 - accuracy: 0.9997 - recall: 0.7857 - precision: 0.9867 - f1_score: 0.9150 - IoU: 0.8892\n",
      "Epoch 43: val_f1_score did not improve from 0.96641\n",
      "41/41 [==============================] - 24s 592ms/step - loss: 0.0917 - accuracy: 0.9997 - recall: 0.7857 - precision: 0.9867 - f1_score: 0.9150 - IoU: 0.8892 - val_loss: 0.0427 - val_accuracy: 1.0000 - val_recall: 0.9338 - val_precision: 0.9913 - val_f1_score: 0.9590 - val_IoU: 0.9330\n",
      "Epoch 44/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0966 - accuracy: 0.9997 - recall: 0.7791 - precision: 0.9833 - f1_score: 0.9102 - IoU: 0.8895\n",
      "Epoch 44: val_f1_score did not improve from 0.96641\n",
      "41/41 [==============================] - 28s 677ms/step - loss: 0.0966 - accuracy: 0.9997 - recall: 0.7791 - precision: 0.9833 - f1_score: 0.9102 - IoU: 0.8895 - val_loss: 0.1042 - val_accuracy: 0.9999 - val_recall: 0.9633 - val_precision: 0.8848 - val_f1_score: 0.8608 - val_IoU: 0.9299\n",
      "Epoch 45/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0983 - accuracy: 0.9997 - recall: 0.7755 - precision: 0.9819 - f1_score: 0.9086 - IoU: 0.8841\n",
      "Epoch 45: val_f1_score did not improve from 0.96641\n",
      "41/41 [==============================] - 26s 636ms/step - loss: 0.0983 - accuracy: 0.9997 - recall: 0.7755 - precision: 0.9819 - f1_score: 0.9086 - IoU: 0.8841 - val_loss: 0.0404 - val_accuracy: 1.0000 - val_recall: 0.9516 - val_precision: 0.9758 - val_f1_score: 0.9593 - val_IoU: 0.9459\n",
      "Epoch 46/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0980 - accuracy: 0.9997 - recall: 0.7734 - precision: 0.9843 - f1_score: 0.9087 - IoU: 0.8900\n",
      "Epoch 46: val_f1_score did not improve from 0.96641\n",
      "41/41 [==============================] - 26s 626ms/step - loss: 0.0980 - accuracy: 0.9997 - recall: 0.7734 - precision: 0.9843 - f1_score: 0.9087 - IoU: 0.8900 - val_loss: 0.1131 - val_accuracy: 0.9999 - val_recall: 0.8311 - val_precision: 0.9878 - val_f1_score: 0.8963 - val_IoU: 0.8758\n",
      "Epoch 47/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0899 - accuracy: 0.9997 - recall: 0.7813 - precision: 0.9871 - f1_score: 0.9165 - IoU: 0.8904\n",
      "Epoch 47: val_f1_score did not improve from 0.96641\n",
      "41/41 [==============================] - 27s 663ms/step - loss: 0.0899 - accuracy: 0.9997 - recall: 0.7813 - precision: 0.9871 - f1_score: 0.9165 - IoU: 0.8904 - val_loss: 0.0290 - val_accuracy: 1.0000 - val_recall: 0.9781 - val_precision: 0.9684 - val_f1_score: 0.9649 - val_IoU: 0.9669\n",
      "Epoch 48/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0865 - accuracy: 0.9997 - recall: 0.7929 - precision: 0.9916 - f1_score: 0.9198 - IoU: 0.8927\n",
      "Epoch 48: val_f1_score improved from 0.96641 to 0.96957, saving model to Trans UNet DA DICE 5-fold model/model_5fold.keras\n",
      "41/41 [==============================] - 26s 645ms/step - loss: 0.0865 - accuracy: 0.9997 - recall: 0.7929 - precision: 0.9916 - f1_score: 0.9198 - IoU: 0.8927 - val_loss: 0.0313 - val_accuracy: 1.0000 - val_recall: 0.9571 - val_precision: 0.9840 - val_f1_score: 0.9696 - val_IoU: 0.9555\n",
      "Epoch 49/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0931 - accuracy: 0.9997 - recall: 0.7838 - precision: 0.9815 - f1_score: 0.9134 - IoU: 0.8842\n",
      "Epoch 49: val_f1_score did not improve from 0.96957\n",
      "41/41 [==============================] - 26s 643ms/step - loss: 0.0931 - accuracy: 0.9997 - recall: 0.7838 - precision: 0.9815 - f1_score: 0.9134 - IoU: 0.8842 - val_loss: 0.0347 - val_accuracy: 1.0000 - val_recall: 0.9433 - val_precision: 0.9871 - val_f1_score: 0.9652 - val_IoU: 0.9438\n",
      "Epoch 50/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0966 - accuracy: 0.9997 - recall: 0.7747 - precision: 0.9816 - f1_score: 0.9099 - IoU: 0.8852\n",
      "Epoch 50: val_f1_score did not improve from 0.96957\n",
      "41/41 [==============================] - 27s 664ms/step - loss: 0.0966 - accuracy: 0.9997 - recall: 0.7747 - precision: 0.9816 - f1_score: 0.9099 - IoU: 0.8852 - val_loss: 0.7140 - val_accuracy: 0.9995 - val_recall: 0.1866 - val_precision: 0.9931 - val_f1_score: 0.3039 - val_IoU: 0.5690\n",
      "Epoch 51/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1013 - accuracy: 0.9996 - recall: 0.7779 - precision: 0.9790 - f1_score: 0.9057 - IoU: 0.8872\n",
      "Epoch 51: val_f1_score did not improve from 0.96957\n",
      "41/41 [==============================] - 26s 624ms/step - loss: 0.1013 - accuracy: 0.9996 - recall: 0.7779 - precision: 0.9790 - f1_score: 0.9057 - IoU: 0.8872 - val_loss: 0.2382 - val_accuracy: 0.9997 - val_recall: 0.9775 - val_precision: 0.6794 - val_f1_score: 0.7516 - val_IoU: 0.8430\n",
      "Epoch 52/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1066 - accuracy: 0.9996 - recall: 0.7748 - precision: 0.9756 - f1_score: 0.9003 - IoU: 0.8809\n",
      "Epoch 52: val_f1_score did not improve from 0.96957\n",
      "41/41 [==============================] - 24s 597ms/step - loss: 0.1066 - accuracy: 0.9996 - recall: 0.7748 - precision: 0.9756 - f1_score: 0.9003 - IoU: 0.8809 - val_loss: 0.1790 - val_accuracy: 0.9998 - val_recall: 0.9743 - val_precision: 0.7541 - val_f1_score: 0.7963 - val_IoU: 0.8902\n",
      "Epoch 53/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1031 - accuracy: 0.9996 - recall: 0.7701 - precision: 0.9808 - f1_score: 0.9036 - IoU: 0.8818\n",
      "Epoch 53: val_f1_score did not improve from 0.96957\n",
      "41/41 [==============================] - 27s 650ms/step - loss: 0.1031 - accuracy: 0.9996 - recall: 0.7701 - precision: 0.9808 - f1_score: 0.9036 - IoU: 0.8818 - val_loss: 0.0766 - val_accuracy: 0.9999 - val_recall: 0.8875 - val_precision: 0.9809 - val_f1_score: 0.9233 - val_IoU: 0.9034\n",
      "Epoch 54/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1071 - accuracy: 0.9996 - recall: 0.7672 - precision: 0.9733 - f1_score: 0.9002 - IoU: 0.8798\n",
      "Epoch 54: val_f1_score did not improve from 0.96957\n",
      "41/41 [==============================] - 27s 654ms/step - loss: 0.1071 - accuracy: 0.9996 - recall: 0.7672 - precision: 0.9733 - f1_score: 0.9002 - IoU: 0.8798 - val_loss: 0.5682 - val_accuracy: 0.9994 - val_recall: 0.4022 - val_precision: 0.5325 - val_f1_score: 0.4201 - val_IoU: 0.6215\n",
      "Epoch 55/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1091 - accuracy: 0.9996 - recall: 0.7656 - precision: 0.9676 - f1_score: 0.8981 - IoU: 0.8822\n",
      "Epoch 55: val_f1_score did not improve from 0.96957\n",
      "41/41 [==============================] - 25s 621ms/step - loss: 0.1091 - accuracy: 0.9996 - recall: 0.7656 - precision: 0.9676 - f1_score: 0.8981 - IoU: 0.8822 - val_loss: 0.0484 - val_accuracy: 0.9999 - val_recall: 0.9347 - val_precision: 0.9711 - val_f1_score: 0.9524 - val_IoU: 0.9386\n",
      "Epoch 56/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0960 - accuracy: 0.9997 - recall: 0.7699 - precision: 0.9889 - f1_score: 0.9104 - IoU: 0.8853\n",
      "Epoch 56: val_f1_score did not improve from 0.96957\n",
      "41/41 [==============================] - 23s 556ms/step - loss: 0.0960 - accuracy: 0.9997 - recall: 0.7699 - precision: 0.9889 - f1_score: 0.9104 - IoU: 0.8853 - val_loss: 0.0542 - val_accuracy: 0.9999 - val_recall: 0.9059 - val_precision: 0.9889 - val_f1_score: 0.9485 - val_IoU: 0.9188\n",
      "Epoch 57/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1047 - accuracy: 0.9996 - recall: 0.7702 - precision: 0.9736 - f1_score: 0.9021 - IoU: 0.8817\n",
      "Epoch 57: val_f1_score did not improve from 0.96957\n",
      "41/41 [==============================] - 23s 560ms/step - loss: 0.1047 - accuracy: 0.9996 - recall: 0.7702 - precision: 0.9736 - f1_score: 0.9021 - IoU: 0.8817 - val_loss: 0.0613 - val_accuracy: 0.9999 - val_recall: 0.8824 - val_precision: 0.9892 - val_f1_score: 0.9387 - val_IoU: 0.8977\n",
      "Epoch 58/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0956 - accuracy: 0.9996 - recall: 0.7731 - precision: 0.9830 - f1_score: 0.9108 - IoU: 0.8875\n",
      "Epoch 58: val_f1_score did not improve from 0.96957\n",
      "41/41 [==============================] - 25s 605ms/step - loss: 0.0956 - accuracy: 0.9996 - recall: 0.7731 - precision: 0.9830 - f1_score: 0.9108 - IoU: 0.8875 - val_loss: 0.0401 - val_accuracy: 0.9999 - val_recall: 0.9726 - val_precision: 0.9436 - val_f1_score: 0.9570 - val_IoU: 0.9558\n",
      "Epoch 59/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1007 - accuracy: 0.9996 - recall: 0.7842 - precision: 0.9753 - f1_score: 0.9060 - IoU: 0.8780\n",
      "Epoch 59: val_f1_score did not improve from 0.96957\n",
      "41/41 [==============================] - 23s 563ms/step - loss: 0.1007 - accuracy: 0.9996 - recall: 0.7842 - precision: 0.9753 - f1_score: 0.9060 - IoU: 0.8780 - val_loss: 0.0394 - val_accuracy: 0.9999 - val_recall: 0.9579 - val_precision: 0.9581 - val_f1_score: 0.9610 - val_IoU: 0.9559\n",
      "Epoch 60/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0949 - accuracy: 0.9997 - recall: 0.7732 - precision: 0.9848 - f1_score: 0.9114 - IoU: 0.8869\n",
      "Epoch 60: val_f1_score did not improve from 0.96957\n",
      "41/41 [==============================] - 23s 563ms/step - loss: 0.0949 - accuracy: 0.9997 - recall: 0.7732 - precision: 0.9848 - f1_score: 0.9114 - IoU: 0.8869 - val_loss: 0.0768 - val_accuracy: 0.9999 - val_recall: 0.9839 - val_precision: 0.9118 - val_f1_score: 0.9285 - val_IoU: 0.9532\n",
      "Epoch 61/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0959 - accuracy: 0.9997 - recall: 0.7729 - precision: 0.9827 - f1_score: 0.9101 - IoU: 0.8830\n",
      "Epoch 61: val_f1_score did not improve from 0.96957\n",
      "41/41 [==============================] - 24s 596ms/step - loss: 0.0959 - accuracy: 0.9997 - recall: 0.7729 - precision: 0.9827 - f1_score: 0.9101 - IoU: 0.8830 - val_loss: 0.0577 - val_accuracy: 0.9999 - val_recall: 0.8948 - val_precision: 0.9819 - val_f1_score: 0.9428 - val_IoU: 0.9219\n",
      "Epoch 62/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0901 - accuracy: 0.9996 - recall: 0.7794 - precision: 0.9916 - f1_score: 0.9160 - IoU: 0.8893\n",
      "Epoch 62: val_f1_score did not improve from 0.96957\n",
      "41/41 [==============================] - 27s 669ms/step - loss: 0.0901 - accuracy: 0.9996 - recall: 0.7794 - precision: 0.9916 - f1_score: 0.9160 - IoU: 0.8893 - val_loss: 0.0864 - val_accuracy: 0.9999 - val_recall: 0.9846 - val_precision: 0.8864 - val_f1_score: 0.8575 - val_IoU: 0.9411\n",
      "Epoch 63/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0926 - accuracy: 0.9996 - recall: 0.7849 - precision: 0.9824 - f1_score: 0.9135 - IoU: 0.8844\n",
      "Epoch 63: val_f1_score did not improve from 0.96957\n",
      "41/41 [==============================] - 27s 656ms/step - loss: 0.0926 - accuracy: 0.9996 - recall: 0.7849 - precision: 0.9824 - f1_score: 0.9135 - IoU: 0.8844 - val_loss: 0.1867 - val_accuracy: 0.9998 - val_recall: 0.7021 - val_precision: 0.9787 - val_f1_score: 0.8314 - val_IoU: 0.8066\n",
      "Epoch 64/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1157 - accuracy: 0.9996 - recall: 0.7666 - precision: 0.9609 - f1_score: 0.8915 - IoU: 0.8703\n",
      "Epoch 64: val_f1_score did not improve from 0.96957\n",
      "41/41 [==============================] - 25s 622ms/step - loss: 0.1157 - accuracy: 0.9996 - recall: 0.7666 - precision: 0.9609 - f1_score: 0.8915 - IoU: 0.8703 - val_loss: 0.2332 - val_accuracy: 0.9998 - val_recall: 0.6539 - val_precision: 0.9889 - val_f1_score: 0.7942 - val_IoU: 0.7791\n",
      "Epoch 65/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1138 - accuracy: 0.9997 - recall: 0.7683 - precision: 0.9581 - f1_score: 0.8931 - IoU: 0.8680\n",
      "Epoch 65: val_f1_score did not improve from 0.96957\n",
      "41/41 [==============================] - 25s 611ms/step - loss: 0.1138 - accuracy: 0.9997 - recall: 0.7683 - precision: 0.9581 - f1_score: 0.8931 - IoU: 0.8680 - val_loss: 0.0461 - val_accuracy: 1.0000 - val_recall: 0.9527 - val_precision: 0.9705 - val_f1_score: 0.9569 - val_IoU: 0.9546\n",
      "Epoch 66/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1116 - accuracy: 0.9996 - recall: 0.7629 - precision: 0.9697 - f1_score: 0.8956 - IoU: 0.8740\n",
      "Epoch 66: val_f1_score did not improve from 0.96957\n",
      "41/41 [==============================] - 25s 617ms/step - loss: 0.1116 - accuracy: 0.9996 - recall: 0.7629 - precision: 0.9697 - f1_score: 0.8956 - IoU: 0.8740 - val_loss: 0.5105 - val_accuracy: 0.9996 - val_recall: 0.3379 - val_precision: 0.9750 - val_f1_score: 0.5521 - val_IoU: 0.6564\n",
      "Epoch 67/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0957 - accuracy: 0.9997 - recall: 0.7832 - precision: 0.9845 - f1_score: 0.9106 - IoU: 0.8881\n",
      "Epoch 67: val_f1_score did not improve from 0.96957\n",
      "41/41 [==============================] - 26s 636ms/step - loss: 0.0957 - accuracy: 0.9997 - recall: 0.7832 - precision: 0.9845 - f1_score: 0.9106 - IoU: 0.8881 - val_loss: 0.0523 - val_accuracy: 0.9999 - val_recall: 0.9822 - val_precision: 0.9308 - val_f1_score: 0.9399 - val_IoU: 0.9612\n",
      "Epoch 68/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0964 - accuracy: 0.9997 - recall: 0.7700 - precision: 0.9791 - f1_score: 0.9098 - IoU: 0.8832\n",
      "Epoch 68: val_f1_score did not improve from 0.96957\n",
      "41/41 [==============================] - 25s 614ms/step - loss: 0.0964 - accuracy: 0.9997 - recall: 0.7700 - precision: 0.9791 - f1_score: 0.9098 - IoU: 0.8832 - val_loss: 0.0319 - val_accuracy: 1.0000 - val_recall: 0.9513 - val_precision: 0.9843 - val_f1_score: 0.9676 - val_IoU: 0.9537\n",
      "Epoch 69/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0949 - accuracy: 0.9996 - recall: 0.7867 - precision: 0.9804 - f1_score: 0.9112 - IoU: 0.8803\n",
      "Epoch 69: val_f1_score did not improve from 0.96957\n",
      "41/41 [==============================] - 26s 637ms/step - loss: 0.0949 - accuracy: 0.9996 - recall: 0.7867 - precision: 0.9804 - f1_score: 0.9112 - IoU: 0.8803 - val_loss: 0.0329 - val_accuracy: 1.0000 - val_recall: 0.9799 - val_precision: 0.9626 - val_f1_score: 0.9624 - val_IoU: 0.9692\n",
      "Epoch 70/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0842 - accuracy: 0.9997 - recall: 0.7888 - precision: 0.9942 - f1_score: 0.9211 - IoU: 0.8892\n",
      "Epoch 70: val_f1_score improved from 0.96957 to 0.97087, saving model to Trans UNet DA DICE 5-fold model/model_5fold.keras\n",
      "41/41 [==============================] - 26s 644ms/step - loss: 0.0842 - accuracy: 0.9997 - recall: 0.7888 - precision: 0.9942 - f1_score: 0.9211 - IoU: 0.8892 - val_loss: 0.0276 - val_accuracy: 1.0000 - val_recall: 0.9828 - val_precision: 0.9627 - val_f1_score: 0.9709 - val_IoU: 0.9727\n",
      "Epoch 71/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0921 - accuracy: 0.9997 - recall: 0.7796 - precision: 0.9880 - f1_score: 0.9136 - IoU: 0.8818\n",
      "Epoch 71: val_f1_score improved from 0.97087 to 0.97390, saving model to Trans UNet DA DICE 5-fold model/model_5fold.keras\n",
      "41/41 [==============================] - 34s 843ms/step - loss: 0.0921 - accuracy: 0.9997 - recall: 0.7796 - precision: 0.9880 - f1_score: 0.9136 - IoU: 0.8818 - val_loss: 0.0255 - val_accuracy: 1.0000 - val_recall: 0.9780 - val_precision: 0.9713 - val_f1_score: 0.9739 - val_IoU: 0.9711\n",
      "Epoch 72/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0910 - accuracy: 0.9997 - recall: 0.7830 - precision: 0.9881 - f1_score: 0.9147 - IoU: 0.8875\n",
      "Epoch 72: val_f1_score did not improve from 0.97390\n",
      "41/41 [==============================] - 24s 580ms/step - loss: 0.0910 - accuracy: 0.9997 - recall: 0.7830 - precision: 0.9881 - f1_score: 0.9147 - IoU: 0.8875 - val_loss: 0.0258 - val_accuracy: 1.0000 - val_recall: 0.9751 - val_precision: 0.9732 - val_f1_score: 0.9731 - val_IoU: 0.9691\n",
      "Epoch 73/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0943 - accuracy: 0.9997 - recall: 0.7798 - precision: 0.9776 - f1_score: 0.9114 - IoU: 0.8809\n",
      "Epoch 73: val_f1_score improved from 0.97390 to 0.97479, saving model to Trans UNet DA DICE 5-fold model/model_5fold.keras\n",
      "41/41 [==============================] - 24s 581ms/step - loss: 0.0943 - accuracy: 0.9997 - recall: 0.7798 - precision: 0.9776 - f1_score: 0.9114 - IoU: 0.8809 - val_loss: 0.0242 - val_accuracy: 1.0000 - val_recall: 0.9769 - val_precision: 0.9729 - val_f1_score: 0.9748 - val_IoU: 0.9714\n",
      "Epoch 74/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0827 - accuracy: 0.9997 - recall: 0.7895 - precision: 0.9951 - f1_score: 0.9227 - IoU: 0.8908\n",
      "Epoch 74: val_f1_score did not improve from 0.97479\n",
      "41/41 [==============================] - 23s 564ms/step - loss: 0.0827 - accuracy: 0.9997 - recall: 0.7895 - precision: 0.9951 - f1_score: 0.9227 - IoU: 0.8908 - val_loss: 0.0247 - val_accuracy: 1.0000 - val_recall: 0.9803 - val_precision: 0.9694 - val_f1_score: 0.9740 - val_IoU: 0.9727\n",
      "Epoch 75/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0892 - accuracy: 0.9997 - recall: 0.7888 - precision: 0.9857 - f1_score: 0.9162 - IoU: 0.8833\n",
      "Epoch 75: val_f1_score did not improve from 0.97479\n",
      "41/41 [==============================] - 23s 568ms/step - loss: 0.0892 - accuracy: 0.9997 - recall: 0.7888 - precision: 0.9857 - f1_score: 0.9162 - IoU: 0.8833 - val_loss: 0.0290 - val_accuracy: 1.0000 - val_recall: 0.9741 - val_precision: 0.9717 - val_f1_score: 0.9599 - val_IoU: 0.9687\n",
      "Epoch 76/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0902 - accuracy: 0.9997 - recall: 0.7804 - precision: 0.9858 - f1_score: 0.9154 - IoU: 0.8850\n",
      "Epoch 76: val_f1_score did not improve from 0.97479\n",
      "41/41 [==============================] - 23s 564ms/step - loss: 0.0902 - accuracy: 0.9997 - recall: 0.7804 - precision: 0.9858 - f1_score: 0.9154 - IoU: 0.8850 - val_loss: 0.0339 - val_accuracy: 1.0000 - val_recall: 0.9398 - val_precision: 0.9908 - val_f1_score: 0.9649 - val_IoU: 0.9474\n",
      "Epoch 77/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0896 - accuracy: 0.9997 - recall: 0.7845 - precision: 0.9871 - f1_score: 0.9160 - IoU: 0.8851\n",
      "Epoch 77: val_f1_score did not improve from 0.97479\n",
      "41/41 [==============================] - 23s 564ms/step - loss: 0.0896 - accuracy: 0.9997 - recall: 0.7845 - precision: 0.9871 - f1_score: 0.9160 - IoU: 0.8851 - val_loss: 0.0254 - val_accuracy: 1.0000 - val_recall: 0.9610 - val_precision: 0.9853 - val_f1_score: 0.9731 - val_IoU: 0.9613\n",
      "Epoch 78/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0899 - accuracy: 0.9997 - recall: 0.7824 - precision: 0.9880 - f1_score: 0.9155 - IoU: 0.8856\n",
      "Epoch 78: val_f1_score did not improve from 0.97479\n",
      "41/41 [==============================] - 23s 572ms/step - loss: 0.0899 - accuracy: 0.9997 - recall: 0.7824 - precision: 0.9880 - f1_score: 0.9155 - IoU: 0.8856 - val_loss: 0.0299 - val_accuracy: 1.0000 - val_recall: 0.9508 - val_precision: 0.9862 - val_f1_score: 0.9688 - val_IoU: 0.9555\n",
      "Epoch 79/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0940 - accuracy: 0.9996 - recall: 0.7795 - precision: 0.9802 - f1_score: 0.9121 - IoU: 0.8875\n",
      "Epoch 79: val_f1_score did not improve from 0.97479\n",
      "41/41 [==============================] - 23s 574ms/step - loss: 0.0940 - accuracy: 0.9996 - recall: 0.7795 - precision: 0.9802 - f1_score: 0.9121 - IoU: 0.8875 - val_loss: 0.1330 - val_accuracy: 0.9998 - val_recall: 0.9414 - val_precision: 0.8257 - val_f1_score: 0.8354 - val_IoU: 0.8885\n",
      "Epoch 80/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0956 - accuracy: 0.9997 - recall: 0.7825 - precision: 0.9826 - f1_score: 0.9101 - IoU: 0.8785\n",
      "Epoch 80: val_f1_score did not improve from 0.97479\n",
      "41/41 [==============================] - 24s 579ms/step - loss: 0.0956 - accuracy: 0.9997 - recall: 0.7825 - precision: 0.9826 - f1_score: 0.9101 - IoU: 0.8785 - val_loss: 0.0323 - val_accuracy: 1.0000 - val_recall: 0.9621 - val_precision: 0.9734 - val_f1_score: 0.9675 - val_IoU: 0.9577\n",
      "Epoch 81/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0906 - accuracy: 0.9997 - recall: 0.7815 - precision: 0.9871 - f1_score: 0.9148 - IoU: 0.8852\n",
      "Epoch 81: val_f1_score did not improve from 0.97479\n",
      "41/41 [==============================] - 23s 571ms/step - loss: 0.0906 - accuracy: 0.9997 - recall: 0.7815 - precision: 0.9871 - f1_score: 0.9148 - IoU: 0.8852 - val_loss: 0.0281 - val_accuracy: 1.0000 - val_recall: 0.9756 - val_precision: 0.9729 - val_f1_score: 0.9625 - val_IoU: 0.9672\n",
      "Epoch 82/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0888 - accuracy: 0.9997 - recall: 0.7860 - precision: 0.9863 - f1_score: 0.9167 - IoU: 0.8875\n",
      "Epoch 82: val_f1_score did not improve from 0.97479\n",
      "41/41 [==============================] - 23s 570ms/step - loss: 0.0888 - accuracy: 0.9997 - recall: 0.7860 - precision: 0.9863 - f1_score: 0.9167 - IoU: 0.8875 - val_loss: 0.0259 - val_accuracy: 1.0000 - val_recall: 0.9628 - val_precision: 0.9823 - val_f1_score: 0.9741 - val_IoU: 0.9595\n",
      "Epoch 83/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0890 - accuracy: 0.9997 - recall: 0.7878 - precision: 0.9871 - f1_score: 0.9165 - IoU: 0.8832\n",
      "Epoch 83: val_f1_score improved from 0.97479 to 0.97616, saving model to Trans UNet DA DICE 5-fold model/model_5fold.keras\n",
      "41/41 [==============================] - 24s 582ms/step - loss: 0.0890 - accuracy: 0.9997 - recall: 0.7878 - precision: 0.9871 - f1_score: 0.9165 - IoU: 0.8832 - val_loss: 0.0241 - val_accuracy: 1.0000 - val_recall: 0.9734 - val_precision: 0.9784 - val_f1_score: 0.9762 - val_IoU: 0.9693\n",
      "Epoch 84/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0859 - accuracy: 0.9997 - recall: 0.7790 - precision: 0.9889 - f1_score: 0.9196 - IoU: 0.8890\n",
      "Epoch 84: val_f1_score did not improve from 0.97616\n",
      "41/41 [==============================] - 23s 565ms/step - loss: 0.0859 - accuracy: 0.9997 - recall: 0.7790 - precision: 0.9889 - f1_score: 0.9196 - IoU: 0.8890 - val_loss: 0.0290 - val_accuracy: 1.0000 - val_recall: 0.9766 - val_precision: 0.9644 - val_f1_score: 0.9707 - val_IoU: 0.9684\n",
      "Epoch 85/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0897 - accuracy: 0.9997 - recall: 0.7802 - precision: 0.9860 - f1_score: 0.9158 - IoU: 0.8848\n",
      "Epoch 85: val_f1_score did not improve from 0.97616\n",
      "41/41 [==============================] - 23s 569ms/step - loss: 0.0897 - accuracy: 0.9997 - recall: 0.7802 - precision: 0.9860 - f1_score: 0.9158 - IoU: 0.8848 - val_loss: 0.0781 - val_accuracy: 0.9999 - val_recall: 0.8713 - val_precision: 0.9890 - val_f1_score: 0.9216 - val_IoU: 0.9113\n",
      "Epoch 86/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0913 - accuracy: 0.9997 - recall: 0.7842 - precision: 0.9855 - f1_score: 0.9143 - IoU: 0.8839\n",
      "Epoch 86: val_f1_score did not improve from 0.97616\n",
      "41/41 [==============================] - 23s 570ms/step - loss: 0.0913 - accuracy: 0.9997 - recall: 0.7842 - precision: 0.9855 - f1_score: 0.9143 - IoU: 0.8839 - val_loss: 0.0299 - val_accuracy: 1.0000 - val_recall: 0.9544 - val_precision: 0.9858 - val_f1_score: 0.9644 - val_IoU: 0.9511\n",
      "Epoch 87/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0863 - accuracy: 0.9997 - recall: 0.7842 - precision: 0.9890 - f1_score: 0.9189 - IoU: 0.8863\n",
      "Epoch 87: val_f1_score did not improve from 0.97616\n",
      "41/41 [==============================] - 23s 572ms/step - loss: 0.0863 - accuracy: 0.9997 - recall: 0.7842 - precision: 0.9890 - f1_score: 0.9189 - IoU: 0.8863 - val_loss: 0.0271 - val_accuracy: 1.0000 - val_recall: 0.9856 - val_precision: 0.9627 - val_f1_score: 0.9680 - val_IoU: 0.9761\n",
      "Epoch 88/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0865 - accuracy: 0.9997 - recall: 0.7805 - precision: 0.9924 - f1_score: 0.9188 - IoU: 0.8879\n",
      "Epoch 88: val_f1_score did not improve from 0.97616\n",
      "41/41 [==============================] - 23s 569ms/step - loss: 0.0865 - accuracy: 0.9997 - recall: 0.7805 - precision: 0.9924 - f1_score: 0.9188 - IoU: 0.8879 - val_loss: 0.0328 - val_accuracy: 1.0000 - val_recall: 0.9907 - val_precision: 0.9460 - val_f1_score: 0.9679 - val_IoU: 0.9741\n",
      "Epoch 89/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0935 - accuracy: 0.9997 - recall: 0.7809 - precision: 0.9807 - f1_score: 0.9120 - IoU: 0.8812\n",
      "Epoch 89: val_f1_score did not improve from 0.97616\n",
      "41/41 [==============================] - 24s 577ms/step - loss: 0.0935 - accuracy: 0.9997 - recall: 0.7809 - precision: 0.9807 - f1_score: 0.9120 - IoU: 0.8812 - val_loss: 0.0227 - val_accuracy: 1.0000 - val_recall: 0.9712 - val_precision: 0.9826 - val_f1_score: 0.9754 - val_IoU: 0.9685\n",
      "Epoch 90/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0927 - accuracy: 0.9997 - recall: 0.7814 - precision: 0.9869 - f1_score: 0.9127 - IoU: 0.8819\n",
      "Epoch 90: val_f1_score did not improve from 0.97616\n",
      "41/41 [==============================] - 23s 573ms/step - loss: 0.0927 - accuracy: 0.9997 - recall: 0.7814 - precision: 0.9869 - f1_score: 0.9127 - IoU: 0.8819 - val_loss: 0.8380 - val_accuracy: 0.9995 - val_recall: 0.0958 - val_precision: 0.9893 - val_f1_score: 0.1567 - val_IoU: 0.5372\n",
      "Epoch 91/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0958 - accuracy: 0.9996 - recall: 0.7768 - precision: 0.9829 - f1_score: 0.9103 - IoU: 0.8785\n",
      "Epoch 91: val_f1_score did not improve from 0.97616\n",
      "41/41 [==============================] - 24s 586ms/step - loss: 0.0958 - accuracy: 0.9996 - recall: 0.7768 - precision: 0.9829 - f1_score: 0.9103 - IoU: 0.8785 - val_loss: 0.0374 - val_accuracy: 0.9999 - val_recall: 0.9646 - val_precision: 0.9518 - val_f1_score: 0.9631 - val_IoU: 0.9616\n",
      "Epoch 92/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1067 - accuracy: 0.9996 - recall: 0.7660 - precision: 0.9735 - f1_score: 0.8999 - IoU: 0.8723\n",
      "Epoch 92: val_f1_score did not improve from 0.97616\n",
      "41/41 [==============================] - 23s 570ms/step - loss: 0.1067 - accuracy: 0.9996 - recall: 0.7660 - precision: 0.9735 - f1_score: 0.8999 - IoU: 0.8723 - val_loss: 0.1517 - val_accuracy: 0.9998 - val_recall: 0.9888 - val_precision: 0.7759 - val_f1_score: 0.7971 - val_IoU: 0.8971\n",
      "Epoch 93/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0963 - accuracy: 0.9997 - recall: 0.7723 - precision: 0.9829 - f1_score: 0.9096 - IoU: 0.8830\n",
      "Epoch 93: val_f1_score did not improve from 0.97616\n",
      "41/41 [==============================] - 23s 574ms/step - loss: 0.0963 - accuracy: 0.9997 - recall: 0.7723 - precision: 0.9829 - f1_score: 0.9096 - IoU: 0.8830 - val_loss: 0.1209 - val_accuracy: 0.9999 - val_recall: 0.8023 - val_precision: 0.9724 - val_f1_score: 0.8843 - val_IoU: 0.8810\n",
      "Epoch 94/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0948 - accuracy: 0.9997 - recall: 0.7717 - precision: 0.9851 - f1_score: 0.9108 - IoU: 0.8826\n",
      "Epoch 94: val_f1_score did not improve from 0.97616\n",
      "41/41 [==============================] - 24s 580ms/step - loss: 0.0948 - accuracy: 0.9997 - recall: 0.7717 - precision: 0.9851 - f1_score: 0.9108 - IoU: 0.8826 - val_loss: 0.3481 - val_accuracy: 0.9997 - val_recall: 0.4909 - val_precision: 0.9933 - val_f1_score: 0.6781 - val_IoU: 0.7141\n",
      "Epoch 95/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0921 - accuracy: 0.9996 - recall: 0.7922 - precision: 0.9820 - f1_score: 0.9136 - IoU: 0.8827\n",
      "Epoch 95: val_f1_score did not improve from 0.97616\n",
      "41/41 [==============================] - 24s 583ms/step - loss: 0.0921 - accuracy: 0.9996 - recall: 0.7922 - precision: 0.9820 - f1_score: 0.9136 - IoU: 0.8827 - val_loss: 0.0262 - val_accuracy: 1.0000 - val_recall: 0.9622 - val_precision: 0.9788 - val_f1_score: 0.9725 - val_IoU: 0.9616\n",
      "Epoch 96/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0880 - accuracy: 0.9997 - recall: 0.7816 - precision: 0.9869 - f1_score: 0.9171 - IoU: 0.8844\n",
      "Epoch 96: val_f1_score did not improve from 0.97616\n",
      "41/41 [==============================] - 25s 624ms/step - loss: 0.0880 - accuracy: 0.9997 - recall: 0.7816 - precision: 0.9869 - f1_score: 0.9171 - IoU: 0.8844 - val_loss: 0.0526 - val_accuracy: 0.9999 - val_recall: 0.8930 - val_precision: 0.9901 - val_f1_score: 0.9499 - val_IoU: 0.9223\n",
      "Epoch 97/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0875 - accuracy: 0.9997 - recall: 0.7839 - precision: 0.9868 - f1_score: 0.9179 - IoU: 0.8838\n",
      "Epoch 97: val_f1_score did not improve from 0.97616\n",
      "41/41 [==============================] - 26s 648ms/step - loss: 0.0875 - accuracy: 0.9997 - recall: 0.7839 - precision: 0.9868 - f1_score: 0.9179 - IoU: 0.8838 - val_loss: 0.0270 - val_accuracy: 1.0000 - val_recall: 0.9598 - val_precision: 0.9839 - val_f1_score: 0.9712 - val_IoU: 0.9604\n",
      "Epoch 98/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0868 - accuracy: 0.9997 - recall: 0.7829 - precision: 0.9890 - f1_score: 0.9186 - IoU: 0.8903\n",
      "Epoch 98: val_f1_score did not improve from 0.97616\n",
      "41/41 [==============================] - 25s 613ms/step - loss: 0.0868 - accuracy: 0.9997 - recall: 0.7829 - precision: 0.9890 - f1_score: 0.9186 - IoU: 0.8903 - val_loss: 0.0349 - val_accuracy: 1.0000 - val_recall: 0.9451 - val_precision: 0.9836 - val_f1_score: 0.9629 - val_IoU: 0.9477\n",
      "Epoch 99/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0851 - accuracy: 0.9997 - recall: 0.7920 - precision: 0.9933 - f1_score: 0.9199 - IoU: 0.8812\n",
      "Epoch 99: val_f1_score did not improve from 0.97616\n",
      "41/41 [==============================] - 24s 597ms/step - loss: 0.0851 - accuracy: 0.9997 - recall: 0.7920 - precision: 0.9933 - f1_score: 0.9199 - IoU: 0.8812 - val_loss: 0.0330 - val_accuracy: 1.0000 - val_recall: 0.9699 - val_precision: 0.9682 - val_f1_score: 0.9640 - val_IoU: 0.9631\n",
      "Epoch 100/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0900 - accuracy: 0.9996 - recall: 0.7861 - precision: 0.9827 - f1_score: 0.9156 - IoU: 0.8823\n",
      "Epoch 100: val_f1_score did not improve from 0.97616\n",
      "41/41 [==============================] - 25s 615ms/step - loss: 0.0900 - accuracy: 0.9996 - recall: 0.7861 - precision: 0.9827 - f1_score: 0.9156 - IoU: 0.8823 - val_loss: 0.1703 - val_accuracy: 0.9998 - val_recall: 0.9408 - val_precision: 0.8059 - val_f1_score: 0.7742 - val_IoU: 0.8773\n",
      "Epoch 101/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0914 - accuracy: 0.9997 - recall: 0.7744 - precision: 0.9836 - f1_score: 0.9141 - IoU: 0.8844\n",
      "Epoch 101: val_f1_score did not improve from 0.97616\n",
      "41/41 [==============================] - 23s 566ms/step - loss: 0.0914 - accuracy: 0.9997 - recall: 0.7744 - precision: 0.9836 - f1_score: 0.9141 - IoU: 0.8844 - val_loss: 0.0262 - val_accuracy: 1.0000 - val_recall: 0.9555 - val_precision: 0.9900 - val_f1_score: 0.9723 - val_IoU: 0.9587\n",
      "Epoch 102/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0825 - accuracy: 0.9997 - recall: 0.7869 - precision: 0.9946 - f1_score: 0.9227 - IoU: 0.8906\n",
      "Epoch 102: val_f1_score did not improve from 0.97616\n",
      "41/41 [==============================] - 27s 656ms/step - loss: 0.0825 - accuracy: 0.9997 - recall: 0.7869 - precision: 0.9946 - f1_score: 0.9227 - IoU: 0.8906 - val_loss: 0.0222 - val_accuracy: 1.0000 - val_recall: 0.9752 - val_precision: 0.9792 - val_f1_score: 0.9758 - val_IoU: 0.9702\n",
      "Epoch 103/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0970 - accuracy: 0.9997 - recall: 0.7660 - precision: 0.9878 - f1_score: 0.9087 - IoU: 0.8775\n",
      "Epoch 103: val_f1_score did not improve from 0.97616\n",
      "41/41 [==============================] - 26s 642ms/step - loss: 0.0970 - accuracy: 0.9997 - recall: 0.7660 - precision: 0.9878 - f1_score: 0.9087 - IoU: 0.8775 - val_loss: 0.0389 - val_accuracy: 1.0000 - val_recall: 0.9903 - val_precision: 0.9352 - val_f1_score: 0.9521 - val_IoU: 0.9727\n",
      "Epoch 104/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1066 - accuracy: 0.9996 - recall: 0.7788 - precision: 0.9662 - f1_score: 0.9000 - IoU: 0.8771\n",
      "Epoch 104: val_f1_score did not improve from 0.97616\n",
      "41/41 [==============================] - 27s 669ms/step - loss: 0.1066 - accuracy: 0.9996 - recall: 0.7788 - precision: 0.9662 - f1_score: 0.9000 - IoU: 0.8771 - val_loss: 0.0318 - val_accuracy: 1.0000 - val_recall: 0.9691 - val_precision: 0.9703 - val_f1_score: 0.9679 - val_IoU: 0.9662\n",
      "Epoch 105/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1040 - accuracy: 0.9997 - recall: 0.7694 - precision: 0.9698 - f1_score: 0.9021 - IoU: 0.8786\n",
      "Epoch 105: val_f1_score did not improve from 0.97616\n",
      "41/41 [==============================] - 29s 715ms/step - loss: 0.1040 - accuracy: 0.9997 - recall: 0.7694 - precision: 0.9698 - f1_score: 0.9021 - IoU: 0.8786 - val_loss: 0.1010 - val_accuracy: 0.9999 - val_recall: 0.8074 - val_precision: 0.9930 - val_f1_score: 0.9036 - val_IoU: 0.8572\n",
      "Epoch 106/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0908 - accuracy: 0.9997 - recall: 0.7807 - precision: 0.9903 - f1_score: 0.9148 - IoU: 0.8815\n",
      "Epoch 106: val_f1_score did not improve from 0.97616\n",
      "41/41 [==============================] - 27s 649ms/step - loss: 0.0908 - accuracy: 0.9997 - recall: 0.7807 - precision: 0.9903 - f1_score: 0.9148 - IoU: 0.8815 - val_loss: 0.0324 - val_accuracy: 1.0000 - val_recall: 0.9400 - val_precision: 0.9912 - val_f1_score: 0.9671 - val_IoU: 0.9475\n",
      "Epoch 107/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0874 - accuracy: 0.9997 - recall: 0.7893 - precision: 0.9870 - f1_score: 0.9180 - IoU: 0.8834\n",
      "Epoch 107: val_f1_score did not improve from 0.97616\n",
      "41/41 [==============================] - 27s 650ms/step - loss: 0.0874 - accuracy: 0.9997 - recall: 0.7893 - precision: 0.9870 - f1_score: 0.9180 - IoU: 0.8834 - val_loss: 0.0259 - val_accuracy: 1.0000 - val_recall: 0.9640 - val_precision: 0.9833 - val_f1_score: 0.9716 - val_IoU: 0.9647\n",
      "Epoch 108/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0927 - accuracy: 0.9996 - recall: 0.7751 - precision: 0.9824 - f1_score: 0.9130 - IoU: 0.8851\n",
      "Epoch 108: val_f1_score did not improve from 0.97616\n",
      "41/41 [==============================] - 28s 694ms/step - loss: 0.0927 - accuracy: 0.9996 - recall: 0.7751 - precision: 0.9824 - f1_score: 0.9130 - IoU: 0.8851 - val_loss: 0.0282 - val_accuracy: 1.0000 - val_recall: 0.9630 - val_precision: 0.9828 - val_f1_score: 0.9704 - val_IoU: 0.9632\n",
      "Epoch 109/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0931 - accuracy: 0.9997 - recall: 0.7774 - precision: 0.9806 - f1_score: 0.9123 - IoU: 0.8785\n",
      "Epoch 109: val_f1_score did not improve from 0.97616\n",
      "41/41 [==============================] - 28s 692ms/step - loss: 0.0931 - accuracy: 0.9997 - recall: 0.7774 - precision: 0.9806 - f1_score: 0.9123 - IoU: 0.8785 - val_loss: 0.0298 - val_accuracy: 1.0000 - val_recall: 0.9659 - val_precision: 0.9785 - val_f1_score: 0.9685 - val_IoU: 0.9637\n",
      "Epoch 110/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0838 - accuracy: 0.9997 - recall: 0.7890 - precision: 0.9952 - f1_score: 0.9213 - IoU: 0.8901\n",
      "Epoch 110: val_f1_score did not improve from 0.97616\n",
      "41/41 [==============================] - 29s 715ms/step - loss: 0.0838 - accuracy: 0.9997 - recall: 0.7890 - precision: 0.9952 - f1_score: 0.9213 - IoU: 0.8901 - val_loss: 0.0238 - val_accuracy: 1.0000 - val_recall: 0.9717 - val_precision: 0.9802 - val_f1_score: 0.9746 - val_IoU: 0.9691\n",
      "Epoch 111/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0865 - accuracy: 0.9997 - recall: 0.7892 - precision: 0.9869 - f1_score: 0.9186 - IoU: 0.8808\n",
      "Epoch 111: val_f1_score did not improve from 0.97616\n",
      "41/41 [==============================] - 32s 790ms/step - loss: 0.0865 - accuracy: 0.9997 - recall: 0.7892 - precision: 0.9869 - f1_score: 0.9186 - IoU: 0.8808 - val_loss: 0.0252 - val_accuracy: 1.0000 - val_recall: 0.9619 - val_precision: 0.9868 - val_f1_score: 0.9736 - val_IoU: 0.9642\n",
      "Epoch 112/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0888 - accuracy: 0.9997 - recall: 0.7864 - precision: 0.9881 - f1_score: 0.9161 - IoU: 0.8818\n",
      "Epoch 112: val_f1_score did not improve from 0.97616\n",
      "41/41 [==============================] - 28s 678ms/step - loss: 0.0888 - accuracy: 0.9997 - recall: 0.7864 - precision: 0.9881 - f1_score: 0.9161 - IoU: 0.8818 - val_loss: 0.0391 - val_accuracy: 1.0000 - val_recall: 0.9257 - val_precision: 0.9937 - val_f1_score: 0.9603 - val_IoU: 0.9424\n",
      "Epoch 113/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0911 - accuracy: 0.9996 - recall: 0.7809 - precision: 0.9856 - f1_score: 0.9145 - IoU: 0.8836\n",
      "Epoch 113: val_f1_score did not improve from 0.97616\n",
      "41/41 [==============================] - 29s 705ms/step - loss: 0.0911 - accuracy: 0.9996 - recall: 0.7809 - precision: 0.9856 - f1_score: 0.9145 - IoU: 0.8836 - val_loss: 0.0720 - val_accuracy: 0.9999 - val_recall: 0.8677 - val_precision: 0.9867 - val_f1_score: 0.9331 - val_IoU: 0.9068\n",
      "Epoch 114/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0951 - accuracy: 0.9996 - recall: 0.7826 - precision: 0.9763 - f1_score: 0.9106 - IoU: 0.8799\n",
      "Epoch 114: val_f1_score did not improve from 0.97616\n",
      "41/41 [==============================] - 30s 732ms/step - loss: 0.0951 - accuracy: 0.9996 - recall: 0.7826 - precision: 0.9763 - f1_score: 0.9106 - IoU: 0.8799 - val_loss: 0.1612 - val_accuracy: 0.9998 - val_recall: 0.9588 - val_precision: 0.7858 - val_f1_score: 0.7887 - val_IoU: 0.8832\n",
      "Epoch 115/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0999 - accuracy: 0.9996 - recall: 0.7747 - precision: 0.9742 - f1_score: 0.9059 - IoU: 0.8779\n",
      "Epoch 115: val_f1_score did not improve from 0.97616\n",
      "41/41 [==============================] - 26s 644ms/step - loss: 0.0999 - accuracy: 0.9996 - recall: 0.7747 - precision: 0.9742 - f1_score: 0.9059 - IoU: 0.8779 - val_loss: 0.2328 - val_accuracy: 0.9997 - val_recall: 0.9684 - val_precision: 0.7000 - val_f1_score: 0.7206 - val_IoU: 0.8481\n",
      "Epoch 116/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1079 - accuracy: 0.9996 - recall: 0.7605 - precision: 0.9696 - f1_score: 0.8982 - IoU: 0.8734\n",
      "Epoch 116: val_f1_score did not improve from 0.97616\n",
      "41/41 [==============================] - 26s 623ms/step - loss: 0.1079 - accuracy: 0.9996 - recall: 0.7605 - precision: 0.9696 - f1_score: 0.8982 - IoU: 0.8734 - val_loss: 0.6742 - val_accuracy: 0.9995 - val_recall: 0.1780 - val_precision: 0.9877 - val_f1_score: 0.3766 - val_IoU: 0.5804\n",
      "Epoch 117/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0983 - accuracy: 0.9996 - recall: 0.7842 - precision: 0.9742 - f1_score: 0.9078 - IoU: 0.8760\n",
      "Epoch 117: val_f1_score did not improve from 0.97616\n",
      "41/41 [==============================] - 27s 662ms/step - loss: 0.0983 - accuracy: 0.9996 - recall: 0.7842 - precision: 0.9742 - f1_score: 0.9078 - IoU: 0.8760 - val_loss: 0.0327 - val_accuracy: 1.0000 - val_recall: 0.9649 - val_precision: 0.9710 - val_f1_score: 0.9665 - val_IoU: 0.9631\n",
      "Epoch 118/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0878 - accuracy: 0.9997 - recall: 0.7819 - precision: 0.9919 - f1_score: 0.9172 - IoU: 0.8831\n",
      "Epoch 118: val_f1_score did not improve from 0.97616\n",
      "41/41 [==============================] - 29s 699ms/step - loss: 0.0878 - accuracy: 0.9997 - recall: 0.7819 - precision: 0.9919 - f1_score: 0.9172 - IoU: 0.8831 - val_loss: 0.0264 - val_accuracy: 1.0000 - val_recall: 0.9604 - val_precision: 0.9848 - val_f1_score: 0.9709 - val_IoU: 0.9612\n",
      "Epoch 119/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0884 - accuracy: 0.9997 - recall: 0.7939 - precision: 0.9838 - f1_score: 0.9169 - IoU: 0.8854\n",
      "Epoch 119: val_f1_score did not improve from 0.97616\n",
      "41/41 [==============================] - 29s 697ms/step - loss: 0.0884 - accuracy: 0.9997 - recall: 0.7939 - precision: 0.9838 - f1_score: 0.9169 - IoU: 0.8854 - val_loss: 0.0283 - val_accuracy: 1.0000 - val_recall: 0.9733 - val_precision: 0.9710 - val_f1_score: 0.9703 - val_IoU: 0.9666\n",
      "Epoch 120/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0895 - accuracy: 0.9997 - recall: 0.7819 - precision: 0.9865 - f1_score: 0.9158 - IoU: 0.8838\n",
      "Epoch 120: val_f1_score did not improve from 0.97616\n",
      "41/41 [==============================] - 28s 679ms/step - loss: 0.0895 - accuracy: 0.9997 - recall: 0.7819 - precision: 0.9865 - f1_score: 0.9158 - IoU: 0.8838 - val_loss: 0.0507 - val_accuracy: 0.9999 - val_recall: 0.9930 - val_precision: 0.9123 - val_f1_score: 0.9371 - val_IoU: 0.9635\n",
      "Epoch 121/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0872 - accuracy: 0.9997 - recall: 0.7842 - precision: 0.9884 - f1_score: 0.9179 - IoU: 0.8838\n",
      "Epoch 121: val_f1_score did not improve from 0.97616\n",
      "41/41 [==============================] - 29s 709ms/step - loss: 0.0872 - accuracy: 0.9997 - recall: 0.7842 - precision: 0.9884 - f1_score: 0.9179 - IoU: 0.8838 - val_loss: 0.0432 - val_accuracy: 1.0000 - val_recall: 0.9642 - val_precision: 0.9601 - val_f1_score: 0.9395 - val_IoU: 0.9566\n",
      "Epoch 122/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0868 - accuracy: 0.9997 - recall: 0.7847 - precision: 0.9876 - f1_score: 0.9184 - IoU: 0.8838\n",
      "Epoch 122: val_f1_score did not improve from 0.97616\n",
      "41/41 [==============================] - 28s 682ms/step - loss: 0.0868 - accuracy: 0.9997 - recall: 0.7847 - precision: 0.9876 - f1_score: 0.9184 - IoU: 0.8838 - val_loss: 0.0233 - val_accuracy: 1.0000 - val_recall: 0.9767 - val_precision: 0.9757 - val_f1_score: 0.9746 - val_IoU: 0.9720\n",
      "Epoch 123/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0873 - accuracy: 0.9997 - recall: 0.7828 - precision: 0.9874 - f1_score: 0.9178 - IoU: 0.8853\n",
      "Epoch 123: val_f1_score did not improve from 0.97616\n",
      "41/41 [==============================] - 28s 687ms/step - loss: 0.0873 - accuracy: 0.9997 - recall: 0.7828 - precision: 0.9874 - f1_score: 0.9178 - IoU: 0.8853 - val_loss: 0.0237 - val_accuracy: 1.0000 - val_recall: 0.9786 - val_precision: 0.9742 - val_f1_score: 0.9738 - val_IoU: 0.9732\n",
      "Epoch 124/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0879 - accuracy: 0.9996 - recall: 0.7845 - precision: 0.9882 - f1_score: 0.9176 - IoU: 0.8846\n",
      "Epoch 124: val_f1_score did not improve from 0.97616\n",
      "41/41 [==============================] - 29s 711ms/step - loss: 0.0879 - accuracy: 0.9996 - recall: 0.7845 - precision: 0.9882 - f1_score: 0.9176 - IoU: 0.8846 - val_loss: 0.5411 - val_accuracy: 0.9996 - val_recall: 0.3016 - val_precision: 0.9956 - val_f1_score: 0.4112 - val_IoU: 0.6307\n",
      "Epoch 125/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0886 - accuracy: 0.9997 - recall: 0.7816 - precision: 0.9870 - f1_score: 0.9165 - IoU: 0.8861\n",
      "Epoch 125: val_f1_score did not improve from 0.97616\n",
      "41/41 [==============================] - 29s 710ms/step - loss: 0.0886 - accuracy: 0.9997 - recall: 0.7816 - precision: 0.9870 - f1_score: 0.9165 - IoU: 0.8861 - val_loss: 0.0251 - val_accuracy: 1.0000 - val_recall: 0.9600 - val_precision: 0.9870 - val_f1_score: 0.9734 - val_IoU: 0.9623\n",
      "Epoch 126/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0879 - accuracy: 0.9997 - recall: 0.7881 - precision: 0.9860 - f1_score: 0.9173 - IoU: 0.8833\n",
      "Epoch 126: val_f1_score did not improve from 0.97616\n",
      "41/41 [==============================] - 28s 693ms/step - loss: 0.0879 - accuracy: 0.9997 - recall: 0.7881 - precision: 0.9860 - f1_score: 0.9173 - IoU: 0.8833 - val_loss: 0.0236 - val_accuracy: 1.0000 - val_recall: 0.9663 - val_precision: 0.9850 - val_f1_score: 0.9744 - val_IoU: 0.9682\n",
      "Epoch 127/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0860 - accuracy: 0.9997 - recall: 0.7881 - precision: 0.9891 - f1_score: 0.9191 - IoU: 0.8839\n",
      "Epoch 127: val_f1_score did not improve from 0.97616\n",
      "41/41 [==============================] - 27s 656ms/step - loss: 0.0860 - accuracy: 0.9997 - recall: 0.7881 - precision: 0.9891 - f1_score: 0.9191 - IoU: 0.8839 - val_loss: 0.0231 - val_accuracy: 1.0000 - val_recall: 0.9748 - val_precision: 0.9788 - val_f1_score: 0.9744 - val_IoU: 0.9729\n",
      "Epoch 128/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0846 - accuracy: 0.9997 - recall: 0.7843 - precision: 0.9886 - f1_score: 0.9204 - IoU: 0.8831\n",
      "Epoch 128: val_f1_score did not improve from 0.97616\n",
      "41/41 [==============================] - 28s 697ms/step - loss: 0.0846 - accuracy: 0.9997 - recall: 0.7843 - precision: 0.9886 - f1_score: 0.9204 - IoU: 0.8831 - val_loss: 0.0234 - val_accuracy: 1.0000 - val_recall: 0.9645 - val_precision: 0.9868 - val_f1_score: 0.9752 - val_IoU: 0.9678\n",
      "Epoch 129/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0868 - accuracy: 0.9997 - recall: 0.7858 - precision: 0.9885 - f1_score: 0.9184 - IoU: 0.8855\n",
      "Epoch 129: val_f1_score did not improve from 0.97616\n",
      "41/41 [==============================] - 28s 684ms/step - loss: 0.0868 - accuracy: 0.9997 - recall: 0.7858 - precision: 0.9885 - f1_score: 0.9184 - IoU: 0.8855 - val_loss: 0.0239 - val_accuracy: 1.0000 - val_recall: 0.9844 - val_precision: 0.9671 - val_f1_score: 0.9745 - val_IoU: 0.9766\n",
      "Epoch 130/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0836 - accuracy: 0.9997 - recall: 0.7821 - precision: 0.9950 - f1_score: 0.9213 - IoU: 0.8836\n",
      "Epoch 130: val_f1_score did not improve from 0.97616\n",
      "41/41 [==============================] - 29s 703ms/step - loss: 0.0836 - accuracy: 0.9997 - recall: 0.7821 - precision: 0.9950 - f1_score: 0.9213 - IoU: 0.8836 - val_loss: 0.0239 - val_accuracy: 1.0000 - val_recall: 0.9689 - val_precision: 0.9825 - val_f1_score: 0.9748 - val_IoU: 0.9686\n",
      "Epoch 131/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0876 - accuracy: 0.9997 - recall: 0.7889 - precision: 0.9832 - f1_score: 0.9176 - IoU: 0.8816\n",
      "Epoch 131: val_f1_score did not improve from 0.97616\n",
      "41/41 [==============================] - 27s 661ms/step - loss: 0.0876 - accuracy: 0.9997 - recall: 0.7889 - precision: 0.9832 - f1_score: 0.9176 - IoU: 0.8816 - val_loss: 0.0230 - val_accuracy: 1.0000 - val_recall: 0.9693 - val_precision: 0.9841 - val_f1_score: 0.9747 - val_IoU: 0.9705\n",
      "Epoch 132/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0859 - accuracy: 0.9997 - recall: 0.7875 - precision: 0.9887 - f1_score: 0.9190 - IoU: 0.8800\n",
      "Epoch 132: val_f1_score improved from 0.97616 to 0.97725, saving model to Trans UNet DA DICE 5-fold model/model_5fold.keras\n",
      "41/41 [==============================] - 32s 778ms/step - loss: 0.0859 - accuracy: 0.9997 - recall: 0.7875 - precision: 0.9887 - f1_score: 0.9190 - IoU: 0.8800 - val_loss: 0.0221 - val_accuracy: 1.0000 - val_recall: 0.9735 - val_precision: 0.9816 - val_f1_score: 0.9773 - val_IoU: 0.9713\n",
      "Epoch 133/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0832 - accuracy: 0.9997 - recall: 0.7945 - precision: 0.9899 - f1_score: 0.9218 - IoU: 0.8826\n",
      "Epoch 133: val_f1_score did not improve from 0.97725\n",
      "41/41 [==============================] - 29s 711ms/step - loss: 0.0832 - accuracy: 0.9997 - recall: 0.7945 - precision: 0.9899 - f1_score: 0.9218 - IoU: 0.8826 - val_loss: 0.0248 - val_accuracy: 1.0000 - val_recall: 0.9583 - val_precision: 0.9884 - val_f1_score: 0.9743 - val_IoU: 0.9630\n",
      "Epoch 134/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0866 - accuracy: 0.9997 - recall: 0.7814 - precision: 0.9890 - f1_score: 0.9186 - IoU: 0.8844\n",
      "Epoch 134: val_f1_score did not improve from 0.97725\n",
      "41/41 [==============================] - 27s 669ms/step - loss: 0.0866 - accuracy: 0.9997 - recall: 0.7814 - precision: 0.9890 - f1_score: 0.9186 - IoU: 0.8844 - val_loss: 0.0218 - val_accuracy: 1.0000 - val_recall: 0.9849 - val_precision: 0.9702 - val_f1_score: 0.9765 - val_IoU: 0.9775\n",
      "Epoch 135/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0808 - accuracy: 0.9997 - recall: 0.7876 - precision: 0.9960 - f1_score: 0.9240 - IoU: 0.8873\n",
      "Epoch 135: val_f1_score improved from 0.97725 to 0.97768, saving model to Trans UNet DA DICE 5-fold model/model_5fold.keras\n",
      "41/41 [==============================] - 29s 711ms/step - loss: 0.0808 - accuracy: 0.9997 - recall: 0.7876 - precision: 0.9960 - f1_score: 0.9240 - IoU: 0.8873 - val_loss: 0.0211 - val_accuracy: 1.0000 - val_recall: 0.9790 - val_precision: 0.9777 - val_f1_score: 0.9777 - val_IoU: 0.9750\n",
      "Epoch 136/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0906 - accuracy: 0.9997 - recall: 0.7823 - precision: 0.9829 - f1_score: 0.9142 - IoU: 0.8811\n",
      "Epoch 136: val_f1_score did not improve from 0.97768\n",
      "41/41 [==============================] - 29s 719ms/step - loss: 0.0906 - accuracy: 0.9997 - recall: 0.7823 - precision: 0.9829 - f1_score: 0.9142 - IoU: 0.8811 - val_loss: 0.0232 - val_accuracy: 1.0000 - val_recall: 0.9674 - val_precision: 0.9850 - val_f1_score: 0.9746 - val_IoU: 0.9687\n",
      "Epoch 137/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0853 - accuracy: 0.9997 - recall: 0.7879 - precision: 0.9892 - f1_score: 0.9199 - IoU: 0.8813\n",
      "Epoch 137: val_f1_score did not improve from 0.97768\n",
      "41/41 [==============================] - 26s 641ms/step - loss: 0.0853 - accuracy: 0.9997 - recall: 0.7879 - precision: 0.9892 - f1_score: 0.9199 - IoU: 0.8813 - val_loss: 0.0398 - val_accuracy: 1.0000 - val_recall: 0.9764 - val_precision: 0.9579 - val_f1_score: 0.9512 - val_IoU: 0.9651\n",
      "Epoch 138/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0860 - accuracy: 0.9997 - recall: 0.7885 - precision: 0.9862 - f1_score: 0.9191 - IoU: 0.8829\n",
      "Epoch 138: val_f1_score did not improve from 0.97768\n",
      "41/41 [==============================] - 27s 666ms/step - loss: 0.0860 - accuracy: 0.9997 - recall: 0.7885 - precision: 0.9862 - f1_score: 0.9191 - IoU: 0.8829 - val_loss: 0.0245 - val_accuracy: 1.0000 - val_recall: 0.9657 - val_precision: 0.9849 - val_f1_score: 0.9740 - val_IoU: 0.9669\n",
      "Epoch 139/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0850 - accuracy: 0.9997 - recall: 0.7862 - precision: 0.9905 - f1_score: 0.9200 - IoU: 0.8819\n",
      "Epoch 139: val_f1_score did not improve from 0.97768\n",
      "41/41 [==============================] - 30s 727ms/step - loss: 0.0850 - accuracy: 0.9997 - recall: 0.7862 - precision: 0.9905 - f1_score: 0.9200 - IoU: 0.8819 - val_loss: 0.0224 - val_accuracy: 1.0000 - val_recall: 0.9870 - val_precision: 0.9676 - val_f1_score: 0.9766 - val_IoU: 0.9790\n",
      "Epoch 140/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0868 - accuracy: 0.9997 - recall: 0.7898 - precision: 0.9882 - f1_score: 0.9182 - IoU: 0.8832\n",
      "Epoch 140: val_f1_score did not improve from 0.97768\n",
      "41/41 [==============================] - 29s 713ms/step - loss: 0.0868 - accuracy: 0.9997 - recall: 0.7898 - precision: 0.9882 - f1_score: 0.9182 - IoU: 0.8832 - val_loss: 0.0332 - val_accuracy: 1.0000 - val_recall: 0.9376 - val_precision: 0.9941 - val_f1_score: 0.9665 - val_IoU: 0.9523\n",
      "Epoch 141/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0845 - accuracy: 0.9997 - recall: 0.7841 - precision: 0.9891 - f1_score: 0.9206 - IoU: 0.8832\n",
      "Epoch 141: val_f1_score did not improve from 0.97768\n",
      "41/41 [==============================] - 25s 612ms/step - loss: 0.0845 - accuracy: 0.9997 - recall: 0.7841 - precision: 0.9891 - f1_score: 0.9206 - IoU: 0.8832 - val_loss: 0.0209 - val_accuracy: 1.0000 - val_recall: 0.9805 - val_precision: 0.9758 - val_f1_score: 0.9775 - val_IoU: 0.9764\n",
      "Epoch 142/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0930 - accuracy: 0.9997 - recall: 0.7790 - precision: 0.9729 - f1_score: 0.9123 - IoU: 0.8763\n",
      "Epoch 142: val_f1_score did not improve from 0.97768\n",
      "41/41 [==============================] - 27s 671ms/step - loss: 0.0930 - accuracy: 0.9997 - recall: 0.7790 - precision: 0.9729 - f1_score: 0.9123 - IoU: 0.8763 - val_loss: 0.0306 - val_accuracy: 1.0000 - val_recall: 0.9492 - val_precision: 0.9834 - val_f1_score: 0.9690 - val_IoU: 0.9581\n",
      "Epoch 143/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0926 - accuracy: 0.9997 - recall: 0.7781 - precision: 0.9865 - f1_score: 0.9128 - IoU: 0.8776\n",
      "Epoch 143: val_f1_score did not improve from 0.97768\n",
      "41/41 [==============================] - 30s 727ms/step - loss: 0.0926 - accuracy: 0.9997 - recall: 0.7781 - precision: 0.9865 - f1_score: 0.9128 - IoU: 0.8776 - val_loss: 0.1729 - val_accuracy: 0.9998 - val_recall: 0.7082 - val_precision: 0.9763 - val_f1_score: 0.8230 - val_IoU: 0.8227\n",
      "Epoch 144/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1016 - accuracy: 0.9996 - recall: 0.7792 - precision: 0.9729 - f1_score: 0.9040 - IoU: 0.8751\n",
      "Epoch 144: val_f1_score did not improve from 0.97768\n",
      "41/41 [==============================] - 29s 706ms/step - loss: 0.1016 - accuracy: 0.9996 - recall: 0.7792 - precision: 0.9729 - f1_score: 0.9040 - IoU: 0.8751 - val_loss: 0.1069 - val_accuracy: 0.9999 - val_recall: 0.8041 - val_precision: 0.9835 - val_f1_score: 0.8974 - val_IoU: 0.8725\n",
      "Epoch 145/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0861 - accuracy: 0.9997 - recall: 0.7868 - precision: 0.9930 - f1_score: 0.9191 - IoU: 0.8848\n",
      "Epoch 145: val_f1_score did not improve from 0.97768\n",
      "41/41 [==============================] - 33s 816ms/step - loss: 0.0861 - accuracy: 0.9997 - recall: 0.7868 - precision: 0.9930 - f1_score: 0.9191 - IoU: 0.8848 - val_loss: 0.0263 - val_accuracy: 1.0000 - val_recall: 0.9655 - val_precision: 0.9816 - val_f1_score: 0.9722 - val_IoU: 0.9664\n",
      "Epoch 146/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0898 - accuracy: 0.9997 - recall: 0.7808 - precision: 0.9802 - f1_score: 0.9153 - IoU: 0.8837\n",
      "Epoch 146: val_f1_score did not improve from 0.97768\n",
      "41/41 [==============================] - 38s 943ms/step - loss: 0.0898 - accuracy: 0.9997 - recall: 0.7808 - precision: 0.9802 - f1_score: 0.9153 - IoU: 0.8837 - val_loss: 0.0349 - val_accuracy: 1.0000 - val_recall: 0.9931 - val_precision: 0.9357 - val_f1_score: 0.9647 - val_IoU: 0.9718\n",
      "Epoch 147/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0876 - accuracy: 0.9997 - recall: 0.7884 - precision: 0.9861 - f1_score: 0.9176 - IoU: 0.8830\n",
      "Epoch 147: val_f1_score did not improve from 0.97768\n",
      "41/41 [==============================] - 29s 701ms/step - loss: 0.0876 - accuracy: 0.9997 - recall: 0.7884 - precision: 0.9861 - f1_score: 0.9176 - IoU: 0.8830 - val_loss: 0.0264 - val_accuracy: 1.0000 - val_recall: 0.9549 - val_precision: 0.9900 - val_f1_score: 0.9731 - val_IoU: 0.9594\n",
      "Epoch 148/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0857 - accuracy: 0.9997 - recall: 0.7816 - precision: 0.9892 - f1_score: 0.9193 - IoU: 0.8847\n",
      "Epoch 148: val_f1_score did not improve from 0.97768\n",
      "41/41 [==============================] - 35s 871ms/step - loss: 0.0857 - accuracy: 0.9997 - recall: 0.7816 - precision: 0.9892 - f1_score: 0.9193 - IoU: 0.8847 - val_loss: 0.0272 - val_accuracy: 1.0000 - val_recall: 0.9536 - val_precision: 0.9897 - val_f1_score: 0.9724 - val_IoU: 0.9618\n",
      "Epoch 149/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0879 - accuracy: 0.9997 - recall: 0.7830 - precision: 0.9884 - f1_score: 0.9172 - IoU: 0.8790\n",
      "Epoch 149: val_f1_score did not improve from 0.97768\n",
      "41/41 [==============================] - 30s 735ms/step - loss: 0.0879 - accuracy: 0.9997 - recall: 0.7830 - precision: 0.9884 - f1_score: 0.9172 - IoU: 0.8790 - val_loss: 0.0251 - val_accuracy: 1.0000 - val_recall: 0.9600 - val_precision: 0.9888 - val_f1_score: 0.9738 - val_IoU: 0.9636\n",
      "Epoch 150/150\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0820 - accuracy: 0.9997 - recall: 0.7859 - precision: 0.9954 - f1_score: 0.9229 - IoU: 0.8857\n",
      "Epoch 150: val_f1_score improved from 0.97768 to 0.97875, saving model to Trans UNet DA DICE 5-fold model/model_5fold.keras\n",
      "41/41 [==============================] - 27s 665ms/step - loss: 0.0820 - accuracy: 0.9997 - recall: 0.7859 - precision: 0.9954 - f1_score: 0.9229 - IoU: 0.8857 - val_loss: 0.0213 - val_accuracy: 1.0000 - val_recall: 0.9802 - val_precision: 0.9769 - val_f1_score: 0.9788 - val_IoU: 0.9756\n",
      "O modelo demorou 3900.92 segundos para treinar.\n",
      "Métricas salvas com sucesso na pasta: Trans UNet DA DICE 5-fold model\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "jacc = []\n",
    "f1 = []\n",
    "prec = []\n",
    "rec = []\n",
    "\n",
    "# Dicionário para armazenar métricas por fold\n",
    "fold_metrics_summary = []\n",
    "seed = [42, 21, 5, 10, 72]\n",
    "\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=28)\n",
    "fold = 3\n",
    "\n",
    "for i, (train_ind, test_ind) in enumerate(kf.split(X)):\n",
    "    if i < (fold-1):\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    print(\"Fold: \" + str(fold))\n",
    "    X_train, X_val, y_train, y_val = X[train_ind], X[test_ind], y[train_ind], y[test_ind]\n",
    "\n",
    "    model = trans_unet()\n",
    "    \n",
    "    \n",
    "    checkpoint_filepath = os.path.join(output_dir, f'model_{fold}fold.keras')\n",
    "    callbacks = [\n",
    "            tf.keras.callbacks.TensorBoard(log_dir='logs'),\n",
    "            tf.keras.callbacks.ModelCheckpoint(\n",
    "                filepath=checkpoint_filepath,\n",
    "                save_weights_only=False,\n",
    "                monitor='val_f1_score',\n",
    "                mode='max',\n",
    "                save_best_only=True,\n",
    "                verbose=1)]\n",
    "    \n",
    "    image_generator = data_genX.flow(X_train, batch_size=16, seed=seed[fold-1])\n",
    "    mask_generator = data_genY.flow(y_train, batch_size=16, seed=seed[fold-1])\n",
    "    \n",
    "    # Criar um gerador que produza (imagem, máscara) no mesmo passo\n",
    "    train_generator = zip(image_generator, mask_generator)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model.fit(train_generator, steps_per_epoch=len(X_train) // 16, validation_data=(X_val,y_val), epochs=150, callbacks=callbacks, class_weight={0:1.0, 1:100.0})\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "\n",
    "     # Salvando o tempo de treinamento\n",
    "    with open(os.path.join(output_dir, 'training_time.txt'), 'a') as f:\n",
    "        f.write(f'Fold {fold}: {training_time:.2f} segundos\\n')\n",
    "    print(f\"O modelo demorou {training_time:.2f} segundos para treinar.\")\n",
    "    \n",
    "    loss = model.history.history['loss']\n",
    "    val_loss = model.history.history['val_loss']\n",
    "    \n",
    "    with open(os.path.join(output_dir, f'loss_fold{fold}.csv'), 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=';')\n",
    "        writer.writerow([\"Epoch\", \"Loss\", \"Validation Loss\"])\n",
    "        for epoch, (l, vl) in enumerate(zip(loss, val_loss), start=1):\n",
    "            writer.writerow([epoch, l, vl])\n",
    "            \n",
    "     # Plotando e salvando a figura\n",
    "    plt.figure()\n",
    "    plt.plot(loss, 'r', label='Training loss')\n",
    "    plt.plot(val_loss, 'g', label='Validation loss')\n",
    "    plt.title(f'Training and Validation Loss - Fold {fold}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss Value')\n",
    "    plt.ylim([0, 1])\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(output_dir, f'loss_plot_fold{fold}.png'))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    fold_metrics = []\n",
    "\n",
    "    acc_fold = []\n",
    "    jacc_fold = []\n",
    "    f1_fold = []\n",
    "    prec_fold = []\n",
    "    rec_fold = []\n",
    "    \n",
    "    for i in range(0, len(X_val)):\n",
    "        sample_image = X_val[i]\n",
    "        sample_mask = y_val[i].astype(np.uint8).flatten()\n",
    "        prediction = model.predict(sample_image[tf.newaxis, ...],verbose=0)[0]\n",
    "        predicted_mask = (prediction > 0.5).astype(np.uint8).flatten()\n",
    "            \n",
    "        acc_score = accuracy_score(sample_mask, predicted_mask)\n",
    "        jacc_score = jaccard_score(sample_mask, predicted_mask)\n",
    "        f1_score_val = f1_score(sample_mask, predicted_mask).numpy()\n",
    "        prec_score = precision_score(sample_mask, predicted_mask)\n",
    "        rec_score = recall_score(sample_mask, predicted_mask)\n",
    "\n",
    "        acc_fold.append(acc_score)\n",
    "        jacc_fold.append(jacc_score)\n",
    "        f1_fold.append(f1_score_val)\n",
    "        prec_fold.append(prec_score)\n",
    "        rec_fold.append(rec_score)\n",
    "\n",
    "        fold_metrics.append([i, acc_score, jacc_score, f1_score_val, prec_score, rec_score])\n",
    "        \n",
    "    # Salvando métricas por imagem\n",
    "    with open(os.path.join(output_dir, f'metrics_fold{fold}.csv'), 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=';')\n",
    "        writer.writerow([\"Index\", \"Accuracy\", \"Jaccard\", \"DICE\", \"Precision\", \"Recall\"])\n",
    "        writer.writerows(fold_metrics)\n",
    "\n",
    "    # Salvando a média do fold para cada métrica\n",
    "    fold_metrics_summary.append([\n",
    "        fold, np.mean(acc_fold), np.std(acc_fold),\n",
    "        np.mean(jacc_fold), np.std(jacc_fold),\n",
    "        np.mean(f1_fold), np.std(f1_fold),\n",
    "        np.mean(prec_fold), np.std(prec_fold),\n",
    "        np.mean(rec_fold), np.std(rec_fold)\n",
    "    ])\n",
    "\n",
    "        \n",
    "    del model \n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    fold+=1\n",
    "    \n",
    "# Calculando médias gerais\n",
    "acc_total = [m[1] for m in fold_metrics_summary]\n",
    "jacc_total = [m[3] for m in fold_metrics_summary]\n",
    "f1_total = [m[5] for m in fold_metrics_summary]\n",
    "prec_total = [m[7] for m in fold_metrics_summary]\n",
    "rec_total = [m[9] for m in fold_metrics_summary]\n",
    "\n",
    "general_summary = [\n",
    "    [\"Fold\", \"Accuracy Mean\", \"Accuracy Std\", \"Jaccard Mean\", \"Jaccard Std\",\n",
    "     \"DICE Mean\", \"DICE Std\", \"Precision Mean\", \"Precision Std\", \"Recall Mean\", \"Recall Std\"]\n",
    "]\n",
    "\n",
    "general_summary.extend(fold_metrics_summary)\n",
    "\n",
    "general_summary.append([\n",
    "    \"Overall Mean\", np.mean(acc_total), np.std(acc_total),\n",
    "    np.mean(jacc_total), np.std(jacc_total),\n",
    "    np.mean(f1_total), np.std(f1_total),\n",
    "    np.mean(prec_total), np.std(prec_total),\n",
    "    np.mean(rec_total), np.std(rec_total)\n",
    "])\n",
    "\n",
    "# Salvando o resumo das métricas por fold e geral\n",
    "with open(os.path.join(output_dir, 'metrics_summary.csv'), 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=';')\n",
    "    writer.writerows(general_summary)\n",
    "\n",
    "print(\"Métricas salvas com sucesso na pasta:\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa5d184f-5b31-4156-849f-d24ddac7c3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "k-fold:  20%|███████████████▍                                                             | 1/5 [00:52<03:30, 52.66s/it]/home/mbouzon/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "k-fold:  40%|██████████████████████████████▊                                              | 2/5 [01:44<02:36, 52.29s/it]/home/mbouzon/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mbouzon/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "k-fold: 100%|█████████████████████████████████████████████████████████████████████████████| 5/5 [04:10<00:00, 50.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas salvas com sucesso na pasta: Trans UNet DA DICE 5-fold model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "acc_mean_fold = []\n",
    "jacc_mean_fold = []\n",
    "f1_mean_fold = []\n",
    "prec_mean_fold = []\n",
    "rec_mean_fold = []\n",
    "\n",
    "acc_std_fold = []\n",
    "jacc_std_fold = []\n",
    "f1_std_fold = []\n",
    "prec_std_fold = []\n",
    "rec_std_fold = []\n",
    "\n",
    "\n",
    "# Dicionário para armazenar métricas por fold\n",
    "fold_metrics_summary = []\n",
    "\n",
    "fold = 1\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=28)\n",
    "for train_ind, test_ind in tqdm(kf.split(X), total=kf.get_n_splits(), desc=\"k-fold\"):\n",
    "    X_train, X_val, y_train, y_val = X[train_ind], X[test_ind], y[train_ind], y[test_ind]\n",
    "\n",
    "    fold_metrics = []\n",
    "\n",
    "    acc_fold = []\n",
    "    jacc_fold = []\n",
    "    f1_fold = []\n",
    "    prec_fold = []\n",
    "    rec_fold = []\n",
    "    \n",
    "    model_filepath = filepath = os.path.join(output_dir, f'model_{fold}fold.keras')\n",
    "    model = tf.keras.models.load_model(model_filepath)\n",
    "\n",
    "    for i in range(0, len(X_val)):\n",
    "        sample_image = X_val[i]\n",
    "        sample_mask = y_val[i].astype(np.uint8).flatten()\n",
    "        prediction = model.predict(sample_image[tf.newaxis, ...],verbose=0)[0]\n",
    "        predicted_mask = (prediction > 0.5).astype(np.uint8).flatten()\n",
    "            \n",
    "        acc_score = accuracy_score(sample_mask, predicted_mask)\n",
    "        jacc_score = jaccard_score(sample_mask, predicted_mask)\n",
    "        f1_score_val = f1_score(sample_mask, predicted_mask).numpy()\n",
    "        prec_score = precision_score(sample_mask, predicted_mask)\n",
    "        rec_score = recall_score(sample_mask, predicted_mask)\n",
    "\n",
    "        acc_fold.append(acc_score)\n",
    "        jacc_fold.append(jacc_score)\n",
    "        f1_fold.append(f1_score_val)\n",
    "        prec_fold.append(prec_score)\n",
    "        rec_fold.append(rec_score)\n",
    "\n",
    "        fold_metrics.append([i, acc_score, jacc_score, f1_score_val, prec_score, rec_score])\n",
    "        \n",
    "    # Salvando métricas por imagem\n",
    "    with open(os.path.join(output_dir, f'metrics_fold{fold}.csv'), 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=';')\n",
    "        writer.writerow([\"Index\", \"Accuracy\", \"Jaccard\", \"DICE\", \"Precision\", \"Recall\"])\n",
    "        writer.writerows(fold_metrics)\n",
    "\n",
    "    # Salvando a média do fold para cada métrica\n",
    "    fold_metrics_summary.append([\n",
    "        fold, np.mean(acc_fold), np.std(acc_fold),\n",
    "        np.mean(jacc_fold), np.std(jacc_fold),\n",
    "        np.mean(f1_fold), np.std(f1_fold),\n",
    "        np.mean(prec_fold), np.std(prec_fold),\n",
    "        np.mean(rec_fold), np.std(rec_fold)\n",
    "    ])\n",
    "\n",
    "\n",
    "    fold += 1\n",
    "\n",
    "# Calculando médias gerais\n",
    "acc_total = [m[1] for m in fold_metrics_summary]\n",
    "jacc_total = [m[3] for m in fold_metrics_summary]\n",
    "f1_total = [m[5] for m in fold_metrics_summary]\n",
    "prec_total = [m[7] for m in fold_metrics_summary]\n",
    "rec_total = [m[9] for m in fold_metrics_summary]\n",
    "\n",
    "general_summary = [\n",
    "    [\"Fold\", \"Accuracy Mean\", \"Accuracy Std\", \"Jaccard Mean\", \"Jaccard Std\",\n",
    "     \"DICE Mean\", \"DICE Std\", \"Precision Mean\", \"Precision Std\", \"Recall Mean\", \"Recall Std\"]\n",
    "]\n",
    "\n",
    "general_summary.extend(fold_metrics_summary)\n",
    "\n",
    "general_summary.append([\n",
    "    \"Overall Mean\", np.mean(acc_total), np.std(acc_total),\n",
    "    np.mean(jacc_total), np.std(jacc_total),\n",
    "    np.mean(f1_total), np.std(f1_total),\n",
    "    np.mean(prec_total), np.std(prec_total),\n",
    "    np.mean(rec_total), np.std(rec_total)\n",
    "])\n",
    "\n",
    "# Salvando o resumo das métricas por fold e geral\n",
    "with open(os.path.join(output_dir, 'metrics_summary.csv'), 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=';')\n",
    "    writer.writerows(general_summary)\n",
    "\n",
    "print(\"Métricas salvas com sucesso na pasta:\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2544ddf-696d-4ff5-8780-9a498daa8413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.99614474370263 +- 0.0012972443067728466\n",
      "Jaccard: 92.03109410821396 +- 1.2770914786758358\n",
      "Dice: 95.358407497406 +- 0.8853478357195854\n",
      "Precision: 96.082425657405 +- 0.44529877249365807\n",
      "Recall: 95.35812684526776 +- 1.27817579024535\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \"+ str(np.mean(acc_total)*100) + \" +- \" + str(np.std(acc_total)*100))\n",
    "print(\"Jaccard: \"+ str(np.mean(jacc_total)*100) + \" +- \" + str(np.std(jacc_total)*100))\n",
    "print(\"Dice: \"+ str(np.mean(f1_total)*100) + \" +- \" + str(np.std(f1_total)*100))\n",
    "print(\"Precision: \"+ str(np.mean(prec_total)*100) + \" +- \" + str(np.std(prec_total)*100))\n",
    "print(\"Recall: \"+ str(np.mean(rec_total)*100) + \" +- \" + str(np.std(rec_total)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e774436e-ff52-47f8-8dce-d80b378b614b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_fold = 2\n",
    "best_model_filepath = filepath = os.path.join(output_dir, f'model_{best_fold}fold.keras')\n",
    "best_model = tf.keras.models.load_model(best_model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ac69b19-a5f7-40f1-b395-d65cd72999d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=k, shuffle=True, random_state=28)\n",
    "for i, (train_ind, test_ind) in enumerate(kf.split(X)):\n",
    "    if i == (best_fold-1):\n",
    "        X_train, X_val, y_train, y_val = X[train_ind], X[test_ind], y[train_ind], y[test_ind]\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6713b66-5fa4-436e-a338-dee9851b3462",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(display_list):\n",
    "  plt.figure(figsize=(15, 15))\n",
    "\n",
    "  title = ['Input image', 'True mask', 'Predicted mask']\n",
    "\n",
    "  for i in range(len(display_list)):\n",
    "    plt.subplot(1, len(display_list), i+1)\n",
    "    plt.title(title[i])\n",
    "    plt.imshow(tf.keras.utils.array_to_img(display_list[i]), cmap='gray')\n",
    "    plt.axis('off')\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "329d56e2-63cb-4232-b7eb-0a9ed7c6b0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 120ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9999847412109375\n",
      "Jaccard: 0.9782608695652174\n",
      "Dice: 0.989010989010989\n",
      "Precision: 0.9836065573770492\n",
      "Recall: 0.994475138121547\n"
     ]
    }
   ],
   "source": [
    "i = random.randint(0, len(X_val))\n",
    "#i = 155\n",
    "sample_image = X_val[i]\n",
    "sample_mask = y_val[i]\n",
    "prediction = best_model.predict(sample_image[tf.newaxis, ...])[0]\n",
    "predicted_mask = (prediction > 0.5).astype(np.uint8)\n",
    "display([sample_image, sample_mask,predicted_mask])\n",
    "\n",
    "sample_mask = y_val[i].astype(np.uint8).flatten()\n",
    "predicted_mask = predicted_mask.flatten()\n",
    "\n",
    "\n",
    "print(\"Accuracy: \"+ str(accuracy_score(sample_mask, predicted_mask)))\n",
    "print(\"Jaccard: \"+ str(jaccard_score(sample_mask, predicted_mask)))\n",
    "print(\"Dice: \"+ str((2*jaccard_score(sample_mask, predicted_mask))/(1+jaccard_score(sample_mask, predicted_mask))))\n",
    "print(\"Precision: \"+ str(precision_score(sample_mask, predicted_mask)))\n",
    "print(\"Recall: \"+ str(recall_score(sample_mask, predicted_mask)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bd9e15-bc6d-4743-ae4b-ce8a3202b64c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
