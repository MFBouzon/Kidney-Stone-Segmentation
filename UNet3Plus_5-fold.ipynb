{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf0339d0-739a-4991-a2c0-4392d2ec6f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 04:46:10.259015: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-22 04:46:10.259071: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-22 04:46:10.260033: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-22 04:46:10.265376: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-22 04:46:10.829653: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.backend import set_session\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    " \n",
    "from tqdm import tqdm \n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b6f5337-7770-4f92-a2a4-251e31af3cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 1\n",
    "k = 5\n",
    "\n",
    "\n",
    "IMG_WIDTH = 512\n",
    "IMG_HEIGHT = 512\n",
    "IMG_CHANNELS = 1\n",
    "\n",
    "DATA_PATH = 'data/'\n",
    "\n",
    "data_ids = next(os.walk(DATA_PATH+'/image'))[2]\n",
    "\n",
    "X = np.zeros((len(data_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "y = np.zeros((len(data_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.float32)\n",
    "\n",
    "# Definição do diretório de saída\n",
    "output_dir = \"UNet3Plus DICE 5-fold model\"\n",
    "os.makedirs(output_dir, exist_ok=True)  # Garante que a pasta existe\n",
    "\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "os.environ['TF_GPU_ALLOCATOR']= 'cuda_malloc_async'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6eeed634-f3f7-4cce-8c45-77e4b7c270ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing training images and masks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 838/838 [00:20<00:00, 40.71it/s]\n"
     ]
    }
   ],
   "source": [
    "print('Resizing training images and masks')\n",
    "for n, id_ in tqdm(enumerate(data_ids), total=len(data_ids)):   \n",
    "    path = DATA_PATH\n",
    "    img = imread(path + '/image/' + id_)[:,:]\n",
    "    img = img.reshape(img.shape[0], img.shape[1], IMG_CHANNELS)\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X[n] = img  #Fill empty X_train with values from img\n",
    "    \n",
    "    mask = imread(path + 'label/' + id_)\n",
    "    mask = (mask >= 250)\n",
    "    mask = np.expand_dims(resize(mask, (IMG_HEIGHT, IMG_WIDTH), mode='constant',  \n",
    "                                      preserve_range=True), axis=-1)\n",
    "    y[n] = mask \n",
    "    #plt.axis(\"off\")\n",
    "    #imshow(y[n])\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2f02a06-5551-4109-97af-8d76f83beb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "def f1_score(y_true, y_pred):\n",
    "    \"\"\"Calcula o F1-Score para segmentação binária\"\"\"\n",
    "    y_pred = K.round(y_pred)  # Arredondar para 0 ou 1\n",
    "    tp = K.sum(K.cast(y_true * y_pred, 'float32'))  # Verdadeiros Positivos\n",
    "    fp = K.sum(K.cast((1 - y_true) * y_pred, 'float32'))  # Falsos Positivos\n",
    "    fn = K.sum(K.cast(y_true * (1 - y_pred), 'float32'))  # Falsos Negativos\n",
    "    \n",
    "    precision = tp / (tp + fp + K.epsilon())  # Precision\n",
    "    recall = tp / (tp + fn + K.epsilon())  # Recall\n",
    "    \n",
    "    f1 = 2 * (precision * recall) / (precision + recall + K.epsilon())  # F1-Score\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e76775c-5fc9-419a-a36a-0bd07fe023ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable()\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1e-6\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return 1 - ((2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7f297ed-a66e-4727-b154-b60aa8f7fa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Dropout, BatchNormalization, ReLU, MaxPooling2D, Conv2DTranspose, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "def unet_3_plus():\n",
    "    inputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "    \n",
    "    def conv_block(x, filters, dropout=0.1):\n",
    "        x = Conv2D(filters, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = Conv2D(filters, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        return ReLU()(x)\n",
    "    \n",
    "    # Encoder\n",
    "    c1 = conv_block(inputs, 16)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    \n",
    "    c2 = conv_block(p1, 32)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "    \n",
    "    c3 = conv_block(p2, 64, dropout=0.2)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "    \n",
    "    c4 = conv_block(p3, 128, dropout=0.2)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "    \n",
    "    c5 = conv_block(p4, 256, dropout=0.3)\n",
    "    \n",
    "    # Decoder - UNet3+\n",
    "    def upsample_concat(filters, source, *targets):\n",
    "        upsample = Conv2DTranspose(filters, (2, 2), strides=(2, 2), padding='same')(source)\n",
    "        return concatenate([upsample] + list(targets))\n",
    "    \n",
    "    # Decoder 4 (H/8)\n",
    "    d5_to_d4 = upsample_concat(256, c5, c4)\n",
    "    d4 = conv_block(d5_to_d4, 128)\n",
    "    \n",
    "    # Decoder 3 (H/4)\n",
    "    d4_to_d3 = upsample_concat(128, d4, c3)\n",
    "    d3 = conv_block(d4_to_d3, 64)\n",
    "    \n",
    "    # Decoder 2 (H/2)\n",
    "    d3_to_d2 = upsample_concat(64, d3, c2)\n",
    "    d2 = conv_block(d3_to_d2, 32)\n",
    "    \n",
    "    # Decoder 1 (Full resolution)\n",
    "    d2_to_d1 = upsample_concat(32, d2, c1)\n",
    "    d1 = conv_block(d2_to_d1, 16)\n",
    "    \n",
    "    # Deep supervision (opcional)\n",
    "    outputs = Conv2D(num_classes, (1, 1), activation='sigmoid')(d1)\n",
    "    \n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    model.compile(optimizer='adam', loss=dice_loss, metrics=[\n",
    "        'accuracy', \n",
    "        tf.keras.metrics.Recall(name='recall'), \n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        f1_score,\n",
    "        tf.keras.metrics.IoU(num_classes=2, target_class_ids={0,1}, name='IoU')\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5bb3dc3-8cc2-41d0-bf67-a27f9775446a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 04:46:32.900030: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-22 04:46:32.924673: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-22 04:46:32.924721: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-22 04:46:32.927490: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-22 04:46:32.927544: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-22 04:46:32.927566: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-22 04:46:33.044334: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-22 04:46:33.044387: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-22 04:46:33.044395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-03-22 04:46:33.044405: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2025-03-22 04:46:33.044409: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:236] Using CUDA malloc Async allocator for GPU: 0\n",
      "2025-03-22 04:46:33.044549: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-22 04:46:33.044574: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9558 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 04:46:36.700126: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2025-03-22 04:46:37.095579: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2025-03-22 04:46:42.211602: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f953ea2a930 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-03-22 04:46:42.211637: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4070, Compute Capability 8.9\n",
      "2025-03-22 04:46:42.216280: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1742629602.281117  743130 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - ETA: 0s - loss: 0.9971 - accuracy: 0.7641 - recall: 0.9482 - precision: 0.0026 - f1_score: 0.0072 - IoU: 0.5144\n",
      "Epoch 1: val_f1_score improved from -inf to 0.00159, saving model to UNet3Plus DICE 5-fold model/model_4fold.keras\n",
      "42/42 [==============================] - 64s 881ms/step - loss: 0.9971 - accuracy: 0.7641 - recall: 0.9482 - precision: 0.0026 - f1_score: 0.0072 - IoU: 0.5144 - val_loss: 0.9985 - val_accuracy: 0.2957 - val_recall: 1.0000 - val_precision: 8.2987e-04 - val_f1_score: 0.0016 - val_IoU: 0.1981\n",
      "Epoch 2/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.9940 - accuracy: 0.9799 - recall: 0.9910 - precision: 0.0305 - f1_score: 0.0663 - IoU: 0.5546\n",
      "Epoch 2: val_f1_score improved from 0.00159 to 0.00180, saving model to UNet3Plus DICE 5-fold model/model_4fold.keras\n",
      "42/42 [==============================] - 14s 331ms/step - loss: 0.9940 - accuracy: 0.9799 - recall: 0.9910 - precision: 0.0305 - f1_score: 0.0663 - IoU: 0.5546 - val_loss: 0.9982 - val_accuracy: 0.3801 - val_recall: 1.0000 - val_precision: 9.4262e-04 - val_f1_score: 0.0018 - val_IoU: 0.3289\n",
      "Epoch 3/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.9887 - accuracy: 0.9938 - recall: 0.9866 - precision: 0.0929 - f1_score: 0.1882 - IoU: 0.6302\n",
      "Epoch 3: val_f1_score improved from 0.00180 to 0.00918, saving model to UNet3Plus DICE 5-fold model/model_4fold.keras\n",
      "42/42 [==============================] - 14s 330ms/step - loss: 0.9887 - accuracy: 0.9938 - recall: 0.9866 - precision: 0.0929 - f1_score: 0.1882 - IoU: 0.6302 - val_loss: 0.9929 - val_accuracy: 0.9231 - val_recall: 0.5474 - val_precision: 0.0042 - val_f1_score: 0.0092 - val_IoU: 0.5450\n",
      "Epoch 4/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.9774 - accuracy: 0.9955 - recall: 0.9743 - precision: 0.1211 - f1_score: 0.2628 - IoU: 0.6417\n",
      "Epoch 4: val_f1_score did not improve from 0.00918\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 0.9774 - accuracy: 0.9955 - recall: 0.9743 - precision: 0.1211 - f1_score: 0.2628 - IoU: 0.6417 - val_loss: 0.9962 - val_accuracy: 0.7339 - val_recall: 0.9991 - val_precision: 0.0022 - val_f1_score: 0.0043 - val_IoU: 0.4995\n",
      "Epoch 5/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.9445 - accuracy: 0.9981 - recall: 0.9579 - precision: 0.2497 - f1_score: 0.4433 - IoU: 0.6950\n",
      "Epoch 5: val_f1_score did not improve from 0.00918\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 0.9445 - accuracy: 0.9981 - recall: 0.9579 - precision: 0.2497 - f1_score: 0.4433 - IoU: 0.6950 - val_loss: 0.9998 - val_accuracy: 0.7554 - val_recall: 0.0165 - val_precision: 3.9507e-05 - val_f1_score: 8.8594e-05 - val_IoU: 0.4617\n",
      "Epoch 6/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.8149 - accuracy: 0.9996 - recall: 0.9680 - precision: 0.6138 - f1_score: 0.7489 - IoU: 0.8585\n",
      "Epoch 6: val_f1_score improved from 0.00918 to 0.18783, saving model to UNet3Plus DICE 5-fold model/model_4fold.keras\n",
      "42/42 [==============================] - 14s 330ms/step - loss: 0.8149 - accuracy: 0.9996 - recall: 0.9680 - precision: 0.6138 - f1_score: 0.7489 - IoU: 0.8585 - val_loss: 0.9451 - val_accuracy: 0.9995 - val_recall: 0.1330 - val_precision: 0.6670 - val_f1_score: 0.1878 - val_IoU: 0.5404\n",
      "Epoch 7/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.5420 - accuracy: 0.9997 - recall: 0.9121 - precision: 0.7340 - f1_score: 0.8129 - IoU: 0.8587\n",
      "Epoch 7: val_f1_score improved from 0.18783 to 0.67419, saving model to UNet3Plus DICE 5-fold model/model_4fold.keras\n",
      "42/42 [==============================] - 14s 329ms/step - loss: 0.5420 - accuracy: 0.9997 - recall: 0.9121 - precision: 0.7340 - f1_score: 0.8129 - IoU: 0.8587 - val_loss: 0.5095 - val_accuracy: 0.9997 - val_recall: 0.7500 - val_precision: 0.6965 - val_f1_score: 0.6742 - val_IoU: 0.7995\n",
      "Epoch 8/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2622 - accuracy: 0.9999 - recall: 0.9339 - precision: 0.8776 - f1_score: 0.9007 - IoU: 0.8967\n",
      "Epoch 8: val_f1_score improved from 0.67419 to 0.91200, saving model to UNet3Plus DICE 5-fold model/model_4fold.keras\n",
      "42/42 [==============================] - 14s 330ms/step - loss: 0.2622 - accuracy: 0.9999 - recall: 0.9339 - precision: 0.8776 - f1_score: 0.9007 - IoU: 0.8967 - val_loss: 0.1502 - val_accuracy: 0.9999 - val_recall: 0.9060 - val_precision: 0.9313 - val_f1_score: 0.9120 - val_IoU: 0.8378\n",
      "Epoch 9/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1429 - accuracy: 0.9999 - recall: 0.9452 - precision: 0.9231 - f1_score: 0.9332 - IoU: 0.9129\n",
      "Epoch 9: val_f1_score did not improve from 0.91200\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 0.1429 - accuracy: 0.9999 - recall: 0.9452 - precision: 0.9231 - f1_score: 0.9332 - IoU: 0.9129 - val_loss: 0.2095 - val_accuracy: 0.9999 - val_recall: 0.7926 - val_precision: 0.9950 - val_f1_score: 0.8585 - val_IoU: 0.6489\n",
      "Epoch 10/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1128 - accuracy: 0.9999 - recall: 0.9408 - precision: 0.9367 - f1_score: 0.9357 - IoU: 0.9148\n",
      "Epoch 10: val_f1_score did not improve from 0.91200\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 0.1128 - accuracy: 0.9999 - recall: 0.9408 - precision: 0.9367 - f1_score: 0.9357 - IoU: 0.9148 - val_loss: 0.2111 - val_accuracy: 0.9998 - val_recall: 0.7449 - val_precision: 0.9946 - val_f1_score: 0.8346 - val_IoU: 0.5747\n",
      "Epoch 11/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1042 - accuracy: 0.9999 - recall: 0.9339 - precision: 0.9269 - f1_score: 0.9281 - IoU: 0.9091\n",
      "Epoch 11: val_f1_score did not improve from 0.91200\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 0.1042 - accuracy: 0.9999 - recall: 0.9339 - precision: 0.9269 - f1_score: 0.9281 - IoU: 0.9091 - val_loss: 0.7260 - val_accuracy: 0.9972 - val_recall: 0.9163 - val_precision: 0.1627 - val_f1_score: 0.2692 - val_IoU: 0.5998\n",
      "Epoch 12/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1066 - accuracy: 0.9999 - recall: 0.9210 - precision: 0.9226 - f1_score: 0.9187 - IoU: 0.9035\n",
      "Epoch 12: val_f1_score did not improve from 0.91200\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 0.1066 - accuracy: 0.9999 - recall: 0.9210 - precision: 0.9226 - f1_score: 0.9187 - IoU: 0.9035 - val_loss: 0.2182 - val_accuracy: 0.9998 - val_recall: 0.9690 - val_precision: 0.7137 - val_f1_score: 0.8123 - val_IoU: 0.8539\n",
      "Epoch 13/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0817 - accuracy: 0.9999 - recall: 0.9393 - precision: 0.9391 - f1_score: 0.9383 - IoU: 0.9156\n",
      "Epoch 13: val_f1_score did not improve from 0.91200\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 0.0817 - accuracy: 0.9999 - recall: 0.9393 - precision: 0.9391 - f1_score: 0.9383 - IoU: 0.9156 - val_loss: 0.1187 - val_accuracy: 0.9999 - val_recall: 0.9669 - val_precision: 0.8672 - val_f1_score: 0.9099 - val_IoU: 0.8837\n",
      "Epoch 14/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0631 - accuracy: 0.9999 - recall: 0.9560 - precision: 0.9532 - f1_score: 0.9528 - IoU: 0.9290\n",
      "Epoch 14: val_f1_score improved from 0.91200 to 0.94973, saving model to UNet3Plus DICE 5-fold model/model_4fold.keras\n",
      "42/42 [==============================] - 14s 336ms/step - loss: 0.0631 - accuracy: 0.9999 - recall: 0.9560 - precision: 0.9532 - f1_score: 0.9528 - IoU: 0.9290 - val_loss: 0.0903 - val_accuracy: 1.0000 - val_recall: 0.9385 - val_precision: 0.9801 - val_f1_score: 0.9497 - val_IoU: 0.8999\n",
      "Epoch 15/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0592 - accuracy: 0.9999 - recall: 0.9553 - precision: 0.9568 - f1_score: 0.9542 - IoU: 0.9315\n",
      "Epoch 15: val_f1_score improved from 0.94973 to 0.96187, saving model to UNet3Plus DICE 5-fold model/model_4fold.keras\n",
      "42/42 [==============================] - 14s 330ms/step - loss: 0.0592 - accuracy: 0.9999 - recall: 0.9553 - precision: 0.9568 - f1_score: 0.9542 - IoU: 0.9315 - val_loss: 0.0702 - val_accuracy: 1.0000 - val_recall: 0.9577 - val_precision: 0.9775 - val_f1_score: 0.9619 - val_IoU: 0.9240\n",
      "Epoch 16/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0551 - accuracy: 0.9999 - recall: 0.9610 - precision: 0.9559 - f1_score: 0.9562 - IoU: 0.9384\n",
      "Epoch 16: val_f1_score did not improve from 0.96187\n",
      "42/42 [==============================] - 14s 325ms/step - loss: 0.0551 - accuracy: 0.9999 - recall: 0.9610 - precision: 0.9559 - f1_score: 0.9562 - IoU: 0.9384 - val_loss: 0.0781 - val_accuracy: 1.0000 - val_recall: 0.9461 - val_precision: 0.9830 - val_f1_score: 0.9582 - val_IoU: 0.9180\n",
      "Epoch 17/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0518 - accuracy: 0.9999 - recall: 0.9616 - precision: 0.9582 - f1_score: 0.9579 - IoU: 0.9371\n",
      "Epoch 17: val_f1_score did not improve from 0.96187\n",
      "42/42 [==============================] - 14s 325ms/step - loss: 0.0518 - accuracy: 0.9999 - recall: 0.9616 - precision: 0.9582 - f1_score: 0.9579 - IoU: 0.9371 - val_loss: 0.1277 - val_accuracy: 0.9999 - val_recall: 0.8468 - val_precision: 0.9937 - val_f1_score: 0.8946 - val_IoU: 0.8652\n",
      "Epoch 18/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0475 - accuracy: 1.0000 - recall: 0.9629 - precision: 0.9605 - f1_score: 0.9610 - IoU: 0.9429\n",
      "Epoch 18: val_f1_score did not improve from 0.96187\n",
      "42/42 [==============================] - 14s 325ms/step - loss: 0.0475 - accuracy: 1.0000 - recall: 0.9629 - precision: 0.9605 - f1_score: 0.9610 - IoU: 0.9429 - val_loss: 0.0631 - val_accuracy: 1.0000 - val_recall: 0.9322 - val_precision: 0.9871 - val_f1_score: 0.9545 - val_IoU: 0.9227\n",
      "Epoch 19/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0493 - accuracy: 0.9999 - recall: 0.9625 - precision: 0.9578 - f1_score: 0.9583 - IoU: 0.9415\n",
      "Epoch 19: val_f1_score did not improve from 0.96187\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 0.0493 - accuracy: 0.9999 - recall: 0.9625 - precision: 0.9578 - f1_score: 0.9583 - IoU: 0.9415 - val_loss: 0.0699 - val_accuracy: 1.0000 - val_recall: 0.9343 - val_precision: 0.9891 - val_f1_score: 0.9560 - val_IoU: 0.9238\n",
      "Epoch 20/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0494 - accuracy: 0.9999 - recall: 0.9617 - precision: 0.9589 - f1_score: 0.9576 - IoU: 0.9417\n",
      "Epoch 20: val_f1_score did not improve from 0.96187\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 0.0494 - accuracy: 0.9999 - recall: 0.9617 - precision: 0.9589 - f1_score: 0.9576 - IoU: 0.9417 - val_loss: 0.0547 - val_accuracy: 1.0000 - val_recall: 0.9493 - val_precision: 0.9810 - val_f1_score: 0.9613 - val_IoU: 0.9345\n",
      "Epoch 21/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0448 - accuracy: 1.0000 - recall: 0.9608 - precision: 0.9616 - f1_score: 0.9611 - IoU: 0.9431\n",
      "Epoch 21: val_f1_score did not improve from 0.96187\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 0.0448 - accuracy: 1.0000 - recall: 0.9608 - precision: 0.9616 - f1_score: 0.9611 - IoU: 0.9431 - val_loss: 0.0608 - val_accuracy: 1.0000 - val_recall: 0.9381 - val_precision: 0.9895 - val_f1_score: 0.9546 - val_IoU: 0.9268\n",
      "Epoch 22/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0429 - accuracy: 1.0000 - recall: 0.9635 - precision: 0.9619 - f1_score: 0.9626 - IoU: 0.9449\n",
      "Epoch 22: val_f1_score improved from 0.96187 to 0.96229, saving model to UNet3Plus DICE 5-fold model/model_4fold.keras\n",
      "42/42 [==============================] - 14s 331ms/step - loss: 0.0429 - accuracy: 1.0000 - recall: 0.9635 - precision: 0.9619 - f1_score: 0.9626 - IoU: 0.9449 - val_loss: 0.0496 - val_accuracy: 1.0000 - val_recall: 0.9747 - val_precision: 0.9665 - val_f1_score: 0.9623 - val_IoU: 0.9500\n",
      "Epoch 23/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0405 - accuracy: 1.0000 - recall: 0.9661 - precision: 0.9642 - f1_score: 0.9645 - IoU: 0.9459\n",
      "Epoch 23: val_f1_score did not improve from 0.96229\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 0.0405 - accuracy: 1.0000 - recall: 0.9661 - precision: 0.9642 - f1_score: 0.9645 - IoU: 0.9459 - val_loss: 0.0623 - val_accuracy: 0.9999 - val_recall: 0.9223 - val_precision: 0.9889 - val_f1_score: 0.9453 - val_IoU: 0.9205\n",
      "Epoch 24/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0403 - accuracy: 1.0000 - recall: 0.9671 - precision: 0.9631 - f1_score: 0.9641 - IoU: 0.9488\n",
      "Epoch 24: val_f1_score did not improve from 0.96229\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 0.0403 - accuracy: 1.0000 - recall: 0.9671 - precision: 0.9631 - f1_score: 0.9641 - IoU: 0.9488 - val_loss: 0.0682 - val_accuracy: 0.9999 - val_recall: 0.9038 - val_precision: 0.9939 - val_f1_score: 0.9407 - val_IoU: 0.9138\n",
      "Epoch 25/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0402 - accuracy: 1.0000 - recall: 0.9642 - precision: 0.9646 - f1_score: 0.9637 - IoU: 0.9469\n",
      "Epoch 25: val_f1_score did not improve from 0.96229\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 0.0402 - accuracy: 1.0000 - recall: 0.9642 - precision: 0.9646 - f1_score: 0.9637 - IoU: 0.9469 - val_loss: 0.0492 - val_accuracy: 1.0000 - val_recall: 0.9354 - val_precision: 0.9867 - val_f1_score: 0.9573 - val_IoU: 0.9269\n",
      "Epoch 26/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0408 - accuracy: 1.0000 - recall: 0.9677 - precision: 0.9623 - f1_score: 0.9631 - IoU: 0.9469\n",
      "Epoch 26: val_f1_score improved from 0.96229 to 0.96504, saving model to UNet3Plus DICE 5-fold model/model_4fold.keras\n",
      "42/42 [==============================] - 14s 329ms/step - loss: 0.0408 - accuracy: 1.0000 - recall: 0.9677 - precision: 0.9623 - f1_score: 0.9631 - IoU: 0.9469 - val_loss: 0.0408 - val_accuracy: 1.0000 - val_recall: 0.9623 - val_precision: 0.9786 - val_f1_score: 0.9650 - val_IoU: 0.9459\n",
      "Epoch 27/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0383 - accuracy: 1.0000 - recall: 0.9657 - precision: 0.9650 - f1_score: 0.9654 - IoU: 0.9486\n",
      "Epoch 27: val_f1_score improved from 0.96504 to 0.97211, saving model to UNet3Plus DICE 5-fold model/model_4fold.keras\n",
      "42/42 [==============================] - 14s 329ms/step - loss: 0.0383 - accuracy: 1.0000 - recall: 0.9657 - precision: 0.9650 - f1_score: 0.9654 - IoU: 0.9486 - val_loss: 0.0335 - val_accuracy: 1.0000 - val_recall: 0.9812 - val_precision: 0.9708 - val_f1_score: 0.9721 - val_IoU: 0.9574\n",
      "Epoch 28/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0454 - accuracy: 0.9999 - recall: 0.9633 - precision: 0.9582 - f1_score: 0.9578 - IoU: 0.9468\n",
      "Epoch 28: val_f1_score did not improve from 0.97211\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 0.0454 - accuracy: 0.9999 - recall: 0.9633 - precision: 0.9582 - f1_score: 0.9578 - IoU: 0.9468 - val_loss: 0.0706 - val_accuracy: 0.9999 - val_recall: 0.9165 - val_precision: 0.9856 - val_f1_score: 0.9346 - val_IoU: 0.9238\n",
      "Epoch 29/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0407 - accuracy: 1.0000 - recall: 0.9622 - precision: 0.9639 - f1_score: 0.9626 - IoU: 0.9463\n",
      "Epoch 29: val_f1_score did not improve from 0.97211\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 0.0407 - accuracy: 1.0000 - recall: 0.9622 - precision: 0.9639 - f1_score: 0.9626 - IoU: 0.9463 - val_loss: 0.0359 - val_accuracy: 1.0000 - val_recall: 0.9714 - val_precision: 0.9761 - val_f1_score: 0.9679 - val_IoU: 0.9544\n",
      "Epoch 30/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0385 - accuracy: 1.0000 - recall: 0.9672 - precision: 0.9642 - f1_score: 0.9644 - IoU: 0.9497\n",
      "Epoch 30: val_f1_score did not improve from 0.97211\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 0.0385 - accuracy: 1.0000 - recall: 0.9672 - precision: 0.9642 - f1_score: 0.9644 - IoU: 0.9497 - val_loss: 0.0495 - val_accuracy: 1.0000 - val_recall: 0.9338 - val_precision: 0.9868 - val_f1_score: 0.9546 - val_IoU: 0.9292\n",
      "Epoch 31/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0394 - accuracy: 1.0000 - recall: 0.9597 - precision: 0.9668 - f1_score: 0.9632 - IoU: 0.9458\n",
      "Epoch 31: val_f1_score did not improve from 0.97211\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 0.0394 - accuracy: 1.0000 - recall: 0.9597 - precision: 0.9668 - f1_score: 0.9632 - IoU: 0.9458 - val_loss: 0.0381 - val_accuracy: 1.0000 - val_recall: 0.9559 - val_precision: 0.9856 - val_f1_score: 0.9638 - val_IoU: 0.9454\n",
      "Epoch 32/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0400 - accuracy: 1.0000 - recall: 0.9648 - precision: 0.9612 - f1_score: 0.9625 - IoU: 0.9482\n",
      "Epoch 32: val_f1_score did not improve from 0.97211\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 0.0400 - accuracy: 1.0000 - recall: 0.9648 - precision: 0.9612 - f1_score: 0.9625 - IoU: 0.9482 - val_loss: 0.0491 - val_accuracy: 1.0000 - val_recall: 0.9362 - val_precision: 0.9896 - val_f1_score: 0.9551 - val_IoU: 0.9336\n",
      "Epoch 33/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0372 - accuracy: 1.0000 - recall: 0.9665 - precision: 0.9645 - f1_score: 0.9652 - IoU: 0.9502\n",
      "Epoch 33: val_f1_score did not improve from 0.97211\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 0.0372 - accuracy: 1.0000 - recall: 0.9665 - precision: 0.9645 - f1_score: 0.9652 - IoU: 0.9502 - val_loss: 0.0318 - val_accuracy: 1.0000 - val_recall: 0.9709 - val_precision: 0.9789 - val_f1_score: 0.9702 - val_IoU: 0.9518\n",
      "Epoch 34/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0372 - accuracy: 1.0000 - recall: 0.9659 - precision: 0.9664 - f1_score: 0.9650 - IoU: 0.9520\n",
      "Epoch 34: val_f1_score did not improve from 0.97211\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 0.0372 - accuracy: 1.0000 - recall: 0.9659 - precision: 0.9664 - f1_score: 0.9650 - IoU: 0.9520 - val_loss: 0.0374 - val_accuracy: 1.0000 - val_recall: 0.9681 - val_precision: 0.9835 - val_f1_score: 0.9701 - val_IoU: 0.9535\n",
      "Epoch 35/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0341 - accuracy: 1.0000 - recall: 0.9704 - precision: 0.9670 - f1_score: 0.9678 - IoU: 0.9549\n",
      "Epoch 35: val_f1_score did not improve from 0.97211\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 0.0341 - accuracy: 1.0000 - recall: 0.9704 - precision: 0.9670 - f1_score: 0.9678 - IoU: 0.9549 - val_loss: 0.0610 - val_accuracy: 0.9999 - val_recall: 0.9020 - val_precision: 0.9949 - val_f1_score: 0.9438 - val_IoU: 0.8600\n",
      "Epoch 36/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0333 - accuracy: 1.0000 - recall: 0.9686 - precision: 0.9677 - f1_score: 0.9684 - IoU: 0.9542\n",
      "Epoch 36: val_f1_score did not improve from 0.97211\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 0.0333 - accuracy: 1.0000 - recall: 0.9686 - precision: 0.9677 - f1_score: 0.9684 - IoU: 0.9542 - val_loss: 0.0389 - val_accuracy: 1.0000 - val_recall: 0.9445 - val_precision: 0.9917 - val_f1_score: 0.9641 - val_IoU: 0.9390\n",
      "Epoch 37/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0332 - accuracy: 1.0000 - recall: 0.9688 - precision: 0.9682 - f1_score: 0.9687 - IoU: 0.9534\n",
      "Epoch 37: val_f1_score improved from 0.97211 to 0.97344, saving model to UNet3Plus DICE 5-fold model/model_4fold.keras\n",
      "42/42 [==============================] - 14s 329ms/step - loss: 0.0332 - accuracy: 1.0000 - recall: 0.9688 - precision: 0.9682 - f1_score: 0.9687 - IoU: 0.9534 - val_loss: 0.0294 - val_accuracy: 1.0000 - val_recall: 0.9838 - val_precision: 0.9712 - val_f1_score: 0.9734 - val_IoU: 0.9664\n",
      "Epoch 38/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0338 - accuracy: 1.0000 - recall: 0.9690 - precision: 0.9684 - f1_score: 0.9680 - IoU: 0.9547\n",
      "Epoch 38: val_f1_score did not improve from 0.97344\n",
      "42/42 [==============================] - 14s 325ms/step - loss: 0.0338 - accuracy: 1.0000 - recall: 0.9690 - precision: 0.9684 - f1_score: 0.9680 - IoU: 0.9547 - val_loss: 0.0296 - val_accuracy: 1.0000 - val_recall: 0.9790 - val_precision: 0.9746 - val_f1_score: 0.9729 - val_IoU: 0.9638\n",
      "Epoch 39/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0318 - accuracy: 1.0000 - recall: 0.9715 - precision: 0.9692 - f1_score: 0.9699 - IoU: 0.9575\n",
      "Epoch 39: val_f1_score did not improve from 0.97344\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 0.0318 - accuracy: 1.0000 - recall: 0.9715 - precision: 0.9692 - f1_score: 0.9699 - IoU: 0.9575 - val_loss: 0.0368 - val_accuracy: 1.0000 - val_recall: 0.9516 - val_precision: 0.9900 - val_f1_score: 0.9648 - val_IoU: 0.9474\n",
      "Epoch 40/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0315 - accuracy: 1.0000 - recall: 0.9703 - precision: 0.9697 - f1_score: 0.9700 - IoU: 0.9580\n",
      "Epoch 40: val_f1_score did not improve from 0.97344\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 0.0315 - accuracy: 1.0000 - recall: 0.9703 - precision: 0.9697 - f1_score: 0.9700 - IoU: 0.9580 - val_loss: 0.0300 - val_accuracy: 1.0000 - val_recall: 0.9654 - val_precision: 0.9873 - val_f1_score: 0.9719 - val_IoU: 0.9554\n",
      "Epoch 41/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0348 - accuracy: 1.0000 - recall: 0.9681 - precision: 0.9694 - f1_score: 0.9667 - IoU: 0.9568\n",
      "Epoch 41: val_f1_score did not improve from 0.97344\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 0.0348 - accuracy: 1.0000 - recall: 0.9681 - precision: 0.9694 - f1_score: 0.9667 - IoU: 0.9568 - val_loss: 0.0309 - val_accuracy: 1.0000 - val_recall: 0.9872 - val_precision: 0.9660 - val_f1_score: 0.9720 - val_IoU: 0.9727\n",
      "Epoch 42/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0318 - accuracy: 1.0000 - recall: 0.9709 - precision: 0.9698 - f1_score: 0.9697 - IoU: 0.9574\n",
      "Epoch 42: val_f1_score improved from 0.97344 to 0.97467, saving model to UNet3Plus DICE 5-fold model/model_4fold.keras\n",
      "42/42 [==============================] - 14s 330ms/step - loss: 0.0318 - accuracy: 1.0000 - recall: 0.9709 - precision: 0.9698 - f1_score: 0.9697 - IoU: 0.9574 - val_loss: 0.0270 - val_accuracy: 1.0000 - val_recall: 0.9838 - val_precision: 0.9735 - val_f1_score: 0.9747 - val_IoU: 0.9675\n",
      "Epoch 43/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0320 - accuracy: 1.0000 - recall: 0.9697 - precision: 0.9686 - f1_score: 0.9694 - IoU: 0.9579\n",
      "Epoch 43: val_f1_score did not improve from 0.97467\n",
      "42/42 [==============================] - 14s 325ms/step - loss: 0.0320 - accuracy: 1.0000 - recall: 0.9697 - precision: 0.9686 - f1_score: 0.9694 - IoU: 0.9579 - val_loss: 0.0347 - val_accuracy: 1.0000 - val_recall: 0.9636 - val_precision: 0.9863 - val_f1_score: 0.9680 - val_IoU: 0.9544\n",
      "Epoch 44/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0336 - accuracy: 1.0000 - recall: 0.9727 - precision: 0.9658 - f1_score: 0.9676 - IoU: 0.9576\n",
      "Epoch 44: val_f1_score improved from 0.97467 to 0.97481, saving model to UNet3Plus DICE 5-fold model/model_4fold.keras\n",
      "42/42 [==============================] - 14s 330ms/step - loss: 0.0336 - accuracy: 1.0000 - recall: 0.9727 - precision: 0.9658 - f1_score: 0.9676 - IoU: 0.9576 - val_loss: 0.0286 - val_accuracy: 1.0000 - val_recall: 0.9878 - val_precision: 0.9675 - val_f1_score: 0.9748 - val_IoU: 0.9711\n",
      "Epoch 45/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0293 - accuracy: 1.0000 - recall: 0.9725 - precision: 0.9709 - f1_score: 0.9720 - IoU: 0.9584\n",
      "Epoch 45: val_f1_score did not improve from 0.97481\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 0.0293 - accuracy: 1.0000 - recall: 0.9725 - precision: 0.9709 - f1_score: 0.9720 - IoU: 0.9584 - val_loss: 0.0276 - val_accuracy: 1.0000 - val_recall: 0.9876 - val_precision: 0.9652 - val_f1_score: 0.9729 - val_IoU: 0.9729\n",
      "Epoch 46/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0303 - accuracy: 1.0000 - recall: 0.9744 - precision: 0.9684 - f1_score: 0.9709 - IoU: 0.9597\n",
      "Epoch 46: val_f1_score did not improve from 0.97481\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 0.0303 - accuracy: 1.0000 - recall: 0.9744 - precision: 0.9684 - f1_score: 0.9709 - IoU: 0.9597 - val_loss: 0.0407 - val_accuracy: 1.0000 - val_recall: 0.9379 - val_precision: 0.9937 - val_f1_score: 0.9596 - val_IoU: 0.9425\n",
      "Epoch 47/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0299 - accuracy: 1.0000 - recall: 0.9742 - precision: 0.9695 - f1_score: 0.9713 - IoU: 0.9597\n",
      "Epoch 47: val_f1_score did not improve from 0.97481\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 0.0299 - accuracy: 1.0000 - recall: 0.9742 - precision: 0.9695 - f1_score: 0.9713 - IoU: 0.9597 - val_loss: 0.0270 - val_accuracy: 1.0000 - val_recall: 0.9896 - val_precision: 0.9653 - val_f1_score: 0.9740 - val_IoU: 0.9724\n",
      "Epoch 48/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0317 - accuracy: 1.0000 - recall: 0.9708 - precision: 0.9721 - f1_score: 0.9695 - IoU: 0.9577\n",
      "Epoch 48: val_f1_score did not improve from 0.97481\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 0.0317 - accuracy: 1.0000 - recall: 0.9708 - precision: 0.9721 - f1_score: 0.9695 - IoU: 0.9577 - val_loss: 0.0316 - val_accuracy: 1.0000 - val_recall: 0.9939 - val_precision: 0.9516 - val_f1_score: 0.9700 - val_IoU: 0.9780\n",
      "Epoch 49/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 1.0000 - recall: 0.9713 - precision: 0.9681 - f1_score: 0.9683 - IoU: 0.9579\n",
      "Epoch 49: val_f1_score did not improve from 0.97481\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 0.0330 - accuracy: 1.0000 - recall: 0.9713 - precision: 0.9681 - f1_score: 0.9683 - IoU: 0.9579 - val_loss: 0.0381 - val_accuracy: 1.0000 - val_recall: 0.9742 - val_precision: 0.9808 - val_f1_score: 0.9732 - val_IoU: 0.9613\n",
      "Epoch 50/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0300 - accuracy: 1.0000 - recall: 0.9704 - precision: 0.9714 - f1_score: 0.9709 - IoU: 0.9573\n",
      "Epoch 50: val_f1_score did not improve from 0.97481\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 0.0300 - accuracy: 1.0000 - recall: 0.9704 - precision: 0.9714 - f1_score: 0.9709 - IoU: 0.9573 - val_loss: 0.0268 - val_accuracy: 1.0000 - val_recall: 0.9885 - val_precision: 0.9661 - val_f1_score: 0.9740 - val_IoU: 0.9731\n",
      "Epoch 51/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0291 - accuracy: 1.0000 - recall: 0.9741 - precision: 0.9710 - f1_score: 0.9720 - IoU: 0.9602\n",
      "Epoch 51: val_f1_score did not improve from 0.97481\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 0.0291 - accuracy: 1.0000 - recall: 0.9741 - precision: 0.9710 - f1_score: 0.9720 - IoU: 0.9602 - val_loss: 0.0423 - val_accuracy: 1.0000 - val_recall: 0.9342 - val_precision: 0.9928 - val_f1_score: 0.9590 - val_IoU: 0.9388\n",
      "Epoch 52/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0305 - accuracy: 1.0000 - recall: 0.9731 - precision: 0.9697 - f1_score: 0.9705 - IoU: 0.9591\n",
      "Epoch 52: val_f1_score did not improve from 0.97481\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 0.0305 - accuracy: 1.0000 - recall: 0.9731 - precision: 0.9697 - f1_score: 0.9705 - IoU: 0.9591 - val_loss: 0.0310 - val_accuracy: 1.0000 - val_recall: 0.9614 - val_precision: 0.9869 - val_f1_score: 0.9703 - val_IoU: 0.9546\n",
      "Epoch 53/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0286 - accuracy: 1.0000 - recall: 0.9742 - precision: 0.9715 - f1_score: 0.9723 - IoU: 0.9611\n",
      "Epoch 53: val_f1_score did not improve from 0.97481\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 0.0286 - accuracy: 1.0000 - recall: 0.9742 - precision: 0.9715 - f1_score: 0.9723 - IoU: 0.9611 - val_loss: 0.0268 - val_accuracy: 1.0000 - val_recall: 0.9917 - val_precision: 0.9627 - val_f1_score: 0.9739 - val_IoU: 0.9768\n",
      "Epoch 54/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0280 - accuracy: 1.0000 - recall: 0.9742 - precision: 0.9716 - f1_score: 0.9729 - IoU: 0.9602\n",
      "Epoch 54: val_f1_score did not improve from 0.97481\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 0.0280 - accuracy: 1.0000 - recall: 0.9742 - precision: 0.9716 - f1_score: 0.9729 - IoU: 0.9602 - val_loss: 0.0258 - val_accuracy: 1.0000 - val_recall: 0.9753 - val_precision: 0.9834 - val_f1_score: 0.9746 - val_IoU: 0.9641\n",
      "Epoch 55/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0292 - accuracy: 1.0000 - recall: 0.9735 - precision: 0.9715 - f1_score: 0.9718 - IoU: 0.9609\n",
      "Epoch 55: val_f1_score did not improve from 0.97481\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 0.0292 - accuracy: 1.0000 - recall: 0.9735 - precision: 0.9715 - f1_score: 0.9718 - IoU: 0.9609 - val_loss: 0.0269 - val_accuracy: 1.0000 - val_recall: 0.9775 - val_precision: 0.9816 - val_f1_score: 0.9729 - val_IoU: 0.9640\n",
      "Epoch 56/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0295 - accuracy: 1.0000 - recall: 0.9693 - precision: 0.9735 - f1_score: 0.9713 - IoU: 0.9586\n",
      "Epoch 56: val_f1_score did not improve from 0.97481\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 0.0295 - accuracy: 1.0000 - recall: 0.9693 - precision: 0.9735 - f1_score: 0.9713 - IoU: 0.9586 - val_loss: 0.0292 - val_accuracy: 1.0000 - val_recall: 0.9909 - val_precision: 0.9602 - val_f1_score: 0.9715 - val_IoU: 0.9748\n",
      "Epoch 57/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0297 - accuracy: 1.0000 - recall: 0.9734 - precision: 0.9697 - f1_score: 0.9712 - IoU: 0.9611\n",
      "Epoch 57: val_f1_score did not improve from 0.97481\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 0.0297 - accuracy: 1.0000 - recall: 0.9734 - precision: 0.9697 - f1_score: 0.9712 - IoU: 0.9611 - val_loss: 0.0342 - val_accuracy: 1.0000 - val_recall: 0.9663 - val_precision: 0.9826 - val_f1_score: 0.9660 - val_IoU: 0.9573\n",
      "Epoch 58/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0305 - accuracy: 1.0000 - recall: 0.9716 - precision: 0.9710 - f1_score: 0.9703 - IoU: 0.9597\n",
      "Epoch 58: val_f1_score did not improve from 0.97481\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 0.0305 - accuracy: 1.0000 - recall: 0.9716 - precision: 0.9710 - f1_score: 0.9703 - IoU: 0.9597 - val_loss: 0.0267 - val_accuracy: 1.0000 - val_recall: 0.9725 - val_precision: 0.9826 - val_f1_score: 0.9738 - val_IoU: 0.9608\n",
      "Epoch 59/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0441 - accuracy: 0.9999 - recall: 0.9540 - precision: 0.9641 - f1_score: 0.9567 - IoU: 0.9488\n",
      "Epoch 59: val_f1_score did not improve from 0.97481\n",
      "42/42 [==============================] - 14s 325ms/step - loss: 0.0441 - accuracy: 0.9999 - recall: 0.9540 - precision: 0.9641 - f1_score: 0.9567 - IoU: 0.9488 - val_loss: 0.0692 - val_accuracy: 0.9999 - val_recall: 0.9098 - val_precision: 0.9773 - val_f1_score: 0.9326 - val_IoU: 0.9341\n",
      "Epoch 60/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0388 - accuracy: 1.0000 - recall: 0.9622 - precision: 0.9659 - f1_score: 0.9620 - IoU: 0.9524\n",
      "Epoch 60: val_f1_score did not improve from 0.97481\n",
      "42/42 [==============================] - 14s 325ms/step - loss: 0.0388 - accuracy: 1.0000 - recall: 0.9622 - precision: 0.9659 - f1_score: 0.9620 - IoU: 0.9524 - val_loss: 0.0363 - val_accuracy: 1.0000 - val_recall: 0.9908 - val_precision: 0.9437 - val_f1_score: 0.9642 - val_IoU: 0.9760\n",
      "Epoch 61/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0368 - accuracy: 1.0000 - recall: 0.9650 - precision: 0.9628 - f1_score: 0.9640 - IoU: 0.9544\n",
      "Epoch 61: val_f1_score did not improve from 0.97481\n",
      "42/42 [==============================] - 14s 325ms/step - loss: 0.0368 - accuracy: 1.0000 - recall: 0.9650 - precision: 0.9628 - f1_score: 0.9640 - IoU: 0.9544 - val_loss: 0.0358 - val_accuracy: 1.0000 - val_recall: 0.9544 - val_precision: 0.9874 - val_f1_score: 0.9667 - val_IoU: 0.9505\n",
      "Epoch 62/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0314 - accuracy: 1.0000 - recall: 0.9702 - precision: 0.9695 - f1_score: 0.9694 - IoU: 0.9583\n",
      "Epoch 62: val_f1_score did not improve from 0.97481\n",
      "42/42 [==============================] - 14s 325ms/step - loss: 0.0314 - accuracy: 1.0000 - recall: 0.9702 - precision: 0.9695 - f1_score: 0.9694 - IoU: 0.9583 - val_loss: 0.0352 - val_accuracy: 1.0000 - val_recall: 0.9599 - val_precision: 0.9876 - val_f1_score: 0.9657 - val_IoU: 0.9539\n",
      "Epoch 63/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0303 - accuracy: 1.0000 - recall: 0.9714 - precision: 0.9697 - f1_score: 0.9705 - IoU: 0.9597\n",
      "Epoch 63: val_f1_score did not improve from 0.97481\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 0.0303 - accuracy: 1.0000 - recall: 0.9714 - precision: 0.9697 - f1_score: 0.9705 - IoU: 0.9597 - val_loss: 0.0368 - val_accuracy: 1.0000 - val_recall: 0.9513 - val_precision: 0.9911 - val_f1_score: 0.9636 - val_IoU: 0.9502\n",
      "Epoch 64/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0326 - accuracy: 1.0000 - recall: 0.9683 - precision: 0.9690 - f1_score: 0.9680 - IoU: 0.9595\n",
      "Epoch 64: val_f1_score did not improve from 0.97481\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 0.0326 - accuracy: 1.0000 - recall: 0.9683 - precision: 0.9690 - f1_score: 0.9680 - IoU: 0.9595 - val_loss: 0.0453 - val_accuracy: 1.0000 - val_recall: 0.9238 - val_precision: 0.9930 - val_f1_score: 0.9564 - val_IoU: 0.9345\n",
      "Epoch 65/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0303 - accuracy: 1.0000 - recall: 0.9722 - precision: 0.9687 - f1_score: 0.9703 - IoU: 0.9607\n",
      "Epoch 65: val_f1_score did not improve from 0.97481\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 0.0303 - accuracy: 1.0000 - recall: 0.9722 - precision: 0.9687 - f1_score: 0.9703 - IoU: 0.9607 - val_loss: 0.0250 - val_accuracy: 1.0000 - val_recall: 0.9766 - val_precision: 0.9810 - val_f1_score: 0.9743 - val_IoU: 0.9628\n",
      "Epoch 66/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0284 - accuracy: 1.0000 - recall: 0.9750 - precision: 0.9712 - f1_score: 0.9723 - IoU: 0.9629\n",
      "Epoch 66: val_f1_score did not improve from 0.97481\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 0.0284 - accuracy: 1.0000 - recall: 0.9750 - precision: 0.9712 - f1_score: 0.9723 - IoU: 0.9629 - val_loss: 0.0266 - val_accuracy: 1.0000 - val_recall: 0.9659 - val_precision: 0.9892 - val_f1_score: 0.9739 - val_IoU: 0.9582\n",
      "Epoch 67/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0290 - accuracy: 1.0000 - recall: 0.9744 - precision: 0.9715 - f1_score: 0.9717 - IoU: 0.9618\n",
      "Epoch 67: val_f1_score did not improve from 0.97481\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 0.0290 - accuracy: 1.0000 - recall: 0.9744 - precision: 0.9715 - f1_score: 0.9717 - IoU: 0.9618 - val_loss: 0.0331 - val_accuracy: 1.0000 - val_recall: 0.9771 - val_precision: 0.9794 - val_f1_score: 0.9573 - val_IoU: 0.9641\n",
      "Epoch 68/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0283 - accuracy: 1.0000 - recall: 0.9728 - precision: 0.9716 - f1_score: 0.9723 - IoU: 0.9613\n",
      "Epoch 68: val_f1_score did not improve from 0.97481\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 0.0283 - accuracy: 1.0000 - recall: 0.9728 - precision: 0.9716 - f1_score: 0.9723 - IoU: 0.9613 - val_loss: 0.0271 - val_accuracy: 1.0000 - val_recall: 0.9675 - val_precision: 0.9879 - val_f1_score: 0.9737 - val_IoU: 0.9583\n",
      "Epoch 69/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0277 - accuracy: 1.0000 - recall: 0.9746 - precision: 0.9715 - f1_score: 0.9729 - IoU: 0.9620\n",
      "Epoch 69: val_f1_score did not improve from 0.97481\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 0.0277 - accuracy: 1.0000 - recall: 0.9746 - precision: 0.9715 - f1_score: 0.9729 - IoU: 0.9620 - val_loss: 0.0268 - val_accuracy: 1.0000 - val_recall: 0.9930 - val_precision: 0.9584 - val_f1_score: 0.9730 - val_IoU: 0.9797\n",
      "Epoch 70/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0298 - accuracy: 1.0000 - recall: 0.9743 - precision: 0.9722 - f1_score: 0.9708 - IoU: 0.9617\n",
      "Epoch 70: val_f1_score improved from 0.97481 to 0.97610, saving model to UNet3Plus DICE 5-fold model/model_4fold.keras\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 0.0298 - accuracy: 1.0000 - recall: 0.9743 - precision: 0.9722 - f1_score: 0.9708 - IoU: 0.9617 - val_loss: 0.0237 - val_accuracy: 1.0000 - val_recall: 0.9748 - val_precision: 0.9819 - val_f1_score: 0.9761 - val_IoU: 0.9646\n",
      "Epoch 71/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0262 - accuracy: 1.0000 - recall: 0.9772 - precision: 0.9721 - f1_score: 0.9743 - IoU: 0.9643\n",
      "Epoch 71: val_f1_score improved from 0.97610 to 0.97795, saving model to UNet3Plus DICE 5-fold model/model_4fold.keras\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 0.0262 - accuracy: 1.0000 - recall: 0.9772 - precision: 0.9721 - f1_score: 0.9743 - IoU: 0.9643 - val_loss: 0.0220 - val_accuracy: 1.0000 - val_recall: 0.9820 - val_precision: 0.9812 - val_f1_score: 0.9779 - val_IoU: 0.9693\n",
      "Epoch 72/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0260 - accuracy: 1.0000 - recall: 0.9769 - precision: 0.9726 - f1_score: 0.9747 - IoU: 0.9633\n",
      "Epoch 72: val_f1_score did not improve from 0.97795\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 0.0260 - accuracy: 1.0000 - recall: 0.9769 - precision: 0.9726 - f1_score: 0.9747 - IoU: 0.9633 - val_loss: 0.0238 - val_accuracy: 1.0000 - val_recall: 0.9787 - val_precision: 0.9829 - val_f1_score: 0.9760 - val_IoU: 0.9678\n",
      "Epoch 73/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0272 - accuracy: 1.0000 - recall: 0.9741 - precision: 0.9737 - f1_score: 0.9731 - IoU: 0.9624\n",
      "Epoch 73: val_f1_score did not improve from 0.97795\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 0.0272 - accuracy: 1.0000 - recall: 0.9741 - precision: 0.9737 - f1_score: 0.9731 - IoU: 0.9624 - val_loss: 0.0330 - val_accuracy: 1.0000 - val_recall: 0.9500 - val_precision: 0.9929 - val_f1_score: 0.9670 - val_IoU: 0.9510\n",
      "Epoch 74/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0289 - accuracy: 1.0000 - recall: 0.9749 - precision: 0.9720 - f1_score: 0.9716 - IoU: 0.9629\n",
      "Epoch 74: val_f1_score did not improve from 0.97795\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 0.0289 - accuracy: 1.0000 - recall: 0.9749 - precision: 0.9720 - f1_score: 0.9716 - IoU: 0.9629 - val_loss: 0.0254 - val_accuracy: 1.0000 - val_recall: 0.9772 - val_precision: 0.9833 - val_f1_score: 0.9758 - val_IoU: 0.9665\n",
      "Epoch 75/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0262 - accuracy: 1.0000 - recall: 0.9749 - precision: 0.9735 - f1_score: 0.9743 - IoU: 0.9638\n",
      "Epoch 75: val_f1_score did not improve from 0.97795\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 0.0262 - accuracy: 1.0000 - recall: 0.9749 - precision: 0.9735 - f1_score: 0.9743 - IoU: 0.9638 - val_loss: 0.0295 - val_accuracy: 1.0000 - val_recall: 0.9954 - val_precision: 0.9520 - val_f1_score: 0.9697 - val_IoU: 0.9816\n",
      "Epoch 76/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0249 - accuracy: 1.0000 - recall: 0.9791 - precision: 0.9727 - f1_score: 0.9756 - IoU: 0.9662\n",
      "Epoch 76: val_f1_score did not improve from 0.97795\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 0.0249 - accuracy: 1.0000 - recall: 0.9791 - precision: 0.9727 - f1_score: 0.9756 - IoU: 0.9662 - val_loss: 0.0224 - val_accuracy: 1.0000 - val_recall: 0.9839 - val_precision: 0.9810 - val_f1_score: 0.9779 - val_IoU: 0.9698\n",
      "Epoch 77/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0271 - accuracy: 1.0000 - recall: 0.9744 - precision: 0.9717 - f1_score: 0.9734 - IoU: 0.9631\n",
      "Epoch 77: val_f1_score did not improve from 0.97795\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 0.0271 - accuracy: 1.0000 - recall: 0.9744 - precision: 0.9717 - f1_score: 0.9734 - IoU: 0.9631 - val_loss: 0.0320 - val_accuracy: 1.0000 - val_recall: 0.9569 - val_precision: 0.9917 - val_f1_score: 0.9695 - val_IoU: 0.9530\n",
      "Epoch 78/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0322 - accuracy: 1.0000 - recall: 0.9705 - precision: 0.9701 - f1_score: 0.9683 - IoU: 0.9606\n",
      "Epoch 78: val_f1_score did not improve from 0.97795\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 0.0322 - accuracy: 1.0000 - recall: 0.9705 - precision: 0.9701 - f1_score: 0.9683 - IoU: 0.9606 - val_loss: 0.0285 - val_accuracy: 1.0000 - val_recall: 0.9643 - val_precision: 0.9880 - val_f1_score: 0.9714 - val_IoU: 0.9559\n",
      "Epoch 79/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0277 - accuracy: 1.0000 - recall: 0.9756 - precision: 0.9722 - f1_score: 0.9728 - IoU: 0.9647\n",
      "Epoch 79: val_f1_score did not improve from 0.97795\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 0.0277 - accuracy: 1.0000 - recall: 0.9756 - precision: 0.9722 - f1_score: 0.9728 - IoU: 0.9647 - val_loss: 0.0266 - val_accuracy: 1.0000 - val_recall: 0.9672 - val_precision: 0.9893 - val_f1_score: 0.9731 - val_IoU: 0.9608\n",
      "Epoch 80/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0261 - accuracy: 1.0000 - recall: 0.9780 - precision: 0.9728 - f1_score: 0.9743 - IoU: 0.9663\n",
      "Epoch 80: val_f1_score did not improve from 0.97795\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 0.0261 - accuracy: 1.0000 - recall: 0.9780 - precision: 0.9728 - f1_score: 0.9743 - IoU: 0.9663 - val_loss: 0.0255 - val_accuracy: 1.0000 - val_recall: 0.9738 - val_precision: 0.9858 - val_f1_score: 0.9742 - val_IoU: 0.9648\n",
      "Epoch 81/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0296 - accuracy: 1.0000 - recall: 0.9728 - precision: 0.9703 - f1_score: 0.9708 - IoU: 0.9624\n",
      "Epoch 81: val_f1_score did not improve from 0.97795\n",
      "42/42 [==============================] - 13s 318ms/step - loss: 0.0296 - accuracy: 1.0000 - recall: 0.9728 - precision: 0.9703 - f1_score: 0.9708 - IoU: 0.9624 - val_loss: 0.1617 - val_accuracy: 0.9999 - val_recall: 0.7900 - val_precision: 0.9688 - val_f1_score: 0.8446 - val_IoU: 0.8774\n",
      "Epoch 82/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0558 - accuracy: 0.9999 - recall: 0.9413 - precision: 0.9496 - f1_score: 0.9449 - IoU: 0.9376\n",
      "Epoch 82: val_f1_score did not improve from 0.97795\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 0.0558 - accuracy: 0.9999 - recall: 0.9413 - precision: 0.9496 - f1_score: 0.9449 - IoU: 0.9376 - val_loss: 0.1309 - val_accuracy: 0.9999 - val_recall: 0.8912 - val_precision: 0.9074 - val_f1_score: 0.8737 - val_IoU: 0.9177\n",
      "Epoch 83/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0340 - accuracy: 1.0000 - recall: 0.9697 - precision: 0.9642 - f1_score: 0.9664 - IoU: 0.9594\n",
      "Epoch 83: val_f1_score did not improve from 0.97795\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 0.0340 - accuracy: 1.0000 - recall: 0.9697 - precision: 0.9642 - f1_score: 0.9664 - IoU: 0.9594 - val_loss: 0.1056 - val_accuracy: 0.9999 - val_recall: 0.9639 - val_precision: 0.8805 - val_f1_score: 0.8788 - val_IoU: 0.9202\n",
      "Epoch 84/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0318 - accuracy: 1.0000 - recall: 0.9706 - precision: 0.9704 - f1_score: 0.9687 - IoU: 0.9612\n",
      "Epoch 84: val_f1_score did not improve from 0.97795\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 0.0318 - accuracy: 1.0000 - recall: 0.9706 - precision: 0.9704 - f1_score: 0.9687 - IoU: 0.9612 - val_loss: 0.0451 - val_accuracy: 1.0000 - val_recall: 0.9658 - val_precision: 0.9683 - val_f1_score: 0.9523 - val_IoU: 0.9581\n",
      "Epoch 85/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0281 - accuracy: 1.0000 - recall: 0.9724 - precision: 0.9715 - f1_score: 0.9723 - IoU: 0.9632\n",
      "Epoch 85: val_f1_score did not improve from 0.97795\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 0.0281 - accuracy: 1.0000 - recall: 0.9724 - precision: 0.9715 - f1_score: 0.9723 - IoU: 0.9632 - val_loss: 0.0338 - val_accuracy: 1.0000 - val_recall: 0.9815 - val_precision: 0.9683 - val_f1_score: 0.9663 - val_IoU: 0.9704\n",
      "Epoch 86/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0281 - accuracy: 1.0000 - recall: 0.9742 - precision: 0.9718 - f1_score: 0.9725 - IoU: 0.9633\n",
      "Epoch 86: val_f1_score did not improve from 0.97795\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 0.0281 - accuracy: 1.0000 - recall: 0.9742 - precision: 0.9718 - f1_score: 0.9725 - IoU: 0.9633 - val_loss: 0.0244 - val_accuracy: 1.0000 - val_recall: 0.9897 - val_precision: 0.9675 - val_f1_score: 0.9750 - val_IoU: 0.9777\n",
      "Epoch 87/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0258 - accuracy: 1.0000 - recall: 0.9772 - precision: 0.9720 - f1_score: 0.9746 - IoU: 0.9656\n",
      "Epoch 87: val_f1_score did not improve from 0.97795\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 0.0258 - accuracy: 1.0000 - recall: 0.9772 - precision: 0.9720 - f1_score: 0.9746 - IoU: 0.9656 - val_loss: 0.0242 - val_accuracy: 1.0000 - val_recall: 0.9886 - val_precision: 0.9705 - val_f1_score: 0.9751 - val_IoU: 0.9779\n",
      "Epoch 88/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0288 - accuracy: 1.0000 - recall: 0.9740 - precision: 0.9725 - f1_score: 0.9716 - IoU: 0.9643\n",
      "Epoch 88: val_f1_score did not improve from 0.97795\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 0.0288 - accuracy: 1.0000 - recall: 0.9740 - precision: 0.9725 - f1_score: 0.9716 - IoU: 0.9643 - val_loss: 0.0255 - val_accuracy: 1.0000 - val_recall: 0.9770 - val_precision: 0.9831 - val_f1_score: 0.9745 - val_IoU: 0.9686\n",
      "Epoch 89/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0307 - accuracy: 1.0000 - recall: 0.9687 - precision: 0.9731 - f1_score: 0.9699 - IoU: 0.9615\n",
      "Epoch 89: val_f1_score did not improve from 0.97795\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 0.0307 - accuracy: 1.0000 - recall: 0.9687 - precision: 0.9731 - f1_score: 0.9699 - IoU: 0.9615 - val_loss: 0.0328 - val_accuracy: 1.0000 - val_recall: 0.9846 - val_precision: 0.9598 - val_f1_score: 0.9657 - val_IoU: 0.9687\n",
      "Epoch 90/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0306 - accuracy: 1.0000 - recall: 0.9723 - precision: 0.9696 - f1_score: 0.9699 - IoU: 0.9623\n",
      "Epoch 90: val_f1_score did not improve from 0.97795\n",
      "42/42 [==============================] - 13s 322ms/step - loss: 0.0306 - accuracy: 1.0000 - recall: 0.9723 - precision: 0.9696 - f1_score: 0.9699 - IoU: 0.9623 - val_loss: 0.0232 - val_accuracy: 1.0000 - val_recall: 0.9768 - val_precision: 0.9836 - val_f1_score: 0.9763 - val_IoU: 0.9676\n",
      "Epoch 91/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0290 - accuracy: 1.0000 - recall: 0.9711 - precision: 0.9716 - f1_score: 0.9714 - IoU: 0.9634\n",
      "Epoch 91: val_f1_score did not improve from 0.97795\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 0.0290 - accuracy: 1.0000 - recall: 0.9711 - precision: 0.9716 - f1_score: 0.9714 - IoU: 0.9634 - val_loss: 0.0266 - val_accuracy: 1.0000 - val_recall: 0.9864 - val_precision: 0.9722 - val_f1_score: 0.9756 - val_IoU: 0.9746\n",
      "Epoch 92/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0279 - accuracy: 1.0000 - recall: 0.9744 - precision: 0.9732 - f1_score: 0.9725 - IoU: 0.9638\n",
      "Epoch 92: val_f1_score did not improve from 0.97795\n",
      "42/42 [==============================] - 14s 322ms/step - loss: 0.0279 - accuracy: 1.0000 - recall: 0.9744 - precision: 0.9732 - f1_score: 0.9725 - IoU: 0.9638 - val_loss: 0.0249 - val_accuracy: 1.0000 - val_recall: 0.9832 - val_precision: 0.9762 - val_f1_score: 0.9752 - val_IoU: 0.9732\n",
      "Epoch 93/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0293 - accuracy: 1.0000 - recall: 0.9721 - precision: 0.9711 - f1_score: 0.9711 - IoU: 0.9628\n",
      "Epoch 93: val_f1_score did not improve from 0.97795\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 0.0293 - accuracy: 1.0000 - recall: 0.9721 - precision: 0.9711 - f1_score: 0.9711 - IoU: 0.9628 - val_loss: 0.0353 - val_accuracy: 1.0000 - val_recall: 0.9481 - val_precision: 0.9925 - val_f1_score: 0.9655 - val_IoU: 0.9514\n",
      "Epoch 94/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0277 - accuracy: 1.0000 - recall: 0.9755 - precision: 0.9694 - f1_score: 0.9727 - IoU: 0.9658\n",
      "Epoch 94: val_f1_score did not improve from 0.97795\n",
      "42/42 [==============================] - 13s 321ms/step - loss: 0.0277 - accuracy: 1.0000 - recall: 0.9755 - precision: 0.9694 - f1_score: 0.9727 - IoU: 0.9658 - val_loss: 0.0238 - val_accuracy: 1.0000 - val_recall: 0.9754 - val_precision: 0.9842 - val_f1_score: 0.9752 - val_IoU: 0.9684\n",
      "Epoch 95/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0295 - accuracy: 1.0000 - recall: 0.9782 - precision: 0.9707 - f1_score: 0.9704 - IoU: 0.9665\n",
      "Epoch 95: val_f1_score did not improve from 0.97795\n",
      "42/42 [==============================] - 13s 321ms/step - loss: 0.0295 - accuracy: 1.0000 - recall: 0.9782 - precision: 0.9707 - f1_score: 0.9704 - IoU: 0.9665 - val_loss: 0.0289 - val_accuracy: 1.0000 - val_recall: 0.9627 - val_precision: 0.9882 - val_f1_score: 0.9713 - val_IoU: 0.9603\n",
      "Epoch 96/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0258 - accuracy: 1.0000 - recall: 0.9745 - precision: 0.9746 - f1_score: 0.9746 - IoU: 0.9654\n",
      "Epoch 96: val_f1_score did not improve from 0.97795\n",
      "42/42 [==============================] - 14s 322ms/step - loss: 0.0258 - accuracy: 1.0000 - recall: 0.9745 - precision: 0.9746 - f1_score: 0.9746 - IoU: 0.9654 - val_loss: 0.0309 - val_accuracy: 1.0000 - val_recall: 0.9604 - val_precision: 0.9900 - val_f1_score: 0.9715 - val_IoU: 0.9585\n",
      "Epoch 97/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0261 - accuracy: 1.0000 - recall: 0.9743 - precision: 0.9750 - f1_score: 0.9742 - IoU: 0.9653\n",
      "Epoch 97: val_f1_score did not improve from 0.97795\n",
      "42/42 [==============================] - 13s 321ms/step - loss: 0.0261 - accuracy: 1.0000 - recall: 0.9743 - precision: 0.9750 - f1_score: 0.9742 - IoU: 0.9653 - val_loss: 0.0314 - val_accuracy: 1.0000 - val_recall: 0.9520 - val_precision: 0.9918 - val_f1_score: 0.9686 - val_IoU: 0.9537\n",
      "Epoch 98/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0270 - accuracy: 1.0000 - recall: 0.9753 - precision: 0.9726 - f1_score: 0.9734 - IoU: 0.9655\n",
      "Epoch 98: val_f1_score did not improve from 0.97795\n",
      "42/42 [==============================] - 13s 321ms/step - loss: 0.0270 - accuracy: 1.0000 - recall: 0.9753 - precision: 0.9726 - f1_score: 0.9734 - IoU: 0.9655 - val_loss: 0.0214 - val_accuracy: 1.0000 - val_recall: 0.9848 - val_precision: 0.9773 - val_f1_score: 0.9776 - val_IoU: 0.9740\n",
      "Epoch 99/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0250 - accuracy: 1.0000 - recall: 0.9788 - precision: 0.9728 - f1_score: 0.9753 - IoU: 0.9678\n",
      "Epoch 99: val_f1_score did not improve from 0.97795\n",
      "42/42 [==============================] - 13s 321ms/step - loss: 0.0250 - accuracy: 1.0000 - recall: 0.9788 - precision: 0.9728 - f1_score: 0.9753 - IoU: 0.9678 - val_loss: 0.0221 - val_accuracy: 1.0000 - val_recall: 0.9769 - val_precision: 0.9865 - val_f1_score: 0.9770 - val_IoU: 0.9687\n",
      "Epoch 100/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0264 - accuracy: 1.0000 - recall: 0.9754 - precision: 0.9745 - f1_score: 0.9739 - IoU: 0.9653\n",
      "Epoch 100: val_f1_score did not improve from 0.97795\n",
      "42/42 [==============================] - 13s 321ms/step - loss: 0.0264 - accuracy: 1.0000 - recall: 0.9754 - precision: 0.9745 - f1_score: 0.9739 - IoU: 0.9653 - val_loss: 0.0233 - val_accuracy: 1.0000 - val_recall: 0.9724 - val_precision: 0.9895 - val_f1_score: 0.9772 - val_IoU: 0.9645\n",
      "Epoch 101/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0271 - accuracy: 1.0000 - recall: 0.9739 - precision: 0.9750 - f1_score: 0.9733 - IoU: 0.9656\n",
      "Epoch 101: val_f1_score did not improve from 0.97795\n",
      "42/42 [==============================] - 13s 321ms/step - loss: 0.0271 - accuracy: 1.0000 - recall: 0.9739 - precision: 0.9750 - f1_score: 0.9733 - IoU: 0.9656 - val_loss: 0.0396 - val_accuracy: 1.0000 - val_recall: 0.9393 - val_precision: 0.9936 - val_f1_score: 0.9619 - val_IoU: 0.9458\n",
      "Epoch 102/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0247 - accuracy: 1.0000 - recall: 0.9778 - precision: 0.9741 - f1_score: 0.9757 - IoU: 0.9677\n",
      "Epoch 102: val_f1_score did not improve from 0.97795\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 0.0247 - accuracy: 1.0000 - recall: 0.9778 - precision: 0.9741 - f1_score: 0.9757 - IoU: 0.9677 - val_loss: 0.0222 - val_accuracy: 1.0000 - val_recall: 0.9764 - val_precision: 0.9850 - val_f1_score: 0.9774 - val_IoU: 0.9666\n",
      "Epoch 103/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0242 - accuracy: 1.0000 - recall: 0.9770 - precision: 0.9751 - f1_score: 0.9763 - IoU: 0.9672\n",
      "Epoch 103: val_f1_score did not improve from 0.97795\n",
      "42/42 [==============================] - 13s 321ms/step - loss: 0.0242 - accuracy: 1.0000 - recall: 0.9770 - precision: 0.9751 - f1_score: 0.9763 - IoU: 0.9672 - val_loss: 0.0240 - val_accuracy: 1.0000 - val_recall: 0.9702 - val_precision: 0.9885 - val_f1_score: 0.9764 - val_IoU: 0.9643\n",
      "Epoch 104/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0239 - accuracy: 1.0000 - recall: 0.9799 - precision: 0.9738 - f1_score: 0.9764 - IoU: 0.9690\n",
      "Epoch 104: val_f1_score did not improve from 0.97795\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 0.0239 - accuracy: 1.0000 - recall: 0.9799 - precision: 0.9738 - f1_score: 0.9764 - IoU: 0.9690 - val_loss: 0.0288 - val_accuracy: 1.0000 - val_recall: 0.9611 - val_precision: 0.9917 - val_f1_score: 0.9714 - val_IoU: 0.9589\n",
      "Epoch 105/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0249 - accuracy: 1.0000 - recall: 0.9775 - precision: 0.9752 - f1_score: 0.9754 - IoU: 0.9678\n",
      "Epoch 105: val_f1_score improved from 0.97795 to 0.97807, saving model to UNet3Plus DICE 5-fold model/model_4fold.keras\n",
      "42/42 [==============================] - 14s 327ms/step - loss: 0.0249 - accuracy: 1.0000 - recall: 0.9775 - precision: 0.9752 - f1_score: 0.9754 - IoU: 0.9678 - val_loss: 0.0215 - val_accuracy: 1.0000 - val_recall: 0.9807 - val_precision: 0.9829 - val_f1_score: 0.9781 - val_IoU: 0.9724\n",
      "Epoch 106/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0243 - accuracy: 1.0000 - recall: 0.9785 - precision: 0.9752 - f1_score: 0.9759 - IoU: 0.9692\n",
      "Epoch 106: val_f1_score did not improve from 0.97807\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 0.0243 - accuracy: 1.0000 - recall: 0.9785 - precision: 0.9752 - f1_score: 0.9759 - IoU: 0.9692 - val_loss: 0.0228 - val_accuracy: 1.0000 - val_recall: 0.9869 - val_precision: 0.9760 - val_f1_score: 0.9768 - val_IoU: 0.9788\n",
      "Epoch 107/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0232 - accuracy: 1.0000 - recall: 0.9791 - precision: 0.9747 - f1_score: 0.9772 - IoU: 0.9686\n",
      "Epoch 107: val_f1_score did not improve from 0.97807\n",
      "42/42 [==============================] - 13s 321ms/step - loss: 0.0232 - accuracy: 1.0000 - recall: 0.9791 - precision: 0.9747 - f1_score: 0.9772 - IoU: 0.9686 - val_loss: 0.0229 - val_accuracy: 1.0000 - val_recall: 0.9943 - val_precision: 0.9629 - val_f1_score: 0.9776 - val_IoU: 0.9817\n",
      "Epoch 108/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0234 - accuracy: 1.0000 - recall: 0.9778 - precision: 0.9751 - f1_score: 0.9768 - IoU: 0.9688\n",
      "Epoch 108: val_f1_score did not improve from 0.97807\n",
      "42/42 [==============================] - 13s 322ms/step - loss: 0.0234 - accuracy: 1.0000 - recall: 0.9778 - precision: 0.9751 - f1_score: 0.9768 - IoU: 0.9688 - val_loss: 0.0222 - val_accuracy: 1.0000 - val_recall: 0.9894 - val_precision: 0.9740 - val_f1_score: 0.9780 - val_IoU: 0.9773\n",
      "Epoch 109/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0268 - accuracy: 1.0000 - recall: 0.9768 - precision: 0.9761 - f1_score: 0.9736 - IoU: 0.9682\n",
      "Epoch 109: val_f1_score did not improve from 0.97807\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 0.0268 - accuracy: 1.0000 - recall: 0.9768 - precision: 0.9761 - f1_score: 0.9736 - IoU: 0.9682 - val_loss: 0.0242 - val_accuracy: 1.0000 - val_recall: 0.9950 - val_precision: 0.9610 - val_f1_score: 0.9758 - val_IoU: 0.9830\n",
      "Epoch 110/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0275 - accuracy: 1.0000 - recall: 0.9777 - precision: 0.9704 - f1_score: 0.9728 - IoU: 0.9677\n",
      "Epoch 110: val_f1_score did not improve from 0.97807\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 0.0275 - accuracy: 1.0000 - recall: 0.9777 - precision: 0.9704 - f1_score: 0.9728 - IoU: 0.9677 - val_loss: 0.0400 - val_accuracy: 1.0000 - val_recall: 0.9723 - val_precision: 0.9662 - val_f1_score: 0.9604 - val_IoU: 0.9708\n",
      "Epoch 111/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0292 - accuracy: 1.0000 - recall: 0.9742 - precision: 0.9713 - f1_score: 0.9712 - IoU: 0.9655\n",
      "Epoch 111: val_f1_score did not improve from 0.97807\n",
      "42/42 [==============================] - 13s 322ms/step - loss: 0.0292 - accuracy: 1.0000 - recall: 0.9742 - precision: 0.9713 - f1_score: 0.9712 - IoU: 0.9655 - val_loss: 0.0306 - val_accuracy: 1.0000 - val_recall: 0.9581 - val_precision: 0.9900 - val_f1_score: 0.9696 - val_IoU: 0.9605\n",
      "Epoch 112/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0246 - accuracy: 1.0000 - recall: 0.9768 - precision: 0.9757 - f1_score: 0.9757 - IoU: 0.9676\n",
      "Epoch 112: val_f1_score did not improve from 0.97807\n",
      "42/42 [==============================] - 14s 322ms/step - loss: 0.0246 - accuracy: 1.0000 - recall: 0.9768 - precision: 0.9757 - f1_score: 0.9757 - IoU: 0.9676 - val_loss: 0.0235 - val_accuracy: 1.0000 - val_recall: 0.9752 - val_precision: 0.9867 - val_f1_score: 0.9764 - val_IoU: 0.9684\n",
      "Epoch 113/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0234 - accuracy: 1.0000 - recall: 0.9790 - precision: 0.9738 - f1_score: 0.9769 - IoU: 0.9692\n",
      "Epoch 113: val_f1_score did not improve from 0.97807\n",
      "42/42 [==============================] - 13s 319ms/step - loss: 0.0234 - accuracy: 1.0000 - recall: 0.9790 - precision: 0.9738 - f1_score: 0.9769 - IoU: 0.9692 - val_loss: 0.0264 - val_accuracy: 1.0000 - val_recall: 0.9949 - val_precision: 0.9573 - val_f1_score: 0.9732 - val_IoU: 0.9819\n",
      "Epoch 114/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0255 - accuracy: 1.0000 - recall: 0.9768 - precision: 0.9740 - f1_score: 0.9748 - IoU: 0.9675\n",
      "Epoch 114: val_f1_score improved from 0.97807 to 0.97955, saving model to UNet3Plus DICE 5-fold model/model_4fold.keras\n",
      "42/42 [==============================] - 14s 325ms/step - loss: 0.0255 - accuracy: 1.0000 - recall: 0.9768 - precision: 0.9740 - f1_score: 0.9748 - IoU: 0.9675 - val_loss: 0.0209 - val_accuracy: 1.0000 - val_recall: 0.9837 - val_precision: 0.9816 - val_f1_score: 0.9796 - val_IoU: 0.9750\n",
      "Epoch 115/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0225 - accuracy: 1.0000 - recall: 0.9810 - precision: 0.9740 - f1_score: 0.9777 - IoU: 0.9701\n",
      "Epoch 115: val_f1_score did not improve from 0.97955\n",
      "42/42 [==============================] - 13s 321ms/step - loss: 0.0225 - accuracy: 1.0000 - recall: 0.9810 - precision: 0.9740 - f1_score: 0.9777 - IoU: 0.9701 - val_loss: 0.0213 - val_accuracy: 1.0000 - val_recall: 0.9793 - val_precision: 0.9860 - val_f1_score: 0.9779 - val_IoU: 0.9713\n",
      "Epoch 116/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0231 - accuracy: 1.0000 - recall: 0.9788 - precision: 0.9757 - f1_score: 0.9772 - IoU: 0.9687\n",
      "Epoch 116: val_f1_score did not improve from 0.97955\n",
      "42/42 [==============================] - 13s 321ms/step - loss: 0.0231 - accuracy: 1.0000 - recall: 0.9788 - precision: 0.9757 - f1_score: 0.9772 - IoU: 0.9687 - val_loss: 0.0232 - val_accuracy: 1.0000 - val_recall: 0.9923 - val_precision: 0.9646 - val_f1_score: 0.9764 - val_IoU: 0.9815\n",
      "Epoch 117/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0232 - accuracy: 1.0000 - recall: 0.9794 - precision: 0.9750 - f1_score: 0.9770 - IoU: 0.9691\n",
      "Epoch 117: val_f1_score did not improve from 0.97955\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 0.0232 - accuracy: 1.0000 - recall: 0.9794 - precision: 0.9750 - f1_score: 0.9770 - IoU: 0.9691 - val_loss: 0.0219 - val_accuracy: 1.0000 - val_recall: 0.9742 - val_precision: 0.9884 - val_f1_score: 0.9785 - val_IoU: 0.9686\n",
      "Epoch 118/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0263 - accuracy: 1.0000 - recall: 0.9760 - precision: 0.9746 - f1_score: 0.9740 - IoU: 0.9675\n",
      "Epoch 118: val_f1_score did not improve from 0.97955\n",
      "42/42 [==============================] - 13s 321ms/step - loss: 0.0263 - accuracy: 1.0000 - recall: 0.9760 - precision: 0.9746 - f1_score: 0.9740 - IoU: 0.9675 - val_loss: 0.0232 - val_accuracy: 1.0000 - val_recall: 0.9920 - val_precision: 0.9694 - val_f1_score: 0.9772 - val_IoU: 0.9795\n",
      "Epoch 119/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0245 - accuracy: 1.0000 - recall: 0.9786 - precision: 0.9752 - f1_score: 0.9757 - IoU: 0.9686\n",
      "Epoch 119: val_f1_score did not improve from 0.97955\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 0.0245 - accuracy: 1.0000 - recall: 0.9786 - precision: 0.9752 - f1_score: 0.9757 - IoU: 0.9686 - val_loss: 0.0259 - val_accuracy: 1.0000 - val_recall: 0.9745 - val_precision: 0.9807 - val_f1_score: 0.9739 - val_IoU: 0.9687\n",
      "Epoch 120/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0238 - accuracy: 1.0000 - recall: 0.9800 - precision: 0.9734 - f1_score: 0.9764 - IoU: 0.9703\n",
      "Epoch 120: val_f1_score did not improve from 0.97955\n",
      "42/42 [==============================] - 14s 322ms/step - loss: 0.0238 - accuracy: 1.0000 - recall: 0.9800 - precision: 0.9734 - f1_score: 0.9764 - IoU: 0.9703 - val_loss: 0.0209 - val_accuracy: 1.0000 - val_recall: 0.9809 - val_precision: 0.9824 - val_f1_score: 0.9787 - val_IoU: 0.9735\n",
      "Epoch 121/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0220 - accuracy: 1.0000 - recall: 0.9807 - precision: 0.9761 - f1_score: 0.9782 - IoU: 0.9701\n",
      "Epoch 121: val_f1_score improved from 0.97955 to 0.98084, saving model to UNet3Plus DICE 5-fold model/model_4fold.keras\n",
      "42/42 [==============================] - 14s 326ms/step - loss: 0.0220 - accuracy: 1.0000 - recall: 0.9807 - precision: 0.9761 - f1_score: 0.9782 - IoU: 0.9701 - val_loss: 0.0197 - val_accuracy: 1.0000 - val_recall: 0.9827 - val_precision: 0.9844 - val_f1_score: 0.9808 - val_IoU: 0.9728\n",
      "Epoch 122/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0234 - accuracy: 1.0000 - recall: 0.9805 - precision: 0.9764 - f1_score: 0.9769 - IoU: 0.9706\n",
      "Epoch 122: val_f1_score did not improve from 0.98084\n",
      "42/42 [==============================] - 13s 321ms/step - loss: 0.0234 - accuracy: 1.0000 - recall: 0.9805 - precision: 0.9764 - f1_score: 0.9769 - IoU: 0.9706 - val_loss: 0.0230 - val_accuracy: 1.0000 - val_recall: 0.9724 - val_precision: 0.9868 - val_f1_score: 0.9767 - val_IoU: 0.9677\n",
      "Epoch 123/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0223 - accuracy: 1.0000 - recall: 0.9818 - precision: 0.9740 - f1_score: 0.9780 - IoU: 0.9709\n",
      "Epoch 123: val_f1_score did not improve from 0.98084\n",
      "42/42 [==============================] - 13s 321ms/step - loss: 0.0223 - accuracy: 1.0000 - recall: 0.9818 - precision: 0.9740 - f1_score: 0.9780 - IoU: 0.9709 - val_loss: 0.0193 - val_accuracy: 1.0000 - val_recall: 0.9823 - val_precision: 0.9857 - val_f1_score: 0.9805 - val_IoU: 0.9730\n",
      "Epoch 124/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0232 - accuracy: 1.0000 - recall: 0.9807 - precision: 0.9750 - f1_score: 0.9771 - IoU: 0.9703\n",
      "Epoch 124: val_f1_score did not improve from 0.98084\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 0.0232 - accuracy: 1.0000 - recall: 0.9807 - precision: 0.9750 - f1_score: 0.9771 - IoU: 0.9703 - val_loss: 0.0292 - val_accuracy: 1.0000 - val_recall: 0.9581 - val_precision: 0.9919 - val_f1_score: 0.9712 - val_IoU: 0.9602\n",
      "Epoch 125/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0216 - accuracy: 1.0000 - recall: 0.9802 - precision: 0.9767 - f1_score: 0.9786 - IoU: 0.9699\n",
      "Epoch 125: val_f1_score did not improve from 0.98084\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 0.0216 - accuracy: 1.0000 - recall: 0.9802 - precision: 0.9767 - f1_score: 0.9786 - IoU: 0.9699 - val_loss: 0.0200 - val_accuracy: 1.0000 - val_recall: 0.9906 - val_precision: 0.9763 - val_f1_score: 0.9803 - val_IoU: 0.9795\n",
      "Epoch 126/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0218 - accuracy: 1.0000 - recall: 0.9779 - precision: 0.9781 - f1_score: 0.9784 - IoU: 0.9688\n",
      "Epoch 126: val_f1_score did not improve from 0.98084\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 0.0218 - accuracy: 1.0000 - recall: 0.9779 - precision: 0.9781 - f1_score: 0.9784 - IoU: 0.9688 - val_loss: 0.0260 - val_accuracy: 1.0000 - val_recall: 0.9934 - val_precision: 0.9609 - val_f1_score: 0.9735 - val_IoU: 0.9826\n",
      "Epoch 127/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0237 - accuracy: 1.0000 - recall: 0.9803 - precision: 0.9741 - f1_score: 0.9764 - IoU: 0.9707\n",
      "Epoch 127: val_f1_score did not improve from 0.98084\n",
      "42/42 [==============================] - 13s 321ms/step - loss: 0.0237 - accuracy: 1.0000 - recall: 0.9803 - precision: 0.9741 - f1_score: 0.9764 - IoU: 0.9707 - val_loss: 0.0245 - val_accuracy: 1.0000 - val_recall: 0.9954 - val_precision: 0.9599 - val_f1_score: 0.9751 - val_IoU: 0.9834\n",
      "Epoch 128/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0239 - accuracy: 1.0000 - recall: 0.9810 - precision: 0.9733 - f1_score: 0.9763 - IoU: 0.9710\n",
      "Epoch 128: val_f1_score did not improve from 0.98084\n",
      "42/42 [==============================] - 13s 322ms/step - loss: 0.0239 - accuracy: 1.0000 - recall: 0.9810 - precision: 0.9733 - f1_score: 0.9763 - IoU: 0.9710 - val_loss: 0.0245 - val_accuracy: 1.0000 - val_recall: 0.9653 - val_precision: 0.9922 - val_f1_score: 0.9756 - val_IoU: 0.9647\n",
      "Epoch 129/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0240 - accuracy: 1.0000 - recall: 0.9794 - precision: 0.9740 - f1_score: 0.9761 - IoU: 0.9704\n",
      "Epoch 129: val_f1_score did not improve from 0.98084\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 0.0240 - accuracy: 1.0000 - recall: 0.9794 - precision: 0.9740 - f1_score: 0.9761 - IoU: 0.9704 - val_loss: 0.0201 - val_accuracy: 1.0000 - val_recall: 0.9847 - val_precision: 0.9814 - val_f1_score: 0.9798 - val_IoU: 0.9769\n",
      "Epoch 130/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0225 - accuracy: 1.0000 - recall: 0.9797 - precision: 0.9756 - f1_score: 0.9776 - IoU: 0.9704\n",
      "Epoch 130: val_f1_score did not improve from 0.98084\n",
      "42/42 [==============================] - 13s 321ms/step - loss: 0.0225 - accuracy: 1.0000 - recall: 0.9797 - precision: 0.9756 - f1_score: 0.9776 - IoU: 0.9704 - val_loss: 0.0219 - val_accuracy: 1.0000 - val_recall: 0.9729 - val_precision: 0.9888 - val_f1_score: 0.9779 - val_IoU: 0.9691\n",
      "Epoch 131/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0239 - accuracy: 1.0000 - recall: 0.9767 - precision: 0.9773 - f1_score: 0.9763 - IoU: 0.9687\n",
      "Epoch 131: val_f1_score did not improve from 0.98084\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 0.0239 - accuracy: 1.0000 - recall: 0.9767 - precision: 0.9773 - f1_score: 0.9763 - IoU: 0.9687 - val_loss: 0.0304 - val_accuracy: 1.0000 - val_recall: 0.9956 - val_precision: 0.9498 - val_f1_score: 0.9694 - val_IoU: 0.9832\n",
      "Epoch 132/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0229 - accuracy: 1.0000 - recall: 0.9807 - precision: 0.9745 - f1_score: 0.9773 - IoU: 0.9711\n",
      "Epoch 132: val_f1_score did not improve from 0.98084\n",
      "42/42 [==============================] - 13s 320ms/step - loss: 0.0229 - accuracy: 1.0000 - recall: 0.9807 - precision: 0.9745 - f1_score: 0.9773 - IoU: 0.9711 - val_loss: 0.0232 - val_accuracy: 1.0000 - val_recall: 0.9701 - val_precision: 0.9905 - val_f1_score: 0.9768 - val_IoU: 0.9683\n",
      "Epoch 133/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0229 - accuracy: 1.0000 - recall: 0.9781 - precision: 0.9768 - f1_score: 0.9773 - IoU: 0.9695\n",
      "Epoch 133: val_f1_score improved from 0.98084 to 0.98188, saving model to UNet3Plus DICE 5-fold model/model_4fold.keras\n",
      "42/42 [==============================] - 14s 325ms/step - loss: 0.0229 - accuracy: 1.0000 - recall: 0.9781 - precision: 0.9768 - f1_score: 0.9773 - IoU: 0.9695 - val_loss: 0.0180 - val_accuracy: 1.0000 - val_recall: 0.9867 - val_precision: 0.9840 - val_f1_score: 0.9819 - val_IoU: 0.9777\n",
      "Epoch 134/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0229 - accuracy: 1.0000 - recall: 0.9798 - precision: 0.9738 - f1_score: 0.9772 - IoU: 0.9711\n",
      "Epoch 134: val_f1_score did not improve from 0.98188\n",
      "42/42 [==============================] - 13s 321ms/step - loss: 0.0229 - accuracy: 1.0000 - recall: 0.9798 - precision: 0.9738 - f1_score: 0.9772 - IoU: 0.9711 - val_loss: 0.0271 - val_accuracy: 1.0000 - val_recall: 0.9597 - val_precision: 0.9928 - val_f1_score: 0.9724 - val_IoU: 0.9625\n",
      "Epoch 135/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0227 - accuracy: 1.0000 - recall: 0.9789 - precision: 0.9764 - f1_score: 0.9776 - IoU: 0.9701\n",
      "Epoch 135: val_f1_score did not improve from 0.98188\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 0.0227 - accuracy: 1.0000 - recall: 0.9789 - precision: 0.9764 - f1_score: 0.9776 - IoU: 0.9701 - val_loss: 0.0235 - val_accuracy: 1.0000 - val_recall: 0.9691 - val_precision: 0.9915 - val_f1_score: 0.9763 - val_IoU: 0.9669\n",
      "Epoch 136/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0241 - accuracy: 1.0000 - recall: 0.9795 - precision: 0.9726 - f1_score: 0.9761 - IoU: 0.9700\n",
      "Epoch 136: val_f1_score did not improve from 0.98188\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 0.0241 - accuracy: 1.0000 - recall: 0.9795 - precision: 0.9726 - f1_score: 0.9761 - IoU: 0.9700 - val_loss: 0.0436 - val_accuracy: 1.0000 - val_recall: 0.9560 - val_precision: 0.9832 - val_f1_score: 0.9582 - val_IoU: 0.9602\n",
      "Epoch 137/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0240 - accuracy: 1.0000 - recall: 0.9779 - precision: 0.9755 - f1_score: 0.9762 - IoU: 0.9699\n",
      "Epoch 137: val_f1_score did not improve from 0.98188\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 0.0240 - accuracy: 1.0000 - recall: 0.9779 - precision: 0.9755 - f1_score: 0.9762 - IoU: 0.9699 - val_loss: 0.0206 - val_accuracy: 1.0000 - val_recall: 0.9837 - val_precision: 0.9802 - val_f1_score: 0.9786 - val_IoU: 0.9758\n",
      "Epoch 138/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0222 - accuracy: 1.0000 - recall: 0.9816 - precision: 0.9745 - f1_score: 0.9781 - IoU: 0.9723\n",
      "Epoch 138: val_f1_score did not improve from 0.98188\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 0.0222 - accuracy: 1.0000 - recall: 0.9816 - precision: 0.9745 - f1_score: 0.9781 - IoU: 0.9723 - val_loss: 0.0221 - val_accuracy: 1.0000 - val_recall: 0.9745 - val_precision: 0.9861 - val_f1_score: 0.9777 - val_IoU: 0.9693\n",
      "Epoch 139/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 1.0000 - recall: 0.9796 - precision: 0.9764 - f1_score: 0.9772 - IoU: 0.9704\n",
      "Epoch 139: val_f1_score did not improve from 0.98188\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 0.0230 - accuracy: 1.0000 - recall: 0.9796 - precision: 0.9764 - f1_score: 0.9772 - IoU: 0.9704 - val_loss: 0.0197 - val_accuracy: 1.0000 - val_recall: 0.9919 - val_precision: 0.9729 - val_f1_score: 0.9799 - val_IoU: 0.9824\n",
      "Epoch 140/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0225 - accuracy: 1.0000 - recall: 0.9823 - precision: 0.9754 - f1_score: 0.9777 - IoU: 0.9728\n",
      "Epoch 140: val_f1_score did not improve from 0.98188\n",
      "42/42 [==============================] - 14s 322ms/step - loss: 0.0225 - accuracy: 1.0000 - recall: 0.9823 - precision: 0.9754 - f1_score: 0.9777 - IoU: 0.9728 - val_loss: 0.0202 - val_accuracy: 1.0000 - val_recall: 0.9791 - val_precision: 0.9858 - val_f1_score: 0.9801 - val_IoU: 0.9742\n",
      "Epoch 141/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0228 - accuracy: 1.0000 - recall: 0.9789 - precision: 0.9771 - f1_score: 0.9774 - IoU: 0.9705\n",
      "Epoch 141: val_f1_score did not improve from 0.98188\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 0.0228 - accuracy: 1.0000 - recall: 0.9789 - precision: 0.9771 - f1_score: 0.9774 - IoU: 0.9705 - val_loss: 0.0183 - val_accuracy: 1.0000 - val_recall: 0.9884 - val_precision: 0.9809 - val_f1_score: 0.9813 - val_IoU: 0.9789\n",
      "Epoch 142/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0223 - accuracy: 1.0000 - recall: 0.9817 - precision: 0.9749 - f1_score: 0.9780 - IoU: 0.9718\n",
      "Epoch 142: val_f1_score did not improve from 0.98188\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 0.0223 - accuracy: 1.0000 - recall: 0.9817 - precision: 0.9749 - f1_score: 0.9780 - IoU: 0.9718 - val_loss: 0.0192 - val_accuracy: 1.0000 - val_recall: 0.9842 - val_precision: 0.9841 - val_f1_score: 0.9810 - val_IoU: 0.9768\n",
      "Epoch 143/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0235 - accuracy: 1.0000 - recall: 0.9790 - precision: 0.9761 - f1_score: 0.9766 - IoU: 0.9706\n",
      "Epoch 143: val_f1_score did not improve from 0.98188\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 0.0235 - accuracy: 1.0000 - recall: 0.9790 - precision: 0.9761 - f1_score: 0.9766 - IoU: 0.9706 - val_loss: 0.0280 - val_accuracy: 1.0000 - val_recall: 0.9598 - val_precision: 0.9918 - val_f1_score: 0.9720 - val_IoU: 0.9630\n",
      "Epoch 144/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0247 - accuracy: 1.0000 - recall: 0.9807 - precision: 0.9725 - f1_score: 0.9756 - IoU: 0.9712\n",
      "Epoch 144: val_f1_score did not improve from 0.98188\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 0.0247 - accuracy: 1.0000 - recall: 0.9807 - precision: 0.9725 - f1_score: 0.9756 - IoU: 0.9712 - val_loss: 0.0230 - val_accuracy: 1.0000 - val_recall: 0.9695 - val_precision: 0.9903 - val_f1_score: 0.9769 - val_IoU: 0.9672\n",
      "Epoch 145/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0242 - accuracy: 1.0000 - recall: 0.9804 - precision: 0.9752 - f1_score: 0.9760 - IoU: 0.9709\n",
      "Epoch 145: val_f1_score did not improve from 0.98188\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 0.0242 - accuracy: 1.0000 - recall: 0.9804 - precision: 0.9752 - f1_score: 0.9760 - IoU: 0.9709 - val_loss: 0.0219 - val_accuracy: 1.0000 - val_recall: 0.9746 - val_precision: 0.9875 - val_f1_score: 0.9779 - val_IoU: 0.9697\n",
      "Epoch 146/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0222 - accuracy: 1.0000 - recall: 0.9804 - precision: 0.9768 - f1_score: 0.9780 - IoU: 0.9722\n",
      "Epoch 146: val_f1_score did not improve from 0.98188\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 0.0222 - accuracy: 1.0000 - recall: 0.9804 - precision: 0.9768 - f1_score: 0.9780 - IoU: 0.9722 - val_loss: 0.0220 - val_accuracy: 1.0000 - val_recall: 0.9871 - val_precision: 0.9747 - val_f1_score: 0.9774 - val_IoU: 0.9773\n",
      "Epoch 147/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0205 - accuracy: 1.0000 - recall: 0.9818 - precision: 0.9769 - f1_score: 0.9797 - IoU: 0.9727\n",
      "Epoch 147: val_f1_score did not improve from 0.98188\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 0.0205 - accuracy: 1.0000 - recall: 0.9818 - precision: 0.9769 - f1_score: 0.9797 - IoU: 0.9727 - val_loss: 0.0188 - val_accuracy: 1.0000 - val_recall: 0.9881 - val_precision: 0.9807 - val_f1_score: 0.9810 - val_IoU: 0.9786\n",
      "Epoch 148/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0215 - accuracy: 1.0000 - recall: 0.9792 - precision: 0.9778 - f1_score: 0.9787 - IoU: 0.9718\n",
      "Epoch 148: val_f1_score did not improve from 0.98188\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 0.0215 - accuracy: 1.0000 - recall: 0.9792 - precision: 0.9778 - f1_score: 0.9787 - IoU: 0.9718 - val_loss: 0.0245 - val_accuracy: 1.0000 - val_recall: 0.9697 - val_precision: 0.9909 - val_f1_score: 0.9751 - val_IoU: 0.9678\n",
      "Epoch 149/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0217 - accuracy: 1.0000 - recall: 0.9809 - precision: 0.9768 - f1_score: 0.9785 - IoU: 0.9730\n",
      "Epoch 149: val_f1_score did not improve from 0.98188\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 0.0217 - accuracy: 1.0000 - recall: 0.9809 - precision: 0.9768 - f1_score: 0.9785 - IoU: 0.9730 - val_loss: 0.0297 - val_accuracy: 1.0000 - val_recall: 0.9540 - val_precision: 0.9930 - val_f1_score: 0.9707 - val_IoU: 0.9612\n",
      "Epoch 150/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 1.0000 - recall: 0.9831 - precision: 0.9766 - f1_score: 0.9792 - IoU: 0.9737\n",
      "Epoch 150: val_f1_score did not improve from 0.98188\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 0.0210 - accuracy: 1.0000 - recall: 0.9831 - precision: 0.9766 - f1_score: 0.9792 - IoU: 0.9737 - val_loss: 0.0200 - val_accuracy: 1.0000 - val_recall: 0.9769 - val_precision: 0.9882 - val_f1_score: 0.9798 - val_IoU: 0.9718\n",
      "O modelo demorou 2082.90 segundos para treinar.\n",
      "Fold: 5\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 05:21:40.626953: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - ETA: 0s - loss: 0.9972 - accuracy: 0.7546 - recall: 0.9504 - precision: 0.0025 - f1_score: 0.0051 - IoU: 0.5000\n",
      "Epoch 1: val_f1_score improved from -inf to 0.00206, saving model to UNet3Plus DICE 5-fold model/model_5fold.keras\n",
      "42/42 [==============================] - 20s 344ms/step - loss: 0.9972 - accuracy: 0.7546 - recall: 0.9504 - precision: 0.0025 - f1_score: 0.0051 - IoU: 0.5000 - val_loss: 0.9982 - val_accuracy: 0.4535 - val_recall: 1.0000 - val_precision: 0.0011 - val_f1_score: 0.0021 - val_IoU: 0.3642\n",
      "Epoch 2/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.9942 - accuracy: 0.9744 - recall: 0.9875 - precision: 0.0240 - f1_score: 0.0657 - IoU: 0.5452\n",
      "Epoch 2: val_f1_score improved from 0.00206 to 0.00486, saving model to UNet3Plus DICE 5-fold model/model_5fold.keras\n",
      "42/42 [==============================] - 14s 331ms/step - loss: 0.9942 - accuracy: 0.9744 - recall: 0.9875 - precision: 0.0240 - f1_score: 0.0657 - IoU: 0.5452 - val_loss: 0.9958 - val_accuracy: 0.7626 - val_recall: 0.9999 - val_precision: 0.0025 - val_f1_score: 0.0049 - val_IoU: 0.5196\n",
      "Epoch 3/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.9887 - accuracy: 0.9907 - recall: 0.9775 - precision: 0.0630 - f1_score: 0.1654 - IoU: 0.5837\n",
      "Epoch 3: val_f1_score did not improve from 0.00486\n",
      "42/42 [==============================] - 14s 325ms/step - loss: 0.9887 - accuracy: 0.9907 - recall: 0.9775 - precision: 0.0630 - f1_score: 0.1654 - IoU: 0.5837 - val_loss: 0.9983 - val_accuracy: 0.2909 - val_recall: 0.9984 - val_precision: 8.3882e-04 - val_f1_score: 0.0016 - val_IoU: 0.2388\n",
      "Epoch 4/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.9713 - accuracy: 0.9972 - recall: 0.9817 - precision: 0.1808 - f1_score: 0.3930 - IoU: 0.6831\n",
      "Epoch 4: val_f1_score did not improve from 0.00486\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 0.9713 - accuracy: 0.9972 - recall: 0.9817 - precision: 0.1808 - f1_score: 0.3930 - IoU: 0.6831 - val_loss: 0.9991 - val_accuracy: 0.9376 - val_recall: 0.0018 - val_precision: 1.7380e-05 - val_f1_score: 3.6272e-05 - val_IoU: 0.4987\n",
      "Epoch 5/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.9076 - accuracy: 0.9994 - recall: 0.9762 - precision: 0.5237 - f1_score: 0.6878 - IoU: 0.8382\n",
      "Epoch 5: val_f1_score did not improve from 0.00486\n",
      "42/42 [==============================] - 14s 325ms/step - loss: 0.9076 - accuracy: 0.9994 - recall: 0.9762 - precision: 0.5237 - f1_score: 0.6878 - IoU: 0.8382 - val_loss: 0.9999 - val_accuracy: 0.8634 - val_recall: 0.0025 - val_precision: 1.0752e-05 - val_f1_score: 2.3740e-05 - val_IoU: 0.4897\n",
      "Epoch 6/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.6907 - accuracy: 0.9998 - recall: 0.9562 - precision: 0.7447 - f1_score: 0.8331 - IoU: 0.8861\n",
      "Epoch 6: val_f1_score improved from 0.00486 to 0.27062, saving model to UNet3Plus DICE 5-fold model/model_5fold.keras\n",
      "42/42 [==============================] - 14s 331ms/step - loss: 0.6907 - accuracy: 0.9998 - recall: 0.9562 - precision: 0.7447 - f1_score: 0.8331 - IoU: 0.8861 - val_loss: 0.9220 - val_accuracy: 0.9994 - val_recall: 0.1146 - val_precision: 0.6712 - val_f1_score: 0.2706 - val_IoU: 0.5336\n",
      "Epoch 7/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.3794 - accuracy: 0.9998 - recall: 0.9240 - precision: 0.8295 - f1_score: 0.8678 - IoU: 0.8876\n",
      "Epoch 7: val_f1_score did not improve from 0.27062\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 0.3794 - accuracy: 0.9998 - recall: 0.9240 - precision: 0.8295 - f1_score: 0.8678 - IoU: 0.8876 - val_loss: 0.9695 - val_accuracy: 0.9992 - val_recall: 0.0231 - val_precision: 0.0719 - val_f1_score: 0.0529 - val_IoU: 0.5093\n",
      "Epoch 8/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1909 - accuracy: 0.9999 - recall: 0.9287 - precision: 0.9015 - f1_score: 0.9120 - IoU: 0.8998\n",
      "Epoch 8: val_f1_score improved from 0.27062 to 0.79542, saving model to UNet3Plus DICE 5-fold model/model_5fold.keras\n",
      "42/42 [==============================] - 14s 331ms/step - loss: 0.1909 - accuracy: 0.9999 - recall: 0.9287 - precision: 0.9015 - f1_score: 0.9120 - IoU: 0.8998 - val_loss: 0.2673 - val_accuracy: 0.9998 - val_recall: 0.8034 - val_precision: 0.9298 - val_f1_score: 0.7954 - val_IoU: 0.8456\n",
      "Epoch 9/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1249 - accuracy: 0.9999 - recall: 0.9362 - precision: 0.9312 - f1_score: 0.9307 - IoU: 0.9107\n",
      "Epoch 9: val_f1_score improved from 0.79542 to 0.92023, saving model to UNet3Plus DICE 5-fold model/model_5fold.keras\n",
      "42/42 [==============================] - 14s 331ms/step - loss: 0.1249 - accuracy: 0.9999 - recall: 0.9362 - precision: 0.9312 - f1_score: 0.9307 - IoU: 0.9107 - val_loss: 0.1610 - val_accuracy: 0.9999 - val_recall: 0.8785 - val_precision: 0.9844 - val_f1_score: 0.9202 - val_IoU: 0.8234\n",
      "Epoch 10/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1041 - accuracy: 0.9999 - recall: 0.9352 - precision: 0.9340 - f1_score: 0.9317 - IoU: 0.9128\n",
      "Epoch 10: val_f1_score did not improve from 0.92023\n",
      "42/42 [==============================] - 14s 325ms/step - loss: 0.1041 - accuracy: 0.9999 - recall: 0.9352 - precision: 0.9340 - f1_score: 0.9317 - IoU: 0.9128 - val_loss: 0.5432 - val_accuracy: 0.9996 - val_recall: 0.3350 - val_precision: 0.9974 - val_f1_score: 0.5384 - val_IoU: 0.5581\n",
      "Epoch 11/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0826 - accuracy: 0.9999 - recall: 0.9481 - precision: 0.9464 - f1_score: 0.9434 - IoU: 0.9228\n",
      "Epoch 11: val_f1_score improved from 0.92023 to 0.94667, saving model to UNet3Plus DICE 5-fold model/model_5fold.keras\n",
      "42/42 [==============================] - 14s 330ms/step - loss: 0.0826 - accuracy: 0.9999 - recall: 0.9481 - precision: 0.9464 - f1_score: 0.9434 - IoU: 0.9228 - val_loss: 0.1649 - val_accuracy: 0.9999 - val_recall: 0.9139 - val_precision: 0.9930 - val_f1_score: 0.9467 - val_IoU: 0.8454\n",
      "Epoch 12/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0682 - accuracy: 0.9999 - recall: 0.9517 - precision: 0.9533 - f1_score: 0.9517 - IoU: 0.9273\n",
      "Epoch 12: val_f1_score did not improve from 0.94667\n",
      "42/42 [==============================] - 14s 325ms/step - loss: 0.0682 - accuracy: 0.9999 - recall: 0.9517 - precision: 0.9533 - f1_score: 0.9517 - IoU: 0.9273 - val_loss: 0.2594 - val_accuracy: 0.9998 - val_recall: 0.6421 - val_precision: 0.9963 - val_f1_score: 0.8152 - val_IoU: 0.6919\n",
      "Epoch 13/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0668 - accuracy: 0.9999 - recall: 0.9533 - precision: 0.9476 - f1_score: 0.9497 - IoU: 0.9307\n",
      "Epoch 13: val_f1_score did not improve from 0.94667\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 0.0668 - accuracy: 0.9999 - recall: 0.9533 - precision: 0.9476 - f1_score: 0.9497 - IoU: 0.9307 - val_loss: 0.2744 - val_accuracy: 0.9998 - val_recall: 0.6727 - val_precision: 0.9954 - val_f1_score: 0.8320 - val_IoU: 0.7134\n",
      "Epoch 14/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0572 - accuracy: 0.9999 - recall: 0.9574 - precision: 0.9560 - f1_score: 0.9559 - IoU: 0.9334\n",
      "Epoch 14: val_f1_score did not improve from 0.94667\n",
      "42/42 [==============================] - 14s 323ms/step - loss: 0.0572 - accuracy: 0.9999 - recall: 0.9574 - precision: 0.9560 - f1_score: 0.9559 - IoU: 0.9334 - val_loss: 0.2220 - val_accuracy: 0.9998 - val_recall: 0.7266 - val_precision: 0.9940 - val_f1_score: 0.8576 - val_IoU: 0.7456\n",
      "Epoch 15/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0518 - accuracy: 0.9999 - recall: 0.9597 - precision: 0.9596 - f1_score: 0.9591 - IoU: 0.9348\n",
      "Epoch 15: val_f1_score improved from 0.94667 to 0.95741, saving model to UNet3Plus DICE 5-fold model/model_5fold.keras\n",
      "42/42 [==============================] - 14s 331ms/step - loss: 0.0518 - accuracy: 0.9999 - recall: 0.9597 - precision: 0.9596 - f1_score: 0.9591 - IoU: 0.9348 - val_loss: 0.0902 - val_accuracy: 1.0000 - val_recall: 0.9474 - val_precision: 0.9764 - val_f1_score: 0.9574 - val_IoU: 0.9186\n",
      "Epoch 16/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0506 - accuracy: 0.9999 - recall: 0.9603 - precision: 0.9599 - f1_score: 0.9592 - IoU: 0.9362\n",
      "Epoch 16: val_f1_score improved from 0.95741 to 0.96080, saving model to UNet3Plus DICE 5-fold model/model_5fold.keras\n",
      "42/42 [==============================] - 14s 330ms/step - loss: 0.0506 - accuracy: 0.9999 - recall: 0.9603 - precision: 0.9599 - f1_score: 0.9592 - IoU: 0.9362 - val_loss: 0.1151 - val_accuracy: 1.0000 - val_recall: 0.9495 - val_precision: 0.9836 - val_f1_score: 0.9608 - val_IoU: 0.9237\n",
      "Epoch 17/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0495 - accuracy: 0.9999 - recall: 0.9578 - precision: 0.9626 - f1_score: 0.9590 - IoU: 0.9361\n",
      "Epoch 17: val_f1_score did not improve from 0.96080\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 0.0495 - accuracy: 0.9999 - recall: 0.9578 - precision: 0.9626 - f1_score: 0.9590 - IoU: 0.9361 - val_loss: 0.0915 - val_accuracy: 1.0000 - val_recall: 0.9631 - val_precision: 0.9585 - val_f1_score: 0.9531 - val_IoU: 0.9178\n",
      "Epoch 18/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0477 - accuracy: 1.0000 - recall: 0.9602 - precision: 0.9619 - f1_score: 0.9598 - IoU: 0.9385\n",
      "Epoch 18: val_f1_score did not improve from 0.96080\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 0.0477 - accuracy: 1.0000 - recall: 0.9602 - precision: 0.9619 - f1_score: 0.9598 - IoU: 0.9385 - val_loss: 0.1946 - val_accuracy: 0.9998 - val_recall: 0.6858 - val_precision: 0.9913 - val_f1_score: 0.8454 - val_IoU: 0.7550\n",
      "Epoch 19/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0425 - accuracy: 1.0000 - recall: 0.9655 - precision: 0.9622 - f1_score: 0.9644 - IoU: 0.9416\n",
      "Epoch 19: val_f1_score improved from 0.96080 to 0.96630, saving model to UNet3Plus DICE 5-fold model/model_5fold.keras\n",
      "42/42 [==============================] - 14s 331ms/step - loss: 0.0425 - accuracy: 1.0000 - recall: 0.9655 - precision: 0.9622 - f1_score: 0.9644 - IoU: 0.9416 - val_loss: 0.0533 - val_accuracy: 1.0000 - val_recall: 0.9806 - val_precision: 0.9666 - val_f1_score: 0.9663 - val_IoU: 0.9534\n",
      "Epoch 20/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0443 - accuracy: 1.0000 - recall: 0.9641 - precision: 0.9627 - f1_score: 0.9617 - IoU: 0.9419\n",
      "Epoch 20: val_f1_score did not improve from 0.96630\n",
      "42/42 [==============================] - 14s 326ms/step - loss: 0.0443 - accuracy: 1.0000 - recall: 0.9641 - precision: 0.9627 - f1_score: 0.9617 - IoU: 0.9419 - val_loss: 0.0852 - val_accuracy: 0.9999 - val_recall: 0.9054 - val_precision: 0.9830 - val_f1_score: 0.9462 - val_IoU: 0.8888\n",
      "Epoch 21/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0417 - accuracy: 1.0000 - recall: 0.9650 - precision: 0.9625 - f1_score: 0.9637 - IoU: 0.9437\n",
      "Epoch 21: val_f1_score did not improve from 0.96630\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 0.0417 - accuracy: 1.0000 - recall: 0.9650 - precision: 0.9625 - f1_score: 0.9637 - IoU: 0.9437 - val_loss: 0.0864 - val_accuracy: 0.9999 - val_recall: 0.9215 - val_precision: 0.9836 - val_f1_score: 0.9512 - val_IoU: 0.9080\n",
      "Epoch 22/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0403 - accuracy: 1.0000 - recall: 0.9673 - precision: 0.9649 - f1_score: 0.9644 - IoU: 0.9449\n",
      "Epoch 22: val_f1_score did not improve from 0.96630\n",
      "42/42 [==============================] - 14s 326ms/step - loss: 0.0403 - accuracy: 1.0000 - recall: 0.9673 - precision: 0.9649 - f1_score: 0.9644 - IoU: 0.9449 - val_loss: 0.0994 - val_accuracy: 0.9999 - val_recall: 0.8662 - val_precision: 0.9799 - val_f1_score: 0.9294 - val_IoU: 0.8562\n",
      "Epoch 23/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0405 - accuracy: 1.0000 - recall: 0.9645 - precision: 0.9653 - f1_score: 0.9641 - IoU: 0.9431\n",
      "Epoch 23: val_f1_score did not improve from 0.96630\n",
      "42/42 [==============================] - 14s 325ms/step - loss: 0.0405 - accuracy: 1.0000 - recall: 0.9645 - precision: 0.9653 - f1_score: 0.9641 - IoU: 0.9431 - val_loss: 0.0551 - val_accuracy: 1.0000 - val_recall: 0.9959 - val_precision: 0.9385 - val_f1_score: 0.9633 - val_IoU: 0.9727\n",
      "Epoch 24/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0410 - accuracy: 1.0000 - recall: 0.9665 - precision: 0.9645 - f1_score: 0.9631 - IoU: 0.9454\n",
      "Epoch 24: val_f1_score did not improve from 0.96630\n",
      "42/42 [==============================] - 14s 325ms/step - loss: 0.0410 - accuracy: 1.0000 - recall: 0.9665 - precision: 0.9645 - f1_score: 0.9631 - IoU: 0.9454 - val_loss: 0.0723 - val_accuracy: 1.0000 - val_recall: 0.9349 - val_precision: 0.9917 - val_f1_score: 0.9630 - val_IoU: 0.9225\n",
      "Epoch 25/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0357 - accuracy: 1.0000 - recall: 0.9677 - precision: 0.9683 - f1_score: 0.9682 - IoU: 0.9469\n",
      "Epoch 25: val_f1_score improved from 0.96630 to 0.97277, saving model to UNet3Plus DICE 5-fold model/model_5fold.keras\n",
      "42/42 [==============================] - 14s 332ms/step - loss: 0.0357 - accuracy: 1.0000 - recall: 0.9677 - precision: 0.9683 - f1_score: 0.9682 - IoU: 0.9469 - val_loss: 0.0515 - val_accuracy: 1.0000 - val_recall: 0.9574 - val_precision: 0.9918 - val_f1_score: 0.9728 - val_IoU: 0.9410\n",
      "Epoch 26/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0382 - accuracy: 1.0000 - recall: 0.9661 - precision: 0.9661 - f1_score: 0.9655 - IoU: 0.9469\n",
      "Epoch 26: val_f1_score did not improve from 0.97277\n",
      "42/42 [==============================] - 14s 325ms/step - loss: 0.0382 - accuracy: 1.0000 - recall: 0.9661 - precision: 0.9661 - f1_score: 0.9655 - IoU: 0.9469 - val_loss: 0.0333 - val_accuracy: 1.0000 - val_recall: 0.9920 - val_precision: 0.9621 - val_f1_score: 0.9720 - val_IoU: 0.9714\n",
      "Epoch 27/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0377 - accuracy: 1.0000 - recall: 0.9685 - precision: 0.9647 - f1_score: 0.9656 - IoU: 0.9489\n",
      "Epoch 27: val_f1_score did not improve from 0.97277\n",
      "42/42 [==============================] - 14s 325ms/step - loss: 0.0377 - accuracy: 1.0000 - recall: 0.9685 - precision: 0.9647 - f1_score: 0.9656 - IoU: 0.9489 - val_loss: 0.0795 - val_accuracy: 1.0000 - val_recall: 0.9306 - val_precision: 0.9906 - val_f1_score: 0.9573 - val_IoU: 0.9264\n",
      "Epoch 28/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0396 - accuracy: 1.0000 - recall: 0.9644 - precision: 0.9649 - f1_score: 0.9634 - IoU: 0.9465\n",
      "Epoch 28: val_f1_score improved from 0.97277 to 0.97811, saving model to UNet3Plus DICE 5-fold model/model_5fold.keras\n",
      "42/42 [==============================] - 14s 333ms/step - loss: 0.0396 - accuracy: 1.0000 - recall: 0.9644 - precision: 0.9649 - f1_score: 0.9634 - IoU: 0.9465 - val_loss: 0.0356 - val_accuracy: 1.0000 - val_recall: 0.9757 - val_precision: 0.9822 - val_f1_score: 0.9781 - val_IoU: 0.9549\n",
      "Epoch 29/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0375 - accuracy: 1.0000 - recall: 0.9689 - precision: 0.9655 - f1_score: 0.9656 - IoU: 0.9485\n",
      "Epoch 29: val_f1_score did not improve from 0.97811\n",
      "42/42 [==============================] - 14s 324ms/step - loss: 0.0375 - accuracy: 1.0000 - recall: 0.9689 - precision: 0.9655 - f1_score: 0.9656 - IoU: 0.9485 - val_loss: 0.0736 - val_accuracy: 1.0000 - val_recall: 0.9729 - val_precision: 0.9878 - val_f1_score: 0.9773 - val_IoU: 0.9531\n",
      "Epoch 30/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0333 - accuracy: 1.0000 - recall: 0.9694 - precision: 0.9701 - f1_score: 0.9693 - IoU: 0.9497\n",
      "Epoch 30: val_f1_score did not improve from 0.97811\n",
      "42/42 [==============================] - 14s 328ms/step - loss: 0.0333 - accuracy: 1.0000 - recall: 0.9694 - precision: 0.9701 - f1_score: 0.9693 - IoU: 0.9497 - val_loss: 0.0542 - val_accuracy: 1.0000 - val_recall: 0.9646 - val_precision: 0.9900 - val_f1_score: 0.9744 - val_IoU: 0.9477\n",
      "Epoch 31/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0325 - accuracy: 1.0000 - recall: 0.9720 - precision: 0.9682 - f1_score: 0.9697 - IoU: 0.9525\n",
      "Epoch 31: val_f1_score did not improve from 0.97811\n",
      "42/42 [==============================] - 14s 326ms/step - loss: 0.0325 - accuracy: 1.0000 - recall: 0.9720 - precision: 0.9682 - f1_score: 0.9697 - IoU: 0.9525 - val_loss: 0.0630 - val_accuracy: 1.0000 - val_recall: 0.9503 - val_precision: 0.9945 - val_f1_score: 0.9712 - val_IoU: 0.9412\n",
      "Epoch 32/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0349 - accuracy: 1.0000 - recall: 0.9625 - precision: 0.9715 - f1_score: 0.9672 - IoU: 0.9479\n",
      "Epoch 32: val_f1_score did not improve from 0.97811\n",
      "42/42 [==============================] - 14s 327ms/step - loss: 0.0349 - accuracy: 1.0000 - recall: 0.9625 - precision: 0.9715 - f1_score: 0.9672 - IoU: 0.9479 - val_loss: 0.1013 - val_accuracy: 0.9999 - val_recall: 0.9197 - val_precision: 0.9696 - val_f1_score: 0.9097 - val_IoU: 0.9314\n",
      "Epoch 33/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0406 - accuracy: 1.0000 - recall: 0.9651 - precision: 0.9599 - f1_score: 0.9614 - IoU: 0.9466\n",
      "Epoch 33: val_f1_score did not improve from 0.97811\n",
      "42/42 [==============================] - 14s 326ms/step - loss: 0.0406 - accuracy: 1.0000 - recall: 0.9651 - precision: 0.9599 - f1_score: 0.9614 - IoU: 0.9466 - val_loss: 0.0974 - val_accuracy: 1.0000 - val_recall: 0.9810 - val_precision: 0.9497 - val_f1_score: 0.9507 - val_IoU: 0.9563\n",
      "Epoch 34/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0365 - accuracy: 1.0000 - recall: 0.9638 - precision: 0.9693 - f1_score: 0.9655 - IoU: 0.9480\n",
      "Epoch 34: val_f1_score did not improve from 0.97811\n",
      "42/42 [==============================] - 14s 326ms/step - loss: 0.0365 - accuracy: 1.0000 - recall: 0.9638 - precision: 0.9693 - f1_score: 0.9655 - IoU: 0.9480 - val_loss: 0.0338 - val_accuracy: 1.0000 - val_recall: 0.9662 - val_precision: 0.9863 - val_f1_score: 0.9746 - val_IoU: 0.9543\n",
      "Epoch 35/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0332 - accuracy: 1.0000 - recall: 0.9691 - precision: 0.9678 - f1_score: 0.9686 - IoU: 0.9511\n",
      "Epoch 35: val_f1_score did not improve from 0.97811\n",
      "42/42 [==============================] - 14s 326ms/step - loss: 0.0332 - accuracy: 1.0000 - recall: 0.9691 - precision: 0.9678 - f1_score: 0.9686 - IoU: 0.9511 - val_loss: 0.0288 - val_accuracy: 1.0000 - val_recall: 0.9955 - val_precision: 0.9563 - val_f1_score: 0.9740 - val_IoU: 0.9790\n",
      "Epoch 36/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0344 - accuracy: 1.0000 - recall: 0.9717 - precision: 0.9657 - f1_score: 0.9675 - IoU: 0.9540\n",
      "Epoch 36: val_f1_score improved from 0.97811 to 0.98009, saving model to UNet3Plus DICE 5-fold model/model_5fold.keras\n",
      "42/42 [==============================] - 14s 332ms/step - loss: 0.0344 - accuracy: 1.0000 - recall: 0.9717 - precision: 0.9657 - f1_score: 0.9675 - IoU: 0.9540 - val_loss: 0.0298 - val_accuracy: 1.0000 - val_recall: 0.9728 - val_precision: 0.9897 - val_f1_score: 0.9801 - val_IoU: 0.9567\n",
      "Epoch 37/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0344 - accuracy: 1.0000 - recall: 0.9678 - precision: 0.9695 - f1_score: 0.9674 - IoU: 0.9512\n",
      "Epoch 37: val_f1_score did not improve from 0.98009\n",
      "42/42 [==============================] - 14s 327ms/step - loss: 0.0344 - accuracy: 1.0000 - recall: 0.9678 - precision: 0.9695 - f1_score: 0.9674 - IoU: 0.9512 - val_loss: 0.0317 - val_accuracy: 1.0000 - val_recall: 0.9563 - val_precision: 0.9855 - val_f1_score: 0.9706 - val_IoU: 0.9493\n",
      "Epoch 38/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0423 - accuracy: 0.9999 - recall: 0.9574 - precision: 0.9624 - f1_score: 0.9594 - IoU: 0.9461\n",
      "Epoch 38: val_f1_score did not improve from 0.98009\n",
      "42/42 [==============================] - 14s 327ms/step - loss: 0.0423 - accuracy: 0.9999 - recall: 0.9574 - precision: 0.9624 - f1_score: 0.9594 - IoU: 0.9461 - val_loss: 0.1081 - val_accuracy: 0.9999 - val_recall: 0.8921 - val_precision: 0.9680 - val_f1_score: 0.9003 - val_IoU: 0.9153\n",
      "Epoch 39/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0550 - accuracy: 0.9999 - recall: 0.9508 - precision: 0.9444 - f1_score: 0.9466 - IoU: 0.9394\n",
      "Epoch 39: val_f1_score did not improve from 0.98009\n",
      "42/42 [==============================] - 14s 327ms/step - loss: 0.0550 - accuracy: 0.9999 - recall: 0.9508 - precision: 0.9444 - f1_score: 0.9466 - IoU: 0.9394 - val_loss: 0.5961 - val_accuracy: 0.9996 - val_recall: 0.2835 - val_precision: 0.9910 - val_f1_score: 0.4286 - val_IoU: 0.6275\n",
      "Epoch 40/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0470 - accuracy: 0.9999 - recall: 0.9537 - precision: 0.9580 - f1_score: 0.9545 - IoU: 0.9449\n",
      "Epoch 40: val_f1_score did not improve from 0.98009\n",
      "42/42 [==============================] - 14s 327ms/step - loss: 0.0470 - accuracy: 0.9999 - recall: 0.9537 - precision: 0.9580 - f1_score: 0.9545 - IoU: 0.9449 - val_loss: 0.0938 - val_accuracy: 0.9999 - val_recall: 0.9463 - val_precision: 0.9537 - val_f1_score: 0.9267 - val_IoU: 0.9313\n",
      "Epoch 41/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0492 - accuracy: 0.9999 - recall: 0.9547 - precision: 0.9540 - f1_score: 0.9523 - IoU: 0.9432\n",
      "Epoch 41: val_f1_score did not improve from 0.98009\n",
      "42/42 [==============================] - 14s 331ms/step - loss: 0.0492 - accuracy: 0.9999 - recall: 0.9547 - precision: 0.9540 - f1_score: 0.9523 - IoU: 0.9432 - val_loss: 0.0671 - val_accuracy: 0.9999 - val_recall: 0.9244 - val_precision: 0.9899 - val_f1_score: 0.9428 - val_IoU: 0.9291\n",
      "Epoch 42/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0337 - accuracy: 1.0000 - recall: 0.9676 - precision: 0.9686 - f1_score: 0.9675 - IoU: 0.9521\n",
      "Epoch 42: val_f1_score did not improve from 0.98009\n",
      "42/42 [==============================] - 14s 330ms/step - loss: 0.0337 - accuracy: 1.0000 - recall: 0.9676 - precision: 0.9686 - f1_score: 0.9675 - IoU: 0.9521 - val_loss: 0.0294 - val_accuracy: 1.0000 - val_recall: 0.9745 - val_precision: 0.9836 - val_f1_score: 0.9720 - val_IoU: 0.9610\n",
      "Epoch 43/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0303 - accuracy: 1.0000 - recall: 0.9714 - precision: 0.9695 - f1_score: 0.9707 - IoU: 0.9550\n",
      "Epoch 43: val_f1_score did not improve from 0.98009\n",
      "42/42 [==============================] - 14s 333ms/step - loss: 0.0303 - accuracy: 1.0000 - recall: 0.9714 - precision: 0.9695 - f1_score: 0.9707 - IoU: 0.9550 - val_loss: 0.0276 - val_accuracy: 1.0000 - val_recall: 0.9654 - val_precision: 0.9912 - val_f1_score: 0.9753 - val_IoU: 0.9543\n",
      "Epoch 44/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0323 - accuracy: 1.0000 - recall: 0.9747 - precision: 0.9671 - f1_score: 0.9690 - IoU: 0.9571\n",
      "Epoch 44: val_f1_score did not improve from 0.98009\n",
      "42/42 [==============================] - 14s 333ms/step - loss: 0.0323 - accuracy: 1.0000 - recall: 0.9747 - precision: 0.9671 - f1_score: 0.9690 - IoU: 0.9571 - val_loss: 0.0274 - val_accuracy: 1.0000 - val_recall: 0.9730 - val_precision: 0.9846 - val_f1_score: 0.9742 - val_IoU: 0.9591\n",
      "Epoch 45/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0311 - accuracy: 1.0000 - recall: 0.9705 - precision: 0.9713 - f1_score: 0.9700 - IoU: 0.9549\n",
      "Epoch 45: val_f1_score did not improve from 0.98009\n",
      "42/42 [==============================] - 14s 332ms/step - loss: 0.0311 - accuracy: 1.0000 - recall: 0.9705 - precision: 0.9713 - f1_score: 0.9700 - IoU: 0.9549 - val_loss: 0.0273 - val_accuracy: 1.0000 - val_recall: 0.9638 - val_precision: 0.9924 - val_f1_score: 0.9749 - val_IoU: 0.9539\n",
      "Epoch 46/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0297 - accuracy: 1.0000 - recall: 0.9730 - precision: 0.9701 - f1_score: 0.9714 - IoU: 0.9557\n",
      "Epoch 46: val_f1_score did not improve from 0.98009\n",
      "42/42 [==============================] - 14s 332ms/step - loss: 0.0297 - accuracy: 1.0000 - recall: 0.9730 - precision: 0.9701 - f1_score: 0.9714 - IoU: 0.9557 - val_loss: 0.0229 - val_accuracy: 1.0000 - val_recall: 0.9813 - val_precision: 0.9791 - val_f1_score: 0.9785 - val_IoU: 0.9639\n",
      "Epoch 47/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0302 - accuracy: 1.0000 - recall: 0.9719 - precision: 0.9693 - f1_score: 0.9710 - IoU: 0.9569\n",
      "Epoch 47: val_f1_score did not improve from 0.98009\n",
      "42/42 [==============================] - 14s 331ms/step - loss: 0.0302 - accuracy: 1.0000 - recall: 0.9719 - precision: 0.9693 - f1_score: 0.9710 - IoU: 0.9569 - val_loss: 0.0217 - val_accuracy: 1.0000 - val_recall: 0.9907 - val_precision: 0.9701 - val_f1_score: 0.9793 - val_IoU: 0.9742\n",
      "Epoch 48/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0311 - accuracy: 1.0000 - recall: 0.9700 - precision: 0.9715 - f1_score: 0.9701 - IoU: 0.9561\n",
      "Epoch 48: val_f1_score did not improve from 0.98009\n",
      "42/42 [==============================] - 14s 332ms/step - loss: 0.0311 - accuracy: 1.0000 - recall: 0.9700 - precision: 0.9715 - f1_score: 0.9701 - IoU: 0.9561 - val_loss: 0.0224 - val_accuracy: 1.0000 - val_recall: 0.9749 - val_precision: 0.9873 - val_f1_score: 0.9796 - val_IoU: 0.9625\n",
      "Epoch 49/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0286 - accuracy: 1.0000 - recall: 0.9742 - precision: 0.9706 - f1_score: 0.9725 - IoU: 0.9574\n",
      "Epoch 49: val_f1_score improved from 0.98009 to 0.98132, saving model to UNet3Plus DICE 5-fold model/model_5fold.keras\n",
      "42/42 [==============================] - 14s 338ms/step - loss: 0.0286 - accuracy: 1.0000 - recall: 0.9742 - precision: 0.9706 - f1_score: 0.9725 - IoU: 0.9574 - val_loss: 0.0190 - val_accuracy: 1.0000 - val_recall: 0.9901 - val_precision: 0.9780 - val_f1_score: 0.9813 - val_IoU: 0.9752\n",
      "Epoch 50/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0285 - accuracy: 1.0000 - recall: 0.9742 - precision: 0.9709 - f1_score: 0.9726 - IoU: 0.9578\n",
      "Epoch 50: val_f1_score did not improve from 0.98132\n",
      "42/42 [==============================] - 14s 333ms/step - loss: 0.0285 - accuracy: 1.0000 - recall: 0.9742 - precision: 0.9709 - f1_score: 0.9726 - IoU: 0.9578 - val_loss: 0.0206 - val_accuracy: 1.0000 - val_recall: 0.9731 - val_precision: 0.9918 - val_f1_score: 0.9801 - val_IoU: 0.9605\n",
      "Epoch 51/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0302 - accuracy: 1.0000 - recall: 0.9713 - precision: 0.9711 - f1_score: 0.9707 - IoU: 0.9569\n",
      "Epoch 51: val_f1_score did not improve from 0.98132\n",
      "42/42 [==============================] - 14s 332ms/step - loss: 0.0302 - accuracy: 1.0000 - recall: 0.9713 - precision: 0.9711 - f1_score: 0.9707 - IoU: 0.9569 - val_loss: 0.0226 - val_accuracy: 1.0000 - val_recall: 0.9696 - val_precision: 0.9912 - val_f1_score: 0.9790 - val_IoU: 0.9604\n",
      "Epoch 52/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0299 - accuracy: 1.0000 - recall: 0.9743 - precision: 0.9695 - f1_score: 0.9711 - IoU: 0.9590\n",
      "Epoch 52: val_f1_score did not improve from 0.98132\n",
      "42/42 [==============================] - 14s 332ms/step - loss: 0.0299 - accuracy: 1.0000 - recall: 0.9743 - precision: 0.9695 - f1_score: 0.9711 - IoU: 0.9590 - val_loss: 0.0221 - val_accuracy: 1.0000 - val_recall: 0.9805 - val_precision: 0.9825 - val_f1_score: 0.9790 - val_IoU: 0.9671\n",
      "Epoch 53/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0275 - accuracy: 1.0000 - recall: 0.9777 - precision: 0.9702 - f1_score: 0.9736 - IoU: 0.9608\n",
      "Epoch 53: val_f1_score did not improve from 0.98132\n",
      "42/42 [==============================] - 14s 333ms/step - loss: 0.0275 - accuracy: 1.0000 - recall: 0.9777 - precision: 0.9702 - f1_score: 0.9736 - IoU: 0.9608 - val_loss: 0.0419 - val_accuracy: 1.0000 - val_recall: 0.9375 - val_precision: 0.9906 - val_f1_score: 0.9635 - val_IoU: 0.9297\n",
      "Epoch 54/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0301 - accuracy: 1.0000 - recall: 0.9764 - precision: 0.9697 - f1_score: 0.9707 - IoU: 0.9602\n",
      "Epoch 54: val_f1_score did not improve from 0.98132\n",
      "42/42 [==============================] - 14s 333ms/step - loss: 0.0301 - accuracy: 1.0000 - recall: 0.9764 - precision: 0.9697 - f1_score: 0.9707 - IoU: 0.9602 - val_loss: 0.0220 - val_accuracy: 1.0000 - val_recall: 0.9764 - val_precision: 0.9847 - val_f1_score: 0.9794 - val_IoU: 0.9625\n",
      "Epoch 55/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0295 - accuracy: 1.0000 - recall: 0.9729 - precision: 0.9712 - f1_score: 0.9714 - IoU: 0.9589\n",
      "Epoch 55: val_f1_score did not improve from 0.98132\n",
      "42/42 [==============================] - 14s 333ms/step - loss: 0.0295 - accuracy: 1.0000 - recall: 0.9729 - precision: 0.9712 - f1_score: 0.9714 - IoU: 0.9589 - val_loss: 0.0206 - val_accuracy: 1.0000 - val_recall: 0.9755 - val_precision: 0.9887 - val_f1_score: 0.9804 - val_IoU: 0.9636\n",
      "Epoch 56/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0285 - accuracy: 1.0000 - recall: 0.9733 - precision: 0.9725 - f1_score: 0.9723 - IoU: 0.9584\n",
      "Epoch 56: val_f1_score improved from 0.98132 to 0.98249, saving model to UNet3Plus DICE 5-fold model/model_5fold.keras\n",
      "42/42 [==============================] - 14s 339ms/step - loss: 0.0285 - accuracy: 1.0000 - recall: 0.9733 - precision: 0.9725 - f1_score: 0.9723 - IoU: 0.9584 - val_loss: 0.0184 - val_accuracy: 1.0000 - val_recall: 0.9808 - val_precision: 0.9881 - val_f1_score: 0.9825 - val_IoU: 0.9662\n",
      "Epoch 57/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0285 - accuracy: 1.0000 - recall: 0.9721 - precision: 0.9729 - f1_score: 0.9723 - IoU: 0.9593\n",
      "Epoch 57: val_f1_score did not improve from 0.98249\n",
      "42/42 [==============================] - 14s 332ms/step - loss: 0.0285 - accuracy: 1.0000 - recall: 0.9721 - precision: 0.9729 - f1_score: 0.9723 - IoU: 0.9593 - val_loss: 0.0247 - val_accuracy: 1.0000 - val_recall: 0.9970 - val_precision: 0.9587 - val_f1_score: 0.9757 - val_IoU: 0.9839\n",
      "Epoch 58/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0286 - accuracy: 1.0000 - recall: 0.9744 - precision: 0.9706 - f1_score: 0.9721 - IoU: 0.9605\n",
      "Epoch 58: val_f1_score did not improve from 0.98249\n",
      "42/42 [==============================] - 14s 332ms/step - loss: 0.0286 - accuracy: 1.0000 - recall: 0.9744 - precision: 0.9706 - f1_score: 0.9721 - IoU: 0.9605 - val_loss: 0.0260 - val_accuracy: 1.0000 - val_recall: 0.9983 - val_precision: 0.9540 - val_f1_score: 0.9743 - val_IoU: 0.9856\n",
      "Epoch 59/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0286 - accuracy: 1.0000 - recall: 0.9747 - precision: 0.9722 - f1_score: 0.9722 - IoU: 0.9605\n",
      "Epoch 59: val_f1_score improved from 0.98249 to 0.98262, saving model to UNet3Plus DICE 5-fold model/model_5fold.keras\n",
      "42/42 [==============================] - 14s 337ms/step - loss: 0.0286 - accuracy: 1.0000 - recall: 0.9747 - precision: 0.9722 - f1_score: 0.9722 - IoU: 0.9605 - val_loss: 0.0184 - val_accuracy: 1.0000 - val_recall: 0.9831 - val_precision: 0.9867 - val_f1_score: 0.9826 - val_IoU: 0.9694\n",
      "Epoch 60/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0355 - accuracy: 1.0000 - recall: 0.9636 - precision: 0.9701 - f1_score: 0.9651 - IoU: 0.9543\n",
      "Epoch 60: val_f1_score did not improve from 0.98262\n",
      "42/42 [==============================] - 14s 334ms/step - loss: 0.0355 - accuracy: 1.0000 - recall: 0.9636 - precision: 0.9701 - f1_score: 0.9651 - IoU: 0.9543 - val_loss: 0.0626 - val_accuracy: 0.9999 - val_recall: 0.8917 - val_precision: 0.9853 - val_f1_score: 0.9408 - val_IoU: 0.9232\n",
      "Epoch 61/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0391 - accuracy: 1.0000 - recall: 0.9617 - precision: 0.9624 - f1_score: 0.9616 - IoU: 0.9517\n",
      "Epoch 61: val_f1_score did not improve from 0.98262\n",
      "42/42 [==============================] - 14s 334ms/step - loss: 0.0391 - accuracy: 1.0000 - recall: 0.9617 - precision: 0.9624 - f1_score: 0.9616 - IoU: 0.9517 - val_loss: 0.0352 - val_accuracy: 1.0000 - val_recall: 0.9393 - val_precision: 0.9866 - val_f1_score: 0.9639 - val_IoU: 0.9435\n",
      "Epoch 62/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0331 - accuracy: 1.0000 - recall: 0.9727 - precision: 0.9650 - f1_score: 0.9677 - IoU: 0.9581\n",
      "Epoch 62: val_f1_score did not improve from 0.98262\n",
      "42/42 [==============================] - 14s 333ms/step - loss: 0.0331 - accuracy: 1.0000 - recall: 0.9727 - precision: 0.9650 - f1_score: 0.9677 - IoU: 0.9581 - val_loss: 0.0405 - val_accuracy: 1.0000 - val_recall: 0.9338 - val_precision: 0.9932 - val_f1_score: 0.9604 - val_IoU: 0.9402\n",
      "Epoch 63/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0325 - accuracy: 1.0000 - recall: 0.9696 - precision: 0.9682 - f1_score: 0.9680 - IoU: 0.9584\n",
      "Epoch 63: val_f1_score did not improve from 0.98262\n",
      "42/42 [==============================] - 14s 331ms/step - loss: 0.0325 - accuracy: 1.0000 - recall: 0.9696 - precision: 0.9682 - f1_score: 0.9680 - IoU: 0.9584 - val_loss: 0.0277 - val_accuracy: 1.0000 - val_recall: 0.9843 - val_precision: 0.9699 - val_f1_score: 0.9731 - val_IoU: 0.9719\n",
      "Epoch 64/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0299 - accuracy: 1.0000 - recall: 0.9756 - precision: 0.9696 - f1_score: 0.9709 - IoU: 0.9618\n",
      "Epoch 64: val_f1_score did not improve from 0.98262\n",
      "42/42 [==============================] - 14s 333ms/step - loss: 0.0299 - accuracy: 1.0000 - recall: 0.9756 - precision: 0.9696 - f1_score: 0.9709 - IoU: 0.9618 - val_loss: 0.0219 - val_accuracy: 1.0000 - val_recall: 0.9855 - val_precision: 0.9785 - val_f1_score: 0.9787 - val_IoU: 0.9726\n",
      "Epoch 65/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0322 - accuracy: 1.0000 - recall: 0.9696 - precision: 0.9723 - f1_score: 0.9683 - IoU: 0.9580\n",
      "Epoch 65: val_f1_score did not improve from 0.98262\n",
      "42/42 [==============================] - 14s 332ms/step - loss: 0.0322 - accuracy: 1.0000 - recall: 0.9696 - precision: 0.9723 - f1_score: 0.9683 - IoU: 0.9580 - val_loss: 0.0275 - val_accuracy: 1.0000 - val_recall: 0.9566 - val_precision: 0.9921 - val_f1_score: 0.9726 - val_IoU: 0.9541\n",
      "Epoch 66/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0288 - accuracy: 1.0000 - recall: 0.9723 - precision: 0.9724 - f1_score: 0.9718 - IoU: 0.9603\n",
      "Epoch 66: val_f1_score did not improve from 0.98262\n",
      "42/42 [==============================] - 14s 334ms/step - loss: 0.0288 - accuracy: 1.0000 - recall: 0.9723 - precision: 0.9724 - f1_score: 0.9718 - IoU: 0.9603 - val_loss: 0.0222 - val_accuracy: 1.0000 - val_recall: 0.9791 - val_precision: 0.9860 - val_f1_score: 0.9784 - val_IoU: 0.9686\n",
      "Epoch 67/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0269 - accuracy: 1.0000 - recall: 0.9754 - precision: 0.9714 - f1_score: 0.9738 - IoU: 0.9618\n",
      "Epoch 67: val_f1_score did not improve from 0.98262\n",
      "42/42 [==============================] - 14s 334ms/step - loss: 0.0269 - accuracy: 1.0000 - recall: 0.9754 - precision: 0.9714 - f1_score: 0.9738 - IoU: 0.9618 - val_loss: 0.0245 - val_accuracy: 1.0000 - val_recall: 0.9629 - val_precision: 0.9942 - val_f1_score: 0.9772 - val_IoU: 0.9569\n",
      "Epoch 68/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0252 - accuracy: 1.0000 - recall: 0.9768 - precision: 0.9733 - f1_score: 0.9754 - IoU: 0.9624\n",
      "Epoch 68: val_f1_score did not improve from 0.98262\n",
      "42/42 [==============================] - 14s 335ms/step - loss: 0.0252 - accuracy: 1.0000 - recall: 0.9768 - precision: 0.9733 - f1_score: 0.9754 - IoU: 0.9624 - val_loss: 0.0215 - val_accuracy: 1.0000 - val_recall: 0.9675 - val_precision: 0.9914 - val_f1_score: 0.9787 - val_IoU: 0.9609\n",
      "Epoch 69/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0272 - accuracy: 1.0000 - recall: 0.9756 - precision: 0.9723 - f1_score: 0.9733 - IoU: 0.9628\n",
      "Epoch 69: val_f1_score did not improve from 0.98262\n",
      "42/42 [==============================] - 14s 336ms/step - loss: 0.0272 - accuracy: 1.0000 - recall: 0.9756 - precision: 0.9723 - f1_score: 0.9733 - IoU: 0.9628 - val_loss: 0.0186 - val_accuracy: 1.0000 - val_recall: 0.9917 - val_precision: 0.9763 - val_f1_score: 0.9812 - val_IoU: 0.9786\n",
      "Epoch 70/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0323 - accuracy: 1.0000 - recall: 0.9727 - precision: 0.9668 - f1_score: 0.9682 - IoU: 0.9614\n",
      "Epoch 70: val_f1_score did not improve from 0.98262\n",
      "42/42 [==============================] - 14s 333ms/step - loss: 0.0323 - accuracy: 1.0000 - recall: 0.9727 - precision: 0.9668 - f1_score: 0.9682 - IoU: 0.9614 - val_loss: 0.0268 - val_accuracy: 1.0000 - val_recall: 0.9833 - val_precision: 0.9790 - val_f1_score: 0.9707 - val_IoU: 0.9705\n",
      "Epoch 71/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0263 - accuracy: 1.0000 - recall: 0.9761 - precision: 0.9723 - f1_score: 0.9742 - IoU: 0.9626\n",
      "Epoch 71: val_f1_score did not improve from 0.98262\n",
      "42/42 [==============================] - 14s 335ms/step - loss: 0.0263 - accuracy: 1.0000 - recall: 0.9761 - precision: 0.9723 - f1_score: 0.9742 - IoU: 0.9626 - val_loss: 0.0181 - val_accuracy: 1.0000 - val_recall: 0.9801 - val_precision: 0.9891 - val_f1_score: 0.9823 - val_IoU: 0.9687\n",
      "Epoch 72/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0270 - accuracy: 1.0000 - recall: 0.9753 - precision: 0.9723 - f1_score: 0.9736 - IoU: 0.9627\n",
      "Epoch 72: val_f1_score did not improve from 0.98262\n",
      "42/42 [==============================] - 14s 335ms/step - loss: 0.0270 - accuracy: 1.0000 - recall: 0.9753 - precision: 0.9723 - f1_score: 0.9736 - IoU: 0.9627 - val_loss: 0.0182 - val_accuracy: 1.0000 - val_recall: 0.9787 - val_precision: 0.9915 - val_f1_score: 0.9825 - val_IoU: 0.9677\n",
      "Epoch 73/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0249 - accuracy: 1.0000 - recall: 0.9785 - precision: 0.9727 - f1_score: 0.9756 - IoU: 0.9652\n",
      "Epoch 73: val_f1_score did not improve from 0.98262\n",
      "42/42 [==============================] - 14s 335ms/step - loss: 0.0249 - accuracy: 1.0000 - recall: 0.9785 - precision: 0.9727 - f1_score: 0.9756 - IoU: 0.9652 - val_loss: 0.0295 - val_accuracy: 1.0000 - val_recall: 0.9479 - val_precision: 0.9954 - val_f1_score: 0.9715 - val_IoU: 0.9507\n",
      "Epoch 74/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0266 - accuracy: 1.0000 - recall: 0.9770 - precision: 0.9721 - f1_score: 0.9740 - IoU: 0.9637\n",
      "Epoch 74: val_f1_score did not improve from 0.98262\n",
      "42/42 [==============================] - 14s 335ms/step - loss: 0.0266 - accuracy: 1.0000 - recall: 0.9770 - precision: 0.9721 - f1_score: 0.9740 - IoU: 0.9637 - val_loss: 0.0820 - val_accuracy: 0.9999 - val_recall: 0.8402 - val_precision: 0.9963 - val_f1_score: 0.9211 - val_IoU: 0.8681\n",
      "Epoch 75/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0287 - accuracy: 1.0000 - recall: 0.9725 - precision: 0.9725 - f1_score: 0.9718 - IoU: 0.9612\n",
      "Epoch 75: val_f1_score improved from 0.98262 to 0.98490, saving model to UNet3Plus DICE 5-fold model/model_5fold.keras\n",
      "42/42 [==============================] - 14s 340ms/step - loss: 0.0287 - accuracy: 1.0000 - recall: 0.9725 - precision: 0.9725 - f1_score: 0.9718 - IoU: 0.9612 - val_loss: 0.0159 - val_accuracy: 1.0000 - val_recall: 0.9883 - val_precision: 0.9852 - val_f1_score: 0.9849 - val_IoU: 0.9753\n",
      "Epoch 76/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0260 - accuracy: 1.0000 - recall: 0.9780 - precision: 0.9714 - f1_score: 0.9746 - IoU: 0.9649\n",
      "Epoch 76: val_f1_score did not improve from 0.98490\n",
      "42/42 [==============================] - 14s 334ms/step - loss: 0.0260 - accuracy: 1.0000 - recall: 0.9780 - precision: 0.9714 - f1_score: 0.9746 - IoU: 0.9649 - val_loss: 0.0310 - val_accuracy: 1.0000 - val_recall: 0.9437 - val_precision: 0.9957 - val_f1_score: 0.9705 - val_IoU: 0.9483\n",
      "Epoch 77/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0275 - accuracy: 1.0000 - recall: 0.9743 - precision: 0.9730 - f1_score: 0.9729 - IoU: 0.9634\n",
      "Epoch 77: val_f1_score did not improve from 0.98490\n",
      "42/42 [==============================] - 14s 336ms/step - loss: 0.0275 - accuracy: 1.0000 - recall: 0.9743 - precision: 0.9730 - f1_score: 0.9729 - IoU: 0.9634 - val_loss: 0.0183 - val_accuracy: 1.0000 - val_recall: 0.9808 - val_precision: 0.9879 - val_f1_score: 0.9818 - val_IoU: 0.9708\n",
      "Epoch 78/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0261 - accuracy: 1.0000 - recall: 0.9779 - precision: 0.9726 - f1_score: 0.9743 - IoU: 0.9649\n",
      "Epoch 78: val_f1_score did not improve from 0.98490\n",
      "42/42 [==============================] - 14s 337ms/step - loss: 0.0261 - accuracy: 1.0000 - recall: 0.9779 - precision: 0.9726 - f1_score: 0.9743 - IoU: 0.9649 - val_loss: 0.0182 - val_accuracy: 1.0000 - val_recall: 0.9800 - val_precision: 0.9881 - val_f1_score: 0.9823 - val_IoU: 0.9698\n",
      "Epoch 79/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0260 - accuracy: 1.0000 - recall: 0.9779 - precision: 0.9713 - f1_score: 0.9745 - IoU: 0.9655\n",
      "Epoch 79: val_f1_score did not improve from 0.98490\n",
      "42/42 [==============================] - 14s 337ms/step - loss: 0.0260 - accuracy: 1.0000 - recall: 0.9779 - precision: 0.9713 - f1_score: 0.9745 - IoU: 0.9655 - val_loss: 0.0184 - val_accuracy: 1.0000 - val_recall: 0.9862 - val_precision: 0.9815 - val_f1_score: 0.9822 - val_IoU: 0.9753\n",
      "Epoch 80/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0762 - accuracy: 0.9999 - recall: 0.9233 - precision: 0.9328 - f1_score: 0.9247 - IoU: 0.9288\n",
      "Epoch 80: val_f1_score did not improve from 0.98490\n",
      "42/42 [==============================] - 14s 336ms/step - loss: 0.0762 - accuracy: 0.9999 - recall: 0.9233 - precision: 0.9328 - f1_score: 0.9247 - IoU: 0.9288 - val_loss: 0.3634 - val_accuracy: 0.9996 - val_recall: 0.5357 - val_precision: 0.7682 - val_f1_score: 0.6524 - val_IoU: 0.7416\n",
      "Epoch 81/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0336 - accuracy: 1.0000 - recall: 0.9643 - precision: 0.9695 - f1_score: 0.9668 - IoU: 0.9571\n",
      "Epoch 81: val_f1_score did not improve from 0.98490\n",
      "42/42 [==============================] - 14s 337ms/step - loss: 0.0336 - accuracy: 1.0000 - recall: 0.9643 - precision: 0.9695 - f1_score: 0.9668 - IoU: 0.9571 - val_loss: 0.0862 - val_accuracy: 0.9999 - val_recall: 0.9069 - val_precision: 0.9062 - val_f1_score: 0.9156 - val_IoU: 0.9293\n",
      "Epoch 82/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0309 - accuracy: 1.0000 - recall: 0.9731 - precision: 0.9673 - f1_score: 0.9695 - IoU: 0.9606\n",
      "Epoch 82: val_f1_score did not improve from 0.98490\n",
      "42/42 [==============================] - 14s 338ms/step - loss: 0.0309 - accuracy: 1.0000 - recall: 0.9731 - precision: 0.9673 - f1_score: 0.9695 - IoU: 0.9606 - val_loss: 0.0500 - val_accuracy: 1.0000 - val_recall: 0.9810 - val_precision: 0.9421 - val_f1_score: 0.9513 - val_IoU: 0.9672\n",
      "Epoch 83/150\n",
      "20/42 [=============>................] - ETA: 7s - loss: 0.0247 - accuracy: 1.0000 - recall: 0.9716 - precision: 0.9804 - f1_score: 0.9757 - IoU: 0.9648"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 05:40:48.248365: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:306] gpu_async_0 cuMemAllocAsync failed to allocate 1074861327 bytes: CUDA error: out of memory (CUDA_ERROR_OUT_OF_MEMORY)\n",
      " Reported by CUDA: Free memory/Total memory: 631242752/12878086144\n",
      "2025-03-22 05:40:48.248405: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:311] Stats: Limit:                     10022289408\n",
      "InUse:                      7197959241\n",
      "MaxInUse:                  11038268409\n",
      "NumAllocs:                     6241688\n",
      "MaxAllocSize:               6845546512\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2025-03-22 05:40:48.248464: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:63] Histogram of current allocation: (allocation_size_in_bytes, nb_allocation_of_that_sizes), ...;\n",
      "2025-03-22 05:40:48.248468: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1, 45\n",
      "2025-03-22 05:40:48.248470: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 4, 2721\n",
      "2025-03-22 05:40:48.248472: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 8, 17\n",
      "2025-03-22 05:40:48.248473: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 12, 1\n",
      "2025-03-22 05:40:48.248475: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 16, 4\n",
      "2025-03-22 05:40:48.248476: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 64, 65\n",
      "2025-03-22 05:40:48.248477: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 128, 66\n",
      "2025-03-22 05:40:48.248479: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 256, 66\n",
      "2025-03-22 05:40:48.248480: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 512, 66\n",
      "2025-03-22 05:40:48.248481: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 576, 6\n",
      "2025-03-22 05:40:48.248483: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1024, 36\n",
      "2025-03-22 05:40:48.248484: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1028, 1\n",
      "2025-03-22 05:40:48.248486: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 9216, 12\n",
      "2025-03-22 05:40:48.248487: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 16384, 6\n",
      "2025-03-22 05:40:48.248489: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 18432, 6\n",
      "2025-03-22 05:40:48.248490: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 27648, 8\n",
      "2025-03-22 05:40:48.248491: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 36864, 12\n",
      "2025-03-22 05:40:48.248493: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 65536, 6\n",
      "2025-03-22 05:40:48.248494: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 73728, 6\n",
      "2025-03-22 05:40:48.248502: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 110592, 6\n",
      "2025-03-22 05:40:48.248505: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 147456, 12\n",
      "2025-03-22 05:40:48.248506: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 262144, 6\n",
      "2025-03-22 05:40:48.248508: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 294912, 6\n",
      "2025-03-22 05:40:48.248509: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 442368, 6\n",
      "2025-03-22 05:40:48.248511: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 589824, 12\n",
      "2025-03-22 05:40:48.248512: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1048576, 6\n",
      "2025-03-22 05:40:48.248514: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1179648, 6\n",
      "2025-03-22 05:40:48.248515: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1769472, 6\n",
      "2025-03-22 05:40:48.248516: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 2359296, 6\n",
      "2025-03-22 05:40:48.248518: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 4194304, 3\n",
      "2025-03-22 05:40:48.248519: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 8388608, 3\n",
      "2025-03-22 05:40:48.248521: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 16777216, 10\n",
      "2025-03-22 05:40:48.248522: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 33554432, 13\n",
      "2025-03-22 05:40:48.248523: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 43778048, 1\n",
      "2025-03-22 05:40:48.248525: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 67108864, 10\n",
      "2025-03-22 05:40:48.248526: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 100663296, 1\n",
      "2025-03-22 05:40:48.248528: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 134217728, 8\n",
      "2025-03-22 05:40:48.248529: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 175112192, 1\n",
      "2025-03-22 05:40:48.248530: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 175898624, 1\n",
      "2025-03-22 05:40:48.248531: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 201326592, 1\n",
      "2025-03-22 05:40:48.248533: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 268435456, 5\n",
      "2025-03-22 05:40:48.248534: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 402653184, 1\n",
      "2025-03-22 05:40:48.248535: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 703594496, 1\n",
      "2025-03-22 05:40:48.248537: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 805306368, 2\n",
      "2025-03-22 05:40:48.248541: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:97] CU_MEMPOOL_ATTR_RESERVED_MEM_CURRENT: 10972299264\n",
      "2025-03-22 05:40:48.248543: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:99] CU_MEMPOOL_ATTR_USED_MEM_CURRENT: 7197959241\n",
      "2025-03-22 05:40:48.248545: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:100] CU_MEMPOOL_ATTR_RESERVED_MEM_HIGH: 12046041088\n",
      "2025-03-22 05:40:48.248547: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:101] CU_MEMPOOL_ATTR_USED_MEM_HIGH: 11038268409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - ETA: 0s - loss: 0.0284 - accuracy: 1.0000 - recall: 0.9724 - precision: 0.9718 - f1_score: 0.9720 - IoU: 0.9614\n",
      "Epoch 83: val_f1_score did not improve from 0.98490\n",
      "42/42 [==============================] - 15s 361ms/step - loss: 0.0284 - accuracy: 1.0000 - recall: 0.9724 - precision: 0.9718 - f1_score: 0.9720 - IoU: 0.9614 - val_loss: 0.0278 - val_accuracy: 1.0000 - val_recall: 0.9773 - val_precision: 0.9802 - val_f1_score: 0.9732 - val_IoU: 0.9671\n",
      "Epoch 84/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0288 - accuracy: 1.0000 - recall: 0.9753 - precision: 0.9695 - f1_score: 0.9716 - IoU: 0.9629\n",
      "Epoch 84: val_f1_score did not improve from 0.98490\n",
      "42/42 [==============================] - 15s 367ms/step - loss: 0.0288 - accuracy: 1.0000 - recall: 0.9753 - precision: 0.9695 - f1_score: 0.9716 - IoU: 0.9629 - val_loss: 0.0304 - val_accuracy: 1.0000 - val_recall: 0.9549 - val_precision: 0.9893 - val_f1_score: 0.9712 - val_IoU: 0.9536\n",
      "Epoch 85/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0295 - accuracy: 1.0000 - recall: 0.9728 - precision: 0.9710 - f1_score: 0.9709 - IoU: 0.9621\n",
      "Epoch 85: val_f1_score did not improve from 0.98490\n",
      "42/42 [==============================] - 15s 366ms/step - loss: 0.0295 - accuracy: 1.0000 - recall: 0.9728 - precision: 0.9710 - f1_score: 0.9709 - IoU: 0.9621 - val_loss: 0.0235 - val_accuracy: 1.0000 - val_recall: 0.9698 - val_precision: 0.9895 - val_f1_score: 0.9779 - val_IoU: 0.9633\n",
      "Epoch 86/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0272 - accuracy: 1.0000 - recall: 0.9761 - precision: 0.9727 - f1_score: 0.9733 - IoU: 0.9639\n",
      "Epoch 86: val_f1_score did not improve from 0.98490\n",
      "42/42 [==============================] - 15s 358ms/step - loss: 0.0272 - accuracy: 1.0000 - recall: 0.9761 - precision: 0.9727 - f1_score: 0.9733 - IoU: 0.9639 - val_loss: 0.0194 - val_accuracy: 1.0000 - val_recall: 0.9754 - val_precision: 0.9908 - val_f1_score: 0.9816 - val_IoU: 0.9662\n",
      "Epoch 87/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0257 - accuracy: 1.0000 - recall: 0.9732 - precision: 0.9742 - f1_score: 0.9748 - IoU: 0.9625\n",
      "Epoch 87: val_f1_score did not improve from 0.98490\n",
      "42/42 [==============================] - 15s 347ms/step - loss: 0.0257 - accuracy: 1.0000 - recall: 0.9732 - precision: 0.9742 - f1_score: 0.9748 - IoU: 0.9625 - val_loss: 0.0179 - val_accuracy: 1.0000 - val_recall: 0.9803 - val_precision: 0.9883 - val_f1_score: 0.9823 - val_IoU: 0.9691\n",
      "Epoch 88/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0267 - accuracy: 1.0000 - recall: 0.9788 - precision: 0.9712 - f1_score: 0.9737 - IoU: 0.9658\n",
      "Epoch 88: val_f1_score did not improve from 0.98490\n",
      "42/42 [==============================] - 15s 370ms/step - loss: 0.0267 - accuracy: 1.0000 - recall: 0.9788 - precision: 0.9712 - f1_score: 0.9737 - IoU: 0.9658 - val_loss: 0.0212 - val_accuracy: 1.0000 - val_recall: 0.9793 - val_precision: 0.9876 - val_f1_score: 0.9798 - val_IoU: 0.9691\n",
      "Epoch 89/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0248 - accuracy: 1.0000 - recall: 0.9778 - precision: 0.9724 - f1_score: 0.9755 - IoU: 0.9655\n",
      "Epoch 89: val_f1_score did not improve from 0.98490\n",
      "42/42 [==============================] - 15s 354ms/step - loss: 0.0248 - accuracy: 1.0000 - recall: 0.9778 - precision: 0.9724 - f1_score: 0.9755 - IoU: 0.9655 - val_loss: 0.0185 - val_accuracy: 1.0000 - val_recall: 0.9761 - val_precision: 0.9915 - val_f1_score: 0.9825 - val_IoU: 0.9673\n",
      "Epoch 90/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0278 - accuracy: 1.0000 - recall: 0.9751 - precision: 0.9733 - f1_score: 0.9727 - IoU: 0.9639\n",
      "Epoch 90: val_f1_score did not improve from 0.98490\n",
      "42/42 [==============================] - 14s 340ms/step - loss: 0.0278 - accuracy: 1.0000 - recall: 0.9751 - precision: 0.9733 - f1_score: 0.9727 - IoU: 0.9639 - val_loss: 0.0250 - val_accuracy: 1.0000 - val_recall: 0.9578 - val_precision: 0.9953 - val_f1_score: 0.9753 - val_IoU: 0.9577\n",
      "Epoch 91/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0273 - accuracy: 1.0000 - recall: 0.9744 - precision: 0.9745 - f1_score: 0.9731 - IoU: 0.9639\n",
      "Epoch 91: val_f1_score did not improve from 0.98490\n",
      "42/42 [==============================] - 15s 350ms/step - loss: 0.0273 - accuracy: 1.0000 - recall: 0.9744 - precision: 0.9745 - f1_score: 0.9731 - IoU: 0.9639 - val_loss: 0.0188 - val_accuracy: 1.0000 - val_recall: 0.9758 - val_precision: 0.9916 - val_f1_score: 0.9819 - val_IoU: 0.9679\n",
      "Epoch 92/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0249 - accuracy: 1.0000 - recall: 0.9769 - precision: 0.9741 - f1_score: 0.9755 - IoU: 0.9651\n",
      "Epoch 92: val_f1_score did not improve from 0.98490\n",
      "42/42 [==============================] - 15s 350ms/step - loss: 0.0249 - accuracy: 1.0000 - recall: 0.9769 - precision: 0.9741 - f1_score: 0.9755 - IoU: 0.9651 - val_loss: 0.0296 - val_accuracy: 1.0000 - val_recall: 0.9489 - val_precision: 0.9963 - val_f1_score: 0.9716 - val_IoU: 0.9535\n",
      "Epoch 93/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0242 - accuracy: 1.0000 - recall: 0.9798 - precision: 0.9728 - f1_score: 0.9762 - IoU: 0.9669\n",
      "Epoch 93: val_f1_score did not improve from 0.98490\n",
      "42/42 [==============================] - 14s 345ms/step - loss: 0.0242 - accuracy: 1.0000 - recall: 0.9798 - precision: 0.9728 - f1_score: 0.9762 - IoU: 0.9669 - val_loss: 0.0247 - val_accuracy: 1.0000 - val_recall: 0.9594 - val_precision: 0.9960 - val_f1_score: 0.9766 - val_IoU: 0.9581\n",
      "Epoch 94/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0277 - accuracy: 1.0000 - recall: 0.9761 - precision: 0.9723 - f1_score: 0.9726 - IoU: 0.9651\n",
      "Epoch 94: val_f1_score did not improve from 0.98490\n",
      "42/42 [==============================] - 14s 337ms/step - loss: 0.0277 - accuracy: 1.0000 - recall: 0.9761 - precision: 0.9723 - f1_score: 0.9726 - IoU: 0.9651 - val_loss: 0.0229 - val_accuracy: 1.0000 - val_recall: 0.9609 - val_precision: 0.9948 - val_f1_score: 0.9783 - val_IoU: 0.9590\n",
      "Epoch 95/150\n",
      "38/42 [==========================>...] - ETA: 1s - loss: 0.0256 - accuracy: 1.0000 - recall: 0.9763 - precision: 0.9732 - f1_score: 0.9747 - IoU: 0.9654"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 05:43:52.333775: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:306] gpu_async_0 cuMemAllocAsync failed to allocate 1074861327 bytes: CUDA error: out of memory (CUDA_ERROR_OUT_OF_MEMORY)\n",
      " Reported by CUDA: Free memory/Total memory: 631242752/12878086144\n",
      "2025-03-22 05:43:52.333815: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:311] Stats: Limit:                     10022289408\n",
      "InUse:                      7197959753\n",
      "MaxInUse:                  11038268409\n",
      "NumAllocs:                     6572544\n",
      "MaxAllocSize:               6845546512\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2025-03-22 05:43:52.333878: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:63] Histogram of current allocation: (allocation_size_in_bytes, nb_allocation_of_that_sizes), ...;\n",
      "2025-03-22 05:43:52.333882: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1, 45\n",
      "2025-03-22 05:43:52.333884: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 4, 2849\n",
      "2025-03-22 05:43:52.333886: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 8, 17\n",
      "2025-03-22 05:43:52.333887: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 12, 1\n",
      "2025-03-22 05:43:52.333889: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 16, 4\n",
      "2025-03-22 05:43:52.333890: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 64, 65\n",
      "2025-03-22 05:43:52.333892: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 128, 66\n",
      "2025-03-22 05:43:52.333893: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 256, 66\n",
      "2025-03-22 05:43:52.333894: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 512, 66\n",
      "2025-03-22 05:43:52.333896: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 576, 6\n",
      "2025-03-22 05:43:52.333897: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1024, 36\n",
      "2025-03-22 05:43:52.333898: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1028, 1\n",
      "2025-03-22 05:43:52.333900: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 9216, 12\n",
      "2025-03-22 05:43:52.333901: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 16384, 6\n",
      "2025-03-22 05:43:52.333903: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 18432, 6\n",
      "2025-03-22 05:43:52.333904: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 27648, 8\n",
      "2025-03-22 05:43:52.333905: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 36864, 12\n",
      "2025-03-22 05:43:52.333906: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 65536, 6\n",
      "2025-03-22 05:43:52.333908: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 73728, 6\n",
      "2025-03-22 05:43:52.333909: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 110592, 6\n",
      "2025-03-22 05:43:52.333911: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 147456, 12\n",
      "2025-03-22 05:43:52.333912: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 262144, 6\n",
      "2025-03-22 05:43:52.333913: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 294912, 6\n",
      "2025-03-22 05:43:52.333915: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 442368, 6\n",
      "2025-03-22 05:43:52.333916: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 589824, 12\n",
      "2025-03-22 05:43:52.333917: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1048576, 6\n",
      "2025-03-22 05:43:52.333919: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1179648, 6\n",
      "2025-03-22 05:43:52.333920: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1769472, 6\n",
      "2025-03-22 05:43:52.333921: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 2359296, 6\n",
      "2025-03-22 05:43:52.333923: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 4194304, 3\n",
      "2025-03-22 05:43:52.333924: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 8388608, 3\n",
      "2025-03-22 05:43:52.333926: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 16777216, 10\n",
      "2025-03-22 05:43:52.333927: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 33554432, 13\n",
      "2025-03-22 05:43:52.333928: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 43778048, 1\n",
      "2025-03-22 05:43:52.333930: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 67108864, 10\n",
      "2025-03-22 05:43:52.333931: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 100663296, 1\n",
      "2025-03-22 05:43:52.333932: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 134217728, 8\n",
      "2025-03-22 05:43:52.333934: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 175112192, 1\n",
      "2025-03-22 05:43:52.333935: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 175898624, 1\n",
      "2025-03-22 05:43:52.333936: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 201326592, 1\n",
      "2025-03-22 05:43:52.333938: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 268435456, 5\n",
      "2025-03-22 05:43:52.333939: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 402653184, 1\n",
      "2025-03-22 05:43:52.333940: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 703594496, 1\n",
      "2025-03-22 05:43:52.333942: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 805306368, 2\n",
      "2025-03-22 05:43:52.333945: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:97] CU_MEMPOOL_ATTR_RESERVED_MEM_CURRENT: 10972299264\n",
      "2025-03-22 05:43:52.333947: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:99] CU_MEMPOOL_ATTR_USED_MEM_CURRENT: 7197959753\n",
      "2025-03-22 05:43:52.333949: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:100] CU_MEMPOOL_ATTR_RESERVED_MEM_HIGH: 12180258816\n",
      "2025-03-22 05:43:52.333950: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:101] CU_MEMPOOL_ATTR_USED_MEM_HIGH: 11038268409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - ETA: 0s - loss: 0.0249 - accuracy: 1.0000 - recall: 0.9764 - precision: 0.9749 - f1_score: 0.9754 - IoU: 0.9657\n",
      "Epoch 95: val_f1_score did not improve from 0.98490\n",
      "42/42 [==============================] - 14s 342ms/step - loss: 0.0249 - accuracy: 1.0000 - recall: 0.9764 - precision: 0.9749 - f1_score: 0.9754 - IoU: 0.9657 - val_loss: 0.0201 - val_accuracy: 1.0000 - val_recall: 0.9731 - val_precision: 0.9893 - val_f1_score: 0.9803 - val_IoU: 0.9652\n",
      "Epoch 96/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0249 - accuracy: 1.0000 - recall: 0.9777 - precision: 0.9744 - f1_score: 0.9754 - IoU: 0.9664\n",
      "Epoch 96: val_f1_score did not improve from 0.98490\n",
      "42/42 [==============================] - 16s 383ms/step - loss: 0.0249 - accuracy: 1.0000 - recall: 0.9777 - precision: 0.9744 - f1_score: 0.9754 - IoU: 0.9664 - val_loss: 0.0166 - val_accuracy: 1.0000 - val_recall: 0.9857 - val_precision: 0.9853 - val_f1_score: 0.9838 - val_IoU: 0.9746\n",
      "Epoch 97/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0243 - accuracy: 1.0000 - recall: 0.9777 - precision: 0.9750 - f1_score: 0.9760 - IoU: 0.9667\n",
      "Epoch 97: val_f1_score did not improve from 0.98490\n",
      "42/42 [==============================] - 15s 367ms/step - loss: 0.0243 - accuracy: 1.0000 - recall: 0.9777 - precision: 0.9750 - f1_score: 0.9760 - IoU: 0.9667 - val_loss: 0.0160 - val_accuracy: 1.0000 - val_recall: 0.9941 - val_precision: 0.9783 - val_f1_score: 0.9840 - val_IoU: 0.9830\n",
      "Epoch 98/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0250 - accuracy: 1.0000 - recall: 0.9796 - precision: 0.9736 - f1_score: 0.9754 - IoU: 0.9677\n",
      "Epoch 98: val_f1_score did not improve from 0.98490\n",
      "42/42 [==============================] - 14s 337ms/step - loss: 0.0250 - accuracy: 1.0000 - recall: 0.9796 - precision: 0.9736 - f1_score: 0.9754 - IoU: 0.9677 - val_loss: 0.0192 - val_accuracy: 1.0000 - val_recall: 0.9782 - val_precision: 0.9910 - val_f1_score: 0.9824 - val_IoU: 0.9702\n",
      "Epoch 99/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0243 - accuracy: 1.0000 - recall: 0.9787 - precision: 0.9736 - f1_score: 0.9760 - IoU: 0.9674\n",
      "Epoch 99: val_f1_score did not improve from 0.98490\n",
      "42/42 [==============================] - 14s 334ms/step - loss: 0.0243 - accuracy: 1.0000 - recall: 0.9787 - precision: 0.9736 - f1_score: 0.9760 - IoU: 0.9674 - val_loss: 0.0252 - val_accuracy: 1.0000 - val_recall: 0.9621 - val_precision: 0.9924 - val_f1_score: 0.9757 - val_IoU: 0.9603\n",
      "Epoch 100/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0316 - accuracy: 1.0000 - recall: 0.9726 - precision: 0.9671 - f1_score: 0.9687 - IoU: 0.9619\n",
      "Epoch 100: val_f1_score did not improve from 0.98490\n",
      "42/42 [==============================] - 15s 366ms/step - loss: 0.0316 - accuracy: 1.0000 - recall: 0.9726 - precision: 0.9671 - f1_score: 0.9687 - IoU: 0.9619 - val_loss: 0.0334 - val_accuracy: 1.0000 - val_recall: 0.9921 - val_precision: 0.9536 - val_f1_score: 0.9618 - val_IoU: 0.9734\n",
      "Epoch 101/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0314 - accuracy: 1.0000 - recall: 0.9686 - precision: 0.9685 - f1_score: 0.9689 - IoU: 0.9601\n",
      "Epoch 101: val_f1_score did not improve from 0.98490\n",
      "42/42 [==============================] - 19s 464ms/step - loss: 0.0314 - accuracy: 1.0000 - recall: 0.9686 - precision: 0.9685 - f1_score: 0.9689 - IoU: 0.9601 - val_loss: 0.1045 - val_accuracy: 0.9999 - val_recall: 0.9916 - val_precision: 0.8909 - val_f1_score: 0.8952 - val_IoU: 0.9454\n",
      "Epoch 102/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0272 - accuracy: 1.0000 - recall: 0.9756 - precision: 0.9718 - f1_score: 0.9732 - IoU: 0.9654\n",
      "Epoch 102: val_f1_score did not improve from 0.98490\n",
      "42/42 [==============================] - 14s 341ms/step - loss: 0.0272 - accuracy: 1.0000 - recall: 0.9756 - precision: 0.9718 - f1_score: 0.9732 - IoU: 0.9654 - val_loss: 0.0346 - val_accuracy: 1.0000 - val_recall: 0.9920 - val_precision: 0.9634 - val_f1_score: 0.9666 - val_IoU: 0.9759\n",
      "Epoch 103/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0283 - accuracy: 1.0000 - recall: 0.9744 - precision: 0.9720 - f1_score: 0.9719 - IoU: 0.9646\n",
      "Epoch 103: val_f1_score did not improve from 0.98490\n",
      "42/42 [==============================] - 14s 335ms/step - loss: 0.0283 - accuracy: 1.0000 - recall: 0.9744 - precision: 0.9720 - f1_score: 0.9719 - IoU: 0.9646 - val_loss: 0.0324 - val_accuracy: 1.0000 - val_recall: 0.9914 - val_precision: 0.9661 - val_f1_score: 0.9685 - val_IoU: 0.9753\n",
      "Epoch 104/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0252 - accuracy: 1.0000 - recall: 0.9775 - precision: 0.9721 - f1_score: 0.9750 - IoU: 0.9668\n",
      "Epoch 104: val_f1_score did not improve from 0.98490\n",
      "42/42 [==============================] - 15s 358ms/step - loss: 0.0252 - accuracy: 1.0000 - recall: 0.9775 - precision: 0.9721 - f1_score: 0.9750 - IoU: 0.9668 - val_loss: 0.0175 - val_accuracy: 1.0000 - val_recall: 0.9820 - val_precision: 0.9855 - val_f1_score: 0.9830 - val_IoU: 0.9724\n",
      "Epoch 105/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0284 - accuracy: 1.0000 - recall: 0.9777 - precision: 0.9688 - f1_score: 0.9719 - IoU: 0.9663\n",
      "Epoch 105: val_f1_score did not improve from 0.98490\n",
      "42/42 [==============================] - 16s 384ms/step - loss: 0.0284 - accuracy: 1.0000 - recall: 0.9777 - precision: 0.9688 - f1_score: 0.9719 - IoU: 0.9663 - val_loss: 0.0213 - val_accuracy: 1.0000 - val_recall: 0.9954 - val_precision: 0.9651 - val_f1_score: 0.9783 - val_IoU: 0.9836\n",
      "Epoch 106/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0257 - accuracy: 1.0000 - recall: 0.9779 - precision: 0.9744 - f1_score: 0.9746 - IoU: 0.9672\n",
      "Epoch 106: val_f1_score did not improve from 0.98490\n",
      "42/42 [==============================] - 18s 425ms/step - loss: 0.0257 - accuracy: 1.0000 - recall: 0.9779 - precision: 0.9744 - f1_score: 0.9746 - IoU: 0.9672 - val_loss: 0.0198 - val_accuracy: 1.0000 - val_recall: 0.9712 - val_precision: 0.9905 - val_f1_score: 0.9801 - val_IoU: 0.9660\n",
      "Epoch 107/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0252 - accuracy: 1.0000 - recall: 0.9759 - precision: 0.9755 - f1_score: 0.9751 - IoU: 0.9661\n",
      "Epoch 107: val_f1_score did not improve from 0.98490\n",
      "42/42 [==============================] - 19s 446ms/step - loss: 0.0252 - accuracy: 1.0000 - recall: 0.9759 - precision: 0.9755 - f1_score: 0.9751 - IoU: 0.9661 - val_loss: 0.0499 - val_accuracy: 1.0000 - val_recall: 0.9913 - val_precision: 0.9428 - val_f1_score: 0.9516 - val_IoU: 0.9656\n",
      "Epoch 108/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0244 - accuracy: 1.0000 - recall: 0.9772 - precision: 0.9744 - f1_score: 0.9759 - IoU: 0.9669\n",
      "Epoch 108: val_f1_score did not improve from 0.98490\n",
      "42/42 [==============================] - 17s 401ms/step - loss: 0.0244 - accuracy: 1.0000 - recall: 0.9772 - precision: 0.9744 - f1_score: 0.9759 - IoU: 0.9669 - val_loss: 0.0239 - val_accuracy: 1.0000 - val_recall: 0.9599 - val_precision: 0.9956 - val_f1_score: 0.9767 - val_IoU: 0.9600\n",
      "Epoch 109/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0241 - accuracy: 1.0000 - recall: 0.9770 - precision: 0.9756 - f1_score: 0.9762 - IoU: 0.9666\n",
      "Epoch 109: val_f1_score did not improve from 0.98490\n",
      "42/42 [==============================] - 18s 417ms/step - loss: 0.0241 - accuracy: 1.0000 - recall: 0.9770 - precision: 0.9756 - f1_score: 0.9762 - IoU: 0.9666 - val_loss: 0.0164 - val_accuracy: 1.0000 - val_recall: 0.9869 - val_precision: 0.9861 - val_f1_score: 0.9840 - val_IoU: 0.9772\n",
      "Epoch 110/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0240 - accuracy: 1.0000 - recall: 0.9778 - precision: 0.9748 - f1_score: 0.9762 - IoU: 0.9667\n",
      "Epoch 110: val_f1_score did not improve from 0.98490\n",
      "42/42 [==============================] - 15s 359ms/step - loss: 0.0240 - accuracy: 1.0000 - recall: 0.9778 - precision: 0.9748 - f1_score: 0.9762 - IoU: 0.9667 - val_loss: 0.0306 - val_accuracy: 1.0000 - val_recall: 0.9479 - val_precision: 0.9959 - val_f1_score: 0.9693 - val_IoU: 0.9543\n",
      "Epoch 111/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 1.0000 - recall: 0.9800 - precision: 0.9748 - f1_score: 0.9767 - IoU: 0.9690\n",
      "Epoch 111: val_f1_score did not improve from 0.98490\n",
      "42/42 [==============================] - 15s 352ms/step - loss: 0.0236 - accuracy: 1.0000 - recall: 0.9800 - precision: 0.9748 - f1_score: 0.9767 - IoU: 0.9690 - val_loss: 0.0202 - val_accuracy: 1.0000 - val_recall: 0.9715 - val_precision: 0.9945 - val_f1_score: 0.9810 - val_IoU: 0.9672\n",
      "Epoch 112/150\n",
      " 2/42 [>.............................] - ETA: 12s - loss: 0.0219 - accuracy: 1.0000 - recall: 0.9715 - precision: 0.9860 - f1_score: 0.9784 - IoU: 0.9681"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 05:48:09.648789: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:306] gpu_async_0 cuMemAllocAsync failed to allocate 1074861327 bytes: CUDA error: out of memory (CUDA_ERROR_OUT_OF_MEMORY)\n",
      " Reported by CUDA: Free memory/Total memory: 396361728/12878086144\n",
      "2025-03-22 05:48:09.648829: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:311] Stats: Limit:                     10022289408\n",
      "InUse:                      7197960461\n",
      "MaxInUse:                  11038268409\n",
      "NumAllocs:                     7005758\n",
      "MaxAllocSize:               6845546512\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2025-03-22 05:48:09.648886: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:63] Histogram of current allocation: (allocation_size_in_bytes, nb_allocation_of_that_sizes), ...;\n",
      "2025-03-22 05:48:09.648889: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1, 45\n",
      "2025-03-22 05:48:09.648891: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 4, 3026\n",
      "2025-03-22 05:48:09.648893: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 8, 17\n",
      "2025-03-22 05:48:09.648894: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 12, 1\n",
      "2025-03-22 05:48:09.648896: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 16, 4\n",
      "2025-03-22 05:48:09.648897: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 64, 65\n",
      "2025-03-22 05:48:09.648898: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 128, 66\n",
      "2025-03-22 05:48:09.648900: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 256, 66\n",
      "2025-03-22 05:48:09.648901: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 512, 66\n",
      "2025-03-22 05:48:09.648902: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 576, 6\n",
      "2025-03-22 05:48:09.648904: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1024, 36\n",
      "2025-03-22 05:48:09.648905: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1028, 1\n",
      "2025-03-22 05:48:09.648907: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 9216, 12\n",
      "2025-03-22 05:48:09.648908: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 16384, 6\n",
      "2025-03-22 05:48:09.648909: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 18432, 6\n",
      "2025-03-22 05:48:09.648911: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 27648, 8\n",
      "2025-03-22 05:48:09.648912: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 36864, 12\n",
      "2025-03-22 05:48:09.648913: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 65536, 6\n",
      "2025-03-22 05:48:09.648915: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 73728, 6\n",
      "2025-03-22 05:48:09.648916: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 110592, 6\n",
      "2025-03-22 05:48:09.648918: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 147456, 12\n",
      "2025-03-22 05:48:09.648919: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 262144, 6\n",
      "2025-03-22 05:48:09.648920: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 294912, 6\n",
      "2025-03-22 05:48:09.648922: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 442368, 6\n",
      "2025-03-22 05:48:09.648923: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 589824, 12\n",
      "2025-03-22 05:48:09.648924: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1048576, 6\n",
      "2025-03-22 05:48:09.648926: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1179648, 6\n",
      "2025-03-22 05:48:09.648927: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1769472, 6\n",
      "2025-03-22 05:48:09.648928: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 2359296, 6\n",
      "2025-03-22 05:48:09.648930: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 4194304, 3\n",
      "2025-03-22 05:48:09.648931: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 8388608, 3\n",
      "2025-03-22 05:48:09.648933: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 16777216, 10\n",
      "2025-03-22 05:48:09.648934: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 33554432, 13\n",
      "2025-03-22 05:48:09.648936: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 43778048, 1\n",
      "2025-03-22 05:48:09.648937: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 67108864, 10\n",
      "2025-03-22 05:48:09.648938: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 100663296, 1\n",
      "2025-03-22 05:48:09.648940: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 134217728, 8\n",
      "2025-03-22 05:48:09.648941: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 175112192, 1\n",
      "2025-03-22 05:48:09.648942: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 175898624, 1\n",
      "2025-03-22 05:48:09.648944: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 201326592, 1\n",
      "2025-03-22 05:48:09.648945: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 268435456, 5\n",
      "2025-03-22 05:48:09.648946: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 402653184, 1\n",
      "2025-03-22 05:48:09.648948: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 703594496, 1\n",
      "2025-03-22 05:48:09.648949: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 805306368, 2\n",
      "2025-03-22 05:48:09.648953: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:97] CU_MEMPOOL_ATTR_RESERVED_MEM_CURRENT: 11207180288\n",
      "2025-03-22 05:48:09.648955: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:99] CU_MEMPOOL_ATTR_USED_MEM_CURRENT: 7197960461\n",
      "2025-03-22 05:48:09.648956: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:100] CU_MEMPOOL_ATTR_RESERVED_MEM_HIGH: 12280922112\n",
      "2025-03-22 05:48:09.648958: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:101] CU_MEMPOOL_ATTR_USED_MEM_HIGH: 11038268409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - ETA: 0s - loss: 0.0243 - accuracy: 1.0000 - recall: 0.9793 - precision: 0.9753 - f1_score: 0.9760 - IoU: 0.9684\n",
      "Epoch 112: val_f1_score improved from 0.98490 to 0.98522, saving model to UNet3Plus DICE 5-fold model/model_5fold.keras\n",
      "42/42 [==============================] - 15s 369ms/step - loss: 0.0243 - accuracy: 1.0000 - recall: 0.9793 - precision: 0.9753 - f1_score: 0.9760 - IoU: 0.9684 - val_loss: 0.0152 - val_accuracy: 1.0000 - val_recall: 0.9897 - val_precision: 0.9853 - val_f1_score: 0.9852 - val_IoU: 0.9804\n",
      "Epoch 113/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0256 - accuracy: 1.0000 - recall: 0.9788 - precision: 0.9743 - f1_score: 0.9747 - IoU: 0.9687\n",
      "Epoch 113: val_f1_score did not improve from 0.98522\n",
      "42/42 [==============================] - 14s 345ms/step - loss: 0.0256 - accuracy: 1.0000 - recall: 0.9788 - precision: 0.9743 - f1_score: 0.9747 - IoU: 0.9687 - val_loss: 0.0361 - val_accuracy: 1.0000 - val_recall: 0.9392 - val_precision: 0.9955 - val_f1_score: 0.9661 - val_IoU: 0.9521\n",
      "Epoch 114/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0246 - accuracy: 1.0000 - recall: 0.9761 - precision: 0.9751 - f1_score: 0.9755 - IoU: 0.9670\n",
      "Epoch 114: val_f1_score did not improve from 0.98522\n",
      "42/42 [==============================] - 15s 354ms/step - loss: 0.0246 - accuracy: 1.0000 - recall: 0.9761 - precision: 0.9751 - f1_score: 0.9755 - IoU: 0.9670 - val_loss: 0.0165 - val_accuracy: 1.0000 - val_recall: 0.9903 - val_precision: 0.9805 - val_f1_score: 0.9838 - val_IoU: 0.9789\n",
      "Epoch 115/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0248 - accuracy: 1.0000 - recall: 0.9787 - precision: 0.9734 - f1_score: 0.9754 - IoU: 0.9686\n",
      "Epoch 115: val_f1_score did not improve from 0.98522\n",
      "42/42 [==============================] - 16s 393ms/step - loss: 0.0248 - accuracy: 1.0000 - recall: 0.9787 - precision: 0.9734 - f1_score: 0.9754 - IoU: 0.9686 - val_loss: 0.0210 - val_accuracy: 1.0000 - val_recall: 0.9748 - val_precision: 0.9856 - val_f1_score: 0.9789 - val_IoU: 0.9694\n",
      "Epoch 116/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0235 - accuracy: 1.0000 - recall: 0.9804 - precision: 0.9752 - f1_score: 0.9768 - IoU: 0.9699\n",
      "Epoch 116: val_f1_score improved from 0.98522 to 0.98535, saving model to UNet3Plus DICE 5-fold model/model_5fold.keras\n",
      "42/42 [==============================] - 21s 500ms/step - loss: 0.0235 - accuracy: 1.0000 - recall: 0.9804 - precision: 0.9752 - f1_score: 0.9768 - IoU: 0.9699 - val_loss: 0.0147 - val_accuracy: 1.0000 - val_recall: 0.9861 - val_precision: 0.9896 - val_f1_score: 0.9853 - val_IoU: 0.9775\n",
      "Epoch 117/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0227 - accuracy: 1.0000 - recall: 0.9814 - precision: 0.9743 - f1_score: 0.9774 - IoU: 0.9709\n",
      "Epoch 117: val_f1_score did not improve from 0.98535\n",
      "42/42 [==============================] - 20s 472ms/step - loss: 0.0227 - accuracy: 1.0000 - recall: 0.9814 - precision: 0.9743 - f1_score: 0.9774 - IoU: 0.9709 - val_loss: 0.0147 - val_accuracy: 1.0000 - val_recall: 0.9901 - val_precision: 0.9851 - val_f1_score: 0.9849 - val_IoU: 0.9808\n",
      "Epoch 118/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0231 - accuracy: 1.0000 - recall: 0.9779 - precision: 0.9767 - f1_score: 0.9771 - IoU: 0.9686\n",
      "Epoch 118: val_f1_score did not improve from 0.98535\n",
      "42/42 [==============================] - 20s 492ms/step - loss: 0.0231 - accuracy: 1.0000 - recall: 0.9779 - precision: 0.9767 - f1_score: 0.9771 - IoU: 0.9686 - val_loss: 0.0172 - val_accuracy: 1.0000 - val_recall: 0.9773 - val_precision: 0.9923 - val_f1_score: 0.9831 - val_IoU: 0.9718\n",
      "Epoch 119/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0238 - accuracy: 1.0000 - recall: 0.9780 - precision: 0.9759 - f1_score: 0.9764 - IoU: 0.9683\n",
      "Epoch 119: val_f1_score did not improve from 0.98535\n",
      "42/42 [==============================] - 19s 458ms/step - loss: 0.0238 - accuracy: 1.0000 - recall: 0.9780 - precision: 0.9759 - f1_score: 0.9764 - IoU: 0.9683 - val_loss: 0.0184 - val_accuracy: 1.0000 - val_recall: 0.9762 - val_precision: 0.9916 - val_f1_score: 0.9818 - val_IoU: 0.9730\n",
      "Epoch 120/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 1.0000 - recall: 0.9812 - precision: 0.9738 - f1_score: 0.9773 - IoU: 0.9699\n",
      "Epoch 120: val_f1_score did not improve from 0.98535\n",
      "42/42 [==============================] - 18s 437ms/step - loss: 0.0230 - accuracy: 1.0000 - recall: 0.9812 - precision: 0.9738 - f1_score: 0.9773 - IoU: 0.9699 - val_loss: 0.0156 - val_accuracy: 1.0000 - val_recall: 0.9889 - val_precision: 0.9852 - val_f1_score: 0.9846 - val_IoU: 0.9800\n",
      "Epoch 121/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0231 - accuracy: 1.0000 - recall: 0.9809 - precision: 0.9750 - f1_score: 0.9772 - IoU: 0.9701\n",
      "Epoch 121: val_f1_score did not improve from 0.98535\n",
      "42/42 [==============================] - 22s 527ms/step - loss: 0.0231 - accuracy: 1.0000 - recall: 0.9809 - precision: 0.9750 - f1_score: 0.9772 - IoU: 0.9701 - val_loss: 0.0170 - val_accuracy: 1.0000 - val_recall: 0.9832 - val_precision: 0.9880 - val_f1_score: 0.9825 - val_IoU: 0.9760\n",
      "Epoch 122/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0246 - accuracy: 1.0000 - recall: 0.9802 - precision: 0.9754 - f1_score: 0.9757 - IoU: 0.9690\n",
      "Epoch 122: val_f1_score did not improve from 0.98535\n",
      "42/42 [==============================] - 19s 453ms/step - loss: 0.0246 - accuracy: 1.0000 - recall: 0.9802 - precision: 0.9754 - f1_score: 0.9757 - IoU: 0.9690 - val_loss: 0.0154 - val_accuracy: 1.0000 - val_recall: 0.9806 - val_precision: 0.9917 - val_f1_score: 0.9852 - val_IoU: 0.9728\n",
      "Epoch 123/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0224 - accuracy: 1.0000 - recall: 0.9807 - precision: 0.9750 - f1_score: 0.9778 - IoU: 0.9703\n",
      "Epoch 123: val_f1_score did not improve from 0.98535\n",
      "42/42 [==============================] - 22s 515ms/step - loss: 0.0224 - accuracy: 1.0000 - recall: 0.9807 - precision: 0.9750 - f1_score: 0.9778 - IoU: 0.9703 - val_loss: 0.0151 - val_accuracy: 1.0000 - val_recall: 0.9816 - val_precision: 0.9911 - val_f1_score: 0.9851 - val_IoU: 0.9737\n",
      "Epoch 124/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0215 - accuracy: 1.0000 - recall: 0.9794 - precision: 0.9764 - f1_score: 0.9786 - IoU: 0.9701\n",
      "Epoch 124: val_f1_score improved from 0.98535 to 0.98585, saving model to UNet3Plus DICE 5-fold model/model_5fold.keras\n",
      "42/42 [==============================] - 18s 427ms/step - loss: 0.0215 - accuracy: 1.0000 - recall: 0.9794 - precision: 0.9764 - f1_score: 0.9786 - IoU: 0.9701 - val_loss: 0.0142 - val_accuracy: 1.0000 - val_recall: 0.9866 - val_precision: 0.9891 - val_f1_score: 0.9859 - val_IoU: 0.9785\n",
      "Epoch 125/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0250 - accuracy: 1.0000 - recall: 0.9795 - precision: 0.9756 - f1_score: 0.9753 - IoU: 0.9690\n",
      "Epoch 125: val_f1_score did not improve from 0.98585\n",
      "42/42 [==============================] - 18s 425ms/step - loss: 0.0250 - accuracy: 1.0000 - recall: 0.9795 - precision: 0.9756 - f1_score: 0.9753 - IoU: 0.9690 - val_loss: 0.0149 - val_accuracy: 1.0000 - val_recall: 0.9948 - val_precision: 0.9796 - val_f1_score: 0.9847 - val_IoU: 0.9846\n",
      "Epoch 126/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0218 - accuracy: 1.0000 - recall: 0.9814 - precision: 0.9759 - f1_score: 0.9785 - IoU: 0.9709\n",
      "Epoch 126: val_f1_score did not improve from 0.98585\n",
      "42/42 [==============================] - 20s 473ms/step - loss: 0.0218 - accuracy: 1.0000 - recall: 0.9814 - precision: 0.9759 - f1_score: 0.9785 - IoU: 0.9709 - val_loss: 0.0153 - val_accuracy: 1.0000 - val_recall: 0.9885 - val_precision: 0.9880 - val_f1_score: 0.9829 - val_IoU: 0.9802\n",
      "Epoch 127/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0221 - accuracy: 1.0000 - recall: 0.9810 - precision: 0.9761 - f1_score: 0.9780 - IoU: 0.9703\n",
      "Epoch 127: val_f1_score did not improve from 0.98585\n",
      "42/42 [==============================] - 24s 573ms/step - loss: 0.0221 - accuracy: 1.0000 - recall: 0.9810 - precision: 0.9761 - f1_score: 0.9780 - IoU: 0.9703 - val_loss: 0.0178 - val_accuracy: 1.0000 - val_recall: 0.9761 - val_precision: 0.9926 - val_f1_score: 0.9825 - val_IoU: 0.9719\n",
      "Epoch 128/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0224 - accuracy: 1.0000 - recall: 0.9817 - precision: 0.9743 - f1_score: 0.9777 - IoU: 0.9708\n",
      "Epoch 128: val_f1_score did not improve from 0.98585\n",
      "42/42 [==============================] - 20s 493ms/step - loss: 0.0224 - accuracy: 1.0000 - recall: 0.9817 - precision: 0.9743 - f1_score: 0.9777 - IoU: 0.9708 - val_loss: 0.0177 - val_accuracy: 1.0000 - val_recall: 0.9767 - val_precision: 0.9921 - val_f1_score: 0.9824 - val_IoU: 0.9732\n",
      "Epoch 129/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0231 - accuracy: 1.0000 - recall: 0.9810 - precision: 0.9766 - f1_score: 0.9771 - IoU: 0.9707\n",
      "Epoch 129: val_f1_score did not improve from 0.98585\n",
      "42/42 [==============================] - 19s 463ms/step - loss: 0.0231 - accuracy: 1.0000 - recall: 0.9810 - precision: 0.9766 - f1_score: 0.9771 - IoU: 0.9707 - val_loss: 0.0168 - val_accuracy: 1.0000 - val_recall: 0.9949 - val_precision: 0.9770 - val_f1_score: 0.9824 - val_IoU: 0.9854\n",
      "Epoch 130/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0300 - accuracy: 1.0000 - recall: 0.9750 - precision: 0.9672 - f1_score: 0.9701 - IoU: 0.9645\n",
      "Epoch 130: val_f1_score did not improve from 0.98585\n",
      "42/42 [==============================] - 20s 486ms/step - loss: 0.0300 - accuracy: 1.0000 - recall: 0.9750 - precision: 0.9672 - f1_score: 0.9701 - IoU: 0.9645 - val_loss: 0.0720 - val_accuracy: 0.9999 - val_recall: 0.8896 - val_precision: 0.9646 - val_f1_score: 0.9303 - val_IoU: 0.9305\n",
      "Epoch 131/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0286 - accuracy: 1.0000 - recall: 0.9731 - precision: 0.9709 - f1_score: 0.9716 - IoU: 0.9656\n",
      "Epoch 131: val_f1_score did not improve from 0.98585\n",
      "42/42 [==============================] - 31s 750ms/step - loss: 0.0286 - accuracy: 1.0000 - recall: 0.9731 - precision: 0.9709 - f1_score: 0.9716 - IoU: 0.9656 - val_loss: 0.0400 - val_accuracy: 1.0000 - val_recall: 0.9772 - val_precision: 0.9573 - val_f1_score: 0.9609 - val_IoU: 0.9721\n",
      "Epoch 132/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0300 - accuracy: 1.0000 - recall: 0.9739 - precision: 0.9735 - f1_score: 0.9702 - IoU: 0.9664\n",
      "Epoch 132: val_f1_score did not improve from 0.98585\n",
      "42/42 [==============================] - 18s 417ms/step - loss: 0.0300 - accuracy: 1.0000 - recall: 0.9739 - precision: 0.9735 - f1_score: 0.9702 - IoU: 0.9664 - val_loss: 0.0223 - val_accuracy: 1.0000 - val_recall: 0.9844 - val_precision: 0.9789 - val_f1_score: 0.9776 - val_IoU: 0.9781\n",
      "Epoch 133/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0238 - accuracy: 1.0000 - recall: 0.9803 - precision: 0.9753 - f1_score: 0.9765 - IoU: 0.9695\n",
      "Epoch 133: val_f1_score did not improve from 0.98585\n",
      "42/42 [==============================] - 21s 501ms/step - loss: 0.0238 - accuracy: 1.0000 - recall: 0.9803 - precision: 0.9753 - f1_score: 0.9765 - IoU: 0.9695 - val_loss: 0.0178 - val_accuracy: 1.0000 - val_recall: 0.9826 - val_precision: 0.9878 - val_f1_score: 0.9819 - val_IoU: 0.9754\n",
      "Epoch 134/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0243 - accuracy: 1.0000 - recall: 0.9789 - precision: 0.9734 - f1_score: 0.9759 - IoU: 0.9695\n",
      "Epoch 134: val_f1_score did not improve from 0.98585\n",
      "42/42 [==============================] - 22s 536ms/step - loss: 0.0243 - accuracy: 1.0000 - recall: 0.9789 - precision: 0.9734 - f1_score: 0.9759 - IoU: 0.9695 - val_loss: 0.0166 - val_accuracy: 1.0000 - val_recall: 0.9858 - val_precision: 0.9835 - val_f1_score: 0.9837 - val_IoU: 0.9772\n",
      "Epoch 135/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0225 - accuracy: 1.0000 - recall: 0.9803 - precision: 0.9765 - f1_score: 0.9776 - IoU: 0.9705\n",
      "Epoch 135: val_f1_score did not improve from 0.98585\n",
      "42/42 [==============================] - 24s 570ms/step - loss: 0.0225 - accuracy: 1.0000 - recall: 0.9803 - precision: 0.9765 - f1_score: 0.9776 - IoU: 0.9705 - val_loss: 0.0176 - val_accuracy: 1.0000 - val_recall: 0.9763 - val_precision: 0.9922 - val_f1_score: 0.9824 - val_IoU: 0.9711\n",
      "Epoch 136/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0217 - accuracy: 1.0000 - recall: 0.9810 - precision: 0.9752 - f1_score: 0.9784 - IoU: 0.9708\n",
      "Epoch 136: val_f1_score did not improve from 0.98585\n",
      "42/42 [==============================] - 20s 481ms/step - loss: 0.0217 - accuracy: 1.0000 - recall: 0.9810 - precision: 0.9752 - f1_score: 0.9784 - IoU: 0.9708 - val_loss: 0.0164 - val_accuracy: 1.0000 - val_recall: 0.9797 - val_precision: 0.9923 - val_f1_score: 0.9836 - val_IoU: 0.9738\n",
      "Epoch 137/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 1.0000 - recall: 0.9817 - precision: 0.9764 - f1_score: 0.9792 - IoU: 0.9709\n",
      "Epoch 137: val_f1_score did not improve from 0.98585\n",
      "42/42 [==============================] - 17s 416ms/step - loss: 0.0210 - accuracy: 1.0000 - recall: 0.9817 - precision: 0.9764 - f1_score: 0.9792 - IoU: 0.9709 - val_loss: 0.0172 - val_accuracy: 1.0000 - val_recall: 0.9761 - val_precision: 0.9928 - val_f1_score: 0.9829 - val_IoU: 0.9726\n",
      "Epoch 138/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0216 - accuracy: 1.0000 - recall: 0.9803 - precision: 0.9761 - f1_score: 0.9786 - IoU: 0.9703\n",
      "Epoch 138: val_f1_score improved from 0.98585 to 0.98636, saving model to UNet3Plus DICE 5-fold model/model_5fold.keras\n",
      "42/42 [==============================] - 17s 401ms/step - loss: 0.0216 - accuracy: 1.0000 - recall: 0.9803 - precision: 0.9761 - f1_score: 0.9786 - IoU: 0.9703 - val_loss: 0.0139 - val_accuracy: 1.0000 - val_recall: 0.9838 - val_precision: 0.9905 - val_f1_score: 0.9864 - val_IoU: 0.9765\n",
      "Epoch 139/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0215 - accuracy: 1.0000 - recall: 0.9804 - precision: 0.9765 - f1_score: 0.9787 - IoU: 0.9704\n",
      "Epoch 139: val_f1_score did not improve from 0.98636\n",
      "42/42 [==============================] - 19s 461ms/step - loss: 0.0215 - accuracy: 1.0000 - recall: 0.9804 - precision: 0.9765 - f1_score: 0.9787 - IoU: 0.9704 - val_loss: 0.0236 - val_accuracy: 1.0000 - val_recall: 0.9612 - val_precision: 0.9941 - val_f1_score: 0.9771 - val_IoU: 0.9630\n",
      "Epoch 140/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0237 - accuracy: 1.0000 - recall: 0.9797 - precision: 0.9756 - f1_score: 0.9764 - IoU: 0.9699\n",
      "Epoch 140: val_f1_score did not improve from 0.98636\n",
      "42/42 [==============================] - 22s 513ms/step - loss: 0.0237 - accuracy: 1.0000 - recall: 0.9797 - precision: 0.9756 - f1_score: 0.9764 - IoU: 0.9699 - val_loss: 0.0190 - val_accuracy: 1.0000 - val_recall: 0.9708 - val_precision: 0.9936 - val_f1_score: 0.9816 - val_IoU: 0.9682\n",
      "Epoch 141/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 1.0000 - recall: 0.9791 - precision: 0.9765 - f1_score: 0.9765 - IoU: 0.9703\n",
      "Epoch 141: val_f1_score did not improve from 0.98636\n",
      "42/42 [==============================] - 19s 457ms/step - loss: 0.0236 - accuracy: 1.0000 - recall: 0.9791 - precision: 0.9765 - f1_score: 0.9765 - IoU: 0.9703 - val_loss: 0.0200 - val_accuracy: 1.0000 - val_recall: 0.9699 - val_precision: 0.9929 - val_f1_score: 0.9803 - val_IoU: 0.9693\n",
      "Epoch 142/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 1.0000 - recall: 0.9804 - precision: 0.9745 - f1_score: 0.9765 - IoU: 0.9719\n",
      "Epoch 142: val_f1_score did not improve from 0.98636\n",
      "42/42 [==============================] - 27s 655ms/step - loss: 0.0236 - accuracy: 1.0000 - recall: 0.9804 - precision: 0.9745 - f1_score: 0.9765 - IoU: 0.9719 - val_loss: 0.0150 - val_accuracy: 1.0000 - val_recall: 0.9833 - val_precision: 0.9911 - val_f1_score: 0.9852 - val_IoU: 0.9766\n",
      "Epoch 143/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0218 - accuracy: 1.0000 - recall: 0.9815 - precision: 0.9770 - f1_score: 0.9784 - IoU: 0.9713\n",
      "Epoch 143: val_f1_score improved from 0.98636 to 0.98662, saving model to UNet3Plus DICE 5-fold model/model_5fold.keras\n",
      "42/42 [==============================] - 18s 435ms/step - loss: 0.0218 - accuracy: 1.0000 - recall: 0.9815 - precision: 0.9770 - f1_score: 0.9784 - IoU: 0.9713 - val_loss: 0.0134 - val_accuracy: 1.0000 - val_recall: 0.9896 - val_precision: 0.9875 - val_f1_score: 0.9866 - val_IoU: 0.9810\n",
      "Epoch 144/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0226 - accuracy: 1.0000 - recall: 0.9790 - precision: 0.9775 - f1_score: 0.9776 - IoU: 0.9709\n",
      "Epoch 144: val_f1_score did not improve from 0.98662\n",
      "42/42 [==============================] - 17s 398ms/step - loss: 0.0226 - accuracy: 1.0000 - recall: 0.9790 - precision: 0.9775 - f1_score: 0.9776 - IoU: 0.9709 - val_loss: 0.0157 - val_accuracy: 1.0000 - val_recall: 0.9812 - val_precision: 0.9906 - val_f1_score: 0.9845 - val_IoU: 0.9765\n",
      "Epoch 145/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 1.0000 - recall: 0.9818 - precision: 0.9769 - f1_score: 0.9790 - IoU: 0.9725\n",
      "Epoch 145: val_f1_score did not improve from 0.98662\n",
      "42/42 [==============================] - 17s 412ms/step - loss: 0.0211 - accuracy: 1.0000 - recall: 0.9818 - precision: 0.9769 - f1_score: 0.9790 - IoU: 0.9725 - val_loss: 0.0158 - val_accuracy: 1.0000 - val_recall: 0.9789 - val_precision: 0.9927 - val_f1_score: 0.9844 - val_IoU: 0.9734\n",
      "Epoch 146/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0222 - accuracy: 1.0000 - recall: 0.9811 - precision: 0.9772 - f1_score: 0.9779 - IoU: 0.9718\n",
      "Epoch 146: val_f1_score did not improve from 0.98662\n",
      "42/42 [==============================] - 18s 424ms/step - loss: 0.0222 - accuracy: 1.0000 - recall: 0.9811 - precision: 0.9772 - f1_score: 0.9779 - IoU: 0.9718 - val_loss: 0.0154 - val_accuracy: 1.0000 - val_recall: 0.9965 - val_precision: 0.9754 - val_f1_score: 0.9845 - val_IoU: 0.9870\n",
      "Epoch 147/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0204 - accuracy: 1.0000 - recall: 0.9809 - precision: 0.9776 - f1_score: 0.9798 - IoU: 0.9721\n",
      "Epoch 147: val_f1_score did not improve from 0.98662\n",
      "42/42 [==============================] - 25s 587ms/step - loss: 0.0204 - accuracy: 1.0000 - recall: 0.9809 - precision: 0.9776 - f1_score: 0.9798 - IoU: 0.9721 - val_loss: 0.0145 - val_accuracy: 1.0000 - val_recall: 0.9957 - val_precision: 0.9783 - val_f1_score: 0.9852 - val_IoU: 0.9867\n",
      "Epoch 148/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0228 - accuracy: 1.0000 - recall: 0.9787 - precision: 0.9749 - f1_score: 0.9773 - IoU: 0.9705\n",
      "Epoch 148: val_f1_score did not improve from 0.98662\n",
      "42/42 [==============================] - 24s 572ms/step - loss: 0.0228 - accuracy: 1.0000 - recall: 0.9787 - precision: 0.9749 - f1_score: 0.9773 - IoU: 0.9705 - val_loss: 0.0269 - val_accuracy: 1.0000 - val_recall: 0.9496 - val_precision: 0.9963 - val_f1_score: 0.9738 - val_IoU: 0.9581\n",
      "Epoch 149/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0225 - accuracy: 1.0000 - recall: 0.9762 - precision: 0.9774 - f1_score: 0.9776 - IoU: 0.9686\n",
      "Epoch 149: val_f1_score improved from 0.98662 to 0.98727, saving model to UNet3Plus DICE 5-fold model/model_5fold.keras\n",
      "42/42 [==============================] - 23s 559ms/step - loss: 0.0225 - accuracy: 1.0000 - recall: 0.9762 - precision: 0.9774 - f1_score: 0.9776 - IoU: 0.9686 - val_loss: 0.0132 - val_accuracy: 1.0000 - val_recall: 0.9892 - val_precision: 0.9870 - val_f1_score: 0.9873 - val_IoU: 0.9811\n",
      "Epoch 150/150\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0235 - accuracy: 1.0000 - recall: 0.9819 - precision: 0.9719 - f1_score: 0.9766 - IoU: 0.9717\n",
      "Epoch 150: val_f1_score did not improve from 0.98727\n",
      "42/42 [==============================] - 24s 560ms/step - loss: 0.0235 - accuracy: 1.0000 - recall: 0.9819 - precision: 0.9719 - f1_score: 0.9766 - IoU: 0.9717 - val_loss: 0.0254 - val_accuracy: 1.0000 - val_recall: 0.9583 - val_precision: 0.9962 - val_f1_score: 0.9750 - val_IoU: 0.9610\n",
      "O modelo demorou 2376.87 segundos para treinar.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mbouzon/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas salvas com sucesso na pasta: UNet3Plus DICE 5-fold model\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "jacc = []\n",
    "f1 = []\n",
    "prec = []\n",
    "rec = []\n",
    "\n",
    "# Dicionário para armazenar métricas por fold\n",
    "fold_metrics_summary = []\n",
    "\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=28)\n",
    "fold = 4\n",
    "\n",
    "for i, (train_ind, test_ind) in enumerate(kf.split(X)):\n",
    "    if i < (fold-1):\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    print(\"Fold: \" + str(fold))\n",
    "    X_train, X_val, y_train, y_val = X[train_ind], X[test_ind], y[train_ind], y[test_ind]\n",
    "\n",
    "    model = unet_3_plus()\n",
    "    \n",
    "    \n",
    "    checkpoint_filepath = os.path.join(output_dir, f'model_{fold}fold.keras')\n",
    "    callbacks = [\n",
    "            tf.keras.callbacks.TensorBoard(log_dir='logs'),\n",
    "            tf.keras.callbacks.ModelCheckpoint(\n",
    "                filepath=checkpoint_filepath,\n",
    "                save_weights_only=False,\n",
    "                monitor='val_f1_score',\n",
    "                mode='max',\n",
    "                save_best_only=True,\n",
    "                verbose=1)]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train, validation_data=(X_val,y_val), batch_size=16, epochs=150, callbacks=callbacks)\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "\n",
    "     # Salvando o tempo de treinamento\n",
    "    with open(os.path.join(output_dir, 'training_time.txt'), 'a') as f:\n",
    "        f.write(f'Fold {fold}: {training_time:.2f} segundos\\n')\n",
    "    print(f\"O modelo demorou {training_time:.2f} segundos para treinar.\")\n",
    "    \n",
    "    loss = model.history.history['loss']\n",
    "    val_loss = model.history.history['val_loss']\n",
    "    \n",
    "    with open(os.path.join(output_dir, f'loss_fold{fold}.csv'), 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=';')\n",
    "        writer.writerow([\"Epoch\", \"Loss\", \"Validation Loss\"])\n",
    "        for epoch, (l, vl) in enumerate(zip(loss, val_loss), start=1):\n",
    "            writer.writerow([epoch, l, vl])\n",
    "            \n",
    "     # Plotando e salvando a figura\n",
    "    plt.figure()\n",
    "    plt.plot(loss, 'r', label='Training loss')\n",
    "    plt.plot(val_loss, 'g', label='Validation loss')\n",
    "    plt.title(f'Training and Validation Loss - Fold {fold}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss Value')\n",
    "    plt.ylim([0, 1])\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(output_dir, f'loss_plot_fold{fold}.png'))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    fold_metrics = []\n",
    "\n",
    "    acc_fold = []\n",
    "    jacc_fold = []\n",
    "    f1_fold = []\n",
    "    prec_fold = []\n",
    "    rec_fold = []\n",
    "    \n",
    "    for i in range(0, len(X_val)):\n",
    "        sample_image = X_val[i]\n",
    "        sample_mask = y_val[i].astype(np.uint8).flatten()\n",
    "        prediction = model.predict(sample_image[tf.newaxis, ...],verbose=0)[0]\n",
    "        predicted_mask = (prediction > 0.5).astype(np.uint8).flatten()\n",
    "            \n",
    "        acc_score = accuracy_score(sample_mask, predicted_mask)\n",
    "        jacc_score = jaccard_score(sample_mask, predicted_mask)\n",
    "        f1_score_val = f1_score(sample_mask, predicted_mask).numpy()\n",
    "        prec_score = precision_score(sample_mask, predicted_mask)\n",
    "        rec_score = recall_score(sample_mask, predicted_mask)\n",
    "\n",
    "        acc_fold.append(acc_score)\n",
    "        jacc_fold.append(jacc_score)\n",
    "        f1_fold.append(f1_score_val)\n",
    "        prec_fold.append(prec_score)\n",
    "        rec_fold.append(rec_score)\n",
    "\n",
    "        fold_metrics.append([i, acc_score, jacc_score, f1_score_val, prec_score, rec_score])\n",
    "        \n",
    "    # Salvando métricas por imagem\n",
    "    with open(os.path.join(output_dir, f'metrics_fold{fold}.csv'), 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=';')\n",
    "        writer.writerow([\"Index\", \"Accuracy\", \"Jaccard\", \"DICE\", \"Precision\", \"Recall\"])\n",
    "        writer.writerows(fold_metrics)\n",
    "\n",
    "    # Salvando a média do fold para cada métrica\n",
    "    fold_metrics_summary.append([\n",
    "        fold, np.mean(acc_fold), np.std(acc_fold),\n",
    "        np.mean(jacc_fold), np.std(jacc_fold),\n",
    "        np.mean(f1_fold), np.std(f1_fold),\n",
    "        np.mean(prec_fold), np.std(prec_fold),\n",
    "        np.mean(rec_fold), np.std(rec_fold)\n",
    "    ])\n",
    "\n",
    "        \n",
    "    del model \n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    fold+=1\n",
    "    \n",
    "# Calculando médias gerais\n",
    "acc_total = [m[1] for m in fold_metrics_summary]\n",
    "jacc_total = [m[3] for m in fold_metrics_summary]\n",
    "f1_total = [m[5] for m in fold_metrics_summary]\n",
    "prec_total = [m[7] for m in fold_metrics_summary]\n",
    "rec_total = [m[9] for m in fold_metrics_summary]\n",
    "\n",
    "general_summary = [\n",
    "    [\"Fold\", \"Accuracy Mean\", \"Accuracy Std\", \"Jaccard Mean\", \"Jaccard Std\",\n",
    "     \"DICE Mean\", \"DICE Std\", \"Precision Mean\", \"Precision Std\", \"Recall Mean\", \"Recall Std\"]\n",
    "]\n",
    "\n",
    "general_summary.extend(fold_metrics_summary)\n",
    "\n",
    "general_summary.append([\n",
    "    \"Overall Mean\", np.mean(acc_total), np.std(acc_total),\n",
    "    np.mean(jacc_total), np.std(jacc_total),\n",
    "    np.mean(f1_total), np.std(f1_total),\n",
    "    np.mean(prec_total), np.std(prec_total),\n",
    "    np.mean(rec_total), np.std(rec_total)\n",
    "])\n",
    "\n",
    "# Salvando o resumo das métricas por fold e geral\n",
    "with open(os.path.join(output_dir, 'metrics_summary.csv'), 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=';')\n",
    "    writer.writerows(general_summary)\n",
    "\n",
    "print(\"Métricas salvas com sucesso na pasta:\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa5d184f-5b31-4156-849f-d24ddac7c3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "k-fold:  80%|█████████████████████████████████████████████████████████████▌               | 4/5 [01:57<00:29, 29.24s/it]/home/mbouzon/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "k-fold: 100%|█████████████████████████████████████████████████████████████████████████████| 5/5 [02:26<00:00, 29.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas salvas com sucesso na pasta: UNet3Plus DICE 5-fold model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "acc_mean_fold = []\n",
    "jacc_mean_fold = []\n",
    "f1_mean_fold = []\n",
    "prec_mean_fold = []\n",
    "rec_mean_fold = []\n",
    "\n",
    "acc_std_fold = []\n",
    "jacc_std_fold = []\n",
    "f1_std_fold = []\n",
    "prec_std_fold = []\n",
    "rec_std_fold = []\n",
    "\n",
    "\n",
    "# Dicionário para armazenar métricas por fold\n",
    "fold_metrics_summary = []\n",
    "\n",
    "fold = 1\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=28)\n",
    "for train_ind, test_ind in tqdm(kf.split(X), total=kf.get_n_splits(), desc=\"k-fold\"):\n",
    "    X_train, X_val, y_train, y_val = X[train_ind], X[test_ind], y[train_ind], y[test_ind]\n",
    "\n",
    "    fold_metrics = []\n",
    "\n",
    "    acc_fold = []\n",
    "    jacc_fold = []\n",
    "    f1_fold = []\n",
    "    prec_fold = []\n",
    "    rec_fold = []\n",
    "    \n",
    "    model_filepath = filepath = os.path.join(output_dir, f'model_{fold}fold.keras')\n",
    "    model = tf.keras.models.load_model(model_filepath)\n",
    "\n",
    "    for i in range(0, len(X_val)):\n",
    "        sample_image = X_val[i]\n",
    "        sample_mask = y_val[i].astype(np.uint8).flatten()\n",
    "        prediction = model.predict(sample_image[tf.newaxis, ...],verbose=0)[0]\n",
    "        predicted_mask = (prediction > 0.5).astype(np.uint8).flatten()\n",
    "            \n",
    "        acc_score = accuracy_score(sample_mask, predicted_mask)\n",
    "        jacc_score = jaccard_score(sample_mask, predicted_mask)\n",
    "        f1_score_val = f1_score(sample_mask, predicted_mask).numpy()\n",
    "        prec_score = precision_score(sample_mask, predicted_mask)\n",
    "        rec_score = recall_score(sample_mask, predicted_mask)\n",
    "\n",
    "        acc_fold.append(acc_score)\n",
    "        jacc_fold.append(jacc_score)\n",
    "        f1_fold.append(f1_score_val)\n",
    "        prec_fold.append(prec_score)\n",
    "        rec_fold.append(rec_score)\n",
    "\n",
    "        fold_metrics.append([i, acc_score, jacc_score, f1_score_val, prec_score, rec_score])\n",
    "        \n",
    "    # Salvando métricas por imagem\n",
    "    with open(os.path.join(output_dir, f'metrics_fold{fold}.csv'), 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=';')\n",
    "        writer.writerow([\"Index\", \"Accuracy\", \"Jaccard\", \"DICE\", \"Precision\", \"Recall\"])\n",
    "        writer.writerows(fold_metrics)\n",
    "\n",
    "    # Salvando a média do fold para cada métrica\n",
    "    fold_metrics_summary.append([\n",
    "        fold, np.mean(acc_fold), np.std(acc_fold),\n",
    "        np.mean(jacc_fold), np.std(jacc_fold),\n",
    "        np.mean(f1_fold), np.std(f1_fold),\n",
    "        np.mean(prec_fold), np.std(prec_fold),\n",
    "        np.mean(rec_fold), np.std(rec_fold)\n",
    "    ])\n",
    "\n",
    "\n",
    "    fold += 1\n",
    "\n",
    "# Calculando médias gerais\n",
    "acc_total = [m[1] for m in fold_metrics_summary]\n",
    "jacc_total = [m[3] for m in fold_metrics_summary]\n",
    "f1_total = [m[5] for m in fold_metrics_summary]\n",
    "prec_total = [m[7] for m in fold_metrics_summary]\n",
    "rec_total = [m[9] for m in fold_metrics_summary]\n",
    "\n",
    "general_summary = [\n",
    "    [\"Fold\", \"Accuracy Mean\", \"Accuracy Std\", \"Jaccard Mean\", \"Jaccard Std\",\n",
    "     \"DICE Mean\", \"DICE Std\", \"Precision Mean\", \"Precision Std\", \"Recall Mean\", \"Recall Std\"]\n",
    "]\n",
    "\n",
    "general_summary.extend(fold_metrics_summary)\n",
    "\n",
    "general_summary.append([\n",
    "    \"Overall Mean\", np.mean(acc_total), np.std(acc_total),\n",
    "    np.mean(jacc_total), np.std(jacc_total),\n",
    "    np.mean(f1_total), np.std(f1_total),\n",
    "    np.mean(prec_total), np.std(prec_total),\n",
    "    np.mean(rec_total), np.std(rec_total)\n",
    "])\n",
    "\n",
    "# Salvando o resumo das métricas por fold e geral\n",
    "with open(os.path.join(output_dir, 'metrics_summary.csv'), 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=';')\n",
    "    writer.writerows(general_summary)\n",
    "\n",
    "print(\"Métricas salvas com sucesso na pasta:\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2544ddf-696d-4ff5-8780-9a498daa8413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.99782324857034 +- 0.0008071275615491656\n",
      "Jaccard: 95.10345249018283 +- 0.4898797640848829\n",
      "Dice: 97.20045328140259 +- 0.19569597207009792\n",
      "Precision: 97.48635566998483 +- 0.21846919897463968\n",
      "Recall: 97.3522914423454 +- 0.416591583982813\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \"+ str(np.mean(acc_total)*100) + \" +- \" + str(np.std(acc_total)*100))\n",
    "print(\"Jaccard: \"+ str(np.mean(jacc_total)*100) + \" +- \" + str(np.std(jacc_total)*100))\n",
    "print(\"Dice: \"+ str(np.mean(f1_total)*100) + \" +- \" + str(np.std(f1_total)*100))\n",
    "print(\"Precision: \"+ str(np.mean(prec_total)*100) + \" +- \" + str(np.std(prec_total)*100))\n",
    "print(\"Recall: \"+ str(np.mean(rec_total)*100) + \" +- \" + str(np.std(rec_total)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e774436e-ff52-47f8-8dce-d80b378b614b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_fold = 2\n",
    "best_model_filepath = filepath = os.path.join(output_dir, f'model_{best_fold}fold.keras')\n",
    "best_model = tf.keras.models.load_model(best_model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ac69b19-a5f7-40f1-b395-d65cd72999d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=k, shuffle=True, random_state=28)\n",
    "for i, (train_ind, test_ind) in enumerate(kf.split(X)):\n",
    "    if i == (best_fold-1):\n",
    "        X_train, X_val, y_train, y_val = X[train_ind], X[test_ind], y[train_ind], y[test_ind]\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6713b66-5fa4-436e-a338-dee9851b3462",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(display_list):\n",
    "  plt.figure(figsize=(15, 15))\n",
    "\n",
    "  title = ['Input image', 'True mask', 'Predicted mask']\n",
    "\n",
    "  for i in range(len(display_list)):\n",
    "    plt.subplot(1, len(display_list), i+1)\n",
    "    plt.title(title[i])\n",
    "    plt.imshow(tf.keras.utils.array_to_img(display_list[i]), cmap='gray')\n",
    "    plt.axis('off')\n",
    "  plt.show()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "329d56e2-63cb-4232-b7eb-0a9ed7c6b0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 178ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9999809265136719\n",
      "Jaccard: 0.9528301886792453\n",
      "Dice: 0.9758454106280194\n",
      "Precision: 0.9619047619047619\n",
      "Recall: 0.9901960784313726\n"
     ]
    }
   ],
   "source": [
    "i = random.randint(0, len(X_val))\n",
    "sample_image = X_val[i]\n",
    "sample_mask = y_val[i]\n",
    "prediction = best_model.predict(sample_image[tf.newaxis, ...])[0]\n",
    "predicted_mask = (prediction > 0.5).astype(np.uint8)\n",
    "display([sample_image, sample_mask,predicted_mask])\n",
    "\n",
    "sample_mask = y_val[i].astype(np.uint8).flatten()\n",
    "predicted_mask = predicted_mask.flatten()\n",
    "\n",
    "\n",
    "print(\"Accuracy: \"+ str(accuracy_score(sample_mask, predicted_mask)))\n",
    "print(\"Jaccard: \"+ str(jaccard_score(sample_mask, predicted_mask)))\n",
    "print(\"Dice: \"+ str((2*jaccard_score(sample_mask, predicted_mask))/(1+jaccard_score(sample_mask, predicted_mask))))\n",
    "print(\"Precision: \"+ str(precision_score(sample_mask, predicted_mask)))\n",
    "print(\"Recall: \"+ str(recall_score(sample_mask, predicted_mask)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bd9e15-bc6d-4743-ae4b-ce8a3202b64c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
