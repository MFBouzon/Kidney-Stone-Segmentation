{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 284,
     "status": "ok",
     "timestamp": 1730729585955,
     "user": {
      "displayName": "Paulo Henrique",
      "userId": "13955216473685151557"
     },
     "user_tz": 180
    },
    "id": "1JwwvaqGOwHP"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 13:39:41.007941: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-17 13:39:41.018892: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-17 13:39:41.022163: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-17 13:39:41.030622: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m set_session\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers, Model\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.backend import set_session\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 281,
     "status": "ok",
     "timestamp": 1730730182204,
     "user": {
      "displayName": "Paulo Henrique",
      "userId": "13955216473685151557"
     },
     "user_tz": 180
    },
    "id": "CbHYzL7I0D08"
   },
   "outputs": [],
   "source": [
    "## Variaveis\n",
    "seeds = [13, 42, 1,83,76]\n",
    "np.random.seed(0)\n",
    "num_classes = 1\n",
    "split_size = 0.2\n",
    "k = 5\n",
    "IMG_HEIGHT = 128\n",
    "IMG_WIDTH = 128\n",
    "IMG_CHANNELS = 1\n",
    "NUM_TEST_IMAGES = 10\n",
    "\n",
    "\n",
    "# Definindo o caminho da pasta\n",
    "imagens = 'Imagens1/'\n",
    "mascara = 'mascaras1/'\n",
    "\n",
    "# Listando todos os arquivos na pasta\n",
    "imagens_lista = os.listdir(imagens)\n",
    "mascaras_lista = os.listdir(mascara)\n",
    "\n",
    "# Inicializando listas para cada coluna\n",
    "imagens_id = []\n",
    "mascara_id = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 291,
     "status": "ok",
     "timestamp": 1730730184616,
     "user": {
      "displayName": "Paulo Henrique",
      "userId": "13955216473685151557"
     },
     "user_tz": 180
    },
    "id": "X0JJyZcU17-3"
   },
   "outputs": [],
   "source": [
    "# Loop pelos arquivos e preenchendo as listas com informações da pasta de imagens:\n",
    "for arquivo in imagens_lista:\n",
    "    # Nome e extensão do arquivo\n",
    "    imagens_id.append(arquivo)\n",
    "\n",
    "# Criando o DataFrame das imagens\n",
    "df_img = pd.DataFrame({\n",
    "    'Imagens_id': imagens_id\n",
    "})\n",
    "\n",
    "# Loop pelos arquivos e preenchendo as listas com informações da pasta de mascaras:\n",
    "for arquivo in mascaras_lista:\n",
    "    # Nome e extensão do arquivo\n",
    "    mascara_id.append(arquivo)\n",
    "\n",
    "# Criando o DataFrame das mascaras\n",
    "df_msk = pd.DataFrame({\n",
    "    'mascaras_id': mascara_id\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 261,
     "status": "ok",
     "timestamp": 1730730186957,
     "user": {
      "displayName": "Paulo Henrique",
      "userId": "13955216473685151557"
     },
     "user_tz": 180
    },
    "id": "pCc6FQYG2CMD",
    "outputId": "addb2cfc-8479-42bd-d5a5-fd111f1d8bea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Imagens_id\n",
      "0  SIMCEPImages_A01_C1_F1_s01_w1.TIF\n",
      "1  SIMCEPImages_A01_C1_F1_s01_w2.TIF\n",
      "2  SIMCEPImages_A01_C1_F1_s02_w1.TIF\n",
      "3  SIMCEPImages_A01_C1_F1_s02_w2.TIF\n",
      "4  SIMCEPImages_A01_C1_F1_s03_w1.TIF\n",
      "5  SIMCEPImages_A01_C1_F1_s03_w2.TIF\n",
      "6  SIMCEPImages_A01_C1_F1_s04_w1.TIF\n",
      "7  SIMCEPImages_A01_C1_F1_s04_w2.TIF\n",
      "8  SIMCEPImages_A01_C1_F1_s05_w1.TIF\n",
      "9  SIMCEPImages_A01_C1_F1_s05_w2.TIF\n",
      "(100, 1)\n",
      "                         mascaras_id\n",
      "0  SIMCEPImages_A01_C1_F1_s01_w1.TIF\n",
      "1  SIMCEPImages_A01_C1_F1_s01_w2.TIF\n",
      "2  SIMCEPImages_A01_C1_F1_s02_w1.TIF\n",
      "3  SIMCEPImages_A01_C1_F1_s02_w2.TIF\n",
      "4  SIMCEPImages_A01_C1_F1_s03_w1.TIF\n",
      "5  SIMCEPImages_A01_C1_F1_s03_w2.TIF\n",
      "6  SIMCEPImages_A01_C1_F1_s04_w1.TIF\n",
      "7  SIMCEPImages_A01_C1_F1_s04_w2.TIF\n",
      "8  SIMCEPImages_A01_C1_F1_s05_w1.TIF\n",
      "9  SIMCEPImages_A01_C1_F1_s05_w2.TIF\n",
      "(100, 1)\n"
     ]
    }
   ],
   "source": [
    "print(df_img.head(10))\n",
    "print(df_img.shape)\n",
    "\n",
    "print(df_msk.head(10))\n",
    "print(df_msk.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 265,
     "status": "ok",
     "timestamp": 1730730190361,
     "user": {
      "displayName": "Paulo Henrique",
      "userId": "13955216473685151557"
     },
     "user_tz": 180
    },
    "id": "U4qWXWcb2K6m"
   },
   "outputs": [],
   "source": [
    "# Get lists of images and their masks.\n",
    "\n",
    "image_id_list = list(df_img['Imagens_id'])\n",
    "mask_id_list = list(df_msk['mascaras_id'])\n",
    "\n",
    "# Create empty arrays\n",
    "\n",
    "X = np.zeros((len(image_id_list), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "\n",
    "y = np.zeros((len(mask_id_list), IMG_HEIGHT, IMG_WIDTH, 1), dtype=bool)\n",
    "\n",
    "X_test = np.zeros((NUM_TEST_IMAGES, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3533,
     "status": "ok",
     "timestamp": 1730730196047,
     "user": {
      "displayName": "Paulo Henrique",
      "userId": "13955216473685151557"
     },
     "user_tz": 180
    },
    "id": "pjS3s6l82TVA",
    "outputId": "e2faab2a-ecfe-4210-a560-d30ffb48928c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "# X imagens\n",
    "\n",
    "for i, imagens_id in enumerate(image_id_list):\n",
    "\n",
    "    path_image = 'Imagens1/' + imagens_id\n",
    "\n",
    "    # read the image using skimage\n",
    "    image = imread(path_image)\n",
    "\n",
    "    # resize the image\n",
    "    image = resize(image, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "\n",
    "    # use np.expand dims to add a channel axis so the shape becomes (IMG_HEIGHT, IMG_WIDTH, 1)\n",
    "    image = np.expand_dims(image, axis=-1)\n",
    "\n",
    "    # insert the image into X_train\n",
    "    X[i] = image\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1553,
     "status": "ok",
     "timestamp": 1730730200600,
     "user": {
      "displayName": "Paulo Henrique",
      "userId": "13955216473685151557"
     },
     "user_tz": 180
    },
    "id": "WWZ25FAh3Adv",
    "outputId": "d2a4a7bf-c564-497f-9aa3-473435a764ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "# Y classes (mascras)\n",
    "\n",
    "\n",
    "for i, mascara_id in enumerate(mask_id_list):\n",
    "\n",
    "    path_mask = 'mascaras1/' + mascara_id\n",
    "\n",
    "    # read the image using skimage\n",
    "    mask = imread(path_mask)\n",
    "    mask = (mask >= 250)\n",
    "\n",
    "    # resize the image\n",
    "    mask = resize(mask, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "\n",
    "    # use np.expand dims to add a channel axis so the shape becomes (IMG_HEIGHT, IMG_WIDTH, 1)\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "\n",
    "    # insert the image into Y_Train\n",
    "    y[i] = mask\n",
    "\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 957
    },
    "executionInfo": {
     "elapsed": 291,
     "status": "ok",
     "timestamp": 1730730204895,
     "user": {
      "displayName": "Paulo Henrique",
      "userId": "13955216473685151557"
     },
     "user_tz": 180
    },
    "id": "QDxtX9dp3hq5",
    "outputId": "fa512518-14ee-4455-c874-734936bf9f1e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sample image and Ground-Truth Label from dataset\n",
    "\n",
    "image_x = random.randint(0, len(X))\n",
    "plt.axis(\"off\")\n",
    "imshow(X[image_x])\n",
    "plt.show()\n",
    "plt.axis(\"off\")\n",
    "imshow(np.squeeze(y[image_x]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 266,
     "status": "ok",
     "timestamp": 1730730214057,
     "user": {
      "displayName": "Paulo Henrique",
      "userId": "13955216473685151557"
     },
     "user_tz": 180
    },
    "id": "BWbVI1GdfCD-"
   },
   "outputs": [],
   "source": [
    "from keras_unet_collection import models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fg3ZGzPdi3rV",
    "outputId": "3e1ebda1-34fe-478b-e3e7-314c9702e1d3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automated hyper-parameter determination is applied with the following details:\n",
      "----------\n",
      "\tNumber of convolution filters after each full-scale skip connection: filter_num_skip = [64, 64, 64]\n",
      "\tNumber of channels of full-scale aggregated feature maps: filter_num_aggregate = 256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 13:46:54.510731: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-04 13:46:54.678850: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-04 13:46:54.678919: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-04 13:46:54.682237: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-04 13:46:54.682299: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-04 13:46:54.682318: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-04 13:46:56.037811: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-04 13:46:56.037878: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-04 13:46:56.037884: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-11-04 13:46:56.037914: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-04 13:46:56.038470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9332 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "deep_supervision = True\n",
      "names of output tensors are listed as follows (\"sup0\" is the shallowest supervision layer;\n",
      "\"final\" is the final output layer):\n",
      "\n",
      "\tunet3plus_output_sup0_activation\n",
      "\tunet3plus_output_sup1_activation\n",
      "\tunet3plus_output_sup2_activation\n",
      "\tunet3plus_output_final_activation\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1730738823.724045  326860 service.cc:145] XLA service 0x4f216cd0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1730738823.724085  326860 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 4070, Compute Capability 8.9\n",
      "2024-11-04 13:47:03.998119: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-11-04 13:47:07.954838: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-11-04 13:47:17.864483: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 25.72GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-11-04 13:47:27.680287: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 24.45GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "I0000 00:00:1730738851.856581  326860 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 2.6369 - unet3plus_output_final_activation_accuracy: 0.6187 - unet3plus_output_final_activation_recall: 0.6536"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 13:47:36.267658: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 6.21GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-11-04 13:47:37.291775: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 24.58GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - loss: 2.5802 - unet3plus_output_final_activation_accuracy: 0.6516 - unet3plus_output_final_activation_recall: 0.6554 - val_loss: 3.2792 - val_unet3plus_output_final_activation_accuracy: 0.9505 - val_unet3plus_output_final_activation_recall: 0.9995\n",
      "Epoch 2/5\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 1.6363 - unet3plus_output_final_activation_accuracy: 0.9920 - unet3plus_output_final_activation_recall: 0.9932"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mbouzon/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/callbacks/model_checkpoint.py:206: UserWarning: Can save best model only with val_recall available, skipping.\n",
      "  self._save_model(epoch=epoch, batch=None, logs=logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 1.5814 - unet3plus_output_final_activation_accuracy: 0.9940 - unet3plus_output_final_activation_recall: 0.8751 - val_loss: 3.0655 - val_unet3plus_output_final_activation_accuracy: 0.9590 - val_unet3plus_output_final_activation_recall: 0.9989\n",
      "Epoch 3/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 1.4528 - unet3plus_output_final_activation_accuracy: 0.9971 - unet3plus_output_final_activation_recall: 0.9243 - val_loss: 4.5456 - val_unet3plus_output_final_activation_accuracy: 0.9729 - val_unet3plus_output_final_activation_recall: 0.9879\n",
      "Epoch 4/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 1.4073 - unet3plus_output_final_activation_accuracy: 0.9977 - unet3plus_output_final_activation_recall: 0.9210 - val_loss: 4.6915 - val_unet3plus_output_final_activation_accuracy: 0.9852 - val_unet3plus_output_final_activation_recall: 0.9868\n",
      "Epoch 5/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 1.3809 - unet3plus_output_final_activation_accuracy: 0.9980 - unet3plus_output_final_activation_recall: 0.9207 - val_loss: 4.2586 - val_unet3plus_output_final_activation_accuracy: 0.9894 - val_unet3plus_output_final_activation_recall: 0.9859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 13:47:42.269459: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 6.13GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-11-04 13:47:42.734901: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 24.30GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automated hyper-parameter determination is applied with the following details:\n",
      "----------\n",
      "\tNumber of convolution filters after each full-scale skip connection: filter_num_skip = [64, 64, 64]\n",
      "\tNumber of channels of full-scale aggregated feature maps: filter_num_aggregate = 256\n",
      "----------\n",
      "deep_supervision = True\n",
      "names of output tensors are listed as follows (\"sup0\" is the shallowest supervision layer;\n",
      "\"final\" is the final output layer):\n",
      "\n",
      "\tunet3plus_output_sup0_activation\n",
      "\tunet3plus_output_sup1_activation\n",
      "\tunet3plus_output_sup2_activation\n",
      "\tunet3plus_output_final_activation\n",
      "Epoch 1/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 499ms/step - loss: 2.6749 - unet3plus_output_final_activation_accuracy: 0.9357 - unet3plus_output_final_activation_recall: 0.4708 - val_loss: 4.2736 - val_unet3plus_output_final_activation_accuracy: 0.9644 - val_unet3plus_output_final_activation_recall: 0.9241\n",
      "Epoch 2/5\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 2.0700 - unet3plus_output_final_activation_accuracy: 0.9905 - unet3plus_output_final_activation_recall: 0.5243"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mbouzon/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/callbacks/model_checkpoint.py:206: UserWarning: Can save best model only with val_recall available, skipping.\n",
      "  self._save_model(epoch=epoch, batch=None, logs=logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 2.0509 - unet3plus_output_final_activation_accuracy: 0.9925 - unet3plus_output_final_activation_recall: 0.7657 - val_loss: 12.4431 - val_unet3plus_output_final_activation_accuracy: 0.7460 - val_unet3plus_output_final_activation_recall: 0.9935\n",
      "Epoch 3/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 2.0093 - unet3plus_output_final_activation_accuracy: 0.9963 - unet3plus_output_final_activation_recall: 0.8179 - val_loss: 11.7511 - val_unet3plus_output_final_activation_accuracy: 0.6505 - val_unet3plus_output_final_activation_recall: 0.9977\n",
      "Epoch 4/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 1.9914 - unet3plus_output_final_activation_accuracy: 0.9974 - unet3plus_output_final_activation_recall: 0.9188 - val_loss: 20.4937 - val_unet3plus_output_final_activation_accuracy: 0.6306 - val_unet3plus_output_final_activation_recall: 0.9954\n",
      "Automated hyper-parameter determination is applied with the following details:\n",
      "----------\n",
      "\tNumber of convolution filters after each full-scale skip connection: filter_num_skip = [64, 64, 64]\n",
      "\tNumber of channels of full-scale aggregated feature maps: filter_num_aggregate = 256\n",
      "----------\n",
      "deep_supervision = True\n",
      "names of output tensors are listed as follows (\"sup0\" is the shallowest supervision layer;\n",
      "\"final\" is the final output layer):\n",
      "\n",
      "\tunet3plus_output_sup0_activation\n",
      "\tunet3plus_output_sup1_activation\n",
      "\tunet3plus_output_sup2_activation\n",
      "\tunet3plus_output_final_activation\n",
      "Epoch 1/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 493ms/step - loss: 2.8011 - unet3plus_output_final_activation_accuracy: 0.6365 - unet3plus_output_final_activation_recall: 0.5478 - val_loss: 3.4835 - val_unet3plus_output_final_activation_accuracy: 0.9747 - val_unet3plus_output_final_activation_recall: 0.3486\n",
      "Epoch 2/5\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 2.1117 - unet3plus_output_final_activation_accuracy: 0.9948 - unet3plus_output_final_activation_recall: 0.6405"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mbouzon/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/callbacks/model_checkpoint.py:206: UserWarning: Can save best model only with val_recall available, skipping.\n",
      "  self._save_model(epoch=epoch, batch=None, logs=logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 2.0886 - unet3plus_output_final_activation_accuracy: 0.9949 - unet3plus_output_final_activation_recall: 0.7468 - val_loss: 3.8632 - val_unet3plus_output_final_activation_accuracy: 0.9787 - val_unet3plus_output_final_activation_recall: 0.2425\n",
      "Epoch 3/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 2.0361 - unet3plus_output_final_activation_accuracy: 0.9964 - unet3plus_output_final_activation_recall: 0.8376 - val_loss: 3.5679 - val_unet3plus_output_final_activation_accuracy: 0.9830 - val_unet3plus_output_final_activation_recall: 0.5606\n",
      "Epoch 4/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 2.0149 - unet3plus_output_final_activation_accuracy: 0.9976 - unet3plus_output_final_activation_recall: 0.8898 - val_loss: 3.5063 - val_unet3plus_output_final_activation_accuracy: 0.9870 - val_unet3plus_output_final_activation_recall: 0.6096\n",
      "Automated hyper-parameter determination is applied with the following details:\n",
      "----------\n",
      "\tNumber of convolution filters after each full-scale skip connection: filter_num_skip = [64, 64, 64]\n",
      "\tNumber of channels of full-scale aggregated feature maps: filter_num_aggregate = 256\n",
      "----------\n",
      "deep_supervision = True\n",
      "names of output tensors are listed as follows (\"sup0\" is the shallowest supervision layer;\n",
      "\"final\" is the final output layer):\n",
      "\n",
      "\tunet3plus_output_sup0_activation\n",
      "\tunet3plus_output_sup1_activation\n",
      "\tunet3plus_output_sup2_activation\n",
      "\tunet3plus_output_final_activation\n",
      "Epoch 1/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 498ms/step - loss: 3.0354 - unet3plus_output_final_activation_accuracy: 0.4125 - unet3plus_output_final_activation_recall: 0.6814 - val_loss: 6.0655 - val_unet3plus_output_final_activation_accuracy: 0.8226 - val_unet3plus_output_final_activation_recall: 0.9970\n",
      "Epoch 2/5\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 2.1295 - unet3plus_output_final_activation_accuracy: 0.9962 - unet3plus_output_final_activation_recall: 0.8703"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mbouzon/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/callbacks/model_checkpoint.py:206: UserWarning: Can save best model only with val_recall available, skipping.\n",
      "  self._save_model(epoch=epoch, batch=None, logs=logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 2.0980 - unet3plus_output_final_activation_accuracy: 0.9946 - unet3plus_output_final_activation_recall: 0.7797 - val_loss: 20.2217 - val_unet3plus_output_final_activation_accuracy: 0.5131 - val_unet3plus_output_final_activation_recall: 0.9989\n",
      "Epoch 3/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 2.0045 - unet3plus_output_final_activation_accuracy: 0.9967 - unet3plus_output_final_activation_recall: 0.8946 - val_loss: 15.4754 - val_unet3plus_output_final_activation_accuracy: 0.5899 - val_unet3plus_output_final_activation_recall: 0.9959\n",
      "Epoch 4/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 1.9803 - unet3plus_output_final_activation_accuracy: 0.9962 - unet3plus_output_final_activation_recall: 0.9501 - val_loss: 5.3000 - val_unet3plus_output_final_activation_accuracy: 0.9482 - val_unet3plus_output_final_activation_recall: 0.9838\n",
      "Epoch 5/5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 1.9617 - unet3plus_output_final_activation_accuracy: 0.9962 - unet3plus_output_final_activation_recall: 0.7977 - val_loss: 15.6794 - val_unet3plus_output_final_activation_accuracy: 0.5767 - val_unet3plus_output_final_activation_recall: 0.9957\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "jacc = []\n",
    "f1 = []\n",
    "prec = []\n",
    "rec = []\n",
    "\n",
    "for f in range(1, len(seeds)):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=split_size, random_state=seeds[f])\n",
    "\n",
    "    # Convert y_train and y_val to dictionaries to match the model's output format\n",
    "    y_train = {\n",
    "        'unet3plus_output_sup0_activation': y_train,\n",
    "        'unet3plus_output_sup1_activation': y_train,\n",
    "        'unet3plus_output_sup2_activation': y_train,\n",
    "        'unet3plus_output_final_activation': y_train\n",
    "    }\n",
    "    y_val = {\n",
    "        'unet3plus_output_sup0_activation': y_val,\n",
    "        'unet3plus_output_sup1_activation': y_val,\n",
    "        'unet3plus_output_sup2_activation': y_val,\n",
    "        'unet3plus_output_final_activation': y_val\n",
    "    }\n",
    "\n",
    "\n",
    "    model = models.unet_3plus_2d((128, 128, 1), n_labels=1, filter_num_down=[64, 128, 256, 512],\n",
    "                             filter_num_skip='auto', filter_num_aggregate='auto',\n",
    "                             stack_num_down=2, stack_num_up=1, activation='ReLU', output_activation='Sigmoid',\n",
    "                             batch_norm=True, pool='max', unpool=False, deep_supervision=True, name='unet3plus')\n",
    "\n",
    "    # Compile o modelo e especifique as métricas para cada saída, se necessário\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss={\n",
    "            'unet3plus_output_sup0_activation': 'binary_crossentropy',\n",
    "            'unet3plus_output_sup1_activation': 'binary_crossentropy',\n",
    "            'unet3plus_output_sup2_activation': 'binary_crossentropy',\n",
    "            'unet3plus_output_final_activation': 'binary_crossentropy'\n",
    "        },\n",
    "        metrics={'unet3plus_output_final_activation': ['accuracy', tf.keras.metrics.Recall(name='recall')]}\n",
    "    )\n",
    "\n",
    "\n",
    "    checkpoint_filepath = 'model1_' + str(f+1)+'fold.keras'\n",
    "    callbacks = [\n",
    "            tf.keras.callbacks.EarlyStopping(patience=3, monitor='val_loss'),\n",
    "            tf.keras.callbacks.TensorBoard(log_dir='logs'),\n",
    "            tf.keras.callbacks.ModelCheckpoint(\n",
    "                filepath=checkpoint_filepath,\n",
    "                save_weights_only=False,\n",
    "                monitor='val_recall',\n",
    "                mode='max',\n",
    "                save_best_only=True,\n",
    "                verbose=1)]\n",
    "\n",
    "    model.fit(X_train, y_train, validation_data=(X_val,y_val), batch_size=16, epochs=5, callbacks=callbacks)\n",
    "\n",
    "    for i in range(0, len(X_val)):\n",
    "        sample_image = X_val[i]\n",
    "        sample_mask = y_val['unet3plus_output_final_activation'][i].astype(np.uint8).flatten()\n",
    "        prediction = model.predict(sample_image[tf.newaxis, ...],verbose=0)[0]\n",
    "        predicted_mask = (prediction > 0.5).astype(np.uint8).flatten()\n",
    "\n",
    "        acc.append(accuracy_score(sample_mask, predicted_mask))\n",
    "        jacc.append(jaccard_score(sample_mask, predicted_mask))\n",
    "        f1.append(f1_score(sample_mask, predicted_mask))\n",
    "        prec.append(precision_score(sample_mask, predicted_mask))\n",
    "        rec.append(recall_score(sample_mask, predicted_mask))\n",
    "\n",
    "    del model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNKft9WeNqPn5XrrA/GysnH",
   "mount_file_id": "1JFzmoKpviAbfxS7nbbmTDC-AqW1e_-9n",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
